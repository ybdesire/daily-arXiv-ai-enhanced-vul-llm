{"id": "2512.03049", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.03049", "abs": "https://arxiv.org/abs/2512.03049", "authors": ["Kirk Roffi"], "title": "State Transition Block Diagram of the Generalized Maxwell Slip Friction Model", "comment": "6 pages, 4 figures", "summary": "Dynamic friction models (DFMs) encode essential information for the simulation and control of systems with friction. Traditionally, DFMs have been published with conceptual block diagrams, promoting clarity and reproducibility in simulation. However, modern DFMs have grown increasingly complex and block diagrams are now rarely presented, limiting accessibility. This letter presents a block diagram representation of the Generalized Maxwell Slip (GMS) friction model, an advanced multi-state DFM capable of simulating a wide range of nonlinear friction phenomena. The diagram can be implemented in the MATLAB-Simulink environment using a Stateflow chart or embedded if-else logic to represent the state transition criteria, but it is not limited to this platform. Closed-loop and open-loop simulations were conducted to verify that the block diagram reproduces non-drifting behavior and stick-slip friction, including benchmarking against the LuGre model. The proposed diagram improves accessibility to advanced dynamic friction models and provides the engineering community with a practical tool for the simulation and control of systems with friction.", "AI": {"tldr": "\u672c\u6587\u4e3a\u590d\u6742\u5e7f\u4e49\u9ea6\u514b\u65af\u97e6\u6ed1\u52a8\u6469\u64e6\u6a21\u578b\u63d0\u4f9b\u4e86\u76f4\u89c2\u7684\u6a21\u5757\u56fe\u8868\u793a\uff0c\u63d0\u9ad8\u53ef\u8bbf\u95ee\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u73b0\u4ee3\u52a8\u6001\u6469\u64e6\u6a21\u578b\u65e5\u76ca\u590d\u6742\uff0c\u4f46\u7f3a\u5c11\u6a21\u5757\u56fe\u8868\u793a\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u6e05\u6670\u5ea6\u548c\u53ef\u91cd\u590d\u6027\u3002", "method": "\u63d0\u51fa\u5e7f\u4e49\u9ea6\u514b\u65af\u97e6\u6ed1\u52a8\u6a21\u578b\u7684\u6a21\u5757\u56fe\uff0c\u53ef\u5728MATLAB-Simulink\u4e2d\u4f7f\u7528Stateflow\u56fe\u8868\u6216\u5d4c\u5165\u5f0f\u903b\u8f91\u5b9e\u73b0\u72b6\u6001\u8f6c\u6362\u3002", "result": "\u95ed\u73af\u548c\u5f00\u73af\u4eff\u771f\u9a8c\u8bc1\u4e86\u6a21\u5757\u56fe\u80fd\u51c6\u786e\u518d\u73b0\u65e0\u6f02\u79fb\u884c\u4e3a\u548c\u7c98\u6ed1\u6469\u64e6\u73b0\u8c61\uff0c\u6027\u80fd\u4e0eLuGre\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u5757\u56fe\u63d0\u9ad8\u4e86\u5148\u8fdb\u52a8\u6001\u6469\u64e6\u6a21\u578b\u7684\u53ef\u8bbf\u95ee\u6027\uff0c\u4e3a\u5de5\u7a0b\u793e\u533a\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6469\u64e6\u7cfb\u7edf\u4eff\u771f\u548c\u63a7\u5236\u5de5\u5177\u3002"}}
{"id": "2512.03839", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.03839", "abs": "https://arxiv.org/abs/2512.03839", "authors": ["Weilian Li", "Jun Zhu", "Saied Pirasteh", "Qing Zhu", "Yukun Guo", "Lan Luo", "Youness Dehbi"], "title": "A 3D virtual geographic environment for flood representation towards risk communication", "comment": null, "summary": "Risk communication seeks to develop a shared understanding of disaster among stakeholders, thereby amplifying public awareness and empowering them to respond more effectively to emergencies. However, existing studies have overemphasized specialized numerical modelling, making the professional output challenging to understand and use by non-research stakeholders. In this context, this article proposes a 3D virtual geographic environment for flood representation towards risk communication, which integrates flood modelling, parallel computation, and 3D representation in a pipeline. Finally, a section of the Rhine River in Bonn, Germany, is selected for experiment analysis. The experimental results show that the proposed approach is capable of flood modelling and 3D representation within a few hours, the parallel speedup ratio reached 6.45. The intuitive flood scene with 3D city models is beneficial for promoting flood risk communication and is particularly helpful for participants without direct experience of floods to understand its spatiotemporal process. It also can be embedded in the Geospatial Infrastructure Management Ecosystem (GeoIME) cloud application for intelligent flood systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6d2a\u6c34\u98ce\u9669\u6c9f\u901a\u76843D\u865a\u62df\u5730\u7406\u73af\u5883\uff0c\u96c6\u6210\u6d2a\u6c34\u5efa\u6a21\u3001\u5e76\u884c\u8ba1\u7b97\u548c3D\u53ef\u89c6\u5316\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u5728\u6570\u5c0f\u65f6\u5185\u5b8c\u6210\u6d2a\u6c34\u6a21\u62df\u548c3D\u8868\u793a\uff0c\u5e76\u884c\u52a0\u901f\u6bd4\u8fbe6.45\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u5ea6\u5f3a\u8c03\u4e13\u4e1a\u6570\u503c\u6a21\u578b\uff0c\u4f7f\u975e\u7814\u7a76\u5229\u76ca\u76f8\u5173\u8005\u96be\u4ee5\u7406\u89e3\u548c\u4f7f\u7528\u4e13\u4e1a\u8f93\u51fa\uff0c\u5f71\u54cd\u4e86\u98ce\u9669\u6c9f\u901a\u6548\u679c\u3002", "method": "\u5f00\u53d13D\u865a\u62df\u5730\u7406\u73af\u5883\u7ba1\u9053\uff0c\u96c6\u6210\u6d2a\u6c34\u5efa\u6a21\u3001\u5e76\u884c\u8ba1\u7b97\u548c3D\u8868\u793a\u6280\u672f\uff0c\u4ee5\u5fb7\u56fd\u6ce2\u6069\u83b1\u8335\u6cb3\u6bb5\u4e3a\u5b9e\u9a8c\u6848\u4f8b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u80fd\u5728\u51e0\u5c0f\u65f6\u5185\u5b8c\u6210\u6d2a\u6c34\u5efa\u6a21\u548c3D\u8868\u793a\uff0c\u5e76\u884c\u52a0\u901f\u6bd4\u8fbe\u52306.45\uff0c3D\u57ce\u5e02\u6a21\u578b\u80fd\u76f4\u89c2\u5c55\u793a\u6d2a\u6c34\u65f6\u7a7a\u8fc7\u7a0b\u3002", "conclusion": "\u8be53D\u6d2a\u6c34\u573a\u666f\u6709\u52a9\u4e8e\u4fc3\u8fdb\u6d2a\u6c34\u98ce\u9669\u6c9f\u901a\uff0c\u7279\u522b\u5e2e\u52a9\u65e0\u76f4\u63a5\u6d2a\u6c34\u7ecf\u9a8c\u7684\u53c2\u4e0e\u8005\u7406\u89e3\u65f6\u7a7a\u8fc7\u7a0b\uff0c\u53ef\u5d4c\u5165GeoIME\u4e91\u5e94\u7528\u6784\u5efa\u667a\u80fd\u6d2a\u6c34\u7cfb\u7edf\u3002"}}
{"id": "2512.03088", "categories": ["cs.CR", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.03088", "abs": "https://arxiv.org/abs/2512.03088", "authors": ["Giulio Caldarelli"], "title": "From Oracle Choice to Oracle Lock-In: An Exploratory Study on Blockchain Oracles Supplier Selection", "comment": "Not peer reviewed", "summary": "As data is an essential asset for any Web3 application, selecting an oracle is a critical decision for its success. To date, academic research has mainly focused on improving oracle technology and internal economics, while the drivers of oracle choice on the client side remain largely unexplored. This study fills this gap by gathering insights from leading Web3 protocols, uncovering their rationale for oracle selection and their preferences when deciding whether to outsource or internalize data request mechanisms. The collected data covers more than 55% of the DeFi market cap and is obtained exclusively by protocol executives, board members, or delegates. Insights support the view that protocol choices are tied to technological dependencies, where immutability of smart contracts amplifies lock-in, preventing agile switching among data providers. Furthermore, when viable third-party solutions exist, protocols overwhelmingly prefer outsourcing rather than building and maintaining internal oracle mechanisms.", "AI": {"tldr": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u5ba2\u6237\u7aef\u9884\u8a00\u673a\u9009\u62e9\u9a71\u52a8\u56e0\u7d20\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u901a\u8fc7\u6536\u96c6\u5934\u90e8Web3\u534f\u8bae\u7684\u89c1\u89e3\uff0c\u53d1\u73b0\u534f\u8bae\u9009\u62e9\u4e0e\u6280\u672f\u4f9d\u8d56\u6027\u76f8\u5173\uff0c\u4e14\u5728\u53ef\u884c\u7b2c\u4e09\u65b9\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u65f6\u66f4\u503e\u5411\u4e8e\u5916\u5305\u3002", "motivation": "\u9884\u8a00\u673a\u9009\u62e9\u5bf9Web3\u5e94\u7528\u6210\u529f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5b66\u672f\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u9884\u8a00\u673a\u6280\u672f\u548c\u5185\u90e8\u7ecf\u6d4e\u6539\u8fdb\uff0c\u5ba2\u6237\u7aef\u9884\u8a00\u673a\u9009\u62e9\u7684\u9a71\u52a8\u56e0\u7d20\u4ecd\u672a\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u72ec\u5bb6\u8bbf\u95ee\u534f\u8bae\u9ad8\u7ba1\u3001\u8463\u4e8b\u4f1a\u6210\u5458\u6216\u4ee3\u8868\uff0c\u6536\u96c6\u5360DeFi\u5e02\u503c55%\u4ee5\u4e0a\u7684\u5934\u90e8Web3\u534f\u8bae\u7684\u89c1\u89e3\uff0c\u5206\u6790\u5176\u9884\u8a00\u673a\u9009\u62e9\u7684\u7406\u7531\u548c\u5916\u5305/\u5185\u90e8\u5316\u504f\u597d\u3002", "result": "\u6570\u636e\u663e\u793a\u534f\u8bae\u9009\u62e9\u4e0e\u6280\u672f\u4f9d\u8d56\u6027\u76f8\u5173\uff0c\u667a\u80fd\u5408\u7ea6\u7684\u4e0d\u53ef\u53d8\u6027\u52a0\u5267\u4e86\u9501\u5b9a\u6548\u5e94\uff0c\u963b\u788d\u4e86\u6570\u636e\u63d0\u4f9b\u8005\u4e4b\u95f4\u7684\u7075\u6d3b\u5207\u6362\u3002\u6b64\u5916\uff0c\u5f53\u53ef\u884c\u7b2c\u4e09\u65b9\u89e3\u51b3\u65b9\u6848\u5b58\u5728\u65f6\uff0c\u534f\u8bae\u5f3a\u70c8\u503e\u5411\u4e8e\u5916\u5305\u800c\u975e\u81ea\u5efa\u548c\u7ef4\u62a4\u5185\u90e8\u9884\u8a00\u673a\u673a\u5236\u3002", "conclusion": "\u9884\u8a00\u673a\u9009\u62e9\u53d7\u6280\u672f\u4f9d\u8d56\u6027\u548c\u9501\u5b9a\u6548\u5e94\u5f71\u54cd\uff0c\u534f\u8bae\u5728\u53ef\u884c\u5916\u5305\u65b9\u6848\u5b58\u5728\u65f6\u504f\u597d\u5916\u5305\uff0c\u63ed\u793a\u4e86Web3\u5e94\u7528\u4e2d\u6570\u636e\u83b7\u53d6\u7b56\u7565\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\u3002"}}
{"id": "2512.03072", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.03072", "abs": "https://arxiv.org/abs/2512.03072", "authors": ["Hu Keyi"], "title": "Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI", "comment": null, "summary": "Current AI paradigms, as \"architects of experience,\" face fundamental challenges in explainability and value alignment. This paper introduces \"Weight-Calculatism,\" a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7b2c\u4e00\u6027\u539f\u7406\u7684Weight-Calculatism\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u903b\u8f91\u539f\u5b50\u548c\u57fa\u672c\u64cd\u4f5c\u5b9e\u73b0\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u6a21\u578b\uff0c\u4e3aAGI\u63d0\u4f9b\u4e86\u900f\u660e\u4e14\u53ef\u9a8c\u8bc1\u7684\u57fa\u7840\u3002", "motivation": "\u5f53\u524dAI\u8303\u5f0f\u5728\u53ef\u89e3\u91ca\u6027\u548c\u4ef7\u503c\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8ba4\u77e5\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u67b6\u6784\u5c06\u8ba4\u77e5\u89e3\u6784\u4e3a\u4e0d\u53ef\u5206\u5272\u7684\u903b\u8f91\u539f\u5b50\u548c\u4e24\u4e2a\u57fa\u672c\u64cd\u4f5c\uff08\u6307\u5411\u548c\u6bd4\u8f83\uff09\uff0c\u5e76\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u6743\u91cd\u8ba1\u7b97\u6a21\u578b\uff08\u6743\u91cd=\u6536\u76ca*\u6982\u7387\uff09\u5f62\u5f0f\u5316\u51b3\u7b56\u8fc7\u7a0b\uff0c\u6240\u6709\u503c\u53ef\u8ffd\u6eaf\u81f3\u53ef\u5ba1\u8ba1\u7684\u521d\u59cb\u6743\u91cd\u3002", "result": "\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u524d\u6240\u672a\u6709\u7684\u900f\u660e\u6027\u3001\u4eba\u7c7b\u7c7b\u4f3c\u63a8\u7406\u548c\u5728\u65b0\u573a\u666f\u4e2d\u7684\u7a33\u5065\u5b66\u4e60\uff0c\u901a\u8fc7\u57fa\u4e8e\u56fe\u7b97\u6cd5\u7684\u8ba1\u7b97\u5f15\u64ce\u548c\u5168\u5c40\u5de5\u4f5c\u6d41\u8fdb\u884c\u4e86\u521d\u6b65\u9a8c\u8bc1\u3002", "conclusion": "Weight-Calculatism\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u548c\u5bf9\u9f50\u7684AGI\u5960\u5b9a\u4e86\u5b9e\u7528\u548c\u7406\u8bba\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u5b9e\u73b0\u901a\u7528\u4eba\u5de5\u667a\u80fd\u7684\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2512.03421", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.03421", "abs": "https://arxiv.org/abs/2512.03421", "authors": ["Hexiang Xu", "Hengyuan Liu", "Yonghao Wu", "Xiaolan Kang", "Xiang Chen", "Yong Liu"], "title": "Exploring the Potential and Limitations of Large Language Models for Novice Program Fault Localization", "comment": "The paper has been accepted for publication in The Journal of Systems & Software", "summary": "Novice programmers often face challenges in fault localization due to their limited experience and understanding of programming syntax and logic. Traditional methods like Spectrum-Based Fault Localization (SBFL) and Mutation-Based Fault Localization (MBFL) help identify faults but often lack the ability to understand code context, making them less effective for beginners. In recent years, Large Language Models (LLMs) have shown promise in overcoming these limitations by utilizing their ability to understand program syntax and semantics. LLM-based fault localization provides more accurate and context-aware results than traditional techniques. This study evaluates six closed-source and seven open-source LLMs using the Codeflaws, Condefects, and BugT datasets, with BugT being a newly constructed dataset specifically designed to mitigate data leakage concerns. Advanced models with reasoning capabilities, such as OpenAI o3 and DeepSeekR1, achieve superior accuracy with minimal reliance on prompt engineering. In contrast, models without reasoning capabilities, like GPT-4, require carefully designed prompts to maintain performance. While LLMs perform well in simple fault localization, their accuracy decreases as problem difficulty increases, though top models maintain robust performance in the BugT dataset. Over-reasoning is another challenge, where some models generate excessive explanations that hinder fault localization clarity. Additionally, the computational cost of deploying LLMs remains a significant barrier for real-time debugging. LLM's explanations demonstrate significant value for novice programmer assistance, with one-year experience participants consistently rating them highly. Our findings demonstrate the potential of LLMs to improve debugging efficiency while stressing the need for further refinement in their reasoning and computational efficiency for practical adoption.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u521d\u5b66\u8005\u8c03\u8bd5\u4e2d\u7684\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\uff0c\u53d1\u73b0\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684\u5148\u8fdb\u6a21\u578b\uff08\u5982OpenAI o3\u3001DeepSeekR1\uff09\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u8fc7\u5ea6\u63a8\u7406\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u6311\u6218\u3002", "motivation": "\u65b0\u624b\u7a0b\u5e8f\u5458\u56e0\u7ecf\u9a8c\u4e0d\u8db3\u5728\u6545\u969c\u5b9a\u4f4d\u4e0a\u9762\u4e34\u56f0\u96be\uff0c\u4f20\u7edf\u65b9\u6cd5\uff08\u5982SBFL\u3001MBFL\uff09\u7f3a\u4e4f\u4ee3\u7801\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u800cLLMs\u80fd\u901a\u8fc7\u7406\u89e3\u7a0b\u5e8f\u8bed\u6cd5\u8bed\u4e49\u6765\u7a81\u7834\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u4f7f\u7528Codeflaws\u3001Condefects\u548c\u65b0\u5efa\u7684BugT\u6570\u636e\u96c6\uff0c\u8bc4\u4f306\u4e2a\u95ed\u6e90\u548c7\u4e2a\u5f00\u6e90LLMs\uff0c\u6bd4\u8f83\u5176\u5728\u4e0d\u540c\u96be\u5ea6\u6545\u969c\u5b9a\u4f4d\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u63d0\u793a\u5de5\u7a0b\u548c\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5177\u5907\u63a8\u7406\u80fd\u529b\u7684LLMs\uff08\u5982o3\u3001DeepSeekR1\uff09\u5728BugT\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u51c6\u786e\u7387\u6700\u9ad8\uff1b\u65e0\u63a8\u7406\u80fd\u529b\u7684\u6a21\u578b\uff08\u5982GPT-4\uff09\u9700\u7cbe\u7ec6\u63d0\u793a\u8bbe\u8ba1\uff1b\u95ee\u9898\u96be\u5ea6\u589e\u52a0\u65f6LLMs\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u4f46\u9876\u7ea7\u6a21\u578b\u4ecd\u8868\u73b0\u826f\u597d\uff1b\u65b0\u624b\u53c2\u4e0e\u8005\u9ad8\u5ea6\u8bc4\u4ef7LLMs\u7684\u89e3\u91ca\u4ef7\u503c\u3002", "conclusion": "LLMs\u6709\u6f5c\u529b\u63d0\u5347\u8c03\u8bd5\u6548\u7387\uff0c\u5c24\u5176\u9002\u5408\u8f85\u52a9\u65b0\u624b\u7a0b\u5e8f\u5458\uff0c\u4f46\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u63a8\u7406\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u4ee5\u6295\u5165\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.03272", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03272", "abs": "https://arxiv.org/abs/2512.03272", "authors": ["Zhiyuan He", "Dingmin Wang"], "title": "When Do Symbolic Solvers Enhance Reasoning in Large Language Models?", "comment": null, "summary": "Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models \"overthink\" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4f20\u7edf\u957f\u601d\u7ef4\u94fe(CoT)\u4f55\u65f6\u80fd\u88ab\u7b26\u53f7\u6c42\u89e3\u5668\u589e\u5f3a\uff0c\u53d1\u73b0\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u4ec5\u5728\u95ee\u9898\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u5206\u641c\u7d22\u7a7a\u95f4\u65f6\u6709\u6548\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u751f\u6210\u957f\u601d\u7ef4\u94fe\u4f1a\u4ea7\u751f\u5927\u91cftoken\u5f00\u9500\uff0c\u53ef\u80fd\u5bfc\u81f4\"\u8fc7\u5ea6\u601d\u8003\"\u751a\u81f3\u9519\u8bef\u7b54\u6848\uff0c\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002", "method": "\u5229\u7528LLM\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c06\u63a8\u7406\u4efb\u52a1\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7136\u540e\u7528\u7b26\u53f7\u6c42\u89e3\u5668\u89e3\u51b3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u5728\u9700\u8981\u6709\u9650\u9690\u5f0f\u63a8\u7406\u4f46\u6d89\u53ca\u5145\u5206\u641c\u7d22\u7a7a\u95f4\u7684\u95ee\u9898\u4e0a\u6709\u6548\uff0c\u5c24\u5176\u80fd\u663e\u8457\u63d0\u5347LLM\u5728\u9700\u8981\u91cd\u590d\u56de\u6eaf\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u5f53\u63d0\u4f9b\u58f0\u660e\u6027\u793a\u4f8b\u65f6\uff0c\u5373\u4f7f\u662fCodeLlama-13B\u4e5f\u80fd\u5728\u56f0\u96be\u7684\u6591\u9a6c\u8c1c\u9898\u4e0a\u8d85\u8d8aGPT-4o\uff0c\u663e\u793a\u4e86\u7b26\u53f7\u6c42\u89e3\u5668\u96c6\u6210\u65b9\u6cd5\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.03815", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.03815", "abs": "https://arxiv.org/abs/2512.03815", "authors": ["Shayan Ghasemnezhad", "Samarth KaPatel", "Sofia Nikiforova", "Giacinto Paolo Saggese", "Paul Smith", "Heanh Sok"], "title": "Runnable Directories: The Solution to the Monorepo vs. Multi-repo Debate", "comment": null, "summary": "Modern software systems increasingly strain traditional codebase organization strategies. Monorepos offer consistency but often suffer from scalability issues and tooling complexity, while multi-repos provide modularity at the cost of coordination and dependency management challenges. As an answer to this trade-off, we present the Causify Dev system, a hybrid approach that integrates key benefits of both. Its central concept is the runnable directory -- a self-contained, independently executable unit with its own development, testing, and deployment lifecycles. Backed by a unified thin environment, shared helper utilities, and containerized Docker-based workflows, runnable directories enable consistent setups, isolated dependencies, and efficient CI/CD processes. The Causify Dev approach provides a practical middle ground between monorepo and multi-repo strategies, improving reliability and maintainability for growing, complex codebases.", "AI": {"tldr": "Causify Dev\u7cfb\u7edf\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u5355\u4f53\u4ed3\u5e93\u548c\u591a\u4ed3\u5e93\u7684\u4f18\u70b9\uff0c\u901a\u8fc7\u53ef\u8fd0\u884c\u76ee\u5f55\u5b9e\u73b0\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u5e93\u53ef\u7ef4\u62a4\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u5e93\u7ec4\u7ec7\u7b56\u7565\u9762\u4e34\u6269\u5c55\u6027\u95ee\u9898\u2014\u2014\u5355\u4f53\u4ed3\u5e93\u5b58\u5728\u5de5\u5177\u590d\u6742\u6027\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u591a\u4ed3\u5e93\u5219\u5728\u534f\u8c03\u548c\u4f9d\u8d56\u7ba1\u7406\u65b9\u9762\u5b58\u5728\u56f0\u96be\u3002", "method": "\u5f15\u5165\u53ef\u8fd0\u884c\u76ee\u5f55\u4f5c\u4e3a\u72ec\u7acb\u53ef\u6267\u884c\u5355\u5143\uff0c\u6bcf\u4e2a\u76ee\u5f55\u62e5\u6709\u5b8c\u6574\u7684\u5f00\u53d1\u3001\u6d4b\u8bd5\u548c\u90e8\u7f72\u751f\u547d\u5468\u671f\uff0c\u5e76\u57fa\u4e8e\u7edf\u4e00\u73af\u5883\u3001\u5171\u4eab\u5de5\u5177\u548c\u5bb9\u5668\u5316Docker\u5de5\u4f5c\u6d41\u5b9e\u73b0\u9694\u79bb\u4f9d\u8d56\u548c\u9ad8\u6548CI/CD\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e00\u81f4\u6027\u548c\u6a21\u5757\u5316\u4e4b\u95f4\u53d6\u5f97\u4e86\u5e73\u8861\uff0c\u63d0\u5347\u4e86\u590d\u6742\u4ee3\u7801\u5e93\u7684\u53ef\u9760\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "conclusion": "Causify Dev\u4e3a\u4e0d\u65ad\u589e\u957f\u7684\u5927\u578b\u4ee3\u7801\u5e93\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u4e2d\u95f4\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4ee3\u7801\u7ec4\u7ec7\u7b56\u7565\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.03097", "categories": ["cs.CR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03097", "abs": "https://arxiv.org/abs/2512.03097", "authors": ["Adeela Bashir", "The Anh han", "Zia Ush Shamszaman"], "title": "Many-to-One Adversarial Consensus: Exposing Multi-Agent Collusion Risks in AI-Based Healthcare", "comment": "7 pages Conference level paper", "summary": "The integration of large language models (LLMs) into healthcare IoT systems promises faster decisions and improved medical support. LLMs are also deployed as multi-agent teams to assist AI doctors by debating, voting, or advising on decisions. However, when multiple assistant agents interact, coordinated adversaries can collude to create false consensus, pushing an AI doctor toward harmful prescriptions. We develop an experimental framework with scripted and unscripted doctor agents, adversarial assistants, and a verifier agent that checks decisions against clinical guidelines. Using 50 representative clinical questions, we find that collusion drives the Attack Success Rate (ASR) and Harmful Recommendation Rates (HRR) up to 100% in unprotected systems. In contrast, the verifier agent restores 100% accuracy by blocking adversarial consensus. This work provides the first systematic evidence of collusion risk in AI healthcare and demonstrates a practical, lightweight defence that ensures guideline fidelity.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u533b\u7597\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u90e8\u7f72\u7684LLM\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5b58\u5728\u4e32\u8c0b\u98ce\u9669\uff0c\u4f1a\u5bfc\u81f4\u6709\u5bb3\u533b\u7597\u5efa\u8bae\uff0c\u800c\u9a8c\u8bc1\u667a\u80fd\u4f53\u80fd\u6709\u6548\u9632\u5fa1\u8fd9\u79cd\u653b\u51fb\u3002", "motivation": "\u867d\u7136LLM\u96c6\u6210\u5230\u533b\u7597\u7269\u8054\u7f51\u7cfb\u7edf\u80fd\u63d0\u5347\u51b3\u7b56\u6548\u7387\uff0c\u4f46\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65f6\u5b58\u5728\u5bf9\u6297\u6027\u4e32\u8c0b\u98ce\u9669\uff0c\u53ef\u80fd\u5bfc\u81f4AI\u533b\u751f\u505a\u51fa\u6709\u5bb3\u5904\u65b9\u3002", "method": "\u5f00\u53d1\u5b9e\u9a8c\u6846\u67b6\uff0c\u5305\u542b\u811a\u672c\u548c\u975e\u811a\u672c\u533b\u751f\u667a\u80fd\u4f53\u3001\u5bf9\u6297\u6027\u52a9\u624b\u667a\u80fd\u4f53\u53ca\u9a8c\u8bc1\u667a\u80fd\u4f53\uff0c\u4f7f\u752850\u4e2a\u5178\u578b\u4e34\u5e8a\u95ee\u9898\u6d4b\u8bd5\u7cfb\u7edf\u3002", "result": "\u65e0\u4fdd\u62a4\u7cfb\u7edf\u4e2d\u4e32\u8c0b\u653b\u51fb\u4f7f\u653b\u51fb\u6210\u529f\u7387\u548c\u6709\u5bb3\u5efa\u8bae\u7387\u9ad8\u8fbe100%\uff1b\u9a8c\u8bc1\u667a\u80fd\u4f53\u80fd\u62e6\u622a\u5bf9\u6297\u6027\u5171\u8bc6\uff0c\u6062\u590d100%\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u63ed\u793aAI\u533b\u7597\u4e2d\u7684\u4e32\u8c0b\u98ce\u9669\uff0c\u5e76\u63d0\u51fa\u8f7b\u91cf\u7ea7\u9632\u5fa1\u65b9\u6848\u786e\u4fdd\u4e34\u5e8a\u6307\u5357\u4f9d\u4ece\u6027\u3002"}}
{"id": "2512.03293", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.03293", "abs": "https://arxiv.org/abs/2512.03293", "authors": ["Filippo Torresan", "Ryota Kanai", "Manuel Baltieri"], "title": "Prior preferences in active inference agents: soft, hard, and goal shaping", "comment": "41 pages, 23 figures", "summary": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u56db\u79cd\u5b9a\u4e49\u504f\u597d\u5206\u5e03\u7684\u65b9\u5f0f\uff08\u786c\u76ee\u6807/\u8f6f\u76ee\u6807\u3001\u6709\u65e0\u76ee\u6807\u5851\u9020\uff09\uff0c\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u53d1\u73b0\u76ee\u6807\u5851\u9020\u80fd\u63d0\u5347\u6027\u80fd\u4f46\u4f1a\u727a\u7272\u73af\u5883\u63a2\u7d22\u3002", "motivation": "\u4e3b\u52a8\u63a8\u7406\u4e2d\u504f\u597d\u5206\u5e03\u7684\u8bbe\u5b9a\u65b9\u5f0f\u53ca\u5176\u5bf9\u63a8\u7406\u548c\u5b66\u4e60\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u8bbe\u8ba1\u4e86\u56db\u79cd\u504f\u597d\u5206\u5e03\u5b9a\u4e49\u65b9\u5f0f\uff08\u786c/\u8f6f\u76ee\u6807 \u00d7 \u6709\u65e0\u76ee\u6807\u5851\u9020\uff09\uff0c\u5728\u7f51\u683c\u4e16\u754c\u5bfc\u822a\u4efb\u52a1\u4e2d\u6bd4\u8f83\u56db\u7c7b\u667a\u80fd\u4f53\u7684\u8868\u73b0\u3002", "result": "\u76ee\u6807\u5851\u9020\u80fd\u6574\u4f53\u63d0\u5347\u6027\u80fd\uff08\u4fc3\u8fdb\u5229\u7528\uff09\uff0c\u4f46\u4f1a\u524a\u5f31\u5bf9\u73af\u5883\u8f6c\u79fb\u52a8\u6001\u7684\u5b66\u4e60\uff08\u963b\u788d\u63a2\u7d22\uff09\u3002", "conclusion": "\u504f\u597d\u5206\u5e03\u7684\u8bbe\u5b9a\u9700\u8981\u5728\u5229\u7528\u548c\u63a2\u7d22\u4e4b\u95f4\u6743\u8861\uff0c\u76ee\u6807\u5851\u9020\u867d\u63d0\u5347\u6027\u80fd\u5374\u4f1a\u9650\u5236\u63a2\u7d22\u80fd\u529b\u3002"}}
{"id": "2512.03868", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03868", "abs": "https://arxiv.org/abs/2512.03868", "authors": ["Shree Hari Bittugondanahalli Indra Kumar", "Lilia Rodrigues Sampaio", "Andr\u00e9 Martin", "Andrey Brito", "Christof Fetzer"], "title": "A Comprehensive Study on the Impact of Vulnerable Dependencies on Open-Source Software", "comment": null, "summary": "Open-source libraries are widely used by software developers to speed up the development of products, however, they can introduce security vulnerabilities, leading to incidents like Log4Shell. With the expanding usage of open-source libraries, it becomes even more imperative to comprehend and address these dependency vulnerabilities. The use of Software Composition Analysis (SCA) tools does greatly help here as they provide a deep insight on what dependencies are used in a project, enhancing the security and integrity in the software supply chain. In order to learn how wide spread vulnerabilities are and how quickly they are being fixed, we conducted a study on over 1k open-source software projects with about 50k releases comprising several languages such as Java, Python, Rust, Go, Ruby, PHP, and JavaScript. Our objective is to investigate the severity, persistence, and distribution of these vulnerabilities, as well as their correlation with project metrics such as team and contributors size, activity and release cycles. In order to perform such analysis, we crawled over 1k projects from github including their version history ranging from 2013 to 2023 using VODA, our SCA tool. Using our approach, we can provide information such as library versions, dependency depth, and known vulnerabilities, and how they evolved over the software development cycle. Being larger and more diverse than datasets used in earlier works and studies, ours provides better insights and generalizability of the gained results. The data collected answers several research questions about the dependency depth and the average time a vulnerability persists. Among other findings, we observed that for most programming languages, vulnerable dependencies are transitive, and a critical vulnerability persists in average for over a year before being fixed.", "AI": {"tldr": "\u901a\u8fc7\u5bf91000\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u7684\u5206\u6790\u53d1\u73b0\uff0c\u5f00\u6e90\u5e93\u7684\u5b89\u5168\u6f0f\u6d1e\u666e\u904d\u5b58\u5728\u4e14\u591a\u4e3a\u4f20\u9012\u6027\u4f9d\u8d56\uff0c\u5173\u952e\u6f0f\u6d1e\u5e73\u5747\u5b58\u5728\u8d85\u8fc7\u4e00\u5e74\u624d\u88ab\u4fee\u590d\u3002\u8f6f\u4ef6\u6210\u5206\u5206\u6790\u5de5\u5177\u80fd\u6709\u6548\u8bc6\u522b\u4f9d\u8d56\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u5e93\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5176\u5f15\u5165\u7684\u5b89\u5168\u6f0f\u6d1e\u98ce\u9669\u65e5\u76ca\u7a81\u51fa\uff08\u5982Log4Shell\u4e8b\u4ef6\uff09\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7814\u7a76\u6f0f\u6d1e\u7684\u5206\u5e03\u3001\u6301\u7eed\u65f6\u95f4\u548c\u4fee\u590d\u60c5\u51b5\u3002", "method": "\u4f7f\u7528VODA\u5de5\u5177\u722c\u53d62013-2023\u5e74\u95f41000\u591a\u4e2aGitHub\u9879\u76ee\u7684\u7248\u672c\u5386\u53f2\uff08\u542b\u7ea65\u4e07\u4e2a\u53d1\u884c\u7248\uff09\uff0c\u6db5\u76d6Java\u3001Python\u7b49\u591a\u8bed\u8a00\uff0c\u5206\u6790\u4f9d\u8d56\u7248\u672c\u3001\u6df1\u5ea6\u548c\u5df2\u77e5\u6f0f\u6d1e\u7684\u6f14\u53d8\u3002", "result": "\u6570\u636e\u96c6\u8f83\u524d\u4eba\u7814\u7a76\u66f4\u5927\u591a\u6837\uff0c\u53d1\u73b0\u591a\u6570\u8bed\u8a00\u7684\u6f0f\u6d1e\u4f9d\u8d56\u662f\u4f20\u9012\u6027\u7684\uff0c\u5173\u952e\u6f0f\u6d1e\u5e73\u5747\u6301\u7eed\u8d85\u4e00\u5e74\uff1b\u6f0f\u6d1e\u6301\u7eed\u65f6\u95f4\u548c\u9879\u76ee\u6307\u6807\uff08\u5982\u56e2\u961f\u89c4\u6a21\u3001\u53d1\u5e03\u5468\u671f\uff09\u5b58\u5728\u76f8\u5173\u6027\u3002", "conclusion": "\u5f00\u6e90\u9879\u76ee\u9700\u66f4\u79ef\u6781\u4e3b\u52a8\u5730\u7ba1\u7406\u4f9d\u8d56\u6f0f\u6d1e\uff0c\u8f6f\u4ef6\u6210\u5206\u5206\u6790\u5de5\u5177\u5bf9\u63d0\u5347\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u5efa\u8bae\u5f00\u53d1\u8005\u5b9a\u671f\u626b\u63cf\u548c\u66f4\u65b0\u4f9d\u8d56\u3002"}}
{"id": "2512.03100", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03100", "abs": "https://arxiv.org/abs/2512.03100", "authors": ["Haowei Fu", "Bo Ni", "Han Xu", "Kunpeng Liu", "Dan Lin", "Tyler Derr"], "title": "Ensemble Privacy Defense for Knowledge-Intensive LLMs against Membership Inference Attacks", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) and Supervised Finetuning (SFT) have become the predominant paradigms for equipping Large Language Models (LLMs) with external knowledge for diverse, knowledge-intensive tasks. However, while such knowledge injection improves performance, it also exposes new attack surfaces. Membership Inference Attacks (MIAs), which aim to determine whether a given data sample was included in a model's training set, pose serious threats to privacy and trust in sensitive domains. To this end, we first systematically evaluate the vulnerability of RAG- and SFT-based LLMs to various MIAs. Then, to address the privacy risk, we further introduce a novel, model-agnostic defense framework, Ensemble Privacy Defense (EPD), which aggregates and evaluates the outputs of a knowledge-injected LLM, a base LLM, and a dedicated judge model to enhance resistance against MIAs. Comprehensive experiments show that, on average, EPD reduces MIA success by up to 27.8\\% for SFT and 526.3\\% for RAG compared to inference-time baseline, while maintaining answer quality.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86RAG\u548cSFT\u589e\u5f3a\u7684LLM\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u96c6\u6210\u9690\u79c1\u9632\u5fa1\u6846\u67b6EPD\u6765\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u8d28\u91cf\u3002", "motivation": "\u968f\u7740RAG\u548cSFT\u6210\u4e3aLLM\u83b7\u53d6\u5916\u90e8\u77e5\u8bc6\u7684\u4e3b\u6d41\u65b9\u6cd5\uff0c\u77e5\u8bc6\u6ce8\u5165\u5728\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\uff0c\u7279\u522b\u662f\u6210\u5458\u63a8\u7406\u653b\u51fb\u5bf9\u9690\u79c1\u548c\u4fe1\u4efb\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u8bc4\u4f30RAG\u548cSFT\u57faLLM\u5bf9\u591a\u79cdMIA\u7684\u8106\u5f31\u6027\uff1b\u7136\u540e\u63d0\u51fa\u6a21\u578b\u65e0\u5173\u7684\u9632\u5fa1\u6846\u67b6EPD\uff0c\u901a\u8fc7\u805a\u5408\u77e5\u8bc6\u6ce8\u5165LLM\u3001\u57fa\u7840LLM\u548c\u4e13\u7528\u8bc4\u5224\u6a21\u578b\u7684\u8f93\u51fa\u6765\u589e\u5f3a\u5bf9MIA\u7684\u62b5\u6297\u3002", "result": "\u7efc\u5408\u5b9e\u9a8c\u8868\u660e\uff0cEPD\u5e73\u5747\u5c06SFT\u7684MIA\u6210\u529f\u7387\u964d\u4f4e\u9ad8\u8fbe27.8%\uff0cRAG\u7684\u964d\u4f4e526.3%\uff08\u76f8\u6bd4\u63a8\u7406\u65f6\u57fa\u7ebf\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u56de\u7b54\u8d28\u91cf\u3002", "conclusion": "EPD\u6846\u67b6\u80fd\u6709\u6548\u9632\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u663e\u8457\u964d\u4f4e\u9690\u79c1\u98ce\u9669\uff0c\u4e3a\u654f\u611f\u9886\u57df\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002"}}
{"id": "2512.03318", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03318", "abs": "https://arxiv.org/abs/2512.03318", "authors": ["Chandler Smith", "Marwa Abdulhai", "Manfred Diaz", "Marko Tesic", "Rakshit S. Trivedi", "Alexander Sasha Vezhnevets", "Lewis Hammond", "Jesse Clifton", "Minsuk Chang", "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n", "John P. Agapiou", "Jayd Matyas", "Danny Karmon", "Akash Kundu", "Aliaksei Korshuk", "Ananya Ananya", "Arrasy Rahman", "Avinaash Anand Kulandaivel", "Bain McHale", "Beining Zhang", "Buyantuev Alexander", "Carlos Saith Rodriguez Rojas", "Caroline Wang", "Chetan Talele", "Chenao Liu", "Chichen Lin", "Diana Riazi", "Di Yang Shi", "Emanuel Tewolde", "Elizaveta Tennant", "Fangwei Zhong", "Fuyang Cui", "Gang Zhao", "Gema Parre\u00f1o Piqueras", "Hyeonggeun Yun", "Ilya Makarov", "Jiaxun Cui", "Jebish Purbey", "Jim Dilkes", "Jord Nguyen", "Lingyun Xiao", "Luis Felipe Giraldo", "Manuela Chacon-Chamorro", "Manuel Sebastian Rios Beltran", "Marta Emili Garc\u00eda Segura", "Mengmeng Wang", "Mogtaba Alim", "Nicanor Quijano", "Nico Schiavone", "Olivia Macmillan-Scott", "Oswaldo Pe\u00f1a", "Peter Stone", "Ram Mohan Rao Kadiyala", "Rolando Fernandez", "Ruben Manrique", "Sunjia Lu", "Sheila A. McIlraith", "Shamika Dhuri", "Shuqing Shi", "Siddhant Gupta", "Sneheel Sarangi", "Sriram Ganapathi Subramanian", "Taehun Cha", "Toryn Q. Klassen", "Wenming Tu", "Weijian Fan", "Wu Ruiyang", "Xue Feng", "Yali Du", "Yang Liu", "Yiding Wang", "Yipeng Kang", "Yoonchang Sung", "Yuxuan Chen", "Zhaowei Zhang", "Zhihan Wang", "Zhiqiang Wu", "Ziang Chen", "Zilong Zheng", "Zixia Jia", "Ziyan Wang", "Dylan Hadfield-Menell", "Natasha Jaques", "Tim Baarslag", "Jose Hernandez-Orallo", "Joel Z. Leibo"], "title": "Evaluating Generalization Capabilities of LLM-Based Agents in Mixed-Motive Scenarios Using Concordia", "comment": "Published at NeurIPS Datasets and Benchmarks 2025, 10 pages", "summary": "Large Language Model (LLM) agents have demonstrated impressive capabilities for social interaction and are increasingly being deployed in situations where they might engage with both human and artificial agents. These interactions represent a critical frontier for LLM-based agents, yet existing evaluation methods fail to measure how well these capabilities generalize to novel social situations. In this paper, we introduce a method for evaluating the ability of LLM-based agents to cooperate in zero-shot, mixed-motive environments using Concordia, a natural language multi-agent simulation environment. Our method measures general cooperative intelligence by testing an agent's ability to identify and exploit opportunities for mutual gain across diverse partners and contexts. We present empirical results from the NeurIPS 2024 Concordia Contest, where agents were evaluated on their ability to achieve mutual gains across a suite of diverse scenarios ranging from negotiation to collective action problems. Our findings reveal significant gaps between current agent capabilities and the robust generalization required for reliable cooperation, particularly in scenarios demanding persuasion and norm enforcement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883Concordia\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u96f6\u6837\u672c\u6df7\u5408\u52a8\u673a\u73af\u5883\u4e2d\u7684\u534f\u4f5c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u8861\u91cf\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u65b0\u7684\u793e\u4ea4\u60c5\u5883\u4e2d\u7684\u6cdb\u5316\u534f\u4f5c\u80fd\u529b\uff0c\u800c\u8fd9\u7c7b\u4ea4\u4e92\u662fLLM\u667a\u80fd\u4f53\u5e94\u7528\u7684\u91cd\u8981\u524d\u6cbf\u3002", "method": "\u4f7f\u7528Concordia\u591a\u667a\u80fd\u4f53\u6a21\u62df\u73af\u5883\uff0c\u901a\u8fc7\u6d4b\u8bd5\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u4f19\u4f34\u548c\u60c5\u5883\u4e2d\u8bc6\u522b\u53ca\u5229\u7528\u4e92\u60e0\u673a\u4f1a\u7684\u80fd\u529b\u6765\u8bc4\u4f30\u534f\u4f5c\u667a\u80fd\u3002", "result": "\u5728NeurIPS 2024 Concordia\u7ade\u8d5b\u4e2d\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u667a\u80fd\u4f53\u5728\u9700\u8981\u8bf4\u670d\u548c\u89c4\u8303\u6267\u884c\u7684\u573a\u666f\u4e2d\uff0c\u5176\u80fd\u529b\u4e0e\u5b9e\u73b0\u53ef\u9760\u534f\u4f5c\u6240\u9700\u7684\u7a33\u5065\u6cdb\u5316\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u590d\u6742\u793e\u4ea4\u534f\u4f5c\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u6d89\u53ca\u8bf4\u670d\u548c\u89c4\u8303\u7ef4\u62a4\u7684\u60c5\u5883\u4e0b\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u5b9e\u73b0\u53ef\u9760\u7684\u5408\u4f5c\u3002"}}
{"id": "2512.03121", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03121", "abs": "https://arxiv.org/abs/2512.03121", "authors": ["Ziyi Tong", "Feifei Sun", "Le Minh Nguyen"], "title": "Lost in Modality: Evaluating the Effectiveness of Text-Based Membership Inference Attacks on Large Multimodal Models", "comment": null, "summary": "Large Multimodal Language Models (MLLMs) are emerging as one of the foundational tools in an expanding range of applications. Consequently, understanding training-data leakage in these systems is increasingly critical. Log-probability-based membership inference attacks (MIAs) have become a widely adopted approach for assessing data exposure in large language models (LLMs), yet their effect in MLLMs remains unclear. We present the first comprehensive evaluation of extending these text-based MIA methods to multimodal settings. Our experiments under vision-and-text (V+T) and text-only (T-only) conditions across the DeepSeek-VL and InternVL model families show that in in-distribution settings, logit-based MIAs perform comparably across configurations, with a slight V+T advantage. Conversely, in out-of-distribution settings, visual inputs act as regularizers, effectively masking membership signals.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8bc4\u4f30\u4e86\u5c06\u57fa\u4e8e\u6587\u672c\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u6269\u5c55\u5230\u591a\u6a21\u6001\u573a\u666f\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e0b\u57fa\u4e8elogit\u7684MIA\u5728\u89c6\u89c9+\u6587\u672c\u548c\u4ec5\u6587\u672c\u914d\u7f6e\u4e0b\u8868\u73b0\u76f8\u4f3c\uff0c\u800c\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\u89c6\u89c9\u8f93\u5165\u8d77\u5230\u4e86\u6b63\u5219\u5316\u4f5c\u7528\u3002", "motivation": "\u5927\u578b\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u7406\u89e3\u8bad\u7ec3\u6570\u636e\u6cc4\u9732\u95ee\u9898\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u867d\u7136\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u5df2\u6210\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6570\u636e\u66b4\u9732\u7684\u5e38\u7528\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u5728MLLMs\u4e2d\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5728DeepSeek-VL\u548cInternVL\u6a21\u578b\u5bb6\u65cf\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5bf9\u6bd4\u4e86\u89c6\u89c9+\u6587\u672c\u548c\u4ec5\u6587\u672c\u4e24\u79cd\u6761\u4ef6\u4e0b\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u6548\u679c\u3002", "result": "\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e2d\uff0c\u57fa\u4e8elogit\u7684MIA\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u8868\u73b0\u76f8\u5f53\uff0c\u89c6\u89c9+\u6587\u672c\u6761\u4ef6\u7565\u6709\u4f18\u52bf\uff1b\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\uff0c\u89c6\u89c9\u8f93\u5165\u8d77\u5230\u6b63\u5219\u5316\u4f5c\u7528\uff0c\u6709\u6548\u63a9\u76d6\u4e86\u6210\u5458\u4fe1\u53f7\u3002", "conclusion": "\u89c6\u89c9\u6a21\u6001\u5728\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u5177\u6709\u53cc\u91cd\u4f5c\u7528\uff1a\u5728\u5206\u5e03\u5185\u8bbe\u7f6e\u4e2d\u8f85\u52a9\u653b\u51fb\uff0c\u5728\u5206\u5e03\u5916\u8bbe\u7f6e\u4e2d\u5219\u63d0\u4f9b\u6b63\u5219\u5316\u4fdd\u62a4\u3002"}}
{"id": "2512.03438", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03438", "abs": "https://arxiv.org/abs/2512.03438", "authors": ["Reuben Tan", "Baolin Peng", "Zhengyuan Yang", "Hao Cheng", "Oier Mees", "Theodore Zhao", "Andrea Tupini", "Isar Meijier", "Qianhui Wu", "Yuncong Yang", "Lars Liden", "Yu Gu", "Sheng Zhang", "Xiaodong Liu", "Lijuan Wang", "Marc Pollefeys", "Yong Jae Lee", "Jianfeng Gao"], "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents", "comment": null, "summary": "Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aArgos\u7684\u65b0\u578b\u5956\u52b1\u673a\u5236\uff0c\u80fd\u591f\u5728\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u4e2d\u63d0\u4f9b\u66f4\u7ec6\u7c92\u5ea6\u7684\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u667a\u80fd\u4f53\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0", "motivation": "\u4f20\u7edf\u7684\u591a\u6a21\u6001\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u7a00\u758f\u7684\u6700\u7ec8\u7ed3\u679c\u5956\u52b1\uff0c\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u7ec6\u7c92\u5ea6\u6307\u5bfc\u3002\u73b0\u6709\u7684\u5956\u52b1\u673a\u5236\u96be\u4ee5\u6839\u636e\u4e0d\u540c\u6837\u672c\u9700\u6c42\u52a8\u6001\u8c03\u6574\u8bc4\u5206\u6807\u51c6", "method": "\u63d0\u51faArgos\u5956\u52b1\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u4ece\u6559\u5e08\u6a21\u578b\u548c\u89c4\u5219\u5e93\u4e2d\u52a8\u6001\u9009\u62e9\u8bc4\u5206\u51fd\u6570\uff0c\u540c\u65f6\u5bf9\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u3001\u65f6\u7a7a\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u63a8\u7406\u8fc7\u7a0b\u8d28\u91cf\u8fdb\u884c\u8bc4\u4f30", "result": "\u5b9e\u9a8c\u8868\u660eArgos\u5728\u7a7a\u95f4\u63a8\u7406\u3001\u89c6\u89c9\u5e7b\u89c9\u68c0\u6d4b\u4ee5\u53ca\u673a\u5668\u4eba\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u6709\u6548\u9632\u6b62\u4e86\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5956\u52b1\u9ed1\u5ba2\u95ee\u9898\u548c\u63a8\u7406\u8fc7\u7a0b\u5d29\u6e83", "conclusion": "Argos\u901a\u8fc7\u5e15\u7d2f\u6258\u6700\u4f18\u7406\u8bba\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u7ec6\u7c92\u5ea6\u591a\u7ef4\u5ea6\u5956\u52b1\u673a\u5236\u5bf9\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u7684\u91cd\u8981\u4ef7\u503c"}}
{"id": "2512.03420", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.03420", "abs": "https://arxiv.org/abs/2512.03420", "authors": ["Kang Yang", "Yunhang Zhang", "Zichuan Li", "GuanHong Tao", "Jun Xu", "XiaoJing Liao"], "title": "HarnessAgent: Scaling Automatic Fuzzing Harness Construction with Tool-Augmented LLM Pipelines", "comment": null, "summary": "Large language model (LLM)-based techniques have achieved notable progress in generating harnesses for program fuzzing. However, applying them to arbitrary functions (especially internal functions) \\textit{at scale} remains challenging due to the requirement of sophisticated contextual information, such as specification, dependencies, and usage examples. State-of-the-art methods heavily rely on static or incomplete context provisioning, causing failure of generating functional harnesses. Furthermore, LLMs tend to exploit harness validation metrics, producing plausible yet logically useless code. % Therefore, harness generation across large and diverse projects continues to face challenges in reliable compilation, robust code retrieval, and comprehensive validation.\n  To address these challenges, we present HarnessAgent, a tool-augmented agentic framework that achieves fully automated, scalable harness construction over hundreds of OSS-Fuzz targets. HarnessAgent introduces three key innovations: 1) a rule-based strategy to identify and minimize various compilation errors; 2) a hybrid tool pool for precise and robust symbol source code retrieval; and 3) an enhanced harness validation pipeline that detects fake definitions. We evaluate HarnessAgent on 243 target functions from OSS-Fuzz projects (65 C projects and 178 C++ projects). It improves the three-shot success rate by approximately 20\\% compared to state-of-the-art techniques, reaching 87\\% for C and 81\\% for C++. Our one-hour fuzzing results show that more than 75\\% of the harnesses generated by HarnessAgent increase the target function coverage, surpassing the baselines by over 10\\%. In addition, the hybrid tool-pool system of HarnessAgent achieves a response rate of over 90\\% for source code retrieval, outperforming Fuzz Introspector by more than 30\\%.", "AI": {"tldr": "HarnessAgent\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u5de5\u5177\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21\u4e3aOSS-Fuzz\u76ee\u6807\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6027\u548c\u8986\u76d6\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u4e3a\u5927\u8303\u56f4\u51fd\u6570\uff08\u5c24\u5176\u662f\u5185\u90e8\u51fd\u6570\uff09\u751f\u6210\u6d4b\u8bd5\u4ee3\u7801\u65f6\u56f0\u96be\uff0c\u56e0\u4e3a\u9700\u8981\u590d\u6742\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6216\u4e0d\u5b8c\u6574\u7684\u4e0a\u4e0b\u6587\u63d0\u4f9b\uff0c\u5e38\u751f\u6210\u65e0\u6548\u4ee3\u7801\u3002", "method": "HarnessAgent\u5f15\u5165\u4e86\u4e09\u4e2a\u5173\u952e\u521b\u65b0\uff1a\u57fa\u4e8e\u89c4\u5219\u7684\u7b56\u7565\u6765\u6700\u5c0f\u5316\u7f16\u8bd1\u9519\u8bef\u3001\u6df7\u5408\u5de5\u5177\u6c60\u7528\u4e8e\u7cbe\u786e\u68c0\u7d22\u7b26\u53f7\u6e90\u4ee3\u7801\u3001\u589e\u5f3a\u7684\u9a8c\u8bc1\u7ba1\u9053\u68c0\u6d4b\u865a\u5047\u5b9a\u4e49\u3002", "result": "\u5728243\u4e2aOSS-Fuzz\u76ee\u6807\u51fd\u6570\u8bc4\u4f30\u4e2d\uff0cHarnessAgent\u5c06\u4e09\u6837\u672c\u6210\u529f\u7387\u63d0\u9ad8\u4e86\u7ea620%\uff0c\u5728C\u548cC++\u4e0a\u5206\u522b\u8fbe\u523087%\u548c81%\uff1b\u4e00\u5c0f\u65f6\u5185\u903e75%\u7684\u751f\u6210\u4ee3\u7801\u589e\u52a0\u4e86\u51fd\u6570\u8986\u76d6\u7387\uff0c\u8d85\u8fc7\u57fa\u51c610%\u4ee5\u4e0a\u3002", "conclusion": "HarnessAgent\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u6d4b\u8bd5\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5728\u7f16\u8bd1\u6210\u529f\u7387\u3001\u4ee3\u7801\u68c0\u7d22\u548c\u9a8c\u8bc1\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002"}}
{"id": "2512.03528", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.03528", "abs": "https://arxiv.org/abs/2512.03528", "authors": ["Guang Yang", "Tianpei Yang", "Jingwen Qiao", "Yanqing Wu", "Jing Huo", "Xingguo Chen", "Yang Gao"], "title": "Multi-Agent Reinforcement Learning with Communication-Constrained Priors", "comment": null, "summary": "Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4e22\u5305\u901a\u4fe1\u95ee\u9898\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u901a\u4fe1\u7ea6\u675f\u6a21\u578b\u548c\u4fe1\u606f\u4f30\u8ba1\u65b9\u6cd5\u6765\u6539\u8fdb\u5206\u5e03\u5f0f\u51b3\u7b56\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u666e\u904d\u5b58\u5728\u901a\u4fe1\u4e22\u5305\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4e0d\u8db3\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u590d\u6742\u52a8\u6001\u73af\u5883\u3002", "method": "\u5efa\u7acb\u901a\u7528\u901a\u4fe1\u7ea6\u675f\u6a21\u578b\u533a\u5206\u4e22\u5305/\u65e0\u635f\u6d88\u606f\uff0c\u4f7f\u7528\u53cc\u4e92\u4fe1\u606f\u4f30\u8ba1\u5668\u89e3\u8026\u4e24\u79cd\u6d88\u606f\u5bf9\u51b3\u7b56\u7684\u5f71\u54cd\uff0c\u5e76\u5c06\u901a\u4fe1\u5f71\u54cd\u91cf\u5316\u5230\u5168\u5c40\u5956\u52b1\u4e2d\u3002", "result": "\u5728\u591a\u4e2a\u901a\u4fe1\u53d7\u9650\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u901a\u4fe1\u7ea6\u675f\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u901a\u4fe1\u4e22\u5305\u95ee\u9898\u3002"}}
{"id": "2512.03238", "categories": ["cs.CR", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03238", "abs": "https://arxiv.org/abs/2512.03238", "authors": ["Natalia Ponomareva", "Zheng Xu", "H. Brendan McMahan", "Peter Kairouz", "Lucas Rosenblatt", "Vincent Cohen-Addad", "Crist\u00f3bal Guzm\u00e1n", "Ryan McKenna", "Galen Andrew", "Alex Bie", "Da Yu", "Alex Kurakin", "Morteza Zadimoghaddam", "Sergei Vassilvitskii", "Andreas Terzis"], "title": "How to DP-fy Your Data: A Practical Guide to Generating Synthetic Data With Differential Privacy", "comment": null, "summary": "High quality data is needed to unlock the full potential of AI for end users. However finding new sources of such data is getting harder: most publicly-available human generated data will soon have been used. Additionally, publicly available data often is not representative of users of a particular system -- for example, a research speech dataset of contractors interacting with an AI assistant will likely be more homogeneous, well articulated and self-censored than real world commands that end users will issue. Therefore unlocking high-quality data grounded in real user interactions is of vital interest. However, the direct use of user data comes with significant privacy risks. Differential Privacy (DP) is a well established framework for reasoning about and limiting information leakage, and is a gold standard for protecting user privacy. The focus of this work, \\emph{Differentially Private Synthetic data}, refers to synthetic data that preserves the overall trends of source data,, while providing strong privacy guarantees to individuals that contributed to the source dataset. DP synthetic data can unlock the value of datasets that have previously been inaccessible due to privacy concerns and can replace the use of sensitive datasets that previously have only had rudimentary protections like ad-hoc rule-based anonymization.\n  In this paper we explore the full suite of techniques surrounding DP synthetic data, the types of privacy protections they offer and the state-of-the-art for various modalities (image, tabular, text and decentralized). We outline all the components needed in a system that generates DP synthetic data, from sensitive data handling and preparation, to tracking the use and empirical privacy testing. We hope that work will result in increased adoption of DP synthetic data, spur additional research and increase trust in DP synthetic data approaches.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u7684\u5b8c\u6574\u6280\u672f\u4f53\u7cfb\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6570\u636e\u7c7b\u578b\uff08\u56fe\u50cf\u3001\u8868\u683c\u3001\u6587\u672c\u3001\u53bb\u4e2d\u5fc3\u5316\uff09\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u751f\u6210\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u4ef6\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u5bf9AI\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u516c\u5f00\u6570\u636e\u5b58\u5728\u4ee3\u8868\u6027\u4e0d\u8db3\u548c\u9690\u79c1\u98ce\u9669\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5e73\u8861\u6570\u636e\u6548\u7528\u4e0e\u9690\u79c1\u4fdd\u62a4\u7684\u6280\u672f\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u7efc\u8ff0\u4e86\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u7684\u6280\u672f\u6846\u67b6\uff0c\u5305\u62ec\u6570\u636e\u5904\u7406\u3001\u9690\u79c1\u9884\u7b97\u5206\u914d\u3001\u751f\u6210\u7b97\u6cd5\u53ca\u9690\u79c1\u6d4b\u8bd5\u7b49\u5b8c\u6574\u6d41\u7a0b\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u5957\u751f\u6210\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u7684\u7cfb\u7edf\u5de5\u7a0b\u65b9\u6cd5\uff0c\u4e3a\u4e0d\u540c\u6a21\u6001\u6570\u636e\u63d0\u4f9b\u4e86\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u5dee\u5206\u9690\u79c1\u5408\u6210\u6570\u636e\u80fd\u6709\u6548\u91ca\u653e\u654f\u611f\u6570\u636e\u7684\u4ef7\u503c\uff0c\u63a8\u52a8\u8be5\u6280\u672f\u7684\u5e7f\u6cdb\u5e94\u7528\u5c06\u589e\u5f3a\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u5e76\u4fc3\u8fdbAI\u53d1\u5c55\u3002"}}
{"id": "2512.03356", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03356", "abs": "https://arxiv.org/abs/2512.03356", "authors": ["Jun Leng", "Litian Zhang", "Xi Zhang"], "title": "Immunity memory-based jailbreak detection: multi-agent adaptive guard for large language models", "comment": null, "summary": "Large language models (LLMs) have become foundational in AI systems, yet they remain vulnerable to adversarial jailbreak attacks. These attacks involve carefully crafted prompts that bypass safety guardrails and induce models to produce harmful content. Detecting such malicious input queries is therefore critical for maintaining LLM safety. Existing methods for jailbreak detection typically involve fine-tuning LLMs as static safety LLMs using fixed training datasets. However, these methods incur substantial computational costs when updating model parameters to improve robustness, especially in the face of novel jailbreak attacks. Inspired by immunological memory mechanisms, we propose the Multi-Agent Adaptive Guard (MAAG) framework for jailbreak detection. The core idea is to equip guard with memory capabilities: upon encountering novel jailbreak attacks, the system memorizes attack patterns, enabling it to rapidly and accurately identify similar threats in future encounters. Specifically, MAAG first extracts activation values from input prompts and compares them to historical activations stored in a memory bank for quick preliminary detection. A defense agent then simulates responses based on these detection results, and an auxiliary agent supervises the simulation process to provide secondary filtering of the detection outcomes. Extensive experiments across five open-source models demonstrate that MAAG significantly outperforms state-of-the-art (SOTA) methods, achieving 98% detection accuracy and a 96% F1-score across a diverse range of attack scenarios.", "AI": {"tldr": "MAAG\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u514d\u75ab\u8bb0\u5fc6\u673a\u5236\uff0c\u91c7\u7528\u591a\u667a\u80fd\u4f53\u534f\u540c\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u8fdb\u884c\u9ad8\u6548\u9632\u62a4\uff0c\u5728\u4e94\u5927\u5f00\u6e90\u6a21\u578b\u4e0a\u53d6\u5f9798%\u68c0\u6d4b\u51c6\u786e\u7387\u548c96%F1\u5206\u6570\u7684\u4f18\u5f02\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u8d8a\u72f1\u68c0\u6d4b\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u6570\u636e\u96c6fine-tuning\u6a21\u578b\uff0c\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u53ca\u65f6\u5e94\u5bf9\u65b0\u578b\u653b\u51fb\u7684\u7f3a\u9677\u3002", "method": "\u57fa\u4e8e\u514d\u75ab\u8bb0\u5fc6\u673a\u5236\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u9632\u62a4\u6846\u67b6\uff1a1\uff09\u4ece\u8f93\u5165\u63d0\u793a\u63d0\u53d6\u6fc0\u6d3b\u503c\u5e76\u4e0e\u8bb0\u5fc6\u5e93\u6bd4\u5bf9\u8fdb\u884c\u521d\u6b65\u68c0\u6d4b\uff1b2\uff09\u9632\u5fa1\u667a\u80fd\u4f53\u6839\u636e\u68c0\u6d4b\u7ed3\u679c\u6a21\u62df\u54cd\u5e94\uff1b3\uff09\u8f85\u52a9\u667a\u80fd\u4f53\u76d1\u63a7\u6a21\u62df\u8fc7\u7a0b\u8fdb\u884c\u4e8c\u6b21\u8fc7\u6ee4\u3002", "result": "\u5728\u591a\u79cd\u653b\u51fb\u573a\u666f\u4e0b\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMAAG\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\uff0c\u68c0\u6d4b\u51c6\u786e\u7387\u8fbe98%\uff0cF1\u5206\u6570\u8fbe96%\u3002", "conclusion": "MAAG\u6846\u67b6\u901a\u8fc7\u8bb0\u5fc6\u673a\u5236\u5b9e\u73b0\u4e86\u5bf9\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u7684\u9ad8\u6548\u81ea\u9002\u5e94\u68c0\u6d4b\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03571", "categories": ["cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.03571", "abs": "https://arxiv.org/abs/2512.03571", "authors": ["Zhening Li", "Armando Solar-Lezama", "Yisong Yue", "Stephan Zheng"], "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths", "comment": "65 pages, 2 figures, published in NeurIPS 2025", "summary": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PAN\uff08\u6982\u7387\u5929\u4f7f\u975e\u786e\u5b9a\u6027\uff09\u7f16\u7a0b\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u8026LLM\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u6838\u5fc3\u5de5\u4f5c\u6d41\u7a0b\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff0c\u5e76\u63d0\u4f9b\u4e86EnCompass\u6846\u67b6\u5b9e\u73b0\u548c\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u4f53\u7f16\u7a0b\u65b9\u6cd5\u901a\u5e38\u5c06\u6838\u5fc3\u5de5\u4f5c\u6d41\u7a0b\u903b\u8f91\u548c\u63a8\u7406\u65f6\u7b56\u7565\uff08\u5982\u6811\u641c\u7d22\uff09\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u9650\u5236\u4e86\u8bbe\u8ba1\u7684\u7075\u6d3b\u6027\u548c\u5b9e\u9a8c\u6548\u7387\u3002", "method": "\u5f15\u5165PAN\u7f16\u7a0b\u6a21\u578b\uff0c\u4f7f\u7528Python\u88c5\u9970\u5668\u5c06\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\u7a0b\u5e8f\u7f16\u8bd1\u6210\u641c\u7d22\u7a7a\u95f4\uff0c\u5b9e\u73b0\u5de5\u4f5c\u6d41\u7a0b\u548c\u63a8\u7406\u7b56\u7565\u7684\u5206\u79bb\u3002", "result": "\u5f00\u53d1\u4e86EnCompass\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u6848\u4f8b\u7814\u7a76\u8868\u660e\u7a0b\u5e8f\u5458\u53ef\u4ee5\u5feb\u901f\u63d0\u9ad8\u667a\u80fd\u4f53\u53ef\u9760\u6027\u5e76\u8f7b\u677e\u5207\u6362\u63a8\u7406\u7b56\u7565\uff0c\u4ec5\u9700\u5c11\u91cf\u989d\u5916\u7f16\u7801\u3002", "conclusion": "PAN\u6a21\u578b\u6709\u6548\u89e3\u8026\u4e86\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u4e24\u5927\u5173\u6ce8\u70b9\uff0c\u63d0\u4f9b\u4e86\u66f4\u9ad8\u7684\u7f16\u7a0b\u7075\u6d3b\u6027\u548c\u5b9e\u9a8c\u6548\u7387\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.03607", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03607", "abs": "https://arxiv.org/abs/2512.03607", "authors": ["Yusen Wu", "Xiaotie Deng"], "title": "DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization", "comment": null, "summary": "This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.\n  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.", "AI": {"tldr": "DeepRule\u662f\u4e00\u4e2a\u7528\u4e8e\u96f6\u552e\u54c1\u7c7b\u548c\u5b9a\u4ef7\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4e1a\u52a1\u89c4\u5219\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u5c42\u67b6\u6784\u89e3\u51b3\u7406\u8bba\u4e0e\u73b0\u5b9e\u7ecf\u6d4e\u590d\u6742\u6027\u4e4b\u95f4\u7684\u4e09\u5927\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u6a21\u578b\u4e0e\u771f\u5b9e\u7ecf\u6d4e\u590d\u6742\u6027\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u9519\u4f4d\uff0c\u5177\u4f53\u8868\u73b0\u4e3a\uff1a\u975e\u7ed3\u6784\u5316\u6587\u672c\u6570\u636e\u96be\u4ee5\u7528\u4e8e\u5ba2\u6237\u753b\u50cf\u3001\u52a8\u6001\u7279\u5f81\u7ea0\u7f20\u96be\u4ee5\u5efa\u6a21\u975e\u7ebf\u6027\u4ef7\u683c\u5f39\u6027\u3001\u591a\u5c42\u4e1a\u52a1\u7ea6\u675f\u5bfc\u81f4\u64cd\u4f5c\u4e0d\u53ef\u884c\u3002", "method": "\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a1\uff09\u6df7\u5408\u77e5\u8bc6\u878d\u5408\u5f15\u64ce\u4f7f\u7528LLM\u89e3\u6790\u975e\u7ed3\u6784\u5316\u6587\u672c\uff1b2\uff09\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u7ea6\u675f\u4f18\u5316\u673a\u5236\u534f\u8c03\u4f9b\u5e94\u94fe\u5229\u76ca\uff1b3\uff09\u53ef\u89e3\u91ca\u51b3\u7b56\u84b8\u998f\u63a5\u53e3\u5229\u7528\u7b26\u53f7\u56de\u5f52\u4f18\u5316\u5b9a\u4ef7\u7b56\u7565\u3002", "result": "\u5728\u5b9e\u9645\u96f6\u552e\u73af\u5883\u4e2d\u9a8c\u8bc1\uff0c\u76f8\u6bd4\u7cfb\u7edfB2C\u57fa\u7ebf\u5b9e\u73b0\u4e86\u66f4\u9ad8\u5229\u6da6\uff0c\u540c\u65f6\u786e\u4fdd\u64cd\u4f5c\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u7edf\u4e00\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u6ce8\u5165\u3001\u591a\u667a\u80fd\u4f53\u4f18\u5316\u548c\u53ef\u89e3\u91ca\u7b56\u7565\u5408\u6210\u7684\u95ed\u73af\u6d41\u7a0b\uff0c\u4e3a\u73b0\u5b9e\u7ecf\u6d4e\u667a\u80fd\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03361", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03361", "abs": "https://arxiv.org/abs/2512.03361", "authors": ["Zhiyuan Xi", "Kun Zhu"], "title": "Rethinking Security in Semantic Communication: Latent Manipulation as a New Threat", "comment": "8 pages, 6 figures", "summary": "Deep learning-based semantic communication (SemCom) has emerged as a promising paradigm for next-generation wireless networks, offering superior transmission efficiency by extracting and conveying task-relevant semantic latent representations rather than raw data. However, the openness of the wireless medium and the intrinsic vulnerability of semantic latent representations expose such systems to previously unrecognized security risks. In this paper, we uncover a fundamental latent-space vulnerability that enables Man-in-the-Middle (MitM) attacker to covertly manipulate the transmitted semantics while preserving the statistical properties of the transmitted latent representations. We first present a Diffusion-based Re-encoding Attack (DiR), wherein the attacker employs a diffusion model to synthesize an attacker-designed semantic variant, and re-encodes it into a valid latent representation compatible with the SemCom decoder. Beyond this model-dependent pathway, we further propose a model-agnostic and training-free Test-Time Adaptation Latent Manipulation attack (TTA-LM), in which the attacker perturbs and steers the intercepted latent representation toward an attacker-specified semantic target by leveraging the gradient of a target loss function. In contrast to diffusion-based manipulation, TTA-LM does not rely on any generative model and does not impose modality-specific or task-specific assumptions, thereby enabling efficient and broadly applicable latent-space tampering across diverse SemCom architectures. Extensive experiments on representative semantic communication architectures demonstrate that both attacks can significantly alter the decoded semantics while preserving natural latent-space distributions, making the attacks covert and difficult to detect.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u5728\u6f5c\u7a7a\u95f4\u4e2d\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u9690\u853d\u7684\u8bed\u4e49\u653b\u51fb\u65b9\u6cd5\uff1a\u4f9d\u8d56\u6269\u6563\u6a21\u578b\u7684DiR\u653b\u51fb\u548c\u65e0\u9700\u8bad\u7ec3\u7684TTA-LM\u653b\u51fb\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8fd9\u4e24\u79cd\u653b\u51fb\u80fd\u6709\u6548\u7be1\u6539\u8bed\u4e49\u4e14\u96be\u4ee5\u68c0\u6d4b\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u901a\u8fc7\u4f20\u8f93\u8bed\u4e49\u6f5c\u8868\u793a\u63d0\u5347\u6548\u7387\uff0c\u4f46\u65e0\u7ebf\u4fe1\u9053\u7684\u5f00\u653e\u6027\u548c\u6f5c\u8868\u793a\u7684\u8106\u5f31\u6027\u5e26\u6765\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u5173\u6ce8\u6f5c\u7a7a\u95f4\u5c42\u9762\u7684\u653b\u51fb\u3002", "method": "\u63d0\u51faDiR\u653b\u51fb\uff08\u5229\u7528\u6269\u6563\u6a21\u578b\u91cd\u7f16\u7801\u8bed\u4e49\u53d8\u4f53\uff09\u548cTTA-LM\u653b\u51fb\uff08\u901a\u8fc7\u76ee\u6807\u635f\u5931\u51fd\u6570\u68af\u5ea6\u6270\u52a8\u6f5c\u8868\u793a\uff09\uff0c\u4e24\u79cd\u65b9\u6cd5\u5747\u80fd\u4fdd\u6301\u6f5c\u8868\u793a\u7edf\u8ba1\u7279\u6027\u4ee5\u9690\u853d\u653b\u51fb\u3002", "result": "\u5728\u591a\u7c7b\u8bed\u4e49\u901a\u4fe1\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e24\u79cd\u653b\u51fb\u5747\u53ef\u663e\u8457\u6539\u53d8\u89e3\u7801\u8bed\u4e49\uff08\u5982\u5c06\u201c\u72d7\u201d\u7be1\u6539\u4e3a\u201c\u732b\u201d\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u6f5c\u7a7a\u95f4\u5206\u5e03\u81ea\u7136\uff0c\u653b\u51fb\u9690\u853d\u6027\u5f3a\u3002", "conclusion": "\u8bed\u4e49\u901a\u4fe1\u7684\u6f5c\u7a7a\u95f4\u5b58\u5728\u672c\u8d28\u5b89\u5168\u8106\u5f31\u6027\uff0c\u9700\u6784\u5efa\u517c\u987e\u8bed\u4e49\u5b8c\u6574\u6027\u548c\u5b89\u5168\u6027\u7684\u65b0\u4e00\u4ee3\u901a\u4fe1\u6846\u67b6\uff0c\u672a\u6765\u5e94\u63a2\u7d22\u6f5c\u7a7a\u95f4\u8ba4\u8bc1\u7b49\u9632\u5fa1\u673a\u5236\u3002"}}
{"id": "2512.03762", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03762", "abs": "https://arxiv.org/abs/2512.03762", "authors": ["Jiawei Xu", "Fengfeng Wei", "Weineng Chen"], "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design", "comment": null, "summary": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RoCo\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u4f5c\u8bbe\u8ba1\u81ea\u52a8\u542f\u53d1\u5f0f\u65b9\u6cd5\u6765\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u7814\u7a76\u901a\u5e38\u53ea\u8003\u8651\u5355\u4e00\u89d2\u8272\uff0c\u9650\u5236\u4e86\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\u3002", "method": "RoCo\u534f\u8c03\u56db\u4e2a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff08\u63a2\u7d22\u8005\u3001\u5229\u7528\u8005\u3001\u6279\u8bc4\u8005\u548c\u6574\u5408\u8005\uff09\uff0c\u901a\u8fc7\u591a\u8f6e\u53cd\u9988\u548c\u7cbe\u82f1\u53d8\u5f02\u8fdb\u884c\u534f\u4f5c\u8bbe\u8ba1\u3002", "result": "\u5728\u4e94\u4e2a\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRoCo\u5728\u767d\u76d2\u548c\u9ed1\u76d2\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5982ReEvo\u548cHSEvo\u3002", "conclusion": "\u57fa\u4e8e\u89d2\u8272\u7684\u534f\u4f5c\u8303\u5f0f\u4e3a\u9c81\u68d2\u9ad8\u6027\u80fd\u7684\u81ea\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u5efa\u7acb\u4e86\u65b0\u6807\u51c6\u3002"}}
{"id": "2512.03783", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.03783", "abs": "https://arxiv.org/abs/2512.03783", "authors": ["Dongchao Yang", "Songxiang Liu", "Disong Wang", "Yuanyuan Wang", "Guanglu Wan", "Helen Meng"], "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning", "comment": null, "summary": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Omni-AutoThink\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u63a8\u7406\u6df1\u5ea6\u6765\u63d0\u9ad8\u591a\u6a21\u6001\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709Omni\u6a21\u578b\u5728\u63a8\u7406\u884c\u4e3a\u4e0a\u5b58\u5728\u50f5\u5316\u95ee\u9898\uff0c\u8981\u4e48\u5bf9\u7b80\u5355\u95ee\u9898\u8fc7\u5ea6\u63a8\u7406\uff0c\u8981\u4e48\u5728\u9700\u8981\u63a8\u7406\u65f6\u65e0\u6cd5\u6709\u6548\u63a8\u7406", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1)\u81ea\u9002\u5e94\u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u4f7f\u7528\u63a8\u7406\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u57fa\u7840\u80fd\u529b\uff1b2)\u81ea\u9002\u5e94\u5f3a\u5316\u5b66\u4e60\u9636\u6bb5\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u4f18\u5316\u63a8\u7406\u884c\u4e3a", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u5728\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u6a21\u578b\u7684\u63a8\u7406\u50f5\u5316\u95ee\u9898\uff0c\u76f8\u5173\u6570\u636e\u548c\u4ee3\u7801\u5c06\u516c\u5f00"}}
{"id": "2512.03465", "categories": ["cs.CR", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.03465", "abs": "https://arxiv.org/abs/2512.03465", "authors": ["Robert Dilworth"], "title": "Tuning for TraceTarnish: Techniques, Trends, and Testing Tangible Traits", "comment": "20 pages, 8 figures, 2 tables", "summary": "In this study, we more rigorously evaluated our attack script $\\textit{TraceTarnish}$, which leverages adversarial stylometry principles to anonymize the authorship of text-based messages. To ensure the efficacy and utility of our attack, we sourced, processed, and analyzed Reddit comments--comments that were later alchemized into $\\textit{TraceTarnish}$ data--to gain valuable insights. The transformed $\\textit{TraceTarnish}$ data was then further augmented by $\\textit{StyloMetrix}$ to manufacture stylometric features--features that were culled using the Information Gain criterion, leaving only the most informative, predictive, and discriminative ones. Our results found that function words and function word types ($L\\_FUNC\\_A$ $\\&$ $L\\_FUNC\\_T$); content words and content word types ($L\\_CONT\\_A$ $\\&$ $L\\_CONT\\_T$); and the Type-Token Ratio ($ST\\_TYPE\\_TOKEN\\_RATIO\\_LEMMAS$) yielded significant Information-Gain readings. The identified stylometric cues--function-word frequencies, content-word distributions, and the Type-Token Ratio--serve as reliable indicators of compromise (IoCs), revealing when a text has been deliberately altered to mask its true author. Similarly, these features could function as forensic beacons, alerting defenders to the presence of an adversarial stylometry attack; granted, in the absence of the original message, this signal may go largely unnoticed, as it appears to depend on a pre- and post-transformation comparison. \"In trying to erase a trace, you often imprint a larger one.\" Armed with this understanding, we framed $\\textit{TraceTarnish}$'s operations and outputs around these five isolated features, using them to conceptualize and implement enhancements that further strengthen the attack.", "AI": {"tldr": "\u63d0\u51fa\u4e86TraceTarnish\u653b\u51fb\u811a\u672c\uff0c\u5229\u7528\u5bf9\u6297\u6027\u98ce\u683c\u6d4b\u91cf\u539f\u7406\u533f\u540d\u5316\u6587\u672c\u6d88\u606f\u7684\u4f5c\u8005\u8eab\u4efd\u3002\u901a\u8fc7\u5206\u6790Reddit\u8bc4\u8bba\uff0c\u8bc6\u522b\u51fa\u4e94\u79cd\u5173\u952e\u98ce\u683c\u7279\u5f81\u4f5c\u4e3a\u653b\u51fb\u6307\u6807\u3002", "motivation": "\u8bc4\u4f30\u548c\u6539\u8fdb\u5bf9\u6297\u6027\u98ce\u683c\u6d4b\u91cf\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u901a\u8fc7\u8bc6\u522b\u6700\u6709\u6548\u7684\u98ce\u683c\u7279\u5f81\u6765\u589e\u5f3a\u6587\u672c\u533f\u540d\u5316\u80fd\u529b\u3002", "method": "\u6536\u96c6Reddit\u8bc4\u8bba\u6570\u636e\uff0c\u4f7f\u7528TraceTarnish\u5904\u7406\u6587\u672c\uff0c\u901a\u8fc7StyloMetrix\u751f\u6210\u98ce\u683c\u7279\u5f81\uff0c\u5e94\u7528\u4fe1\u606f\u589e\u76ca\u51c6\u5219\u7b5b\u9009\u6700\u5177\u9884\u6d4b\u6027\u7684\u7279\u5f81\u3002", "result": "\u8bc6\u522b\u51fa\u4e94\u4e2a\u5173\u952e\u98ce\u683c\u7279\u5f81\u4f5c\u4e3a\u53ef\u9760\u653b\u51fb\u6307\u6807\uff1a\u529f\u80fd\u8bcd\u9891\u7387\u3001\u5185\u5bb9\u8bcd\u5206\u5e03\u548c\u7c7b\u578b\u6807\u8bb0\u6bd4\u3002", "conclusion": "\u8fd9\u4e9b\u7279\u5f81\u65e2\u53ef\u7528\u6765\u589e\u5f3a\u653b\u51fb\u6548\u679c\uff0c\u4e5f\u53ef\u4f5c\u4e3a\u68c0\u6d4b\u5bf9\u6297\u6027\u98ce\u683c\u6d4b\u91cf\u653b\u51fb\u7684\u53d6\u8bc1\u4fe1\u6807\uff0c\u4f46\u9700\u8981\u539f\u59cb\u6587\u672c\u5bf9\u6bd4\u624d\u80fd\u6709\u6548\u68c0\u6d4b\u3002"}}
{"id": "2512.03551", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03551", "abs": "https://arxiv.org/abs/2512.03551", "authors": ["Oylum Gerenli", "Gunes Karabulut-Kurt", "Enver Ozdemir"], "title": "A User Centric Group Authentication Scheme for Secure Communication", "comment": null, "summary": "Group Authentication Schemes (GAS) are methodologies developed to verify the membership of multiple users simultaneously. These schemes enable the concurrent authentication of several users while eliminating the need for a certification authority. Numerous GAS methods have been explored in the literature, and they can be classified into three distinct generations based on their foundational mathematical principles. First-generation GASs rely on polynomial interpolation and the multiplicative subgroup of a finite field. Second-generation GASs also employ polynomial interpolation, but they distinguish themselves by incorporating elliptic curves over finite fields. While third-generation GASs present a promising solution for scalable environments, they demonstrate a limitation in certain applications. Such applications typically require the identification of users participating in the authentication process. In the third-generation GAS, users are able to verify their credentials while maintaining anonymity. However, there are various applications where the identification of participating users is necessary. In this study, we propose an improved version of third-generation GAS, utilizing inner product spaces and polynomial interpolation to resolve this limitation. We address the issue of preventing malicious actions by legitimate group members. The current third-generation scheme allows members to share group credentials, which can jeopardize group confidentiality. Our proposed scheme mitigates this risk by eliminating the ability of individual users to distribute credentials. However, a potential limitation of our scheme is its reliance on a central authority for authentication in certain scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u7b2c\u4e09\u4ee3\u7fa4\u7ec4\u8ba4\u8bc1\u65b9\u6848\uff0c\u4f7f\u7528\u5185\u79ef\u7a7a\u95f4\u548c\u591a\u9879\u5f0f\u63d2\u503c\u6765\u89e3\u51b3\u7528\u6237\u8bc6\u522b\u95ee\u9898\uff0c\u540c\u65f6\u9632\u6b62\u5408\u6cd5\u6210\u5458\u7684\u6076\u610f\u884c\u4e3a", "motivation": "\u7b2c\u4e09\u4ee3GAS\u867d\u80fd\u4fdd\u62a4\u7528\u6237\u533f\u540d\u6027\uff0c\u4f46\u5728\u67d0\u4e9b\u9700\u8981\u8bc6\u522b\u53c2\u4e0e\u7528\u6237\u7684\u5e94\u7528\u4e2d\u5b58\u5728\u5c40\u9650\uff0c\u4e14\u73b0\u6709\u65b9\u6848\u5141\u8bb8\u6210\u5458\u5171\u4eab\u7fa4\u7ec4\u51ed\u8bc1\uff0c\u5371\u53ca\u7fa4\u7ec4\u4fdd\u5bc6\u6027", "method": "\u57fa\u4e8e\u5185\u79ef\u7a7a\u95f4\u548c\u591a\u9879\u5f0f\u63d2\u503c\uff0c\u6d88\u9664\u4e86\u5355\u4e2a\u7528\u6237\u5206\u53d1\u51ed\u8bc1\u7684\u80fd\u529b", "result": "\u65b0\u65b9\u6848\u89e3\u51b3\u4e86\u7528\u6237\u8bc6\u522b\u9700\u6c42\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u51ed\u8bc1\u5171\u4eab\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669", "conclusion": "\u6539\u8fdb\u7684\u7b2c\u4e09\u4ee3GAS\u65b9\u6848\u5728\u4fdd\u6301\u533f\u540d\u6027\u7684\u540c\u65f6\u6ee1\u8db3\u4e86\u7279\u5b9a\u5e94\u7528\u7684\u7528\u6237\u8bc6\u522b\u9700\u6c42\uff0c\u4f46\u90e8\u5206\u573a\u666f\u4ecd\u9700\u4f9d\u8d56\u4e2d\u592e\u6743\u5a01\u8fdb\u884c\u8ba4\u8bc1"}}
{"id": "2512.03955", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03955", "abs": "https://arxiv.org/abs/2512.03955", "authors": ["Niklas Jobs", "Luis Miguel Vieira da Silva", "Jayanth Somashekaraiah", "Maximilian Weigand", "David Kube", "Felix Gehlhoff"], "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol", "comment": "This work has been submitted to IFAC for possible publication", "summary": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.", "AI": {"tldr": "\u5f15\u5165\u4e00\u4e2a\u57fa\u4e8eBlocksworld\u95ee\u9898\u7684\u53ef\u6267\u884c\u57fa\u51c6\u6d4b\u8bd5\u73af\u5883\uff0c\u96c6\u6210MCP\u4f5c\u4e3a\u6807\u51c6\u5316\u5de5\u5177\u63a5\u53e3\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u7684\u81ea\u9002\u5e94\u89c4\u5212\u80fd\u529b\u3002", "motivation": "\u5de5\u4e1a\u81ea\u52a8\u5316\u9700\u8981\u7075\u6d3b\u7684\u81ea\u9002\u5e94\u63a7\u5236\u7b56\u7565\uff0c\u4f46\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u7f3a\u4e4f\u6807\u51c6\u5316\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u521b\u5efa\u5305\u542b\u4e94\u4e2a\u590d\u6742\u5ea6\u7c7b\u522b\u7684Blocksworld\u6a21\u62df\u73af\u5883\uff0c\u901a\u8fc7MCP\u6807\u51c6\u5316\u5de5\u5177\u63a5\u53e3\u8fde\u63a5\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u4e86\u5355\u667a\u80fd\u4f53\u5b9e\u73b0\u9a8c\u8bc1\u57fa\u51c6\u9002\u7528\u6027\uff0c\u5efa\u7acb\u4e86\u91cf\u5316\u6307\u6807\u7528\u4e8e\u6bd4\u8f83\u57fa\u4e8eLLM\u7684\u89c4\u5212\u6267\u884c\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u89e3\u51b3LLM\u667a\u80fd\u4f53\u5728\u5de5\u4e1a\u81ea\u52a8\u5316\u4e2d\u7684\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff0c\u652f\u6301\u4e0d\u540c\u67b6\u6784\u7684\u6807\u51c6\u5316\u6bd4\u8f83\u3002"}}
{"id": "2512.03669", "categories": ["cs.CR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.03669", "abs": "https://arxiv.org/abs/2512.03669", "authors": ["Zuan Wang", "Juntao Lu", "Jiazhuang Wu", "Youliang Tian", "Wei Song", "Qiuxian Li", "Duo Zhang"], "title": "Towards Privacy-Preserving Range Queries with Secure Learned Spatial Index over Encrypted Data", "comment": "IEEE TrustCom-2025", "summary": "With the growing reliance on cloud services for large-scale data management, preserving the security and privacy of outsourced datasets has become increasingly critical. While encrypting data and queries can prevent direct content exposure, recent research reveals that adversaries can still infer sensitive information via access pattern and search path analysis. However, existing solutions that offer strong access pattern privacy often incur substantial performance overhead. In this paper, we propose a novel privacy-preserving range query scheme over encrypted datasets, offering strong security guarantees while maintaining high efficiency. To achieve this, we develop secure learned spatial index (SLS-INDEX), a secure learned index that integrates the Paillier cryptosystem with a hierarchical prediction architecture and noise-injected buckets, enabling data-aware query acceleration in the encrypted domain. To further obfuscate query execution paths, SLS-INDEXbased Range Queries (SLRQ) employs a permutation-based secure bucket prediction protocol. Additionally, we introduce a secure point extraction protocol that generates candidate results to reduce the overhead of secure computation. We provide formal security analysis under realistic leakage functions and implement a prototype to evaluate its practical performance. Extensive experiments on both real-world and synthetic datasets demonstrate that SLRQ significantly outperforms existing solutions in query efficiency while ensuring dataset, query, result, and access pattern privacy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7d22\u5f15\u7684\u9690\u79c1\u4fdd\u62a4\u8303\u56f4\u67e5\u8be2\u65b9\u6848SLRQ\uff0c\u5728\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u67e5\u8be2\u6548\u7387\u3002", "motivation": "\u968f\u7740\u4e91\u670d\u52a1\u4e2d\u6570\u636e\u5916\u5305\u7684\u666e\u53ca\uff0c\u4fdd\u62a4\u6570\u636e\u5b89\u5168\u548c\u9690\u79c1\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6848\u5728\u5904\u7406\u52a0\u5bc6\u6570\u636e\u8303\u56f4\u67e5\u8be2\u65f6\uff0c\u8981\u4e48\u5b89\u5168\u6027\u4e0d\u8db3\uff0c\u8981\u4e48\u6027\u80fd\u5f00\u9500\u8fc7\u5927\u3002", "method": "\u5f00\u53d1\u4e86\u5b89\u5168\u5b66\u4e60\u7a7a\u95f4\u7d22\u5f15SLS-INDEX\uff0c\u96c6\u6210Paillier\u5bc6\u7801\u7cfb\u7edf\u548c\u5c42\u6b21\u9884\u6d4b\u67b6\u6784\uff0c\u91c7\u7528\u566a\u58f0\u6ce8\u5165\u6876\u548c\u57fa\u4e8e\u7f6e\u6362\u7684\u6876\u9884\u6d4b\u534f\u8bae\u6765\u6df7\u6dc6\u67e5\u8be2\u8def\u5f84\uff0c\u540c\u65f6\u4f7f\u7528\u5b89\u5168\u70b9\u63d0\u53d6\u534f\u8bae\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSLRQ\u5728\u67e5\u8be2\u6548\u7387\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6570\u636e\u3001\u67e5\u8be2\u3001\u7ed3\u679c\u548c\u8bbf\u95ee\u6a21\u5f0f\u7684\u9690\u79c1\u3002", "conclusion": "SLRQ\u65b9\u6848\u6210\u529f\u5b9e\u73b0\u4e86\u5b89\u5168\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u4e3a\u52a0\u5bc6\u6570\u636e\u7684\u9690\u79c1\u4fdd\u62a4\u8303\u56f4\u67e5\u8be2\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.03720", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03720", "abs": "https://arxiv.org/abs/2512.03720", "authors": ["Tengyun Ma", "Jiaqi Yao", "Daojing He", "Shihao Peng", "Yu Li", "Shaohui Liu", "Zhuotao Tian"], "title": "Context-Aware Hierarchical Learning: A Two-Step Paradigm towards Safer LLMs", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful tools for diverse applications. However, their uniform token processing paradigm introduces critical vulnerabilities in instruction handling, particularly when exposed to adversarial scenarios. In this work, we identify and propose a novel class of vulnerabilities, termed Tool-Completion Attack (TCA), which exploits function-calling mechanisms to subvert model behavior. To evaluate LLM robustness against such threats, we introduce the Tool-Completion benchmark, a comprehensive security assessment framework, which reveals that even state-of-the-art models remain susceptible to TCA, with surprisingly high attack success rates. To address these vulnerabilities, we introduce Context-Aware Hierarchical Learning (CAHL), a sophisticated mechanism that dynamically balances semantic comprehension with role-specific instruction constraints. CAHL leverages the contextual correlations between different instruction segments to establish a robust, context-aware instruction hierarchy. Extensive experiments demonstrate that CAHL significantly enhances LLM robustness against both conventional attacks and the proposed TCA, exhibiting strong generalization capabilities in zero-shot evaluations while still preserving model performance on generic tasks. Our code is available at https://github.com/S2AILab/CAHL.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5de5\u5177\u5b8c\u6210\u653b\u51fb\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u5c42\u5b66\u4e60\u673a\u5236\u6765\u589e\u5f3a\u6a21\u578b\u5b89\u5168\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u6807\u8bb0\u5904\u7406\u673a\u5236\u5728\u5bf9\u6297\u573a\u666f\u4e0b\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u5728\u6307\u4ee4\u5904\u7406\u65b9\u9762\u3002", "method": "\u63d0\u51fa\u5de5\u5177\u5b8c\u6210\u653b\u51fb\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f00\u53d1\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u5c42\u5b66\u4e60\u673a\u5236\uff0c\u901a\u8fc7\u52a8\u6001\u5e73\u8861\u8bed\u4e49\u7406\u89e3\u548c\u89d2\u8272\u7279\u5b9a\u6307\u4ee4\u7ea6\u675f\u6765\u9632\u5fa1\u653b\u51fb\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCAHL\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u4f20\u7edf\u653b\u51fb\u548c\u5de5\u5177\u5b8c\u6210\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u5728\u96f6\u6837\u672c\u8bc4\u4f30\u4e2d\u8868\u73b0\u826f\u597d\u4e14\u4e0d\u5f71\u54cd\u901a\u7528\u4efb\u52a1\u6027\u80fd\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u611f\u77e5\u5206\u5c42\u5b66\u4e60\u662f\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6f0f\u6d1e\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e3a\u672a\u6765\u5b89\u5168AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2512.03765", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03765", "abs": "https://arxiv.org/abs/2512.03765", "authors": ["Jose E. Puente", "Carlos Puente"], "title": "The Treasury Proof Ledger: A Cryptographic Framework for Accountable Bitcoin Treasuries", "comment": null, "summary": "Public companies and institutional investors that hold Bitcoin face increasing pressure to show solvency, manage risk, and satisfy regulatory expectations without exposing internal wallet structures or trading strategies. This paper introduces the Treasury Proof Ledger (TPL), a Bitcoin-anchored logging framework for multi-domain Bitcoin treasuries that treats on-chain and off-chain exposures as a conserved state machine with an explicit fee sink. A TPL instance records proof-of-reserves snapshots, proof-of-transit receipts for movements between domains, and policy metadata, and it supports restricted views based on stakeholder permissions. We define an idealised TPL model, represent Bitcoin treasuries as multi-domain exposure vectors, and give deployment-level security notions including exposure soundness, policy completeness, non-equivocation, and privacy-compatible policy views. We then outline how practical, restricted forms of these guarantees can be achieved by combining standard proof-of-reserves and proof-of-transit techniques with hash-based commitments anchored on Bitcoin. The results are existence-type statements: they show which guarantees are achievable once economic and governance assumptions are set, without claiming that any current system already provides them. A stylised corporate-treasury example illustrates how TPL could support responsible transparency policies and future cross-institution checks consistent with Bitcoin's fixed monetary supply.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Treasury Proof Ledger (TPL)\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u7279\u5e01\u591a\u9886\u57df\u8d44\u91d1\u5e93\u7684\u900f\u660e\u8bc1\u660e\u8bb0\u5f55\uff0c\u7ed3\u5408\u94fe\u4e0a\u94fe\u4e0b\u72b6\u6001\u8ffd\u8e2a\u548c\u6743\u9650\u89c6\u56fe\u63a7\u5236\uff0c\u5b9e\u73b0\u8d1f\u8d23\u4efb\u7684\u4fe1\u606f\u62ab\u9732\u800c\u4e0d\u66b4\u9732\u654f\u611f\u4fe1\u606f\u3002", "motivation": "\u4e0a\u5e02\u516c\u53f8\u548c\u673a\u6784\u6295\u8d44\u8005\u6301\u6709\u6bd4\u7279\u5e01\u65f6\u9762\u4e34\u8bc1\u660e\u507f\u4ed8\u80fd\u529b\u3001\u7ba1\u7406\u98ce\u9669\u548c\u6ee1\u8db3\u76d1\u7ba1\u8981\u6c42\u7684\u538b\u529b\uff0c\u4f46\u9700\u8981\u5728\u4e0d\u66b4\u9732\u5185\u90e8\u94b1\u5305\u7ed3\u6784\u6216\u4ea4\u6613\u7b56\u7565\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u900f\u660e\u5316\u3002", "method": "\u6784\u5efa\u7406\u60f3\u5316\u7684TPL\u6a21\u578b\uff0c\u5c06\u6bd4\u7279\u5e01\u8d44\u91d1\u5e93\u8868\u793a\u4e3a\u591a\u9886\u57df\u98ce\u9669\u655e\u53e3\u5411\u91cf\uff0c\u7ed3\u5408\u6807\u51c6\u50a8\u5907\u8bc1\u660e\u548c\u8f6c\u79fb\u8bc1\u660e\u6280\u672f\uff0c\u901a\u8fc7\u57fa\u4e8e\u54c8\u5e0c\u7684\u627f\u8bfa\u951a\u5b9a\u5728\u6bd4\u7279\u5e01\u94fe\u4e0a\u3002", "result": "\u63d0\u51fa\u4e86\u5305\u62ec\u98ce\u9669\u655e\u53e3\u5065\u5168\u6027\u3001\u7b56\u7565\u5b8c\u5907\u6027\u3001\u975e\u62b5\u8d56\u6027\u548c\u9690\u79c1\u517c\u5bb9\u7b56\u7565\u89c6\u56fe\u5728\u5185\u7684\u5b89\u5168\u6982\u5ff5\uff0c\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u7ecf\u6d4e\u548c\u6cbb\u7406\u5047\u8bbe\u4e0b\u53ef\u5b9e\u73b0\u7684\u6709\u9650\u5f62\u5f0f\u4fdd\u8bc1\u3002", "conclusion": "TPL\u6846\u67b6\u80fd\u591f\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u900f\u660e\u653f\u7b56\uff0c\u4e0e\u6bd4\u7279\u5e01\u56fa\u5b9a\u8d27\u5e01\u4f9b\u5e94\u91cf\u4e00\u81f4\uff0c\u4f46\u9700\u8981\u660e\u786e\u5f53\u524d\u5c1a\u65e0\u7cfb\u7edf\u5b8c\u5168\u5b9e\u73b0\u8fd9\u4e9b\u4fdd\u8bc1\uff0c\u7ed3\u679c\u5c5e\u4e8e\u5b58\u5728\u6027\u8bc1\u660e\u7c7b\u578b\u3002"}}
{"id": "2512.03775", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.03775", "abs": "https://arxiv.org/abs/2512.03775", "authors": ["Biwei Yan", "Yue Zhang", "Minghui Xu", "Hao Wu", "Yechao Zhang", "Kun Li", "Guoming Zhang", "Xiuzhen Cheng"], "title": "\"MCP Does Not Stand for Misuse Cryptography Protocol\": Uncovering Cryptographic Misuse in Model Context Protocol at Scale", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly emerging as the middleware for LLM-based applications, offering a standardized interface for tool integration. However, its built-in security mechanisms are minimal: while schemas and declarations prevent malformed requests, MCP provides no guarantees of authenticity or confidentiality, forcing developers to implement cryptography themselves. Such ad hoc practices are historically prone to misuse, and within MCP they threaten sensitive data and services. We present MICRYSCOPE, the first domain-specific framework for detecting cryptographic misuses in MCP implementations. MICRYSCOPE combines three key innovations: a cross-language intermediate representation that normalizes cryptographic APIs across diverse ecosystems, a hybrid dependency analysis that uncovers explicit and implicit function relationships (including insecure runtime compositions orchestrated by LLMs) and a taint-based misuse detector that tracks sensitive data flows and flags violations of established cryptographic rules. Applying MICRYSCOPE to 9,403 MCP servers, we identified 720 with cryptographic logic, of which 19.7% exhibited misuses. These flaws are concentrated in certain markets (e.g., Smithery Registry with 42% insecure servers), languages (Python at 34% misuse rate), and categories (Developer Tools and Data Science & ML accounting for over 50% of all misuses). Case studies reveal real-world consequences, including leaked API keys, insecure DES/ECB tools, and MD5-based authentication bypasses. Our study establishes the first ecosystem-wide view of cryptographic misuse in MCP and provides both tools and insights to strengthen the security foundations of this rapidly growing protocol.", "AI": {"tldr": "MICRYSCOPE\u662f\u9996\u4e2a\u4e13\u95e8\u68c0\u6d4bMCP\u5b9e\u73b0\u4e2d\u52a0\u5bc6\u8bef\u7528\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4e2d\u95f4\u8868\u793a\u548c\u6c61\u70b9\u5206\u6790\u57289403\u4e2a\u670d\u52a1\u5668\u4e2d\u53d1\u73b019.7%\u5b58\u5728\u52a0\u5bc6\u6f0f\u6d1e", "motivation": "MCP\u534f\u8bae\u7f3a\u4e4f\u5185\u7f6e\u52a0\u5bc6\u5b89\u5168\u4fdd\u969c\uff0c\u5f00\u53d1\u8005\u81ea\u4e3b\u5b9e\u73b0\u7684\u52a0\u5bc6\u65b9\u6848\u6613\u51fa\u73b0\u8bef\u7528\uff0c\u5a01\u80c1\u654f\u611f\u6570\u636e\u5b89\u5168", "method": "\u63d0\u51fa\u8de8\u8bed\u8a00\u4e2d\u95f4\u8868\u793a\u7edf\u4e00\u52a0\u5bc6API\u3001\u6df7\u5408\u4f9d\u8d56\u5206\u6790\u8ffd\u8e2a\u51fd\u6570\u5173\u7cfb\u3001\u57fa\u4e8e\u6c61\u70b9\u7684\u8bef\u7528\u68c0\u6d4b\u5668\u8ddf\u8e2a\u654f\u611f\u6570\u636e\u6d41", "result": "\u5728720\u4e2a\u542b\u52a0\u5bc6\u903b\u8f91\u7684MCP\u670d\u52a1\u5668\u4e2d\uff0c19.7%\u5b58\u5728\u8bef\u7528\uff0cPython\u8bed\u8a00\u8bef\u7528\u7387\u8fbe34%\uff0c\u5f00\u53d1\u8005\u5de5\u5177\u548c\u6570\u636e\u79d1\u5b66\u7c7b\u5e94\u7528\u5360\u6bd4\u8d8550%", "conclusion": "\u7814\u7a76\u9996\u6b21\u63ed\u793aMCP\u751f\u6001\u52a0\u5bc6\u8bef\u7528\u73b0\u72b6\uff0c\u4e3a\u5f3a\u5316\u8be5\u534f\u8bae\u5b89\u5168\u57fa\u7840\u63d0\u4f9b\u5de5\u5177\u548c insights"}}
