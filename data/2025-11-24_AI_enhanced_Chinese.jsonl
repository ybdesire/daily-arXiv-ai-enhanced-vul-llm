{"id": "2511.16708", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.16708", "abs": "https://arxiv.org/abs/2511.16708", "authors": ["Shreshth Rajan"], "title": "Multi-Agent Code Verification with Compound Vulnerability Detection", "comment": "18 pages, 3 figures, 9 tables", "summary": "LLMs generate buggy code: 29.6% of SWE-bench \"solved\" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86CodeX-Verify\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u56db\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578b\u4ee3\u7801\u7f3a\u9677\uff0c\u76f8\u6bd4\u5355\u4e00\u667a\u80fd\u4f53\u53ef\u63d0\u9ad8\u68c0\u6d4b\u51c6\u786e\u738739.7\u4e2a\u767e\u5206\u70b9\uff0c\u5728300\u4e2a\u771f\u5b9e\u8865\u4e01\u4e0a\u6d4b\u8bd5\u8fbe\u523079.3%\u51c6\u786e\u7387\u4e14\u6bcf\u6837\u672c\u8017\u65f6<200ms\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u4ec5\u80fd\u6355\u83b765%\u7684\u4ee3\u7801\u7f3a\u9677\u4e14\u5b58\u572835%\u5047\u9633\u6027\uff0c\u800c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\uff08SWE-bench\u4e2d29.6%\u8865\u4e01\u5931\u6548\uff0cBaxBench\u4e2d62%\u65b9\u6848\u542b\u6f0f\u6d1e\uff09\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u7f3a\u9677\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCodeX-Verify\uff0c\u4f7f\u7528\u56db\u4e2a\u4e13\u7528\u667a\u80fd\u4f53\u5206\u522b\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578b\u7f3a\u9677\uff0c\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u4e0d\u540c\u68c0\u6d4b\u6a21\u5f0f\u7684\u667a\u80fd\u4f53\u7ec4\u5408\u80fd\u53d1\u73b0\u66f4\u591a\u7f3a\u9677\uff08\u667a\u80fd\u4f53\u76f8\u5173\u6027p=0.05-0.25\uff09\u3002", "result": "\u572899\u4e2a\u5e26\u6807\u6ce8\u4ee3\u7801\u6837\u672c\u4e0a\u6d4b\u8bd5\u663e\u793a\u7cfb\u7edf\u6355\u83b776.1%\u7f3a\u9677\uff0c\u4e0e\u6700\u4f73\u73b0\u6709\u65b9\u6cd5\u6301\u5e73\u4f46\u8fd0\u884c\u66f4\u5feb\u4e14\u65e0\u9700\u6d4b\u8bd5\u6267\u884c\uff1b\u591a\u667a\u80fd\u4f53\u7ec4\u5408\u6bd4\u5355\u4e00\u667a\u80fd\u4f53\u51c6\u786e\u7387\u63d0\u534739.7\u4e2a\u767e\u5206\u70b9\uff08\u4ece32.8%\u81f372.4%\uff09\uff0c\u6700\u4f73\u53cc\u667a\u80fd\u4f53\u7ec4\u5408\u8fbe79.3%\u51c6\u786e\u7387\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u4ee3\u7801\u7f3a\u9677\u68c0\u6d4b\u6548\u679c\uff0c\u540c\u65f6\u8bc1\u660e\u540c\u4e00\u4ee3\u7801\u4e2d\u5b58\u5728\u591a\u4e2a\u6f0f\u6d1e\u4f1a\u4ea7\u751f\u6307\u6570\u7ea7\u98ce\u9669\uff08\u5982SQL\u6ce8\u5165\u52a0\u51ed\u8bc1\u6cc4\u9732\u98ce\u9669\u8fbe300 vs \u4f20\u7edf\u6a21\u578b\u9884\u6d4b\u768420\uff09\uff0c\u7cfb\u7edf\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u5177\u5907\u5b9e\u7528\u6027\uff08300\u4e2a\u8865\u4e01\u6d4b\u8bd5\u8017\u65f6<200ms/\u6837\u672c\uff09\u3002"}}
{"id": "2511.16858", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16858", "abs": "https://arxiv.org/abs/2511.16858", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair", "comment": null, "summary": "Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u4e0b\uff0c\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u662f\u5426\u4f9d\u7136\u5b58\u5728\u3002", "motivation": "\u867d\u7136\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5174\u8d77\u4e4b\u524d\u5df2\u88ab\u8bc6\u522b\u548c\u7814\u7a76\uff0c\u4f46\u9700\u8981\u5b9e\u9a8c\u9a8c\u8bc1\u8fd9\u4e2a\u95ee\u9898\u5728\u5f53\u524d\u662f\u5426\u4ecd\u7136\u663e\u8457\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u4ed3\u5e93\u7ea7\u522b\u7684SWE-bench\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u7814\u7a76\u3002", "result": "\u8bba\u6587\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u6d4b\u8bd5\u8fc7\u62df\u5408\u5728\u5f53\u4ee3\u7a0b\u5e8f\u4fee\u590d\u4e2d\u7684\u7a0b\u5ea6\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u5728\u4eca\u5929\u4ecd\u7136\u662f\u4e00\u4e2a\u9700\u8981\u5173\u6ce8\u7684\u91cd\u8981\u95ee\u9898\u3002"}}
{"id": "2511.16882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16882", "abs": "https://arxiv.org/abs/2511.16882", "authors": ["Tim Menzies", "Tao Chen", "Yulong Ye", "Kishan Kumar Ganguly", "Amirali Rayegan", "Srinath Srinivasan", "Andre Lustosa"], "title": "MOOT: a Repository of Many Multi-Objective Optimization Tasks", "comment": null, "summary": "Software engineers must make decisions that trade off competing goals (faster vs. cheaper, secure vs. usable, accurate vs. interpretable, etc.). Despite MSR's proven techniques for exploring such goals, researchers still struggle with these trade-offs. Similarly, industrial practitioners deliver sub-optimal products since they lack the tools needed to explore these trade-offs.\n  To enable more research in this important area, we introduce MOOT, a repository of multi-objective optimization tasks taken from recent SE research papers. MOOT's tasks cover software configuration, cloud tuning, project health, process modeling, hyperparameter optimization, and more. Located at github.com/timm/moot, MOOT's current 120+ tasks are freely available under an MIT license (and we invite community contributions). As shown here, this data enables dozens of novel research questions.", "AI": {"tldr": "MOOT\u662f\u4e00\u4e2a\u5305\u542b120\u591a\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\u7684\u4ed3\u5e93\uff0c\u5e2e\u52a9\u7814\u7a76\u8005\u63a2\u7d22\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6743\u8861\u51b3\u7b56\u95ee\u9898", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9700\u8981\u5728\u76f8\u4e92\u7ade\u4e89\u7684\u76ee\u6807\u4e4b\u95f4\u505a\u51fa\u6743\u8861\u51b3\u7b56\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u5de5\u5177\u6765\u63a2\u7d22\u8fd9\u4e9b\u6743\u8861", "method": "\u521b\u5efaMOOT\u4ed3\u5e93\uff0c\u6536\u96c6\u6765\u81ea\u8fd1\u671f\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u8bba\u6587\u7684\u591a\u76ee\u6807\u4f18\u5316\u4efb\u52a1\uff0c\u6db5\u76d6\u8f6f\u4ef6\u914d\u7f6e\u3001\u4e91\u8c03\u4f18\u3001\u9879\u76ee\u5065\u5eb7\u7b49\u591a\u4e2a\u9886\u57df", "result": "\u76ee\u524d\u5df2\u6536\u96c6120\u591a\u4e2a\u4efb\u52a1\uff0c\u5728MIT\u8bb8\u53ef\u4e0b\u5f00\u6e90\uff0c\u652f\u6301\u591a\u79cd\u65b0\u9896\u7684\u7814\u7a76\u95ee\u9898", "conclusion": "MOOT\u4ed3\u5e93\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u591a\u76ee\u6807\u4f18\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u6539\u5584\u8f6f\u4ef6\u51b3\u7b56\u8fc7\u7a0b"}}
{"id": "2511.16814", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.16814", "abs": "https://arxiv.org/abs/2511.16814", "authors": ["Silvia Rondini", "Claudia Alvarez-Martin", "Paula Angermair-Barkai", "Olivier Penacchio", "M. Paz", "Matthew Pelowski", "Dan Dediu", "Antoni Rodriguez-Fornells", "Xim Cerda-Company"], "title": "Stable diffusion models reveal a persisting human and AI gap in visual creativity", "comment": null, "summary": "While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.", "AI": {"tldr": "Study compares visual creativity between humans (artists/non-artists) and AI image generation under different prompting conditions, finding humans superior with a creativity gradient from artists to AI, and different rating patterns between human and AI evaluators.", "motivation": "Visual creativity remains underexplored compared to language creativity, despite research showing LLMs match humans in divergent thinking tasks.", "method": "Compared image generation from human participants (Visual Artists and Non-Artists) and AI (with high human input/Human Inspired vs low input/Self Guided prompting), evaluated by human raters (N=255) and GPT4o.", "result": "Clear creativity gradient: Visual Artists > Non-Artists > Human Inspired AI > Self Guided AI. Human guidance strongly improved AI creativity. Human and AI raters showed different judgment patterns.", "conclusion": "GenAI faces unique challenges in visual creativity domains where perceptual nuance and contextual sensitivity - distinctly human capacities - are crucial, unlike language-centered tasks."}}
{"id": "2511.17099", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.17099", "abs": "https://arxiv.org/abs/2511.17099", "authors": ["Aylar Partovizadeh", "Sebastian Sch\u00f6ps", "Dimitrios Loukrezis"], "title": "Multivariate Sensitivity Analysis of Electric Machine Efficiency Maps and Profiles Under Design Uncertainty", "comment": null, "summary": "This work proposes the use of multivariate global sensitivity analysis for assessing the impact of uncertain electric machine design parameters on efficiency maps and profiles. Contrary to the common approach of applying variance-based (Sobol') sensitivity analysis elementwise, multivariate sensitivity analysis provides a single sensitivity index per parameter, thus allowing for a holistic estimation of parameter importance over the full efficiency map or profile. Its benefits are demonstrated on permanent magnet synchronous machine models of different fidelity. Computations based on Monte Carlo sampling and polynomial chaos expansions are compared in terms of computational cost. The sensitivity analysis results are subsequently used to simplify the models, by fixing non-influential parameters to their nominal values and allowing random variations only for influential parameters. Uncertainty estimates obtained with the full and reduced models confirm the validity of model simplification guided by multivariate sensitivity analysis.", "AI": {"tldr": "Proposes multivariate global sensitivity analysis for electric machine design, providing holistic parameter importance assessments over efficiency maps, with model simplification applications.", "motivation": "Common variance-based sensitivity analysis approaches evaluate parameters elementwise, lacking a holistic view of parameter importance across entire efficiency maps/profiles.", "method": "Uses multivariate global sensitivity analysis with Monte Carlo sampling and polynomial chaos expansions on permanent magnet synchronous machine models of varying fidelity.", "result": "Multivariate analysis provides single sensitivity indices per parameter, enabling effective model simplification by fixing non-influential parameters while maintaining accurate uncertainty estimates.", "conclusion": "Multivariate sensitivity analysis is valid for holistic parameter importance assessment and effective model simplification in electric machine design, with reduced models maintaining accuracy comparable to full models."}}
{"id": "2511.17027", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17027", "abs": "https://arxiv.org/abs/2511.17027", "authors": ["Zhijie Chen", "Xiang Chen", "Ziming Li", "Jiacheng Xue", "Chaoyang Gao"], "title": "ReVul-CoT: Towards Effective Software Vulnerability Assessment with Retrieval-Augmented Generation and Chain-of-Thought Prompting", "comment": null, "summary": "Context: Software Vulnerability Assessment (SVA) plays a vital role in evaluating and ranking vulnerabilities in software systems to ensure their security and reliability. Objective: Although Large Language Models (LLMs) have recently shown remarkable potential in SVA, they still face two major limitations. First, most LLMs are trained on general-purpose corpora and thus lack domain-specific knowledge essential for effective SVA. Second, they tend to rely on shallow pattern matching instead of deep contextual reasoning, making it challenging to fully comprehend complex code semantics and their security implications. Method: To alleviate these limitations, we propose a novel framework ReVul-CoT that integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (COT) prompting. In ReVul-CoT, the RAG module dynamically retrieves contextually relevant information from a constructed local knowledge base that consolidates vulnerability data from authoritative sources (such as NVD and CWE), along with corresponding code snippets and descriptive information. Building on DeepSeek-V3.1, CoT prompting guides the LLM to perform step-by-step reasoning over exploitability, impact scope, and related factors Results: We evaluate ReVul-CoT on a dataset of 12,070 vulnerabilities. Experimental results show that ReVul-CoT outperforms state-of-the-art SVA baselines by 16.50%-42.26% in terms of MCC, and outperforms the best baseline by 10.43%, 15.86%, and 16.50% in Accuracy, F1-score, and MCC, respectively. Our ablation studies further validate the contributions of considering dynamic retrieval, knowledge integration, and CoT-based reasoning. Conclusion: Our results demonstrate that combining RAG with CoT prompting significantly enhances LLM-based SVA and points out promising directions for future research.", "AI": {"tldr": "\u63d0\u51faReVul-CoT\u6846\u67b6\uff0c\u7ed3\u5408RAG\u548cCoT\u63d0\u793a\uff0c\u89e3\u51b3LLM\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\u4e2d\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\u548c\u6d45\u5c42\u63a8\u7406\u7684\u95ee\u9898\uff0c\u572812,070\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\u4e2d\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\uff0c\u4ee5\u53ca\u4f9d\u8d56\u6d45\u5c42\u6a21\u5f0f\u5339\u914d\u800c\u975e\u6df1\u5ea6\u4e0a\u4e0b\u6587\u63a8\u7406\u3002", "method": "ReVul-CoT\u6846\u67b6\u96c6\u6210\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u601d\u7ef4\u94fe\u63d0\u793a\u3002RAG\u6a21\u5757\u4ece\u672c\u5730\u77e5\u8bc6\u5e93\u52a8\u6001\u68c0\u7d22\u6f0f\u6d1e\u6570\u636e\uff0cCoT\u63d0\u793a\u5f15\u5bfcLLM\u9010\u6b65\u63a8\u7406\u53ef\u5229\u7528\u6027\u3001\u5f71\u54cd\u8303\u56f4\u7b49\u56e0\u7d20\u3002", "result": "\u572812,070\u4e2a\u6f0f\u6d1e\u6570\u636e\u96c6\u4e0a\uff0cReVul-CoT\u5728MCC\u6307\u6807\u4e0a\u8d85\u8d8a\u6700\u5148\u8fdb\u57fa\u7ebf16.50%-42.26%\uff0c\u5728\u51c6\u786e\u7387\u3001F1\u5206\u6570\u548cMCC\u4e0a\u5206\u522b\u4f18\u4e8e\u6700\u4f73\u57fa\u7ebf10.43%\u300115.86%\u548c16.50%\u3002", "conclusion": "\u7ed3\u5408RAG\u4e0eCoT\u63d0\u793a\u80fd\u663e\u8457\u63d0\u5347\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u8bc4\u4f30\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u6709\u524d\u9014\u7684\u65b9\u5411\u3002"}}
{"id": "2511.16837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16837", "abs": "https://arxiv.org/abs/2511.16837", "authors": ["Oliver Kramer"], "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs", "comment": "6 pages, Submitted to ESANN 2026", "summary": "Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aCognitive BASIC\u7684\u7b80\u7ea6\u63d0\u793a\u8bed\u8a00\u548c\u6a21\u578b\u5185\u89e3\u91ca\u5668\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u7ed3\u6784\u5316\u4e3a\u660e\u786e\u7684\u9010\u6b65\u6267\u884c\u8f68\u8ff9", "motivation": "\u53d7\u5230\u590d\u53e4BASIC\u7b80\u5355\u6027\u7684\u542f\u53d1\uff0c\u65e8\u5728\u4e3aLLM\u521b\u5efa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u8ba4\u77e5\u63a7\u5236\u5c42\uff0c\u5b9e\u73b0\u900f\u660e\u7684\u591a\u6b65\u63a8\u7406", "method": "\u5229\u7528\u7f16\u53f7\u884c\u548c\u7b80\u5355\u547d\u4ee4\u4f5c\u4e3a\u8ba4\u77e5\u63a7\u5236\u5c42\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5668\u6587\u4ef6\u6307\u5b9a\u547d\u4ee4\u8bed\u4e49\u3001\u5185\u5b58\u66f4\u65b0\u548c\u65e5\u5fd7\u884c\u4e3a", "result": "\u5728\u4e09\u4e2aLLM\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u6709\u6a21\u578b\u90fd\u80fd\u6267\u884cCognitive BASIC\u7a0b\u5e8f\uff0c\u6574\u4f53\u8868\u73b0\u51fa\u5f3a\u52b2\u4f46\u975e\u5747\u5300\u7684\u6027\u80fd", "conclusion": "Cognitive BASIC\u6210\u529f\u5730\u5c06LLM\u63a8\u7406\u7ed3\u6784\u5316\uff0c\u5b9e\u73b0\u4e86\u900f\u660e\u7684\u591a\u6b65\u63a8\u7406\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u95f4\u5b58\u5728\u6027\u80fd\u5dee\u5f02"}}
{"id": "2511.17111", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.17111", "abs": "https://arxiv.org/abs/2511.17111", "authors": ["Sergio Torregrosa", "David Munoz", "Hector Navarro", "Charbel Farhat", "Francisco Chinesta"], "title": "Towards Generative Design Using Optimal Transport for Shape Exploration and Solution Field Interpolation", "comment": null, "summary": "Generative Design (GD) combines artificial intelligence (AI), physics-based modeling, and multi-objective optimization to autonomously explore and refine engineering designs. Despite its promise in aerospace, automotive, and other high-performance applications, current GD methods face critical challenges: AI approaches require large datasets and often struggle to generalize; topology optimization is computationally intensive and difficult to extend to multiphysics problems; and model order reduction for evolving geometries remains underdeveloped. To address these challenges, we introduce a unified, structure-preserving framework for GD based on optimal transport (OT), enabling simultaneous interpolation of complex geometries and their associated physical solution fields across evolving design spaces, even with non-matching meshes and substantial shape changes. This capability leverages Gaussian splatting to provide a continuous, mesh-independent representation of the solution and Wasserstein barycenters to enable smooth, mathematically ''mass''-preserving blending of geometries, offering a major advance over surrogate models tied to static meshes. Our framework efficiently interpolates positive scalar fields across arbitrarily shaped, evolving geometries without requiring identical mesh topology or dimensionality. OT also naturally preserves localized physical features -- such as stress concentrations or sharp gradients -- by conserving the spatial distribution of quantities, interpreted as ''mass'' in a mathematical sense, rather than averaging them, avoiding artificial smoothing. Preliminary extensions to signed and vector fields are presented. Representative test cases demonstrate enhanced efficiency, adaptability, and physical fidelity, establishing a foundation for future foundation-model-powered generative design workflows.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7684\u7edf\u4e00\u751f\u6210\u8bbe\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u975e\u5339\u914d\u7f51\u683c\u548c\u5927\u5e45\u51e0\u4f55\u53d8\u5316\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u6027\u3001\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u591a\u7269\u7406\u573a\u5efa\u6a21\u5c40\u9650\u6027\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u8bbe\u8ba1\u65b9\u6cd5\u9762\u4e34\u4e09\u5927\u6311\u6218\uff1aAI\u65b9\u6cd5\u9700\u8981\u5927\u6570\u636e\u4e14\u6cdb\u5316\u6027\u5dee\uff1b\u62d3\u6251\u4f18\u5316\u8ba1\u7b97\u91cf\u5927\u4e14\u96be\u4ee5\u6269\u5c55\u5230\u591a\u7269\u7406\u573a\u95ee\u9898\uff1b\u51e0\u4f55\u6f14\u5316\u7684\u6a21\u578b\u964d\u9636\u65b9\u6cd5\u4e0d\u6210\u719f\u3002", "method": "\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93\u7406\u8bba\u6784\u5efa\u7ed3\u6784\u4fdd\u6301\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u65af\u70b9\u6e32\u67d3\u63d0\u4f9b\u8fde\u7eed\u7f51\u683c\u65e0\u5173\u8868\u793a\uff0c\u5229\u7528Wasserstein\u8d28\u5fc3\u5b9e\u73b0\u51e0\u4f55\u5e73\u6ed1\u6df7\u5408\u3002", "result": "\u6d4b\u8bd5\u6848\u4f8b\u663e\u793a\u8be5\u6846\u67b6\u80fd\u9ad8\u6548\u63d2\u503c\u4efb\u610f\u5f62\u72b6\u6f14\u5316\u51e0\u4f55\u4e2d\u7684\u6807\u91cf\u573a\uff0c\u4fdd\u6301\u7269\u7406\u7279\u5f81\u7684\u7a7a\u95f4\u5206\u5e03\uff0c\u65e0\u9700\u76f8\u540c\u7f51\u683c\u62d3\u6251\u6216\u7ef4\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u57fa\u7840\u6a21\u578b\u9a71\u52a8\u7684\u751f\u6210\u8bbe\u8ba1\u5de5\u4f5c\u6d41\u7a0b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5728\u6548\u7387\u3001\u9002\u5e94\u6027\u548c\u7269\u7406\u4fdd\u771f\u5ea6\u65b9\u9762\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.16842", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16842", "abs": "https://arxiv.org/abs/2511.16842", "authors": ["Sang Truong", "Yuheng Tu", "Michael Hardy", "Anka Reuel", "Zeyu Tang", "Jirayu Burapacheep", "Jonathan Perera", "Chibuike Uwakwe", "Ben Domingue", "Nick Haber", "Sanmi Koyejo"], "title": "Fantastic Bugs and Where to Find Them in AI Benchmarks", "comment": null, "summary": "Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u7edf\u8ba1\u5206\u6790\u81ea\u52a8\u8bc6\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u65e0\u6548\u95ee\u9898\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u54cd\u5e94\u6a21\u5f0f\u5206\u6790\u6807\u8bb0\u6f5c\u5728\u95ee\u9898\u9898\u76ee\u4f9b\u4e13\u5bb6\u5ba1\u6838\uff0c\u5728\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523084%\u7684\u7cbe\u786e\u5ea6\uff0c\u5e76\u5f15\u5165LLM-judge\u521d\u6b65\u5ba1\u6838\u4ee5\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u57fa\u51c6\u6d4b\u8bd5\u5bf9AI\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u65e0\u6548\u95ee\u9898\u4f1a\u524a\u5f31\u5176\u53ef\u9760\u6027\u3002\u624b\u52a8\u68c0\u67e5\u6210\u5343\u4e0a\u4e07\u4e2a\u95ee\u9898\u4e0d\u53ef\u884c\uff0c\u6210\u4e3a\u53ef\u9760\u8bc4\u4f30\u7684\u5173\u952e\u74f6\u9888\u3002", "method": "\u57fa\u4e8eAI\u8bc4\u4f30\u4e2d\u5e38\u7528\u7684\u6838\u5fc3\u5047\u8bbe\uff08\u5e73\u5747\u5206\u8db3\u591f\u6982\u62ec\u6a21\u578b\u6027\u80fd\uff09\uff0c\u901a\u8fc7\u7edf\u8ba1\u5206\u6790\u54cd\u5e94\u6a21\u5f0f\uff0c\u5f53\u9898\u76ee\u7684\u7edf\u8ba1\u503c\u8d85\u51fa\u9884\u671f\u8303\u56f4\u65f6\u6807\u8bb0\u4e3a\u6f5c\u5728\u95ee\u9898\u9898\u76ee\u3002", "result": "\u5728\u4e5d\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6307\u5bfc\u4e13\u5bb6\u5ba1\u6838\u8bc6\u522b\u95ee\u9898\u9898\u76ee\u7684\u7cbe\u786e\u5ea6\u9ad8\u8fbe84%\u3002LLM-judge\u521d\u6b65\u5ba1\u6838\u8fdb\u4e00\u6b65\u51cf\u5c11\u4e86\u4eba\u5de5\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u5316\u57fa\u51c6\u6d4b\u8bd5\u4fee\u8ba2\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u7edf\u8ba1\u5206\u6790\u4e0e\u4e13\u5bb6\u5ba1\u6838\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.17226", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.17226", "abs": "https://arxiv.org/abs/2511.17226", "authors": ["Stefan Ivi\u0107", "Sini\u0161a Dru\u017eeta", "Luka Grb\u010di\u0107"], "title": "Randomness as Reference: Benchmark Metric for Optimization in Engineering", "comment": null, "summary": "Benchmarking optimization algorithms is fundamental for the advancement of computational intelligence. However, widely adopted artificial test suites exhibit limited correspondence with the diversity and complexity of real-world engineering optimization tasks. This paper presents a new benchmark suite comprising 231 bounded, continuous, unconstrained optimization problems, the majority derived from engineering design and simulation scenarios, including computational fluid dynamics and finite element analysis models. In conjunction with this suite, a novel performance metric is introduced, which employs random sampling as a statistical reference, providing nonlinear normalization of objective values and enabling unbiased comparison of algorithmic efficiency across heterogeneous problems. Using this framework, 20 deterministic and stochastic optimization methods were systematically evaluated through hundreds of independent runs per problem, ensuring statistical robustness. The results indicate that only a few of the tested optimization methods consistently achieve excellent performance, while several commonly used metaheuristics exhibit severe efficiency loss on engineering-type problems, emphasizing the limitations of conventional benchmarks. Furthermore, the conducted tests are used for analyzing various features of the optimization methods, providing practical guidelines for their application. The proposed test suite and metric together offer a transparent, reproducible, and practically relevant platform for evaluating and comparing optimization methods, thereby narrowing the gap between the available benchmark tests and realistic engineering applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5305\u542b231\u4e2a\u4f18\u5316\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548c\u6027\u80fd\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u4f18\u5316\u7b97\u6cd5\u5728\u5de5\u7a0b\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u4f18\u5316\u7b97\u6cd5\u57fa\u51c6\u6d4b\u8bd5\u96c6\u4e0e\u771f\u5b9e\u5de5\u7a0b\u95ee\u9898\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u5bf9\u5e94\u6709\u9650\uff0c\u9700\u8981\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u8bc4\u4f30\u5e73\u53f0\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8e\u5de5\u7a0b\u8bbe\u8ba1\u548c\u4eff\u771f\u573a\u666f\u7684\u6d4b\u8bd5\u96c6\uff0c\u5f15\u5165\u4f7f\u7528\u968f\u673a\u91c7\u6837\u4f5c\u4e3a\u7edf\u8ba1\u53c2\u8003\u7684\u65b0\u6027\u80fd\u5ea6\u91cf\uff0c\u5bf920\u79cd\u4f18\u5316\u65b9\u6cd5\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u5c11\u6570\u4f18\u5316\u65b9\u6cd5\u8868\u73b0\u4f18\u5f02\uff0c\u800c\u4e00\u4e9b\u5e38\u7528\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u5728\u5de5\u7a0b\u7c7b\u95ee\u9898\u4e0a\u6548\u7387\u4e25\u91cd\u4e0b\u964d\uff0c\u51f8\u663e\u4e86\u4f20\u7edf\u57fa\u51c6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d4b\u8bd5\u96c6\u548c\u5ea6\u91cf\u65b9\u6cd5\u4e3a\u4f18\u5316\u7b97\u6cd5\u7684\u8bc4\u4f30\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u590d\u5236\u4e14\u5b9e\u7528\u7684\u5e73\u53f0\uff0c\u7f29\u5c0f\u4e86\u57fa\u51c6\u6d4b\u8bd5\u4e0e\u5de5\u7a0b\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2511.17262", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17262", "abs": "https://arxiv.org/abs/2511.17262", "authors": ["Jinfeng Wen", "Yuehan Sun"], "title": "SlsReuse: LLM-Powered Serverless Function Reuse", "comment": null, "summary": "Serverless computing has rapidly emerged as a popular cloud computing paradigm. It enables developers to implement function-level tasks, i.e., serverless functions, without managing infrastructure. While reducing operational overhead, it poses challenges, especially for novice developers. Developing functions from scratch requires adapting to heterogeneous, platform-specific programming styles, making the process time-consuming and error-prone. Function reuse offers a promising solution to address these challenges. However, research on serverless computing lacks a dedicated approach for function recommendation. Existing techniques from traditional contexts remain insufficient due to the semantic gap between task descriptions and heterogeneous function implementations. Advances in large language models (LLMs), pre-trained on large-scale corpora, create opportunities to bridge this gap by aligning developer requirements with function semantics.\n  This paper presents SlsReuse, the first LLM-powered framework for serverless function reuse. Specifically, SlsReuse first constructs a reusable function repository serving as a foundational knowledge base. Then, it learns unified semantic-enhanced representations of heterogeneous functions through effective prompt engineering with few-shot prompting, capturing implicit code intent, target platforms, programming languages, and cloud services. Finally, given a natural language task query, SlsReuse performs intent-aware discovery combined with a multi-level pruning strategy and similarity matching. We evaluate SlsReuse on a curated dataset of 110 task queries. Built on ChatGPT-4o, one of the most representative LLMs, SlsReuse achieves Recall@10 of 91.20%, exceeding the state-of-the-art baseline by 24.53 percentage points.", "AI": {"tldr": "SlsReuse\u662f\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7b2c\u4e00\u4e2a\u670d\u52a1\u5668less\u51fd\u6570\u91cd\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u53ef\u91cd\u7528\u51fd\u6570\u5e93\u548c\u4f7f\u7528\u63d0\u793a\u5de5\u7a0b\u5b66\u4e60\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff0c\u5b9e\u73b0\u51fd\u6570\u63a8\u8350\uff0c\u5728ChatGPT-4o\u4e0a\u8fbe\u523091.20%\u7684Recall@10", "motivation": "\u670d\u52a1\u5668less\u8ba1\u7b97\u867d\u7136\u51cf\u5c11\u8fd0\u8425\u5f00\u9500\uff0c\u4f46\u5bf9\u65b0\u624b\u5f00\u53d1\u8005\u9762\u4e34\u6311\u6218\uff1a\u4ece\u5934\u5f00\u53d1\u51fd\u6570\u9700\u8981\u9002\u5e94\u5f02\u6784\u7684\u5e73\u53f0\u7279\u5b9a\u7f16\u7a0b\u98ce\u683c\uff0c\u8fc7\u7a0b\u8017\u65f6\u4e14\u6613\u9519\u3002\u73b0\u6709\u4f20\u7edf\u63a8\u8350\u6280\u672f\u56e0\u4efb\u52a1\u63cf\u8ff0\u4e0e\u5f02\u6784\u51fd\u6570\u5b9e\u73b0\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\u800c\u4e0d\u8db3\u3002", "method": "SlsReuse\u6846\u67b6\u6784\u5efa\u53ef\u91cd\u7528\u51fd\u6570\u5e93\u4f5c\u4e3a\u57fa\u7840\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u5c11\u91cf\u63d0\u793a\u7684\u6709\u6548\u63d0\u793a\u5de5\u7a0b\u5b66\u4e60\u5f02\u6784\u51fd\u6570\u7684\u7edf\u4e00\u8bed\u4e49\u589e\u5f3a\u8868\u793a\uff0c\u7ed3\u5408\u610f\u56fe\u611f\u77e5\u53d1\u73b0\u3001\u591a\u7ea7\u526a\u679d\u7b56\u7565\u548c\u76f8\u4f3c\u6027\u5339\u914d\u8fdb\u884c\u51fd\u6570\u63a8\u8350\u3002", "result": "\u5728110\u4e2a\u4efb\u52a1\u67e5\u8be2\u7684\u7b56\u5212\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u57fa\u4e8eChatGPT-4o\u7684SlsReuse\u8fbe\u523091.20%\u7684Recall@10\uff0c\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u9ad8\u51fa24.53\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "SlsReuse\u901a\u8fc7LLM\u6709\u6548\u6865\u63a5\u5f00\u53d1\u8005\u9700\u6c42\u4e0e\u51fd\u6570\u8bed\u4e49\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u670d\u52a1\u5668less\u51fd\u6570\u91cd\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51fd\u6570\u63a8\u8350\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2511.16916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16916", "abs": "https://arxiv.org/abs/2511.16916", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving", "comment": null, "summary": "In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.", "AI": {"tldr": "Proposes a Hybrid Differential Reward (HDR) mechanism to address vanishing reward differences in multi-vehicle control, combining temporal and action-based rewards to improve policy learning.", "motivation": "Traditional state-based rewards in multi-agent driving tasks suffer from low signal-to-noise ratios due to temporal quasi-steady states and action proximity, hindering convergence.", "method": "HDR integrates Temporal Difference Reward (based on global potential function) and Action Gradient Reward (measuring action utility) within a Multi-Agent POMDP framework.", "result": "Experiments with MCTS, QMIX, MAPPO, and MADDPG show HDR significantly improves convergence speed, stability, and policy quality in cooperative driving.", "conclusion": "HDR effectively balances traffic efficiency and safety by providing high-SNR guidance, overcoming limitations of traditional reward structures."}}
{"id": "2511.16716", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16716", "abs": "https://arxiv.org/abs/2511.16716", "authors": ["Maurizio Atzori", "Eleonora Cal\u00f2", "Loredana Caruccio", "Stefano Cirillo", "Giuseppe Polese", "Giandomenico Solimando"], "title": "Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models", "comment": "This is a post-peer-review, pre-copyedit version to be published in the Prooceedings of the 33rd Symposium On Advanced Database Systems (SEBD 2025), 7 pages, 4 figures", "summary": "Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SODA ADVANCE\u5de5\u5177\uff0c\u7528\u4e8e\u6539\u8fdb\u5bc6\u7801\u5f3a\u5ea6\u8bc4\u4f30\uff0c\u5e76\u7814\u7a76\u4e86LLMs\u5728\u5bc6\u7801\u751f\u6210\u548c\u8bc4\u4f30\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5bc6\u7801\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\uff0c\u7528\u6237\u503e\u5411\u4e8e\u4f7f\u7528\u6613\u8bb0\u4f46\u8106\u5f31\u7684\u5bc6\u7801\uff0c\u5bfc\u81f4\u5b89\u5168\u98ce\u9669\u589e\u52a0\u3002", "method": "\u5f00\u53d1SODA ADVANCE\u5de5\u5177\uff0c\u96c6\u6210\u591a\u6e90\u516c\u5f00\u6570\u636e\u8bc4\u4f30\u5bc6\u7801\u5f3a\u5ea6\uff1b\u6d4b\u8bd5LLMs\u5728\u5bc6\u7801\u751f\u6210\u548c\u8bc4\u4f30\u4e2d\u7684\u8868\u73b0\uff0c\u6d89\u53ca100\u540d\u771f\u5b9e\u7528\u6237\u7684\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u663e\u793aLLMs\u80fd\u751f\u6210\u5f3a\u4e14\u4e2a\u6027\u5316\u7684\u5bc6\u7801\uff0c\u5e76\u5728\u8003\u8651\u7528\u6237\u8d44\u6599\u65f6\u6709\u6548\u8bc4\u4f30\u5bc6\u7801\u5f3a\u5ea6\u3002", "conclusion": "LLMs\u5728\u5bc6\u7801\u5b89\u5168\u9886\u57df\u5177\u6709\u6f5c\u529b\uff0cSODA ADVANCE\u5de5\u5177\u6709\u52a9\u4e8e\u63d0\u5347\u5bc6\u7801\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2511.17271", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17271", "abs": "https://arxiv.org/abs/2511.17271", "authors": ["Sebastian B\u00f6hm", "Florian Sattler", "Norbert Siegmund", "Sven Apel"], "title": "Detecting Performance-Relevant Changes in Configurable Software Systems", "comment": null, "summary": "Performance is a volatile property of a software system and frequent performance profiling is required to keep the knowledge about a software system's performance behavior up to date. Repeating all performance measurements after every revision is a cost-intensive task, especially in the presence of configurability, where one has to measure multiple configurations to obtain a comprehensive picture. Configuration sampling is a common approach to control the measurement cost. However, it cannot guarantee completeness and might miss performance regressions, especially if they only affect few configurations. As an alternative to solve the cost reduction problem, we present ConfFLARE: ConfFLARE estimates whether a change potentially impacts performance by identifying data-flow interactions with performance-relevant code and extracts which software features participate in such interactions. Based on these features, we can select a subset of relevant configurations to focus performance profiling efforts on. In a study conducted on both, synthetic and real-world software systems, ConfFLARE correctly detects performance regressions in almost all cases and identifies relevant features in all but two cases, reducing the number of configurations to be tested on average by $79\\%$ for synthetic and by $70\\%$ for real-world regression scenarios saving hours of performance testing time.", "AI": {"tldr": "ConfFLARE is a method that reduces performance testing costs by identifying performance-relevant code interactions and selecting optimal configuration subsets.", "motivation": "Frequent performance profiling is expensive, especially for configurable systems where testing all configurations is costly.", "method": "Identifies data-flow interactions with performance-relevant code and selects configurations based on affected features.", "result": "Reduces configurations by 79% (synthetic) and 70% (real-world) while maintaining high regression detection accuracy.", "conclusion": "ConfFLARE effectively minimizes performance testing effort while reliably detecting performance regressions."}}
{"id": "2511.16961", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16961", "abs": "https://arxiv.org/abs/2511.16961", "authors": ["Erik P. Nyberg", "Steven Mascaro", "Ingrid Zukerman", "Michael Wybrow", "Duc-Minh Vo", "Ann Nicholson"], "title": "Comparing verbal, visual and combined explanations for Bayesian Network inferences", "comment": "26 pages total, 12 pages main, 14 pages for 5 appendices", "summary": "Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.\n  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.", "AI": {"tldr": "Study comparing verbal, visual, and combined UI extensions for Bayesian Networks, showing improved user performance over baseline for understanding probabilistic reasoning.", "motivation": "Bayesian Networks are considered transparent but users struggle to understand them; current UIs do not sufficiently clarify the reasoning process.", "method": "Designed verbal and visual UI extensions to guide users through inference patterns, conducted a user study comparing these extensions against a baseline UI.", "result": "Users performed better with all extension types than baseline for questions about observation impact, enabling paths, and influence of observations; combined modality was best for some tasks.", "conclusion": "UI extensions, especially combining verbal and visual modalities, can significantly improve user comprehension of Bayesian Network reasoning."}}
{"id": "2511.17303", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17303", "abs": "https://arxiv.org/abs/2511.17303", "authors": ["Timmie M. R. Lagermann", "Kristina Sophia Carter", "Su Mei Gwen Ho", "Lu\u00eds Cruz", "Kerstin Eder", "Maja H. Kirkeby"], "title": "Framework Matters: Energy Efficiency of UI Automation Testing Frameworks", "comment": "10 pages, 6 figures, submitted to The 41st ACM/SIGAPP Symposium On Applied Computing (SAC2026)", "summary": "We examine per action energy consumption across four web user interface (UI) automation testing frameworks to determine whether consistent tendencies can guide energy-aware test design. Using a controlled client-server setup with external power metering, we repeat each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times. Across each of the actions, energy costs vary by both framework and action. Puppeteer is the most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium is the most efficient for refresh and scroll; Nightwatch is generally the least energy efficient. The energy cost of performing the same action varied by up to a factor of six depending on the framework. This indicates that providing transparency of energy consumption for UI automation testing frameworks allows developers to make informed, energy-aware decisions when testing a specific UI action.", "AI": {"tldr": "This paper compares energy consumption of four web UI automation testing frameworks (Puppeteer, Selenium, Nightwatch) across different UI actions, finding significant energy variations (up to 6x) between frameworks.", "motivation": "To provide transparency about energy consumption differences between web UI testing frameworks, enabling developers to make energy-aware decisions when selecting frameworks for specific UI actions.", "method": "Controlled client-server setup with external power metering, repeating each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times across four frameworks.", "result": "Puppeteer was most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium was most efficient for refresh and scroll; Nightwatch was generally least energy efficient.", "conclusion": "Significant energy cost variations (up to 6x) exist between frameworks for the same actions, highlighting the importance of energy transparency for informed framework selection in UI testing."}}
{"id": "2511.16792", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16792", "abs": "https://arxiv.org/abs/2511.16792", "authors": ["Mona Khalil", "Alberto Blanco-Justicia", "Najeeb Jebreel", "Josep Domingo-Ferrer"], "title": "Membership Inference Attacks Beyond Overfitting", "comment": null, "summary": "Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.", "AI": {"tldr": "This paper investigates membership inference attacks (MIAs) beyond overfitting, finding that outliers in training data are vulnerable even in generalized models, and proposes targeted defenses to protect these samples.", "motivation": "To understand root causes of MIA vulnerabilities in non-overfitted ML models and develop effective defenses without sacrificing accuracy like differential privacy often does.", "method": "Empirical analysis of training data characteristics vulnerable to MIAs in models that can generalize well, focusing on identifying outlier samples.", "result": "Found that vulnerable samples are typically outliers within their classes (noisy or hard-to-classify data points) rather than just overfitted samples.", "conclusion": "Targeted defensive strategies can protect vulnerable outlier training samples to enhance ML model privacy without the significant accuracy costs of broader defenses like differential privacy."}}
{"id": "2511.17330", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17330", "abs": "https://arxiv.org/abs/2511.17330", "authors": ["Haoxin Tu", "Huan Zhao", "Yahui Song", "Mehtab Zafar", "Ruijie Meng", "Abhik Roychoudhury"], "title": "Agentic Program Verification", "comment": "21 pages, 8 figures", "summary": "Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.\n  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.\n  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7528\u4e8e\u7a0b\u5e8f\u9a8c\u8bc1\u7684LLM\u667a\u80fd\u4f53AutoRocq\uff0c\u5b83\u901a\u8fc7\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u7684\u81ea\u4e3b\u534f\u4f5c\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u6837\u672c\u7684\u8fed\u4ee3\u5f0f\u8bc1\u660e\u751f\u6210\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u6765\u9a8c\u8bc1\u8fd9\u4e9b\u4ee3\u7801\u7684\u6b63\u786e\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u800c\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u5373\u65f6\u5b66\u4e60\u5b9e\u73b0\u7a0b\u5e8f\u9a8c\u8bc1\u3002", "method": "AutoRocq\u901a\u8fc7\u8fed\u4ee3\u7ec6\u5316\u5faa\u73af\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u4ea4\u4e92\uff0c\u83b7\u53d6\u4e0a\u4e0b\u6587\u53cd\u9988\uff0c\u81ea\u4e3b\u6784\u5efa\u7ecf\u8bc1\u660e\u5668\u9a8c\u8bc1\u7684\u63a8\u5bfc\u8fc7\u7a0b\u3002", "result": "\u5728SV-COMP\u57fa\u51c6\u6d4b\u8bd5\u548cLinux\u5185\u6838\u6a21\u5757\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u65b9\u9762\u5177\u6709\u826f\u597d\u6548\u679c\u3002", "conclusion": "\u8be5\u9a8c\u8bc1\u667a\u80fd\u4f53\u672a\u6765\u53ef\u4e0eAI\u4ee3\u7801\u751f\u6210\u5668\u96c6\u6210\uff0c\u5f62\u6210'\u751f\u6210-\u9a8c\u8bc1'\u5faa\u73af\uff0c\u63a8\u52a8\u53ef\u4fe1\u81ea\u52a8\u7f16\u7a0b\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.17006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17006", "abs": "https://arxiv.org/abs/2511.17006", "authors": ["Tengxiao Liu", "Zifeng Wang", "Jin Miao", "I-Hung Hsu", "Jun Yan", "Jiefeng Chen", "Rujun Han", "Fangyuan Xu", "Yanfei Chen", "Ke Jiang", "Samira Daruki", "Yi Liang", "William Yang Wang", "Tomas Pfister", "Chen-Yu Lee"], "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling", "comment": null, "summary": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u63d0\u5347\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u7684\u6269\u5c55\u6027\u80fd\uff0c\u901a\u8fc7Budget Tracker\u548cBATS\u6846\u67b6\u5b9e\u73b0\u52a8\u6001\u89c4\u5212\uff0c\u7edf\u4e00\u6210\u672c\u5ea6\u91cf\u5206\u6790\u6210\u672c-\u6027\u80fd\u5173\u7cfb\u3002", "motivation": "\u5f53\u524d\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u5728\u589e\u52a0\u5de5\u5177\u8c03\u7528\u9884\u7b97\u65f6\u7f3a\u4e4f\u9884\u7b97\u610f\u8bc6\uff0c\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u65b9\u6cd5\u89e3\u51b3\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u6709\u6548\u6269\u5c55\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8f7b\u91cf\u7ea7Budget Tracker\u63d2\u4ef6\u63d0\u4f9b\u6301\u7eed\u9884\u7b97\u611f\u77e5\uff0c\u5f00\u53d1BATS\u6846\u67b6\u52a8\u6001\u8c03\u6574\u89c4\u5212\u548c\u9a8c\u8bc1\u7b56\u7565\uff0c\u7edf\u4e00\u5316token\u548c\u5de5\u5177\u8c03\u7528\u7684\u6210\u672c\u5ea6\u91cf\u3002", "result": "\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u4ea7\u751f\u66f4\u4f18\u7684\u6269\u5c55\u66f2\u7ebf\uff0c\u63d0\u5347\u6210\u672c-\u6027\u80fd\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u5728\u53d7\u63a7\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u9884\u7b97\u611f\u77e5\u662f\u5b9e\u73b0\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u900f\u660e\u548c\u539f\u5219\u6027\u6269\u5c55\u7684\u5173\u952e\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2511.17070", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17070", "abs": "https://arxiv.org/abs/2511.17070", "authors": ["Robert Krahn", "Nikson Kanti Paul", "Franz Gregor", "Do Le Quoc", "Andrey Brito", "Andr\u00e9 Martin", "Christof Fetzer"], "title": "TICAL: Trusted and Integrity-protected Compilation of AppLications", "comment": "19th European Dependable Computing Conference (EDCC) 2024", "summary": "During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system.In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.", "AI": {"tldr": "Tical\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u53ef\u4fe1\u7f16\u8bd1\u6846\u67b6\uff0c\u5728\u6574\u4e2a\u6784\u5efa\u6d41\u6c34\u7ebf\u4e2d\uff08\u4ece\u6e90\u4ee3\u7801\u5230\u6700\u7ec8\u53ef\u6267\u884c\u6587\u4ef6\uff09\u63d0\u4f9b\u5b8c\u6574\u6027\u4fdd\u62a4\u548c\u4fdd\u5bc6\u6027\uff0c\u89e3\u51b3\u6784\u5efa\u65f6\u4fdd\u62a4\u5e38\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u786c\u4ef6\u6269\u5c55\uff08\u5982Intel SGX\u3001TDX\u3001AMD SEV\u7b49\uff09\u4e3a\u4e0d\u53ef\u4fe1\u73af\u5883\u4e2d\u7684\u5e94\u7528\u7a0b\u5e8f\u63d0\u4f9b\u4e86\u8fd0\u884c\u65f6\u4fdd\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u4fdd\u62a4\uff0c\u4f46\u6784\u5efa\u65f6\u7684\u4fdd\u62a4\u548c\u673a\u5bc6\u6027\u5e38\u88ab\u5ffd\u89c6\uff0c\u6076\u610f\u6ce8\u5165\u7684\u4ee3\u7801\u53ef\u80fd\u5728\u7f16\u8bd1\u65f6\u7834\u574f\u6574\u4e2a\u7cfb\u7edf\u548c\u5e94\u7528\u3002", "method": "\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\uff08TEEs\uff09\u4f5c\u4e3a\u8fd0\u884c\u65f6\u4fdd\u62a4\uff0c\u5e76\u901a\u8fc7\u6587\u4ef6\u7cfb\u7edf\u5c4f\u853d\u548c\u5e26\u6709\u7248\u672c\u5386\u53f2\u7684\u4e0d\u53ef\u53d8\u5ba1\u8ba1\u65e5\u5fd7\u589e\u5f3aTEEs\uff0c\u786e\u4fdd\u7f16\u8bd1\u94fe\u53ea\u80fd\u8bbf\u95ee\u53ef\u4fe1\u6587\u4ef6\u548c\u53ef\u4fe1\u8fdb\u7a0b\u751f\u6210\u7684\u4e2d\u95f4\u8f93\u51fa\u3002", "result": "\u4f7f\u7528\u5fae\u57fa\u51c6\u548c\u5b8f\u57fa\u51c6\u8fdb\u884c\u7684\u8bc4\u4f30\u8868\u660e\uff0cTical\u80fd\u4ee5\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5f00\u9500\u4fdd\u62a4\u6574\u4e2aCI/CD\u6d41\u6c34\u7ebf\u7684\u4fdd\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u3002", "conclusion": "Tical\u662f\u4e00\u4e2a\u5b9e\u7528\u7684\u53ef\u4fe1\u7f16\u8bd1\u6846\u67b6\uff0c\u586b\u8865\u4e86\u6784\u5efa\u65f6\u4fdd\u62a4\u7684\u7a7a\u7f3a\uff0c\u5e76\u901a\u8fc7\u589e\u5f3a\u7684TEE\u673a\u5236\u5b9e\u73b0\u4e86\u6784\u5efa\u6d41\u6c34\u7ebf\u7684\u7aef\u5230\u7aef\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2511.17368", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17368", "abs": "https://arxiv.org/abs/2511.17368", "authors": ["Eric L. Melin", "Ahmed Musa Awon", "Nasir U. Eisty", "Neil A. Ernst", "Shurui Zhou"], "title": "Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software", "comment": "11 pages, 2 figures, 6 tables", "summary": "Developers often leave behind clues in their code, admitting where it falls short, known as Self-Admitted Technical Debt (SATD). In the world of Scientific Software (SSW), where innovation moves fast and collaboration is key, such debt is not just common but deeply impactful. As research relies on accurate and reproducible results, accumulating SATD can threaten the very foundations of scientific discovery. Yet, despite its significance, the relationship between SATD and SSW remains largely unexplored, leaving a crucial gap in understanding how to manage SATD in this critical domain. This study explores SATD in SSW repositories, comparing SATD in scientific versus general-purpose open-source software and evaluating transformer-based models for SATD identification. We analyzed SATD in 27 scientific and general-purpose repositories across multiple domains and languages. We fine-tuned and compared 10 transformer-based models (100M-7B parameters) on 67,066 labeled code comments. SSW contains 9.25x more Scientific Debt and 4.93x more SATD than general-purpose software due to complex computations, domain constraints, and evolving research needs. Furthermore, our best model outperforms existing ones. This study uncovers how SATD in SSW differs from general software, revealing its impact on quality and scientific validity. By recognizing these challenges, developers and researchers can adopt smarter strategies to manage debt and safeguard the integrity of scientific discovery.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u7684\u81ea\u8ba4\u6280\u672f\u503a\u52a1\uff0c\u53d1\u73b0\u5728\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u5b58\u5728\u6bd4\u901a\u7528\u8f6f\u4ef6\u9ad89.25\u500d\u7684\u79d1\u5b66\u503a\u52a1\u548c4.93\u500d\u7684SATD\uff0c\u5e76\u8bc1\u660e\u57fa\u4e8etransformer\u7684\u6a21\u578b\u5728\u8bc6\u522bSATD\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002", "motivation": "\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u7684\u81ea\u8ba4\u6280\u672f\u503a\u52a1\u5bf9\u7814\u7a76\u7ed3\u679c\u7684\u51c6\u786e\u6027\u548c\u53ef\u91cd\u73b0\u6027\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u4f46\u76ee\u524d\u79d1\u5b66\u8f6f\u4ef6\u4e0eSATD\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5206\u6790\u4e8627\u4e2a\u79d1\u5b66\u548c\u901a\u7528\u8f6f\u4ef6\u4ed3\u5e93\uff0c\u572867,066\u4e2a\u6807\u6ce8\u4ee3\u7801\u6ce8\u91ca\u4e0a\u5fae\u8c03\u6bd4\u8f83\u4e8610\u4e2a\u57fa\u4e8etransformer\u7684\u6a21\u578b\u3002", "result": "\u79d1\u5b66\u8f6f\u4ef6\u4e2d\u7684SATD\u663e\u8457\u9ad8\u4e8e\u901a\u7528\u8f6f\u4ef6\uff0c\u6700\u4f73\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u79d1\u5b66\u8f6f\u4ef6\u4e2dSATD\u7684\u7279\u6b8a\u6027\u53ca\u5176\u5bf9\u79d1\u5b66\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u4e3a\u5f00\u53d1\u8005\u7ba1\u7406\u6280\u672f\u503a\u52a1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2511.17038", "categories": ["cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.17038", "abs": "https://arxiv.org/abs/2511.17038", "authors": ["Hao Chen", "Renzheng Zhang", "Scott S. Howard"], "title": "DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing", "comment": null, "summary": "From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \\textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \\textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86DAPS++\u65b9\u6cd5\uff0c\u91cd\u65b0\u89e3\u91ca\u6269\u6563\u6a21\u578b\u5728\u9006\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u89d2\u8272\uff0c\u5c06\u5176\u4f5c\u4e3a\u671f\u671b\u6700\u5927\u5316\u6846\u67b6\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u7684\u91cd\u5efa\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u8d1d\u53f6\u65af\u89c6\u89d2\u7684\u5f97\u5206\u6269\u6563\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff1a\u5148\u9a8c\u63d0\u4f9b\u7684\u5f15\u5bfc\u6709\u9650\uff0c\u91cd\u5efa\u4e3b\u8981\u7531\u6d4b\u91cf\u4e00\u81f4\u6027\u9879\u9a71\u52a8\uff0c\u4e0e\u6269\u6563\u52a8\u529b\u5b66\u6709\u6548\u89e3\u8026\u3002\u9700\u8981\u66f4\u6e05\u6670\u5730\u89e3\u91ca\u8fd9\u4e00\u7ed3\u6784\u3002", "method": "\u5c06\u6269\u6563\u91cd\u65b0\u89e3\u91ca\u4e3a\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u6846\u67b6\u4e2d\u7684\u521d\u59cb\u5316\u9636\u6bb5\uff0c\u4f7f\u6269\u6563\u9636\u6bb5\u548c\u6570\u636e\u9a71\u52a8\u7ec6\u5316\u5b8c\u5168\u89e3\u8026\u3002\u63d0\u51fa\u7684DAPS++\u65b9\u6cd5\u5141\u8bb8\u4f3c\u7136\u9879\u66f4\u76f4\u63a5\u5730\u6307\u5bfc\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u503c\u7a33\u5b9a\u6027\u3002", "result": "DAPS++\u901a\u8fc7\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\u548c\u6d4b\u91cf\u4f18\u5316\u6b65\u9aa4\uff0c\u5728\u591a\u79cd\u56fe\u50cf\u590d\u539f\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u9c81\u68d2\u7684\u91cd\u5efa\u6027\u80fd\u3002", "conclusion": "DAPS++\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5bf9\u7edf\u4e00\u6269\u6563\u8f68\u8ff9\u5728\u5b9e\u8df5\u4e2d\u4fdd\u6301\u6709\u6548\u7684\u7406\u8bba\u89e3\u91ca\uff0c\u5e76\u4e3a\u9006\u95ee\u9898\u6c42\u89e3\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7a33\u5b9a\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17417", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17417", "abs": "https://arxiv.org/abs/2511.17417", "authors": ["Soroush Javdan", "Pragash Krishnamoorthy", "Olga Baysal"], "title": "CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval", "comment": null, "summary": "The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \\textbf{CREST} (\\textbf{C}riteria-specific \\textbf{R}etrieval via \\textbf{E}nsemble of \\textbf{S}pecialized \\textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51faCREST\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e13\u95e8\u5316\u6a21\u578b\u5904\u7406\u7535\u4fe1\u6545\u969c\u62a5\u544a\u7684\u4e0d\u540c\u6807\u51c6\uff0c\u63d0\u5347\u68c0\u7d22\u6548\u679c\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u7535\u4fe1\u884c\u4e1a\u6545\u969c\u62a5\u544a\u6570\u636e\u590d\u6742\u591a\u6837\uff0c\u73b0\u6709\u68c0\u7d22\u7cfb\u7edf\u96be\u4ee5\u6709\u6548\u5904\u7406\u4e0d\u540c\u6807\u51c6\u7684\u6545\u969c\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u5de5\u4f5c\u6d41\uff08\u521d\u59cb\u68c0\u7d22\u548c\u91cd\u6392\u5e8f\uff09\uff0c\u4e3a\u4e0d\u540cTR\u6807\u51c6\u8bad\u7ec3\u4e13\u95e8\u6a21\u578b\u5e76\u96c6\u6210\u8f93\u51fa\u3002", "result": "\u5728\u7231\u7acb\u4fe1\u5185\u90e8TR\u6570\u636e\u4e0a\u9a8c\u8bc1\uff0cCREST\u5728\u5173\u952e\u8bc4\u4f30\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u5355\u4e00\u6a21\u578b\u65b9\u6cd5\u3002", "conclusion": "\u9488\u5bf9\u4e0d\u540c\u6807\u51c6\u4f7f\u7528\u4e13\u95e8\u5316\u6a21\u578b\u80fd\u4f18\u5316\u68c0\u7d22\u7cfb\u7edf\u6027\u80fd\uff0c\u63d0\u9ad8\u6545\u969c\u89e3\u51b3\u6548\u7387\u3002"}}
{"id": "2511.17056", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17056", "abs": "https://arxiv.org/abs/2511.17056", "authors": ["Paloma Rabaey", "Adrick Tench", "Stefan Heytens", "Thomas Demeester"], "title": "Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks", "comment": null, "summary": "Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.", "AI": {"tldr": "A multi-modal approach combining structured EHR data (via Bayesian network) and unstructured clinical notes (via neural classifiers) for patient-level information extraction, enhanced with virtual evidence and consistency nodes for better prediction calibration.", "motivation": "EHRs contain valuable but fragmented information across structured (diagnosis codes, medications) and unstructured (clinical notes) formats, requiring effective fusion methods for reliable clinical decision support systems.", "method": "Proposes a probabilistic fusion method using: 1) Expert-informed Bayesian network for tabular EHR features 2) Neural text classifiers for clinical notes 3) Virtual evidence augmented with consistency nodes to handle missing information and resolve contradictions", "result": "The method improves prediction calibration compared to using virtual evidence alone, effectively handling data inconsistencies between structured and unstructured sources on the SimSUM benchmark dataset.", "conclusion": "The proposed multi-modal fusion approach provides an interpretable framework that leverages both structured and unstructured EHR data while addressing challenges like missing information and contradictory evidence through probabilistic consistency modeling."}}
{"id": "2511.17118", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17118", "abs": "https://arxiv.org/abs/2511.17118", "authors": ["Leo Kao"], "title": "Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows", "comment": "12 pages. Preprint on cryptographic evidence and compliance for regulated AI workflows", "summary": "This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.", "AI": {"tldr": "This paper proposes constant-size cryptographic evidence structures for verifiable audit trails in regulated AI workflows, providing fixed-size tuples that ensure integrity, efficient storage/verification, and compatibility with hash-chains and Merkle trees.", "motivation": "Need for cryptographic verification of AI workflow events in regulated environments (e.g., clinical trials) where audit integrity and non-repudiation are critical, inspired by industrial experience at Codebat Technologies.", "method": "Formalizes regulated AI workflows, defines evidence structure syntax/algorithms, and presents a hash-and-sign construction using collision-resistant hash functions and digital signatures. Integrates with hash-chains, Merkle trees, and trusted execution environments.", "result": "Achieves constant-size storage and uniform verification cost per event. Prototype implementation shows small, predictable per-event overhead on commodity hardware.", "conclusion": "The constant-size evidence abstraction enables practical, verifiable audit trails for regulated AI systems, with applications in clinical trial management and medical AI governance."}}
{"id": "2511.17464", "categories": ["cs.CR", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17464", "abs": "https://arxiv.org/abs/2511.17464", "authors": ["Tanzim Hossain Romel", "Kawshik Kumar Paul", "Tanberul Islam Ruhan", "Maisha Rahman Mim", "Abu Sayed Md. Latiful Hoque"], "title": "A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control", "comment": null, "summary": "We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u60a3\u8005\u4e2d\u5fc3\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5171\u4eab\u67b6\u6784\uff0c\u5b9e\u73b0\u5b58\u50a8\u4e0e\u6388\u6743\u5206\u79bb\uff0c\u4fdd\u8bc1\u5b89\u5168\u6027\u7684\u540c\u65f6\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u60a3\u8005\u6570\u636e\u63a7\u5236\u6743\u5f31\u3001\u9690\u79c1\u4fdd\u62a4\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6ee1\u8db3\u533b\u7597\u6570\u636e\u7684\u5b89\u5168\u5408\u89c4\u8981\u6c42\u3002", "method": "\u91c7\u7528\u94fe\u4e0b\u5b58\u50a8\u52a0\u5bc6FHIR\u8d44\u6e90\uff0c\u94fe\u4e0a\u8bb0\u5f55\u52a0\u5bc6\u627f\u8bfa\u548c\u65f6\u9650\u6743\u9650\uff1b\u4f7f\u7528\u516c\u94a5\u5305\u88c5\u5206\u53d1\u5bc6\u94a5\uff0cSolidity\u667a\u80fd\u5408\u7ea6\u5b9e\u73b0\u3002", "result": "\u6743\u9650\u6388\u4e88\u5e73\u5747gas\u6210\u672c78000\uff08L1\uff09\uff0c1MB\u8bb0\u5f55\u7aef\u5230\u7aef\u8bbf\u95ee\u5ef6\u8fdf0.7-1.4\u79d2\uff1bLayer-2\u90e8\u7f72\u53ef\u964d\u4f4egas\u6d88\u801710-13\u500d\u3002", "conclusion": "\u8be5\u67b6\u6784\u5728\u4fdd\u6301\u4e34\u5e8a\u6570\u636e\u5b89\u5168\u6027\u7684\u540c\u65f6\u6709\u6548\u6062\u590d\u60a3\u8005\u63a7\u5236\u6743\uff0c\u4e3aHIPAA/GDPR\u5408\u89c4\u63d0\u4f9b\u4e86\u53ef\u884c\u8def\u5f84\u3002"}}
{"id": "2511.17162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17162", "abs": "https://arxiv.org/abs/2511.17162", "authors": ["Sara Zuppiroli", "Carmelo Fabio Longo", "Anna Sofia Lippolis", "Rocco Paolillo", "Lorenzo Giammei", "Miguel Ceriani", "Francesco Poggi", "Antonio Zinilli", "Andrea Giovanni Nuzzolese"], "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency", "comment": null, "summary": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.", "AI": {"tldr": "This paper introduces a formal BDI Ontology as a modular pattern to represent agent cognition, with experiments showing its integration with LLMs via Logic Augmented Generation and the Semas reasoning platform.", "motivation": "To address the limited integration of the BDI model into semantically interoperable knowledge representations, creating a bridge between declarative and procedural intelligence.", "method": "Development of a modular BDI Ontology aligned with foundational ontologies, tested through LLM integration via Logic Augmented Generation and implementation in the Semas platform using the T2B2T paradigm.", "result": "The ontology enables bidirectional flow between RDF triples and agent mental states, enhancing inferential coherence and consistency in neuro-symbolic systems.", "conclusion": "The BDI Ontology serves as both conceptual and operational framework for explainable, semantically interoperable multi-agent systems within the Web of Data."}}
{"id": "2511.17194", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17194", "abs": "https://arxiv.org/abs/2511.17194", "authors": ["Zhiyuan Xu", "Stanislav Abaimov", "Joseph Gardiner", "Sana Belguith"], "title": "Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models", "comment": "31 pages, 5 figures, 9 tables", "summary": "Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u4e2d\u95f4\u6fc0\u6d3b\u5c42\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u63d0\u51fa\u4e86\u654f\u611f\u6027\u7f29\u653e\u5bfc\u5411(SSS)\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u5728\u4e0d\u5f71\u54cd\u6a21\u578b\u57fa\u672c\u80fd\u529b\u7684\u60c5\u51b5\u4e0b\u63a7\u5236LLM\u884c\u4e3a\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u3001\u63d0\u793a\u548c\u62d2\u7edd\u7b56\u7565\uff0c\u4f46\u5ffd\u7565\u4e86\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u4e2d\u95f4\u6fc0\u6d3b\u5c42\u53ef\u80fd\u6210\u4e3a\u653b\u51fb\u9762\u3002", "method": "\u57fa\u4e8e\u6ce8\u610f\u529b\u6c47\u805a\u548c\u538b\u7f29\u8c37\u7406\u8bba\uff0c\u8bc6\u522b\u6b8b\u5dee\u6d41\u4e2d\u7684\u9ad8\u589e\u76ca\u533a\u57df\uff0c\u63d0\u51faSSS\u653b\u51fb\u65b9\u6cd5\uff0c\u7ed3\u5408BOS\u951a\u5b9a\u548c\u654f\u611f\u6027\u5f3a\u5316\u6280\u672f\u3002", "result": "\u5728\u591a\u6b3e\u5f00\u6e90\u6a21\u578b\u548c\u56db\u4e2a\u884c\u4e3a\u7ef4\u5ea6\u4e0a\u6d4b\u8bd5\uff0cSSS\u80fd\u6709\u6548\u8bf1\u5bfc\u6076\u610f\u884c\u4e3a\u3001\u5e7b\u89c9\u3001\u5949\u627f\u548c\u60c5\u611f\u504f\u89c1\u7684\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u6fc0\u6d3b\u5bfc\u5411\u6210\u4e3aLLM\u767d\u76d2\u548c\u4f9b\u5e94\u94fe\u90e8\u7f72\u4e2d\u7684\u5b9e\u9645\u5b89\u5168\u5a01\u80c1\uff0c\u9700\u8981\u65b0\u7684\u9632\u5fa1\u63aa\u65bd\u3002"}}
{"id": "2511.17165", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17165", "abs": "https://arxiv.org/abs/2511.17165", "authors": ["Kesheng Chen", "Wenjian Luo", "Bang Zhang", "Zeping Yin", "Zipeng Ye"], "title": "MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward", "comment": null, "summary": "Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.", "AI": {"tldr": "MIR introduces mutual intrinsic rewards for multi-agent reinforcement learning to address sparse episodic rewards by encouraging agents to explore actions that influence teammates, validated through MiniGrid-MA environment.", "motivation": "Episodic rewards pose challenges in MARL due to exponential sparsity of joint action trajectories and inadequate consideration of team-influencing actions in existing methods.", "method": "Proposes Mutual Intrinsic Reward (MIR) strategy enhancement where agents are incentivized to explore actions affecting teammates, combined with original strategies for team exploration.", "result": "Experimental validation in extended MiniGrid-MA environments shows MIR outperforms state-of-the-art approaches in scenarios with extremely sparse rewards.", "conclusion": "MIR effectively addresses sparse reward challenges in MARL by promoting team-oriented exploration, demonstrating superior performance in experimental comparisons."}}
{"id": "2511.17198", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17198", "abs": "https://arxiv.org/abs/2511.17198", "authors": ["Kaiyu Li", "Jiayu Wang", "Zhi Wang", "Hui Qiao", "Weizhan Zhang", "Deyu Meng", "Xiangyong Cao"], "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism", "comment": "Page: https://earth-insights.github.io/EarthAgent", "summary": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.", "AI": {"tldr": "EarthAgent\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ed3\u6784\u5316\uff0c\u4e13\u95e8\u7528\u4e8e\u590d\u6742\u5730\u7406\u7a7a\u95f4\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u901a\u7528LLM\u667a\u80fd\u4f53\u5728\u4e13\u4e1a\u9886\u57df\u4e2d\u65e0\u6cd5\u5904\u7406\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u95ee\u9898\u3002", "motivation": "\u901a\u7528LLM\u667a\u80fd\u4f53\u5728\u9700\u8981\u4e25\u683c\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4e13\u7528\u5de5\u5177\u548c\u591a\u6b65\u9aa4\u7a0b\u5e8f\u7684\u9886\u57df\u5982\u9065\u611f\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6784\u5efa\u4e3a\u53cd\u6620\u9886\u57df\u56fa\u6709\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\u7684\u903b\u8f91\u5c42\u6b21\u7ed3\u6784\uff0c\u786e\u4fdd\u7a0b\u5e8f\u6b63\u786e\u6027\u5e76\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u987a\u5e8f\u5c42\u7ea7\u3002\u6846\u67b6\u5b9e\u4f8b\u5316\u4e3aEarthAgent\u7cfb\u7edf\u3002", "result": "\u6784\u5efa\u4e86GeoPlan-bench\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u8868\u660eEarthAgent\u5728\u5de5\u5177\u9009\u62e9\u3001\u8def\u5f84\u76f8\u4f3c\u6027\u548c\u903b\u8f91\u5b8c\u6574\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "conclusion": "\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u9886\u57df\u56fa\u6709\u4efb\u52a1\u7ed3\u6784\u5bf9\u9f50\u662f\u6784\u5efa\u9c81\u68d2\u53ef\u9760\u4e13\u7528\u81ea\u6cbb\u7cfb\u7edf\u7684\u5173\u952e\u6b65\u9aa4\u3002"}}
{"id": "2511.17408", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17408", "abs": "https://arxiv.org/abs/2511.17408", "authors": ["Nathalie Kirch", "Samuel Dower", "Adrians Skapars", "Ekdeep Singh Lubana", "Dmitrii Krasheninnikov"], "title": "That's not natural: The Impact of Off-Policy Training Data on Probe Performance", "comment": "10 pages, EurIPS 2025 Workshop on Private AI Governance", "summary": "Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76d1\u63a7\u4e2d\uff0c\u4f7f\u7528\u5408\u6210\u6216\u975e\u7b56\u7565\u6570\u636e\u8bad\u7ec3\u63a2\u6d4b\u5668\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u6570\u636e\u751f\u6210\u7b56\u7565\u548c\u9886\u57df\u504f\u79fb\u663e\u8457\u5f71\u54cd\u63a2\u6d4b\u5668\u6027\u80fd\u3002", "motivation": "\u81ea\u7136\u884c\u4e3a\u6837\u672c\u7a00\u7f3a\uff0c\u7814\u7a76\u8005\u88ab\u8feb\u4f9d\u8d56\u5408\u6210\u6216\u975e\u7b56\u7565\u6570\u636e\u8bad\u7ec3\u63a2\u6d4b\u5668\uff0c\u4f46\u8fd9\u7c7b\u6570\u636e\u5bf9\u63a2\u6d4b\u5668\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5728\u516b\u79cdLLM\u884c\u4e3a\u4e0a\u6d4b\u8bd5\u7ebf\u6027\u548c\u6ce8\u610f\u529b\u63a2\u6d4b\u5668\uff0c\u6bd4\u8f83\u4e0d\u540c\u54cd\u5e94\u751f\u6210\u7b56\u7565\uff08\u5408\u6210\u3001\u975e\u7b56\u7565\u3001\u540c\u9886\u57df\u3001\u4e0d\u540c\u9886\u57df\uff09\u5bf9\u63a2\u6d4b\u5668\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u975e\u7b56\u7565\u6570\u636e\u6cdb\u5316\u5230\u76ee\u6807\u884c\u4e3a\u6d4b\u8bd5\u96c6\u7684\u80fd\u529b\u53ef\u9884\u6d4b\u5176\u7b56\u7565\u5185\u6cdb\u5316\u6210\u529f\u7387\uff1b\u9886\u57df\u504f\u79fb\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u6bd4\u7b56\u7565\u5dee\u5f02\u66f4\u4e25\u91cd\u3002", "conclusion": "\u7f3a\u4e4f\u7b56\u7565\u5185\u6570\u636e\u65f6\uff0c\u4f7f\u7528\u540c\u9886\u57df\u975e\u7b56\u7565\u6570\u636e\u6bd4\u4e0d\u540c\u9886\u57df\u7b56\u7565\u5185\u6570\u636e\u66f4\u53ef\u9760\uff1b\u9700\u5f00\u53d1\u66f4\u597d\u5904\u7406\u5206\u5e03\u504f\u79fb\u7684LLM\u76d1\u63a7\u65b9\u6cd5\u3002"}}
{"id": "2511.17461", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17461", "abs": "https://arxiv.org/abs/2511.17461", "authors": ["Jiaxi Liu", "Chengyuan Ma", "Hang Zhou", "Weizhe Tang", "Shixiao Liang", "Haoyang Ding", "Xiaopeng Li", "Bin Ran"], "title": "SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception", "comment": null, "summary": "Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u53d1\u7684\u98ce\u9669\u611f\u77e5\u9009\u62e9\u6027\u534f\u540c\u611f\u77e5\u6846\u67b6SRA-CP\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u76f2\u533a\u68c0\u6d4b\u548c\u6309\u9700\u4fe1\u606f\u4ea4\u6362\uff0c\u5728\u4fdd\u6301\u611f\u77e5\u7cbe\u5ea6\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u901a\u4fe1\u5e26\u5bbd\u9700\u6c42\u3002", "motivation": "\u73b0\u6709\u534f\u540c\u611f\u77e5\u65b9\u6cd5\u9700\u8981\u4f20\u8f93\u5927\u91cf\u4e0e\u9a7e\u9a76\u5b89\u5168\u65e0\u5173\u7684\u6570\u636e\uff0c\u4e14\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u901a\u4fe1\u4f19\u4f34\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u4ea4\u901a\u73af\u5883\u3002", "method": "\u91c7\u7528\u5206\u5e03\u5f0f\u534f\u8bae\uff0c\u8f66\u8f86\u6301\u7eed\u5e7f\u64ad\u8f7b\u91cf\u7ea7\u611f\u77e5\u8986\u76d6\u6458\u8981\uff0c\u53ea\u5728\u68c0\u6d4b\u5230\u98ce\u9669\u76f8\u5173\u76f2\u533a\u65f6\u89e6\u53d1\u6709\u9488\u5bf9\u6027\u7684\u5408\u4f5c\u3002\u901a\u8fc7\u98ce\u9669\u8bc6\u522b\u6a21\u5757\u8bc4\u4f30\u906e\u6321\u5f71\u54cd\uff0c\u9009\u62e9\u6027\u8fdb\u884c\u4fe1\u606f\u4ea4\u6362\u3002", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0cSRA-CP\u76f8\u6bd4\u901a\u7528CP\u65b9\u6cd5\u4ec5\u4ea7\u751f\u4e0d\u52301%\u7684\u5173\u952e\u5b89\u5168\u5bf9\u8c61\u68c0\u6d4b\u7cbe\u5ea6\u635f\u5931\uff0c\u4f46\u901a\u4fe1\u5e26\u5bbd\u4f7f\u7528\u91cf\u51cf\u5c1180%\u3002\u76f8\u6bd4\u65e0\u98ce\u9669\u611f\u77e5\u7684\u9009\u62e9\u6027CP\u65b9\u6cd5\uff0c\u611f\u77e5\u6027\u80fd\u63d0\u534715%\u3002", "conclusion": "SRA-CP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u534f\u540c\u611f\u77e5\u4e2d\u7684\u901a\u4fe1\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u98ce\u9669\u611f\u77e5\u548c\u9009\u62e9\u6027\u5408\u4f5c\u5b9e\u73b0\u4e86\u5b89\u5168\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u4ea4\u901a\u73af\u5883\u3002"}}
