{"id": "2512.09006", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09006", "abs": "https://arxiv.org/abs/2512.09006", "authors": ["Dyna Soumhane Ouchebara", "St\u00e9phane Dupont"], "title": "Llama-based source code vulnerability detection: Prompt engineering vs Fine tuning", "comment": "20 pages, Accepted at ESORICS 2025", "summary": "The significant increase in software production, driven by the acceleration of development cycles over the past two decades, has led to a steady rise in software vulnerabilities, as shown by statistics published yearly by the CVE program. The automation of the source code vulnerability detection (CVD) process has thus become essential, and several methods have been proposed ranging from the well established program analysis techniques to the more recent AI-based methods. Our research investigates Large Language Models (LLMs), which are considered among the most performant AI models to date, for the CVD task. The objective is to study their performance and apply different state-of-the-art techniques to enhance their effectiveness for this task. We explore various fine-tuning and prompt engineering settings. We particularly suggest one novel approach for fine-tuning LLMs which we call Double Fine-tuning, and also test the understudied Test-Time fine-tuning approach. We leverage the recent open-source Llama-3.1 8B, with source code samples extracted from BigVul and PrimeVul datasets. Our conclusions highlight the importance of fine-tuning to resolve the task, the performance of Double tuning, as well as the potential of Llama models for CVD. Though prompting proved ineffective, Retrieval augmented generation (RAG) performed relatively well as an example selection technique. Overall, some of our research questions have been answered, and many are still on hold, which leaves us many future work perspectives. Code repository is available here: https://github.com/DynaSoumhaneOuchebara/Llama-based-vulnerability-detection.", "AI": {"tldr": "Llama-3.1 8B\u6a21\u578b\u5728\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u7814\u7a76\uff0c\u63a2\u7d22\u4e86\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u53cc\u5fae\u8c03\u65b9\u6cd5\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u5468\u671f\u52a0\u901f\u5bfc\u81f4\u6f0f\u6d1e\u589e\u52a0\uff0c\u9700\u8981\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528Llama-3.1 8B\u6a21\u578b\uff0c\u7ed3\u5408BigVul\u548cPrimeVul\u6570\u636e\u96c6\uff0c\u6d4b\u8bd5\u5fae\u8c03\u3001\u53cc\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u7b49\u65b9\u6cd5\u3002", "result": "\u5fae\u8c03\u5bf9\u4efb\u52a1\u89e3\u51b3\u5f88\u91cd\u8981\uff0c\u53cc\u5fae\u8c03\u8868\u73b0\u826f\u597d\uff0cRAG\u4f5c\u4e3a\u793a\u4f8b\u9009\u62e9\u6280\u672f\u8868\u73b0\u76f8\u5bf9\u8f83\u597d\u3002", "conclusion": "Llama\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u63d0\u793a\u5de5\u7a0b\u6548\u679c\u4e0d\u4f73\uff0c\u672a\u6765\u5de5\u4f5c\u4ecd\u9700\u63a2\u7d22\u3002"}}
{"id": "2512.09196", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09196", "abs": "https://arxiv.org/abs/2512.09196", "authors": ["Haonan Li", "Keyu Man", "Partha Kanuparthy", "Hanning Chen", "Wei Sun", "Sreen Tallam", "Chenguang Zhu", "Kevin Zhu", "Zhiyun Qian"], "title": "TritonForge: Profiling-Guided Framework for Automated Triton Kernel Optimization", "comment": null, "summary": "High-performance GPU kernel optimization remains a critical yet labor-intensive task in modern machine learning workloads. Although Triton, a domain-specific language for GPU programming, enables developers to write efficient kernels with concise code, achieving expert-level performance still requires deep understanding of GPU architectures and low-level performance trade-offs. We present TritonForge, a profiling-guided framework for automated Triton kernel optimization. TritonForge integrates kernel analysis, runtime profiling, and iterative code transformation to streamline the optimization process. By incorporating data-driven feedback from profiling results, the system identifies performance bottlenecks, proposes targeted code modifications, and evaluates their impact automatically. While our prototype leverages large language models (LLMs) to assist in code reasoning and transformation, the framework remains modular and model-agnostic. Across diverse kernel types and GPU architectures, TritonForge achieves up to 5x performance improvement over baseline implementations and on average 1.76x of the cases are successful, providing a foundation for future research in automated GPU performance optimization.", "AI": {"tldr": "TritonForge\u662f\u4e00\u4e2a\u57fa\u4e8e\u6027\u80fd\u5206\u6790\u7684\u81ea\u52a8Triton GPU\u5185\u6838\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u3001\u6027\u80fd\u5206\u6790\u548c\u8fed\u4ee3\u4ee3\u7801\u8f6c\u6362\u5b9e\u73b0\u81ea\u52a8\u5316\u4f18\u5316\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe5\u500d", "motivation": "GPU\u5185\u6838\u4f18\u5316\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u81f3\u5173\u91cd\u8981\u4f46\u52b3\u52a8\u5bc6\u96c6\uff0cTriton\u8bed\u8a00\u867d\u7b80\u5316\u7f16\u7a0b\u4f46\u8fbe\u5230\u4e13\u5bb6\u7ea7\u6027\u80fd\u4ecd\u9700\u6df1\u539aGPU\u67b6\u6784\u77e5\u8bc6", "method": "\u96c6\u6210\u5185\u6838\u5206\u6790\u3001\u8fd0\u884c\u65f6\u6027\u80fd\u5206\u6790\u548c\u8fed\u4ee3\u4ee3\u7801\u8f6c\u6362\uff0c\u5229\u7528\u6027\u80fd\u5206\u6790\u6570\u636e\u9a71\u52a8\u53cd\u9988\u8bc6\u522b\u74f6\u9888\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u4ee3\u7801\u4fee\u6539\uff0c\u4f7f\u7528LLM\u8f85\u52a9\u4ee3\u7801\u63a8\u7406\u548c\u8f6c\u6362\u4f46\u4fdd\u6301\u6846\u67b6\u6a21\u5757\u5316\u548c\u6a21\u578b\u65e0\u5173", "result": "\u5728\u591a\u6837\u5316\u5185\u6838\u7c7b\u578b\u548cGPU\u67b6\u6784\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5b9e\u73b0\u6700\u9ad85\u500d\u6027\u80fd\u63d0\u5347\uff0c\u5e73\u57471.76\u500d\u6848\u4f8b\u4f18\u5316\u6210\u529f", "conclusion": "TritonForge\u4e3a\u81ea\u52a8\u5316GPU\u6027\u80fd\u4f18\u5316\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u5206\u6790\u7684\u81ea\u52a8\u5316\u4f18\u5316\u65b9\u6cd5\u6f5c\u529b"}}
{"id": "2512.09216", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09216", "abs": "https://arxiv.org/abs/2512.09216", "authors": ["Guangzong Cai", "Zengyang Li", "Peng Liang", "Ran Mo", "Hui Liu", "Yutao Ma"], "title": "Bug Priority Change Prediction: An Exploratory Study on Apache Software", "comment": "Preprint accepted for publication in ACM Transactions on Software Engineering and Methodology (TOSEM), 2025", "summary": "Bug fixing is a critical activity in the software development process. In issue tracking systems such as JIRA, each bug report is assigned a priority level to indicate the urgency and importance level of the bug. The priority may change during the bug fixing process, indicating that the urgency and importance level of the bug will change with the bug fixing. However, manually evaluating priority changes for bugs is a tedious process that heavily relies on the subjective judgment of developers and project managers, leading to incorrect priority changes and thus hindering timely bug fixes. Given the lack of research on bug priority change prediction, we propose a novel two-phase bug report priority change prediction method based on bug fixing evolution features and class imbalance handling strategy. Specifically, we divided the bug lifecycle into two phases: bug reporting and bug fixing, and constructed bug priority change prediction models for each phase. To evaluate the performance of our method, we conducted experiments on a bug dataset constructed from 32 non-trivial Apache projects. The experimental results show that our proposed bug fixing evolution features and the adopted class imbalance handling strategy can effectively improve the performance of prediction models. The F1-score of the prediction model constructed for the bug reporting phase reached 0.798, while the F1-weighted and F1-macro of the prediction model constructed for the bug fixing phase were 0.712 and 0.613, respectively. Furthermore, we explored the cross-project applicability of our prediction models and their performance at different priority levels. The findings indicate large variations in model performance across different projects, although the overall scores remain decent. Meanwhile, the predictive performance across various priority levels remained relatively consistently high.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eBug\u4fee\u590d\u6f14\u8fdb\u7279\u5f81\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406\u7b56\u7565\u7684\u4e24\u9636\u6bb5Bug\u62a5\u544a\u4f18\u5148\u7ea7\u53d8\u5316\u9884\u6d4b\u65b9\u6cd5\uff0c\u572832\u4e2aApache\u9879\u76ee\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c", "motivation": "Bug\u4f18\u5148\u7ea7\u5728\u4fee\u590d\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u53d8\u5316\uff0c\u624b\u5de5\u8bc4\u4f30\u4f9d\u8d56\u4e3b\u89c2\u5224\u65ad\u6613\u51fa\u9519\u4e14\u8017\u65f6\uff0c\u7f3a\u4e4f\u81ea\u52a8\u9884\u6d4b\u65b9\u6cd5", "method": "\u5c06Bug\u751f\u547d\u5468\u671f\u5206\u4e3a\u62a5\u544a\u548c\u4fee\u590d\u4e24\u9636\u6bb5\uff0c\u5206\u522b\u6784\u5efa\u9884\u6d4b\u6a21\u578b\uff0c\u91c7\u7528Bug\u4fee\u590d\u6f14\u8fdb\u7279\u5f81\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u5904\u7406\u7b56\u7565", "result": "\u62a5\u544a\u9636\u6bb5\u6a21\u578bF1-score\u8fbe0.798\uff0c\u4fee\u590d\u9636\u6bb5\u6a21\u578bF1\u52a0\u6743\u548c\u5b8f\u5e73\u5747\u5206\u522b\u4e3a0.712\u548c0.613\uff0c\u4e0d\u540c\u4f18\u5148\u7ea7\u9884\u6d4b\u6027\u80fd\u7a33\u5b9a", "conclusion": "\u63d0\u51fa\u7684\u7279\u5f81\u548c\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u9884\u6d4b\u6027\u80fd\uff0c\u6a21\u578b\u5177\u6709\u8de8\u9879\u76ee\u9002\u7528\u6027\uff0c\u4f46\u4e0d\u540c\u9879\u76ee\u95f4\u6027\u80fd\u5dee\u5f02\u8f83\u5927"}}
{"id": "2512.09088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09088", "abs": "https://arxiv.org/abs/2512.09088", "authors": ["Adrian Ryser", "Florian Allwein", "Tim Schlippe"], "title": "Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study", "comment": null, "summary": "Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Bl\u00f6baum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u5e7b\u89c9\u73b0\u8c61\u5982\u4f55\u5f71\u54cd\u7528\u6237\u5bf9LLM\u7684\u4fe1\u4efb\u53ca\u4ea4\u4e92\u884c\u4e3a\uff0c\u901a\u8fc7\u5b9a\u6027\u7814\u7a76\u53d1\u73b0\u5e7b\u89c9\u4e0d\u4f1a\u5bfc\u81f4\u5168\u9762\u4e0d\u4fe1\u4efb\uff0c\u800c\u662f\u5f15\u53d1\u60c5\u5883\u654f\u611f\u7684\u4fe1\u4efb\u6821\u51c6", "motivation": "\u63a2\u7d22LLM\u4ea7\u751f\u7684\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u5e7b\u89c9\u8f93\u51fa\u5982\u4f55\u5f71\u54cd\u7528\u6237\u7684\u4fe1\u4efb\u548c\u4ea4\u4e92\u6a21\u5f0f", "method": "\u5bf9192\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u5b9a\u6027\u7814\u7a76\uff0c\u57fa\u4e8eLee & See\u7684\u6821\u51c6\u4fe1\u4efb\u6a21\u578b\u548cAfroogh\u7b49\u4eba\u7684\u4fe1\u4efb\u76f8\u5173\u56e0\u7d20\u6846\u67b6", "result": "\u786e\u8ba4\u671f\u671b\u503c\u3001\u5148\u524d\u7ecf\u9a8c\u3001\u7528\u6237\u4e13\u4e1a\u77e5\u8bc6\u4e3a\u4fe1\u4efb\u76f8\u5173\u56e0\u7d20\uff0c\u5e76\u8bc6\u522b\u76f4\u89c9\u4f5c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u7684\u989d\u5916\u56e0\u7d20\uff1b\u4fe1\u4efb\u52a8\u6001\u8fd8\u53d7\u60c5\u5883\u56e0\u7d20\u5f71\u54cd", "conclusion": "\u9a8c\u8bc1\u4e86\u9012\u5f52\u4fe1\u4efb\u6821\u51c6\u8fc7\u7a0b\uff0c\u63d0\u51fa\u8d1f\u8d23\u4efb\u548c\u53cd\u601d\u6027\u4f7f\u7528LLM\u7684\u5b9e\u8df5\u5efa\u8bae"}}
{"id": "2512.09049", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09049", "abs": "https://arxiv.org/abs/2512.09049", "authors": ["Gandham Sai Santhosh", "Siddhartha Sanjay Naik", "Ritwik Badola", "Chester Rebeiro"], "title": "EMMap: A Systematic Framework for Spatial EMFI Mapping and Fault Classification on Microcontrollers", "comment": null, "summary": "Electromagnetic Fault Injection (EMFI) is a powerful technique for inducing bit flips and instruction-level perturbations on microcontrollers, yet existing literature lacks a unified methodology for systematically mapping spatial sensitivity and classifying resulting fault behaviors. Building on insights from O'Flynn and Kuhnapfel et al., we introduce a platform-agnostic framework for Spatial EMFI Mapping and Fault Classification, aimed at understanding how spatial probe position influences fault outcomes. We present pilot experiments on three representative microcontroller targets including the Xtensa LX6 (ESP32) and two ChipWhisper boards not as definitive evaluations, but as illustrative demonstrations of how the proposed methodology can be applied in practice. These preliminary observations motivate a generalized and reproducible workflow that researchers can adopt when analyzing EMFI susceptibility across diverse embedded architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0e\u5e73\u53f0\u65e0\u5173\u7684\u7535\u78c1\u6545\u969c\u6ce8\u5165\u7a7a\u95f4\u6620\u5c04\u4e0e\u6545\u969c\u5206\u7c7b\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u5206\u6790\u5fae\u63a7\u5236\u5668\u5bf9EMFI\u7684\u654f\u611f\u5ea6", "motivation": "\u73b0\u6709\u6587\u732e\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u7a7a\u95f4\u654f\u611f\u6027\u6620\u5c04\u548c\u6545\u969c\u884c\u4e3a\u5206\u7c7b\u65b9\u6cd5\uff0c\u96be\u4ee5\u7edf\u4e00\u8bc4\u4f30\u4e0d\u540c\u5fae\u63a7\u5236\u5668\u7684EMFI\u8106\u5f31\u6027", "method": "\u57fa\u4e8eO'Flynn\u548cKuhnapfel\u7b49\u4eba\u7684\u7814\u7a76\uff0c\u5efa\u7acb\u4e86\u7a7a\u95f4EMFI\u6620\u5c04\u548c\u6545\u969c\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u5728\u4e09\u79cd\u4ee3\u8868\u6027\u5fae\u63a7\u5236\u5668\u4e0a\u8fdb\u884c\u4e86\u521d\u6b65\u5b9e\u9a8c\u6f14\u793a", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u91cd\u590d\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u7528\u5b83\u6765\u5206\u6790\u4e0d\u540c\u5d4c\u5165\u5f0f\u67b6\u6784\u7684EMFI\u654f\u611f\u6027", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7cfb\u7edf\u7814\u7a76EMFI\u7a7a\u95f4\u654f\u611f\u6027\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u8de8\u5e73\u53f0\u6bd4\u8f83\u548c\u8106\u5f31\u6027\u8bc4\u4f30"}}
{"id": "2512.09114", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.09114", "abs": "https://arxiv.org/abs/2512.09114", "authors": ["Pamela Gupta"], "title": "AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance", "comment": "47 pages", "summary": "The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.", "AI": {"tldr": "AI TIPS 2.0\u6846\u67b6\u89e3\u51b3\u4e86\u5f53\u524dAI\u6cbb\u7406\u7684\u4e09\u5927\u6311\u6218\uff1a\u7528\u4f8b\u98ce\u9669\u8bc4\u4f30\u4e0d\u8db3\u3001\u6846\u67b6\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u6027\u3001\u89c4\u6a21\u5316\u5b9e\u65bd\u673a\u5236\u7f3a\u5931\uff0c\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u63a7\u5236\u63aa\u65bd\u548c\u5b9e\u65bd\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u5b58\u5728\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a1) \u7f3a\u4e4f\u9488\u5bf9\u5177\u4f53\u7528\u4f8b\u7684\u98ce\u9669\u8bc4\u4f30\uff1b2) \u73b0\u6709\u6846\u67b6\u505c\u7559\u5728\u6982\u5ff5\u5c42\u9762\uff0c\u7f3a\u4e4f\u53ef\u64cd\u4f5c\u63a7\u5236\uff1b3) \u7ec4\u7ec7\u7f3a\u4e4f\u89c4\u6a21\u5316\u5b9e\u65bd\u6cbb\u7406\u7684\u673a\u5236\u3002\u8fd9\u4e9b\u95ee\u9898\u5728Humana\u96c6\u4f53\u8bc9\u8bbc\u7b49\u6848\u4f8b\u4e2d\u5df2\u663e\u73b0\u4e25\u91cd\u540e\u679c\u3002", "method": "\u63d0\u51fa\u4e86AI TIPS\uff08\u4eba\u5de5\u667a\u80fd\u4fe1\u4efb\u96c6\u6210\u652f\u67f1\u53ef\u6301\u7eed\u60272.0\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u5bf92019\u5e74\u5f00\u53d1\u7684\u5168\u9762\u64cd\u4f5c\u6846\u67b6\u7684\u66f4\u65b0\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u5177\u4f53\u7684\u63a7\u5236\u63aa\u65bd\u3001\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u548c\u89c4\u6a21\u5316\u5b9e\u65bd\u673a\u5236\u3002", "result": "AI TIPS\u6846\u67b6\u80fd\u591f\u76f4\u63a5\u89e3\u51b3\u73b0\u6709\u6cbb\u7406\u6846\u67b6\u7684\u4e0d\u8db3\uff0c\u4e3a\u7ec4\u7ec7\u63d0\u4f9b\u5c06\u6cbb\u7406\u8981\u6c42\u8f6c\u5316\u4e3a\u5177\u4f53\u6280\u672f\u5b9e\u73b0\u7684\u80fd\u529b\uff0c\u5e76\u5728\u6574\u4e2a\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u5d4c\u5165\u53ef\u4fe1AI\u5b9e\u8df5\u3002", "conclusion": "AI TIPS 2.0\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6cbb\u7406\u63a7\u5236\u63aa\u65bd\u3001\u9488\u5bf9\u5177\u4f53\u7528\u4f8b\u7684\u98ce\u9669\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u53ca\u7cfb\u7edf\u5316\u7684\u89c4\u6a21\u5316\u5b9e\u65bd\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524dAI\u6cbb\u7406\u6846\u67b6\u7684\u4e09\u5927\u6311\u6218\uff0c\u4e3a\u7ec4\u7ec7\u5b9e\u73b0\u53ef\u4fe1\u8d56AI\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09150", "categories": ["cs.CR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09150", "abs": "https://arxiv.org/abs/2512.09150", "authors": ["Anirudh Nakra", "Nayeeb Rashid", "Chau-Wai Wong", "Min Wu"], "title": "Exposing Vulnerabilities in Counterfeit Prevention Systems Utilizing Physically Unclonable Surface Features", "comment": "15 pages; This work builds on arXiv:2408.02221 [cs.CR]", "summary": "Counterfeit products pose significant risks to public health and safety through infiltrating untrusted supply chains. Among numerous anti-counterfeiting techniques, leveraging inherent, unclonable microscopic irregularities of paper surfaces is an accurate and cost-effective solution. Prior work of this approach has focused on enabling ubiquitous acquisition of these physically unclonable features (PUFs). However, we will show that existing authentication methods relying on paper surface PUFs may be vulnerable to adversaries, resulting in a gap between technological feasibility and secure real-world deployment. This gap is investigated through formalizing an operational framework for paper-PUF-based authentication. Informed by this framework, we reveal system-level vulnerabilities across both physical and digital domains, designing physical denial-of-service and digital forgery attacks to disrupt proper authentication. The effectiveness of the designed attacks underscores the strong need for security countermeasures for reliable and resilient authentication based on paper PUFs. The proposed framework further facilitates a comprehensive, stage-by-stage security analysis, guiding the design of future counterfeit prevention systems. This analysis delves into potential attack strategies, offering a foundational understanding of how various system components, such as physical features and verification processes, might be exploited by adversaries.", "AI": {"tldr": "\u7eb8\u8d28\u8868\u9762\u7269\u7406\u4e0d\u53ef\u514b\u9686\u7279\u5f81\uff08PUFs\uff09\u8ba4\u8bc1\u7cfb\u7edf\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u9762\u4e34\u7269\u7406\u62d2\u7edd\u670d\u52a1\u548c\u6570\u5b57\u4f2a\u9020\u653b\u51fb\u5a01\u80c1\uff0c\u9700\u52a0\u5f3a\u5b89\u5168\u63aa\u65bd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7eb8\u8d28\u8868\u9762\u5fae\u89c2\u4e0d\u89c4\u5219\u6027\u7684\u9632\u4f2a\u6280\u672f\u867d\u80fd\u5b9e\u73b0\u4f4e\u6210\u672c\u8ba4\u8bc1\uff0c\u4f46\u73b0\u6709\u8ba4\u8bc1\u65b9\u6cd5\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u5bfc\u81f4\u6280\u672f\u53ef\u884c\u6027\u4e0e\u5b9e\u9645\u5b89\u5168\u90e8\u7f72\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u7eb8\u8d28PUF\u8ba4\u8bc1\u64cd\u4f5c\u6846\u67b6\uff0c\u8bbe\u8ba1\u7269\u7406\u62d2\u7edd\u670d\u52a1\u653b\u51fb\u548c\u6570\u5b57\u4f2a\u9020\u653b\u51fb\uff0c\u63ed\u793a\u7cfb\u7edf\u5728\u7269\u7406\u548c\u6570\u5b57\u9886\u57df\u7684\u8106\u5f31\u6027\u3002", "result": "\u8bbe\u8ba1\u7684\u653b\u51fb\u6709\u6548\u51f8\u663e\u4e86\u7eb8\u8d28PUF\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5b89\u5168\u98ce\u9669\uff0c\u8bc1\u660e\u73b0\u6709\u65b9\u6cd5\u6613\u53d7\u5bf9\u624b\u7834\u574f\u3002", "conclusion": "\u9700\u5236\u5b9a\u9636\u6bb5\u6027\u5b89\u5168\u5206\u6790\u6846\u67b6\u548c\u9488\u5bf9\u6027\u9632\u62a4\u63aa\u65bd\uff0c\u4ee5\u63d0\u5347\u57fa\u4e8e\u7eb8\u8d28PUF\u7684\u9632\u4f2a\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u97e7\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u9632\u4f2a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002"}}
{"id": "2512.09562", "categories": ["cs.SE", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.09562", "abs": "https://arxiv.org/abs/2512.09562", "authors": ["Radoslaw Klimek", "Jakub Blazowski"], "title": "Explainable Verification of Hierarchical Workflows Mined from Event Logs with Shapley Values", "comment": "This manuscript has been submitted to Rank A/A* conference", "summary": "Workflow mining discovers hierarchical process trees from event logs, but it remains unclear why such models satisfy or violate logical properties, or how individual elements contribute to overall behavior. We propose to translate mined workflows into logical specifications and analyze properties such as satisfiability, liveness, and safety with automated theorem provers. On this basis, we adapt Shapley values from cooperative game theory to attribute outcomes to workflow elements and quantify their contributions. Experiments on benchmark datasets show that this combination identifies critical nodes, reveals redundancies, and exposes harmful structures. This outlines a novel direction for explainable workflow analysis with direct relevance to software engineering practice, supporting compliance checks, process optimization, redundancy reduction, and the design of next-generation process mining tools.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u6316\u6398\u7684\u5de5\u4f5c\u6d41\u8f6c\u5316\u4e3a\u903b\u8f91\u89c4\u8303\uff0c\u5229\u7528\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u5206\u6790\u5c5e\u6027\uff0c\u5e76\u5f15\u5165Shapley\u503c\u91cf\u5316\u5de5\u4f5c\u6d41\u5143\u7d20\u7684\u8d21\u732e\uff0c\u4ee5\u63d0\u5347\u5de5\u4f5c\u6d41\u5206\u6790\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u5de5\u4f5c\u6d41\u6316\u6398\u65b9\u6cd5\u867d\u7136\u80fd\u4ece\u4e8b\u4ef6\u65e5\u5fd7\u4e2d\u53d1\u73b0\u5c42\u6b21\u5316\u8fc7\u7a0b\u6811\uff0c\u4f46\u65e0\u6cd5\u660e\u786e\u89e3\u91ca\u6a21\u578b\u4e3a\u4f55\u6ee1\u8db3\u6216\u8fdd\u53cd\u903b\u8f91\u5c5e\u6027\uff0c\u4ee5\u53ca\u5404\u5143\u7d20\u5982\u4f55\u5f71\u54cd\u6574\u4f53\u884c\u4e3a\u3002", "method": "\u5c06\u6316\u6398\u7684\u5de5\u4f5c\u6d41\u7ffb\u8bd1\u6210\u903b\u8f91\u89c4\u8303\uff0c\u4f7f\u7528\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u5668\u5206\u6790\u53ef\u6ee1\u8db3\u6027\u3001\u6d3b\u6027\u548c\u5b89\u5168\u6027\u7b49\u5c5e\u6027\uff0c\u5e76\u91c7\u7528\u5408\u4f5c\u535a\u5f08\u8bba\u4e2d\u7684Shapley\u503c\u5bf9\u5de5\u4f5c\u6d41\u5143\u7d20\u8fdb\u884c\u5f52\u56e0\u5206\u6790\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u8bc6\u522b\u5173\u952e\u8282\u70b9\u3001\u63ed\u793a\u5197\u4f59\u7ed3\u6784\u5e76\u66b4\u9732\u6709\u5bb3\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u53ef\u89e3\u91ca\u7684\u5de5\u4f5c\u6d41\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\uff0c\u652f\u6301\u5408\u89c4\u6027\u68c0\u67e5\u3001\u6d41\u7a0b\u4f18\u5316\u3001\u5197\u4f59\u51cf\u5c11\u53ca\u4e0b\u4e00\u4ee3\u8fc7\u7a0b\u6316\u6398\u5de5\u5177\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2512.09117", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09117", "abs": "https://arxiv.org/abs/2512.09117", "authors": ["Luciano Floridi", "Yiyang Jia", "Fernando Tohm\u00e9"], "title": "A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem", "comment": null, "summary": "This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u5f62\u5f0f\u5316\u8303\u7574\u6846\u67b6\u5206\u6790\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5c06\u5185\u5bb9\u8f6c\u5316\u4e3a\u5173\u4e8e\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u7a7a\u95f4\u7684\u771f\u503c\u547d\u9898\uff0c\u8bba\u8bc1LLMs\u5e76\u975e\u89e3\u51b3\u800c\u662f\u7ed5\u8fc7\u4e86\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7b26\u53f7\u63a5\u5730\u95ee\u9898\u5173\u6ce8\u5982\u4f55\u5c06\u7b26\u53f7\u4e0e\u771f\u5b9e\u4e16\u754c\u4f53\u9a8c\u8fde\u63a5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5206\u6790LLMs\u5728\u7f3a\u4e4f\u771f\u5b9e\u4e16\u754c\u4f53\u9a8c\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u5904\u7406\u8bed\u4e49\u5185\u5bb9\u3002", "method": "\u5efa\u7acb\u8303\u7574\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u7a7a\u95f4W\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5bf9\u6bd4\u5206\u6790\u4eba\u7c7b\u4e0eLLMs\u751f\u6210\u771f\u503c\u547d\u9898\u7684\u8ba4\u77e5\u673a\u5236\u5dee\u5f02\u3002", "result": "\u53d1\u73b0LLMs\u901a\u8fc7\u7edf\u8ba1\u6a21\u5f0f\u5339\u914d\u5728\u53ef\u80fd\u4e16\u754c\u72b6\u6001\u7a7a\u95f4\u4e2d\u751f\u6210\u8fde\u8d2f\u547d\u9898\uff0c\u4f46\u7f3a\u4e4f\u4eba\u7c7b\u5f0f\u7684\u611f\u77e5-\u52a8\u4f5c\u5faa\u73af\u57fa\u7840\u3002", "conclusion": "LLMs\u5b9e\u9645\u4e0a\u89c4\u907f\u800c\u975e\u89e3\u51b3\u4e86\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u5176\u8bed\u4e49\u7406\u89e3\u5efa\u7acb\u5728\u8868\u9762\u7edf\u8ba1\u89c4\u5f8b\u800c\u975e\u5177\u8eab\u8ba4\u77e5\u57fa\u7840\u4e0a\u3002"}}
{"id": "2512.09233", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09233", "abs": "https://arxiv.org/abs/2512.09233", "authors": ["Alan T. Sherman", "Jeremy J. Romanik Romano", "Edward Zieglar", "Enis Golaszewski", "Jonathan D. Fuchs", "William E. Byrd"], "title": "Analysis of the Security Design, Engineering, and Implementation of the SecureDNA System", "comment": "A shorter version of this paper will appear in the Proceedings of the Network and Distributed System Security Symposium (NDSS) 2026 published by the Internet Society", "summary": "We analyze security aspects of the SecureDNA system regarding its system design, engineering, and implementation. This system enables DNA synthesizers to screen order requests against a database of hazards. By applying novel cryptography, the system aims to keep order requests and the database of hazards secret. Discerning the detailed operation of the system in part from source code (Version 1.0.8), our analysis examines key management, certificate infrastructure, authentication, and rate-limiting mechanisms. We also perform the first formal-methods analysis of the mutual authentication, basic request, and exemption-handling protocols.\n  Without breaking the cryptography, our main finding is that SecureDNA's custom mutual authentication protocol SCEP achieves only one-way authentication: the hazards database and keyservers never learn with whom they communicate. This structural weakness violates the principle of defense in depth and enables an adversary to circumvent rate limits that protect the secrecy of the hazards database, if the synthesizer connects with a malicious or corrupted keyserver or hashed database. We point out an additional structural weakness that also violates the principle of defense in depth: inadequate cryptographic bindings prevent the system from detecting if responses, within a TLS channel, from the hazards database were modified. Consequently, if a synthesizer were to reconnect with the database over the same TLS session, an adversary could replay and swap responses from the database without breaking TLS. Although the SecureDNA implementation does not allow such reconnections, it would be stronger security engineering to avoid the underlying structural weakness. We identify these vulnerabilities and suggest and verify mitigations, including adding strong bindings. Software Version 1.1.0 fixes SCEP with our proposed SCEP+ protocol.", "AI": {"tldr": "\u5bf9SecureDNA\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u5206\u6790\uff0c\u53d1\u73b0\u5176\u81ea\u5b9a\u4e49\u8ba4\u8bc1\u534f\u8bae\u5b58\u5728\u7ed3\u6784\u6027\u5f31\u70b9\uff0c\u5141\u8bb8\u7ed5\u8fc7\u901f\u7387\u9650\u5236\u5e76\u53ef\u80fd\u906d\u53d7\u54cd\u5e94\u7be1\u6539\u653b\u51fb", "motivation": "\u5206\u6790SecureDNA DNA\u5408\u6210\u7b5b\u9009\u7cfb\u7edf\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5176\u7cfb\u7edf\u8bbe\u8ba1\u3001\u5de5\u7a0b\u5b9e\u73b0\u548c\u5bc6\u7801\u5b66\u5e94\u7528", "method": "\u901a\u8fc7\u6e90\u4ee3\u7801\u5206\u6790\uff08\u7248\u672c1.0.8\uff09\u68c0\u67e5\u5bc6\u94a5\u7ba1\u7406\u3001\u8bc1\u4e66\u57fa\u7840\u8bbe\u65bd\u3001\u8ba4\u8bc1\u548c\u901f\u7387\u9650\u5236\u673a\u5236\uff0c\u5e76\u8fdb\u884c\u5f62\u5f0f\u5316\u65b9\u6cd5\u5206\u6790", "result": "\u53d1\u73b0SCEP\u534f\u8bae\u4ec5\u5b9e\u73b0\u5355\u5411\u8ba4\u8bc1\uff0c\u5b58\u5728\u7ed5\u8fc7\u901f\u7387\u9650\u5236\u548c\u54cd\u5e94\u7be1\u6539\u7684\u6f0f\u6d1e", "conclusion": "\u8bc6\u522b\u4e86\u7ed3\u6784\u6027\u5b89\u5168\u5f31\u70b9\u5e76\u63d0\u51fa\u4e86\u7f13\u89e3\u63aa\u65bd\uff0c\u8f6f\u4ef6\u7248\u672c1.1.0\u5df2\u901a\u8fc7SCEP+\u534f\u8bae\u4fee\u590d\u76f8\u5173\u95ee\u9898"}}
{"id": "2512.09506", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.09506", "abs": "https://arxiv.org/abs/2512.09506", "authors": ["Jinru Ding", "Chao Ding", "Wenrao Pang", "Boyi Xiao", "Zhiqiang Liu", "Pengcheng Chen", "Jiayuan Chen", "Tiantian Yuan", "Junming Guan", "Yidong Jiang", "Dawei Cheng", "Jie Xu"], "title": "CNFinBench: A Benchmark for Safety and Compliance of Large Language Models in Finance", "comment": null, "summary": "Large language models are increasingly deployed across the financial sector for tasks such as research, compliance, risk analysis, and customer service, which makes rigorous safety evaluation essential. However, existing financial benchmarks primarily focus on textbook-style question answering and numerical problem solving, but fail to evaluate models' real-world safety behaviors. They weakly assess regulatory compliance and investor-protection norms, rarely stress-test multi-turn adversarial tactics such as jailbreaks or prompt injection, inconsistently ground answers in long filings, ignore tool- or RAG-induced over-reach risks, and rely on opaque or non-auditable evaluation protocols. To close these gaps, we introduce CNFinBench, a benchmark that employs finance-tailored red-team dialogues and is structured around a Capability-Compliance-Safety triad, including evidence-grounded reasoning over long reports and jurisdiction-aware rule/tax compliance tasks. For systematic safety quantification, we introduce the Harmful Instruction Compliance Score (HICS) to measure how consistently models resist harmful prompts across multi-turn adversarial dialogues. To ensure auditability, CNFinBench enforces strict output formats with dynamic option perturbation for objective tasks and employs a hybrid LLM-ensemble plus human-calibrated judge for open-ended evaluations. Experiments on 21 models across 15 subtasks confirm a persistent capability-compliance gap: models achieve an average score of 61.0 on capability tasks but fall to 34.18 on compliance and risk-control evaluations. Under multi-turn adversarial dialogue tests, most systems reach only partial resistance (HICS 60-79), demonstrating that refusal alone is not a reliable proxy for safety without cited and verifiable reasoning.", "AI": {"tldr": "CNFinBench\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u91d1\u878d\u9886\u57df\u7684\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\uff0c\u901a\u8fc7\u591a\u8f6e\u5bf9\u6297\u5bf9\u8bdd\u548cCapability-Compliance-Safety\u6846\u67b6\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5408\u89c4\u6027\u548c\u98ce\u9669\u63a7\u5236\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u91d1\u878d\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u6559\u79d1\u4e66\u5f0f\u95ee\u7b54\u548c\u6570\u503c\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6a21\u578b\u5b9e\u9645\u5b89\u5168\u884c\u4e3a\u7684\u8bc4\u4f30\uff0c\u65e0\u6cd5\u6709\u6548\u6d4b\u8bd5\u76d1\u7ba1\u5408\u89c4\u3001\u5bf9\u6297\u653b\u51fb\u3001\u5de5\u5177\u6ee5\u7528\u7b49\u98ce\u9669\u3002", "method": "\u8bbe\u8ba1\u4e86\u91d1\u878d\u5b9a\u5236\u7684\u7ea2\u961f\u5bf9\u8bdd\u57fa\u51c6\uff0c\u5305\u62ec\u57fa\u4e8e\u957f\u62a5\u544a\u7684\u8bc1\u636e\u63a8\u7406\u548c\u53f8\u6cd5\u611f\u77e5\u7684\u89c4\u5219/\u7a0e\u52a1\u5408\u89c4\u4efb\u52a1\uff0c\u5f15\u5165Harmful Instruction Compliance Score\uff08HICS\uff09\u91cf\u5316\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u6297\u5bf9\u8bdd\u4e2d\u7684\u6297\u6709\u5bb3\u63d0\u793a\u80fd\u529b\uff0c\u5e76\u91c7\u7528\u53ef\u5ba1\u8ba1\u7684\u6df7\u5408\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u572821\u4e2a\u6a21\u578b\u548c15\u4e2a\u5b50\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u6a21\u578b\u5728\u80fd\u529b\u4efb\u52a1\u4e0a\u5e73\u5747\u5f97\u5206\u4e3a61.0\uff0c\u4f46\u5728\u5408\u89c4\u548c\u98ce\u9669\u63a7\u5236\u8bc4\u4f30\u4e2d\u964d\u81f334.18\uff1b\u591a\u8f6e\u5bf9\u6297\u5bf9\u8bdd\u6d4b\u8bd5\u4e2d\uff0c\u591a\u6570\u7cfb\u7edf\u4ec5\u8fbe\u5230\u90e8\u5206\u62b5\u6297\uff08HICS 60-79\uff09\u3002", "conclusion": "\u4ec5\u9760\u62d2\u7edd\u4e0d\u8db3\u4ee5\u786e\u4fdd\u5b89\u5168\u6027\uff0c\u6a21\u578b\u9700\u8981\u63d0\u4f9b\u53ef\u5f15\u7528\u548c\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\uff1bCNFinBench\u4e3a\u91d1\u878d\u9886\u57df\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u6846\u67b6\u3002"}}
{"id": "2512.09596", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09596", "abs": "https://arxiv.org/abs/2512.09596", "authors": ["Arkadiusz Ry\u015b", "Lucas Lima", "Joeri Exelmans", "Dennis Janssens", "Hans Vangheluwe"], "title": "Model management to support systems engineering workflows using ontology-based knowledge graphs", "comment": null, "summary": "System engineering has been shifting from document-centric to model-based approaches, where assets are becoming more and more digital. Although digitisation conveys several benefits, it also brings several concerns (e.g., storage and access) and opportunities. In the context of Cyber- Physical Systems (CPS), we have experts from various domains executing complex workflows and manipulating models in a plethora of different formalisms, each with their own methods, techniques and tools. Storing knowledge on these workflows can reduce considerable effort during system development not only to allow their repeatability and replicability but also to access and reason on data generated by their execution. In this work, we propose a framework to manage modelling artefacts generated from workflow executions. The basic workflow concepts, related formalisms and artefacts are formally defined in an ontology specified in OML (Ontology Modelling Language). This ontology enables the construction of a knowledge graph that contains system engineering data to which we can apply reasoning. We also developed several tools to support system engineering during the design of workflows, their enactment, and artefact storage, considering versioning, querying and reasoning on the stored data. These tools also hide the complexity of manipulating the knowledge graph directly. Finally, we have applied our proposed framework in a real-world system development scenario of a drivetrain smart sensor system. Results show that our proposal not only helped the system engineer with fundamental difficulties like storage and versioning but also reduced the time needed to access relevant information and new knowledge that can be inferred from the knowledge graph.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u672c\u4f53\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u7ba1\u7406\u7cfb\u7edf\u5de5\u7a0b\u5de5\u4f5c\u6d41\u6267\u884c\u4ea7\u751f\u7684\u5efa\u6a21\u5de5\u4ef6\uff0c\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u652f\u6301\u6570\u636e\u5b58\u50a8\u3001\u7248\u672c\u63a7\u5236\u3001\u67e5\u8be2\u548c\u63a8\u7406\uff0c\u5e76\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u5de5\u7a0b\u4ece\u6587\u6863\u4e2d\u5fc3\u8f6c\u5411\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u6570\u5b57\u5316\u5e26\u6765\u4e86\u5b58\u50a8\u548c\u8bbf\u95ee\u7b49\u6311\u6218\u3002\u591a\u9886\u57df\u4e13\u5bb6\u4f7f\u7528\u4e0d\u540c\u5f62\u5f0f\u5316\u65b9\u6cd5\u6267\u884c\u590d\u6742\u5de5\u4f5c\u6d41\uff0c\u9700\u8981\u6709\u6548\u7ba1\u7406\u7531\u6b64\u4ea7\u751f\u7684\u5efa\u6a21\u5de5\u4ef6\u4ee5\u5b9e\u73b0\u53ef\u91cd\u590d\u6027\u3001\u53ef\u590d\u5236\u6027\u548c\u6570\u636e\u63a8\u7406\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528OML\u5b9a\u4e49\u7684\u5de5\u4f5c\u6d41\u6982\u5ff5\u3001\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u5de5\u4ef6\u7684\u672c\u4f53\uff0c\u6784\u5efa\u5305\u542b\u7cfb\u7edf\u5de5\u7a0b\u6570\u636e\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u5f00\u53d1\u5de5\u5177\u652f\u6301\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u3001\u6267\u884c\u3001\u5de5\u4ef6\u5b58\u50a8\u53ca\u7248\u672c\u7ba1\u7406\u3002", "result": "\u5728\u5b9e\u9645\u7684\u4f20\u52a8\u7cfb\u7edf\u667a\u80fd\u4f20\u611f\u5668\u5f00\u53d1\u573a\u666f\u4e2d\u5e94\u7528\u8be5\u6846\u67b6\uff0c\u7ed3\u679c\u8868\u660e\u5b83\u6709\u6548\u89e3\u51b3\u4e86\u5b58\u50a8\u548c\u7248\u672c\u63a7\u5236\u7b49\u57fa\u672c\u96be\u9898\uff0c\u51cf\u5c11\u4e86\u8bbf\u95ee\u76f8\u5173\u4fe1\u606f\u7684\u65f6\u95f4\uff0c\u5e76\u80fd\u4ece\u77e5\u8bc6\u56fe\u8c31\u63a8\u65ad\u65b0\u77e5\u8bc6\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e0d\u4ec5\u5e2e\u52a9\u7cfb\u7edf\u5de5\u7a0b\u5e08\u514b\u670d\u5b58\u50a8\u548c\u7248\u672c\u63a7\u5236\u7b49\u56f0\u96be\uff0c\u8fd8\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u63d0\u5347\u4e86\u4fe1\u606f\u8bbf\u95ee\u6548\u7387\u548c\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u590d\u6742\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.09817", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09817", "abs": "https://arxiv.org/abs/2512.09817", "authors": ["Habiba BEN ABDERRAHMANE", "Slimane Oulad-Naoui", "Benameur ZIANI"], "title": "A roadmap of geospatial soil quality analysis systems", "comment": null, "summary": "Soil quality (SQ) plays a crucial role in sustainable agriculture, environmental conservation, and land-use planning. Traditional SQ assessment techniques rely on costly, labor-intensive sampling and laboratory analysis, limiting their spatial and temporal coverage. Advances in Geographic Information Systems (GIS), remote sensing, and machine learning (ML) enabled efficient SQ evaluation. This paper presents a comprehensive roadmap distinguishing it from previous reviews by proposing a unified and modular pipeline that integrates multi-source soil data, GIS and remote sensing tools, and machine learning techniques to support transparent and scalable soil quality assessment. It also includes practical applications. Contrary to existing studies that predominantly target isolated soil parameters or specific modeling methodologies, this approach consolidates recent advancements in Geographic Information Systems (GIS), remote sensing technologies, and machine learning algorithms within the entire soil quality assessment pipeline. It also addresses existing challenges and limitations while exploring future developments and emerging trends in the field that can deliver the next generation of soil quality systems making them more transparent, adaptive, and aligned with sustainable land management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408GIS\u3001\u9065\u611f\u548c\u673a\u5668\u5b66\u4e60\u7684\u7edf\u4e00\u6a21\u5757\u5316\u7ba1\u9053\uff0c\u7528\u4e8e\u9ad8\u6548\u3001\u900f\u660e\u548c\u53ef\u6269\u5c55\u7684\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\uff0c\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63a2\u8ba8\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u3002", "motivation": "\u4f20\u7edf\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u6602\u8d35\u3001\u52b3\u52a8\u5bc6\u96c6\u578b\u7684\u91c7\u6837\u548c\u5b9e\u9a8c\u5ba4\u5206\u6790\uff0c\u9650\u5236\u4e86\u5176\u7a7a\u95f4\u548c\u65f6\u95f4\u8986\u76d6\u8303\u56f4\u3002GIS\u3001\u9065\u611f\u548c\u673a\u5668\u5b66\u4e60\u7684\u53d1\u5c55\u4e3a\u9ad8\u6548\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "method": "\u901a\u8fc7\u6574\u5408\u591a\u6e90\u571f\u58e4\u6570\u636e\u3001GIS\u548c\u9065\u611f\u5de5\u5177\u4ee5\u53ca\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6a21\u5757\u5316\u7ba1\u9053\uff0c\u7528\u4e8e\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u8def\u7ebf\u56fe\uff0c\u533a\u522b\u4e8e\u4ee5\u5f80\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u6574\u5408\u591a\u6e90\u571f\u58e4\u6570\u636e\u3001GIS\u548c\u9065\u611f\u5de5\u5177\u4ee5\u53ca\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u652f\u6301\u900f\u660e\u548c\u53ef\u6269\u5c55\u7684\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\uff0c\u5e76\u5305\u62ec\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u6574\u5408\u4e86\u591a\u6e90\u571f\u58e4\u6570\u636e\u3001GIS\u548c\u9065\u611f\u5de5\u5177\u4ee5\u53ca\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u4ee5\u652f\u6301\u900f\u660e\u548c\u53ef\u6269\u5c55\u7684\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u514b\u670d\u73b0\u6709\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u63a8\u52a8\u571f\u58e4\u8d28\u91cf\u8bc4\u4f30\u7cfb\u7edf\u5411\u66f4\u900f\u660e\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6301\u7eed\u571f\u5730\u7ba1\u7406\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2512.09627", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09627", "abs": "https://arxiv.org/abs/2512.09627", "authors": ["Jingwei Ye", "Zhi Wang", "Chenbin Su", "Jieshuai Yang", "Jiayi Ding", "Chunbo Liu", "Ge Chu"], "title": "LogICL: Distilling LLM Reasoning to Bridge the Semantic Gap in Cross-Domain Log Anomaly Detection", "comment": null, "summary": "Effective log anomaly detection is critical to sustaining reliability in large-scale IT infrastructures. Transformer-based models require substantial resources and labeled data, exacerbating the cold-start problem in target domains where logs are scarce. Existing cross-domain methods leverage source logs but struggle with generalization due to reliance on surface lexical similarity, failing to capture latent semantic equivalence amid structural divergences. To address this, we propose LogICL, a framework distilling Large Language Model (LLM) reasoning into a lightweight encoder for cross-domain anomaly detection. During training, LogICL constructs a delta matrix measuring the utility of demonstrations selected via Maximal Marginal Relevance relative to zero-shot inference. The encoder is optimized via a multi-objective loss comprising an ICL-Guided term that aligns representations based on reasoning assistance utility, maximum mean discrepancy for domain alignment, and supervised contrastive loss. At inference, the optimized encoder retrieves reasoning-aware demonstrations using semantic similarity and delta scores, enabling frozen-LLM in-context learning with Chain-of-Thought for accurate and interpretable detection. Experiments on few-shot and zero-shot cross-domain benchmarks confirm LogICL achieves state-of-the-art performance across heterogeneous systems. Further analysis via visualizations and case studies confirms LogICL bridges the semantic gap beyond surface lexical similarity, effectively capturing latent semantic equivalence for rapid deployment.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.09340", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09340", "abs": "https://arxiv.org/abs/2512.09340", "authors": ["Chethana Prasad Kabgere"], "title": "Visual Categorization Across Minds and Models: Cognitive Analysis of Human Labeling and Neuro-Symbolic Integration", "comment": "12 pages, 3 figures. Research manuscript based on the final project for CS6795 (Introduction to Cognitive Science), Georgia Tech", "summary": "Understanding how humans and AI systems interpret ambiguous visual stimuli offers critical insight into the nature of perception, reasoning, and decision-making. This paper examines image labeling performance across human participants and deep neural networks, focusing on low-resolution, perceptually degraded stimuli. Drawing from computational cognitive science, cognitive architectures, and connectionist-symbolic hybrid models, we contrast human strategies such as analogical reasoning, shape-based recognition, and confidence modulation with AI's feature-based processing. Grounded in Marr's tri-level hypothesis, Simon's bounded rationality, and Thagard's frameworks of representation and emotion, we analyze participant responses in relation to Grad-CAM visualizations of model attention. Human behavior is further interpreted through cognitive principles modeled in ACT-R and Soar, revealing layered and heuristic decision strategies under uncertainty. Our findings highlight key parallels and divergences between biological and artificial systems in representation, inference, and confidence calibration. The analysis motivates future neuro-symbolic architectures that unify structured symbolic reasoning with connectionist representations. Such architectures, informed by principles of embodiment, explainability, and cognitive alignment, offer a path toward AI systems that are not only performant but also interpretable and cognitively grounded.", "AI": {"tldr": "\u6bd4\u8f83\u4eba\u7c7b\u548cAI\u7cfb\u7edf\u5728\u6a21\u7cca\u89c6\u89c9\u523a\u6fc0\u89e3\u91ca\u4e2d\u7684\u5dee\u5f02\uff0c\u63a2\u7d22\u751f\u7269\u4e0e\u4eba\u5de5\u7cfb\u7edf\u5728\u611f\u77e5\u3001\u63a8\u7406\u548c\u51b3\u7b56\u65b9\u9762\u7684\u5f02\u540c", "motivation": "\u7406\u89e3\u4eba\u7c7b\u548cAI\u7cfb\u7edf\u5982\u4f55\u89e3\u91ca\u6a21\u7cca\u89c6\u89c9\u523a\u6fc0\u5bf9\u4e8e\u63ed\u793a\u611f\u77e5\u3001\u63a8\u7406\u548c\u51b3\u7b56\u7684\u672c\u8d28\u81f3\u5173\u91cd\u8981", "method": "\u7ed3\u5408\u8ba1\u7b97\u8ba4\u77e5\u79d1\u5b66\u3001\u8ba4\u77e5\u67b6\u6784\u548c\u8fde\u63a5\u4e3b\u4e49-\u7b26\u53f7\u6df7\u5408\u6a21\u578b\uff0c\u5bf9\u6bd4\u4eba\u7c7b\u7b56\u7565\u4e0eAI\u7684\u7279\u5f81\u5904\u7406\uff0c\u4f7f\u7528Grad-CAM\u53ef\u89c6\u5316\u6a21\u578b\u6ce8\u610f\u529b\uff0c\u5e76\u901a\u8fc7ACT-R\u548cSoar\u6a21\u578b\u5206\u6790\u4eba\u7c7b\u884c\u4e3a", "result": "\u63ed\u793a\u4e86\u751f\u7269\u548c\u4eba\u5de5\u7cfb\u7edf\u5728\u8868\u5f81\u3001\u63a8\u7406\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u9762\u7684\u5173\u952e\u76f8\u4f3c\u70b9\u548c\u5dee\u5f02", "conclusion": "\u7814\u7a76\u4fc3\u8fdb\u4e86\u672a\u6765\u795e\u7ecf\u7b26\u53f7\u67b6\u6784\u7684\u53d1\u5c55\uff0c\u8fd9\u4e9b\u67b6\u6784\u5c06\u7ed3\u6784\u5316\u7b26\u53f7\u63a8\u7406\u4e0e\u8fde\u63a5\u4e3b\u4e49\u8868\u5f81\u76f8\u7ed3\u5408\uff0c\u4e3a\u5b9e\u73b0\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u8ba4\u77e5\u57fa\u7840\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8def\u5f84"}}
{"id": "2512.09321", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09321", "abs": "https://arxiv.org/abs/2512.09321", "authors": ["Ruiqi Wang", "Yuqi Jia", "Neil Zhenqiang Gong"], "title": "ObliInjection: Order-Oblivious Prompt Injection Attack to LLM Agents with Multi-source Data", "comment": "To appear in NDSS 2026", "summary": "Prompt injection attacks aim to contaminate the input data of an LLM to mislead it into completing an attacker-chosen task instead of the intended task. In many applications and agents, the input data originates from multiple sources, with each source contributing a segment of the overall input. In these multi-source scenarios, an attacker may control only a subset of the sources and contaminate the corresponding segments, but typically does not know the order in which the segments are arranged within the input. Existing prompt injection attacks either assume that the entire input data comes from a single source under the attacker's control or ignore the uncertainty in the ordering of segments from different sources. As a result, their success is limited in domains involving multi-source data.\n  In this work, we propose ObliInjection, the first prompt injection attack targeting LLM applications and agents with multi-source input data. ObliInjection introduces two key technical innovations: the order-oblivious loss, which quantifies the likelihood that the LLM will complete the attacker-chosen task regardless of how the clean and contaminated segments are ordered; and the orderGCG algorithm, which is tailored to minimize the order-oblivious loss and optimize the contaminated segments. Comprehensive experiments across three datasets spanning diverse application domains and twelve LLMs demonstrate that ObliInjection is highly effective, even when only one out of 6-100 segments in the input data is contaminated.", "AI": {"tldr": "\u9996\u4e2a\u9488\u5bf9\u591a\u6e90\u8f93\u5165\u6570\u636e\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5ObliInjection\uff0c\u901a\u8fc7\u987a\u5e8f\u65e0\u5173\u635f\u5931\u548corderGCG\u7b97\u6cd5\u63d0\u9ad8\u653b\u51fb\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5047\u8bbe\u653b\u51fb\u8005\u63a7\u5236\u5168\u90e8\u8f93\u5165\u6e90\u6216\u5ffd\u7565\u591a\u6e90\u8f93\u5165\u4e2d\u7684\u987a\u5e8f\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u591a\u6e90\u6570\u636e\u573a\u666f\u4e0b\u6548\u679c\u6709\u9650", "method": "\u63d0\u51fa\u987a\u5e8f\u65e0\u5173\u635f\u5931\u51fd\u6570\u6765\u91cf\u5316LLM\u5b8c\u6210\u653b\u51fb\u8005\u6307\u5b9a\u4efb\u52a1\u7684\u53ef\u80fd\u6027\uff0c\u5f00\u53d1orderGCG\u7b97\u6cd5\u4f18\u5316\u6c61\u67d3\u6bb5", "result": "\u57283\u4e2a\u6570\u636e\u96c6\u548c12\u4e2aLLM\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5373\u4f7f\u57286-100\u4e2a\u8f93\u5165\u6bb5\u4e2d\u53ea\u67091\u4e2a\u88ab\u6c61\u67d3\uff0cObliInjection\u4ecd\u9ad8\u5ea6\u6709\u6548", "conclusion": "ObliInjection\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u591a\u6e90\u8f93\u5165\u6570\u636e\u7684\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027"}}
{"id": "2512.09679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09679", "abs": "https://arxiv.org/abs/2512.09679", "authors": ["Naizhu Jin", "Zhong Li", "Guang Yang", "Tian Zhang", "Qingkai Zeng"], "title": "Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis", "comment": null, "summary": "Large language models (LLMs) achieve strong performance on code generation, but the mechanisms by which Chain-of-Thought (CoT) prompting helps remain unclear. We present a systematic empirical and information-theoretic study of CoT effectiveness in neural code generation, evaluating five paradigms (Zero-Shot, Zero-Shot CoT, Self-Planning, Structured CoT, Reasoning-CoT) across six Python benchmarks, a multilingual benchmark with 12 programming languages, and six models from 7B to 480B parameters, using conditional mutual information $I(Y;C|X)$ as a conceptual lens. Our results show that externally guided CoT consistently outperforms direct generation, with structured methods improving Pass@1 by 5--12\\% on average while using substantially fewer tokens than reflective reasoning, and that CoT benefits depend on language type systems and model capacity. We further find that reasoning \\emph{quality} is critical: high-quality structured CoT from strong generators yields significantly higher accuracy than lightweight alternatives with the same template, whereas naive Zero-Shot CoT can even degrade performance. These findings provide practical guidance for choosing CoT strategies based on model capacity, language characteristics, and task complexity.", "AI": {"tldr": "\u8bba\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u601d\u7ef4\u94fe\u63d0\u793a\u5728\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u548c\u6a21\u578b\u89c4\u6a21\u4e0b\u7684\u4ee3\u7801\u751f\u6210\u6548\u679c\uff0c\u53d1\u73b0\u7ed3\u6784\u5316CoT\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u66f4\u9ad8\u6548\uff0cCoT\u6548\u679c\u53d6\u51b3\u4e8e\u6a21\u578b\u80fd\u529b\u3001\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u63a8\u7406\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u601d\u7ef4\u94fe\u63d0\u793a\u7684\u6709\u6548\u673a\u5236\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76CoT\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u91c7\u7528\u4fe1\u606f\u8bba\u6846\u67b6\uff0c\u8bc4\u4f305\u79cdCoT\u8303\u5f0f\u57286\u4e2aPython\u57fa\u51c6\u300112\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c6\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u7684\u8868\u73b0\uff0c\u4f7f\u7528\u6761\u4ef6\u4e92\u4fe1\u606f\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\u3002", "result": "\u5916\u90e8\u5f15\u5bfc\u7684CoT\u6301\u7eed\u4f18\u4e8e\u76f4\u63a5\u751f\u6210\uff0c\u7ed3\u6784\u5316\u65b9\u6cd5\u5e73\u5747\u63d0\u53475-12%\u7684Pass@1\u4e14\u6bd4\u53cd\u601d\u63a8\u7406\u66f4\u8282\u7701token\uff1bCoT\u6548\u679c\u53d7\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u6a21\u578b\u5bb9\u91cf\u5f71\u54cd\uff1b\u63a8\u7406\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u7814\u7a76\u4e3a\u6839\u636e\u6a21\u578b\u80fd\u529b\u3001\u8bed\u8a00\u7279\u6027\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u9009\u62e9CoT\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u5f3a\u8c03\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.09775", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09775", "abs": "https://arxiv.org/abs/2512.09775", "authors": ["Vladimir Balditsyn", "Philippe Lalanda", "German Vega", "St\u00e9phanie Chollet"], "title": "Quantifying Uncertainty in Machine Learning-Based Pervasive Systems: Application to Human Activity Recognition", "comment": null, "summary": "The recent convergence of pervasive computing and machine learning has given rise to numerous services, impacting almost all areas of economic and social activity. However, the use of AI techniques precludes certain standard software development practices, which emphasize rigorous testing to ensure the elimination of all bugs and adherence to well-defined specifications. ML models are trained on numerous high-dimensional examples rather than being manually coded. Consequently, the boundaries of their operating range are uncertain, and they cannot guarantee absolute error-free performance. In this paper, we propose to quantify uncertainty in ML-based systems. To achieve this, we propose to adapt and jointly utilize a set of selected techniques to evaluate the relevance of model predictions at runtime. We apply and evaluate these proposals in the highly heterogeneous and evolving domain of Human Activity Recognition (HAR). The results presented demonstrate the relevance of the approach, and we discuss in detail the assistance provided to domain experts.", "AI": {"tldr": "\u63d0\u51fa\u7528\u4e8e\u91cf\u5316\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u8fdb\u884c\u9a8c\u8bc1", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u5f00\u53d1\u4f9d\u8d56\u4e8e\u4e25\u683c\u6d4b\u8bd5\u548c\u89c4\u8303\uff0c\u800cML\u6a21\u578b\u57fa\u4e8e\u6570\u636e\u8bad\u7ec3\uff0c\u5176\u8fd0\u884c\u8fb9\u754c\u4e0d\u786e\u5b9a\u4e14\u65e0\u6cd5\u4fdd\u8bc1\u5b8c\u5168\u65e0\u9519\u8bef\u6027\u80fd", "method": "\u8c03\u6574\u5e76\u8054\u5408\u4f7f\u7528\u4e00\u7ec4\u9009\u5b9a\u6280\u672f\uff0c\u5728\u8fd0\u884c\u65f6\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u7684\u76f8\u5173\u6027", "result": "\u65b9\u6cd5\u5728\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u9886\u57df\u5f97\u5230\u9a8c\u8bc1\uff0c\u7ed3\u679c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u5b9e\u7528\u6027", "conclusion": "\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u80fd\u4e3a\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u6709\u6548\u5e2e\u52a9"}}
{"id": "2512.09566", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09566", "abs": "https://arxiv.org/abs/2512.09566", "authors": ["Junkai Ji", "Zhangfan Yang", "Dong Xu", "Ruibin Bai", "Jianqiang Li", "Tingjun Hou", "Zexuan Zhu"], "title": "Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search", "comment": "21 pages, 5 figures", "summary": "Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.09409", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09409", "abs": "https://arxiv.org/abs/2512.09409", "authors": ["Kyle Habib", "Vladislav Kapitsyn", "Giovanni Mazzeo", "Faisal Mehrban"], "title": "Proof of Trusted Execution: A Consensus Paradigm for Deterministic Blockchain Finality", "comment": "Submitted to Middleware 2026 Conference", "summary": "Current blockchain consensus protocols -- notably, Proof of Work (PoW) and Proof of Stake (PoS) -- deliver global agreement but exhibit structural constraints. PoW anchors security in heavy computation, inflating energy use and imposing high confirmation latency. PoS improves efficiency but introduces stake concentration, long-range and \"nothing-at-stake\" vulnerabilities, and a hard performance ceiling shaped by slot times and multi-round committee voting. In this paper, we propose Proof of Trusted Execution (PoTE), a consensus paradigm where agreement emerges from verifiable execution rather than replicated re-execution. Validators operate inside heterogeneous VM-based TEEs, each running the same canonical program whose measurement is publicly recorded, and each producing vendor-backed attestations that bind the enclave code hash to the block contents. Because the execution is deterministic and the proposer is uniquely derived from public randomness, PoTE avoids forks, eliminates slot.time bottlenecks, and commits blocks in a single round of verification. We present the design of a PoTE consensus client, describe our reference implementation, and evaluate its performance against the stringent throughput requirements of the Trillion decentralized exchange.", "AI": {"tldr": "\u63d0\u51faPoTE\u5171\u8bc6\u534f\u8bae\uff0c\u5229\u7528TEEs\u5b9e\u73b0\u9ad8\u6548\u7684\u5355\u8f6e\u9a8c\u8bc1\u5171\u8bc6\uff0c\u89e3\u51b3\u4f20\u7edfPoW\u548cPoS\u7684\u7ed3\u6784\u6027\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3PoW\u7684\u9ad8\u80fd\u8017\u3001\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u4ee5\u53caPoS\u7684\u6743\u76ca\u96c6\u4e2d\u5316\u3001\u957f\u7a0b\u653b\u51fb\u548c\u65e0\u5229\u5bb3\u5173\u7cfb\u6f0f\u6d1e\u7b49\u7ed3\u6784\u7ea6\u675f\u3002", "method": "\u9a8c\u8bc1\u5668\u5728\u5f02\u6784VM-based TEEs\u4e2d\u8fd0\u884c\u76f8\u540c\u7684\u89c4\u8303\u7a0b\u5e8f\uff0c\u6bcf\u4e2a\u7a0b\u5e8f\u751f\u6210\u4f9b\u5e94\u5546\u652f\u6301\u7684\u8bc1\u660e\uff0c\u5c06\u4ee3\u7801\u54c8\u5e0c\u4e0e\u533a\u5757\u5185\u5bb9\u7ed1\u5b9a\uff0c\u901a\u8fc7\u516c\u5f00\u968f\u673a\u6027\u552f\u4e00\u786e\u5b9a\u63d0\u8bae\u8005\u3002", "result": "PoTE\u80fd\u591f\u907f\u514d\u5206\u53c9\uff0c\u6d88\u9664\u65f6\u9699\u65f6\u95f4\u74f6\u9888\uff0c\u5e76\u5728\u5355\u8f6e\u9a8c\u8bc1\u4e2d\u63d0\u4ea4\u533a\u5757\u3002", "conclusion": "PoTE\u901a\u8fc7\u5229\u7528\u53ef\u4fe1\u6267\u884c\u73af\u5883\u5b9e\u73b0\u5355\u8f6e\u9a8c\u8bc1\u7684\u5171\u8bc6\u673a\u5236\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u5171\u8bc6\u534f\u8bae\u7684\u5206\u53c9\u95ee\u9898\uff0c\u4e3a\u9ad8\u541e\u5410\u91cf\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09442", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09442", "abs": "https://arxiv.org/abs/2512.09442", "authors": ["Xiaoxiao Chi", "Xuyun Zhang", "Yan Wang", "Hongsheng Hu", "Wanchun Dou"], "title": "Reference Recommendation based Membership Inference Attack against Hybrid-based Recommender Systems", "comment": "This paper has been accepted by AAAI 2026", "summary": "Recommender systems have been widely deployed across various domains such as e-commerce and social media, and intelligently suggest items like products and potential friends to users based on their preferences and interaction history, which are often privacy-sensitive. Recent studies have revealed that recommender systems are prone to membership inference attacks (MIAs), where an attacker aims to infer whether or not a user's data has been used for training a target recommender system. However, existing MIAs fail to exploit the unique characteristic of recommender systems, and therefore are only applicable to mixed recommender systems consisting of two recommendation algorithms. This leaves a gap in investigating MIAs against hybrid-based recommender systems where the same algorithm utilizing user-item historical interactions and attributes of users and items serves and produces personalised recommendations. To investigate how the personalisation in hybrid-based recommender systems influences MIA, we propose a novel metric-based MIA. Specifically, we leverage the characteristic of personalisation to obtain reference recommendation for any target users. Then, a relative membership metric is proposed to exploit a target user's historical interactions, target recommendation, and reference recommendation to infer the membership of the target user's data. Finally, we theoretically and empirically demonstrate the efficacy of the proposed metric-based MIA on hybrid-based recommender systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u4e2a\u6027\u5316\u63a8\u8350\u7279\u6027\u6765\u63d0\u9ad8\u653b\u51fb\u6548\u679c", "motivation": "\u73b0\u6709\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u672a\u5145\u5206\u5229\u7528\u63a8\u8350\u7cfb\u7edf\u7684\u4e2a\u6027\u5316\u7279\u6027\uff0c\u4e14\u4ec5\u9002\u7528\u4e8e\u6df7\u5408\u4e24\u79cd\u63a8\u8350\u7b97\u6cd5\u7684\u7cfb\u7edf\uff0c\u65e0\u6cd5\u6709\u6548\u653b\u51fb\u57fa\u4e8e\u5355\u4e00\u7b97\u6cd5\u7684\u6df7\u5408\u63a8\u8350\u7cfb\u7edf", "method": "\u63d0\u51fa\u57fa\u4e8e\u5ea6\u91cf\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\uff1a\u5229\u7528\u4e2a\u6027\u5316\u7279\u6027\u83b7\u53d6\u76ee\u6807\u7528\u6237\u7684\u53c2\u8003\u63a8\u8350\uff0c\u7136\u540e\u63d0\u51fa\u76f8\u5bf9\u6210\u5458\u5ea6\u91cf\u6765\u7ed3\u5408\u7528\u6237\u5386\u53f2\u4ea4\u4e92\u3001\u76ee\u6807\u63a8\u8350\u548c\u53c2\u8003\u63a8\u8350\u8fdb\u884c\u6210\u5458\u63a8\u65ad", "result": "\u7406\u8bba\u4e0a\u548c\u7ecf\u9a8c\u4e0a\u90fd\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5ea6\u91cf\u7684\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\u5728\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027", "conclusion": "\u8bba\u6587\u586b\u8865\u4e86\u6df7\u5408\u63a8\u8350\u7cfb\u7edf\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u8bc1\u660e\u4e86\u4e2a\u6027\u5316\u7279\u6027\u5bf9\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u91cd\u8981\u5f71\u54cd"}}
{"id": "2512.09727", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09727", "abs": "https://arxiv.org/abs/2512.09727", "authors": ["Junlin Xiao", "Victor-Alexandru Darvariu", "Bruno Lacerda", "Nick Hawes"], "title": "Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions", "comment": null, "summary": "Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u805a\u5408\u5e76\u884cMCTS\u7edf\u8ba1\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "motivation": "\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u73af\u5883\u4e2d\uff0c\u5982\u4f55\u6700\u4f18\u5730\u805a\u5408\u6765\u81ea\u4e0d\u540c\u7ebf\u7a0b\u7684\u5e76\u884cMCTS\u7edf\u8ba1\u4fe1\u606f\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u83b7\u53d6\u672a\u5728\u73af\u5883\u4e2d\u8bd5\u9a8c\u7684\u6709\u5e0c\u671b\u52a8\u4f5c\u7684\u4ef7\u503c\u4f30\u8ba1", "result": "\u57286\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u7cfb\u7edf\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u805a\u5408\u7b56\u7565\uff0c\u63a8\u7406\u65f6\u95f4\u589e\u52a0\u9002\u4e2d", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5e76\u884cMCTS\u5728\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u7684\u7edf\u8ba1\u805a\u5408\u95ee\u9898"}}
{"id": "2512.09829", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09829", "abs": "https://arxiv.org/abs/2512.09829", "authors": ["Khurram Khalil", "Muhammad Mahad Khaliq", "Khaza Anuarul Hoque"], "title": "RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning", "comment": "Accepted in the IEEE DATE 2026 conference", "summary": "The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \\textbf{2.2$\\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \\textbf{99\\%} compared to random fault injection, all while achieving \\textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \\textbf{12.8$\\times$} improvement in \\textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.", "AI": {"tldr": "RIFT\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u667a\u80fd\u6545\u969c\u5b9a\u4f4d\u6846\u67b6\uff0c\u7528\u4e8eAI\u52a0\u901f\u5668\u7684\u8bbe\u8ba1\u9636\u6bb5\u6545\u969c\u8bc4\u4f30\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u53ef\u52a0\u901f2.2\u500d\u5e76\u51cf\u5c1199%\u7684\u6d4b\u8bd5\u5411\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u6545\u969c\u8986\u76d6\u7387\u548c\u6210\u672c\u6548\u76ca\u3002", "motivation": "\u73b0\u4ee3AI\u52a0\u901f\u5668\u89c4\u6a21\u5de8\u5927\uff0c\u4f20\u7edf\u6545\u969c\u8bc4\u4f30\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u4e14\u5173\u952e\u6545\u969c\u6a21\u5f0f\u8986\u76d6\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u6700\u574f\u60c5\u51b5\u6545\u969c\u641c\u7d22\u8f6c\u5316\u4e3a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u7ed3\u5408\u6df7\u5408\u654f\u611f\u6027\u5206\u6790\u8fdb\u884c\u641c\u7d22\u7a7a\u95f4\u526a\u679d\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u751f\u6210\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u529b\u6d4b\u8bd5\u5957\u4ef6\u3002", "result": "\u5728\u4ebf\u53c2\u6570\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u8d1f\u8f7d\u548cNVIDIA A100 GPU\u4e0a\u8bc4\u4f30\uff0c\u76f8\u6bd4\u8fdb\u5316\u65b9\u6cd5\u52a0\u901f2.2\u500d\uff0c\u76f8\u6bd4\u968f\u673a\u6545\u969c\u6ce8\u5165\u51cf\u5c1199%\u6d4b\u8bd5\u5411\u91cf\uff0c\u540c\u65f6\u83b7\u5f97\u66f4\u4f18\u6545\u969c\u8986\u76d6\u7387\u3002\u9009\u62e9\u6027\u9519\u8bef\u6821\u6b63\u4ee3\u7801\u7684\u6210\u672c\u6548\u76ca\u6bd4\u7edf\u4e00\u4e09\u91cd\u6a21\u5757\u5197\u4f59\u4fdd\u62a4\u63d0\u9ad812.8\u500d\u3002", "conclusion": "RIFT\u6846\u67b6\u80fd\u81ea\u52a8\u5316\u53d1\u73b0\u6700\u5c0f\u5316\u9ad8\u5f71\u54cd\u529b\u6545\u969c\u573a\u666f\uff0c\u751f\u6210\u53ef\u76f4\u63a5\u96c6\u6210\u5230\u5546\u4e1aRTL\u9a8c\u8bc1\u6d41\u7a0b\u7684UVM\u517c\u5bb9\u9a8c\u8bc1\u5de5\u4ef6\uff0c\u4e3a\u667a\u80fd\u786c\u4ef6\u4fdd\u62a4\u7b56\u7565\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6570\u636e\u3002"}}
{"id": "2512.09549", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09549", "abs": "https://arxiv.org/abs/2512.09549", "authors": ["Jonathan Evertz", "Niklas Risse", "Nicolai Neuer", "Andreas M\u00fcller", "Philipp Normann", "Gaetano Sapia", "Srishti Gupta", "David Pape", "Soumya Shaw", "Devansh Srivastav", "Christian Wressnegger", "Erwin Quiring", "Thorsten Eisenhofer", "Daniel Arp", "Lea Sch\u00f6nherr"], "title": "Chasing Shadows: Pitfalls in LLM Security Research", "comment": "About to appear at NDSS'26", "summary": "Large language models (LLMs) are increasingly prevalent in security research. Their unique characteristics, however, introduce challenges that undermine established paradigms of reproducibility, rigor, and evaluation. Prior work has identified common pitfalls in traditional machine learning research, but these studies predate the advent of LLMs. In this paper, we identify \\emph{nine} common pitfalls that have become (more) relevant with the emergence of LLMs and that can compromise the validity of research involving them. These pitfalls span the entire computation process, from data collection, pre-training, and fine-tuning to prompting and evaluation.\n  We assess the prevalence of these pitfalls across all 72 peer-reviewed papers published at leading Security and Software Engineering venues between 2023 and 2024. We find that every paper contains at least one pitfall, and each pitfall appears in multiple papers. Yet only 15.7\\% of the present pitfalls were explicitly discussed, suggesting that the majority remain unrecognized. To understand their practical impact, we conduct four empirical case studies showing how individual pitfalls can mislead evaluation, inflate performance, or impair reproducibility. Based on our findings, we offer actionable guidelines to support the community in future work.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc6\u522b\u4e86LLM\u5b89\u5168\u7814\u7a76\u4e2d\u5e38\u89c1\u7684\u4e5d\u4e2a\u9677\u9631\uff0c\u5206\u6790\u4e8672\u7bc7\u8bba\u6587\u53d1\u73b0\u6bcf\u4e2a\u90fd\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u9677\u9631\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8fd9\u4e9b\u9677\u9631\u5bf9\u7814\u7a76\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u6700\u540e\u63d0\u51fa\u4e86\u6539\u8fdb\u6307\u5357\u3002", "motivation": "LLMs\u5728\u5b89\u5168\u7814\u7a76\u4e2d\u7684\u666e\u53ca\u5e26\u6765\u4e86\u53ef\u91cd\u590d\u6027\u3001\u4e25\u8c28\u6027\u548c\u8bc4\u4f30\u65b9\u9762\u7684\u6311\u6218\uff0c\u73b0\u6709\u7814\u7a76\u5bf9LLM\u7279\u6709\u7684\u9677\u9631\u7f3a\u4e4f\u7cfb\u7edf\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5ba1\u67e52023-2024\u5e74\u95f472\u7bc7\u9876\u7ea7\u5b89\u5168\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u7684\u8bba\u6587\uff0c\u8bc6\u522b\u4e5d\u7c7b\u5e38\u89c1\u9677\u9631\uff0c\u5e76\u8fdb\u884c\u56db\u9879\u5b9e\u8bc1\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u6240\u6709\u88ab\u5206\u6790\u7684\u8bba\u6587\u90fd\u5b58\u5728\u81f3\u5c11\u4e00\u4e2a\u9677\u9631\uff0c\u5e73\u5747\u6bcf\u4e2a\u9677\u9631\u51fa\u73b0\u5728\u591a\u7bc7\u8bba\u6587\u4e2d\uff0c\u4f46\u4ec5\u670915.7%\u7684\u9677\u9631\u88ab\u660e\u786e\u8ba8\u8bba\u3002", "conclusion": "LLM\u5b89\u5168\u7814\u7a76\u666e\u904d\u5b58\u5728\u672a\u88ab\u5145\u5206\u8ba4\u8bc6\u7684\u9677\u9631\uff0c\u9700\u8981\u793e\u533a\u91c7\u7eb3\u8bba\u6587\u63d0\u51fa\u7684\u884c\u52a8\u6307\u5357\u6765\u63d0\u5347\u7814\u7a76\u8d28\u91cf\u3002"}}
{"id": "2512.09769", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09769", "abs": "https://arxiv.org/abs/2512.09769", "authors": ["Hanzhou Wu", "Yige Wang"], "title": "Defining Cost Function of Steganography with Large Language Models", "comment": "https://scholar.google.com/citations?hl=en&user=IdiF7M0AAAAJ", "summary": "In this paper, we make the first attempt towards defining cost function of steganography with large language models (LLMs), which is totally different from previous works that rely heavily on expert knowledge or require large-scale datasets for cost learning. To achieve this goal, a two-stage strategy combining LLM-guided program synthesis with evolutionary search is applied in the proposed method. In the first stage, a certain number of cost functions in the form of computer program are synthesized from LLM responses to structured prompts. These cost functions are then evaluated with pretrained steganalysis models so that candidate cost functions suited to steganography can be collected. In the second stage, by retraining a steganalysis model for each candidate cost function, the optimal cost function(s) can be determined according to the detection accuracy. This two-stage strategy is performed by an iterative fashion so that the best cost function can be collected at the last iteration. Experiments show that the proposed method enables LLMs to design new cost functions of steganography that significantly outperform existing works in terms of resisting steganalysis tools, which verifies the superiority of the proposed method. To the best knowledge of the authors, this is the first work applying LLMs to the design of advanced cost function of steganography, which presents a novel perspective for steganography design and may shed light on further research.", "AI": {"tldr": "\u9996\u7bc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9a\u4e49\u9690\u5199\u672f\u6210\u672c\u51fd\u6570\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u7b56\u7565\u663e\u8457\u63d0\u5347\u6297\u9690\u5199\u5206\u6790\u80fd\u529b", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u8fc7\u5ea6\u4f9d\u8d56\u4e13\u5bb6\u77e5\u8bc6\u6216\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8fdb\u884c\u6210\u672c\u5b66\u4e60\uff0cLLMs\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027", "method": "\u7ed3\u5408LLM\u5f15\u5bfc\u7684\u7a0b\u5e8f\u5408\u6210\u4e0e\u8fdb\u5316\u641c\u7d22\u7684\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u9996\u9636\u6bb5\u4ece\u7ed3\u6784\u5316\u63d0\u793a\u751f\u6210\u7a0b\u5e8f\u5f62\u5f0f\u7684\u6210\u672c\u51fd\u6570\uff0c\u6b21\u9636\u6bb5\u901a\u8fc7\u91cd\u65b0\u8bad\u7ec3\u9690\u5199\u5206\u6790\u6a21\u578b\u8bc4\u4f30\u4f18\u5316", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u8bbe\u8ba1\u7684\u6210\u672c\u51fd\u6570\u5728\u62b5\u6297\u9690\u5199\u5206\u6790\u5de5\u5177\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5c06LLMs\u5e94\u7528\u4e8e\u9ad8\u7ea7\u9690\u5199\u672f\u6210\u672c\u51fd\u6570\u8bbe\u8ba1\uff0c\u4e3a\u9690\u5199\u672f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2"}}
{"id": "2512.09872", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09872", "abs": "https://arxiv.org/abs/2512.09872", "authors": ["Khurram Khalil", "Khaza Anuarul Hoque"], "title": "FlipLLM: Efficient Bit-Flip Attacks on Multimodal LLMs using Reinforcement Learning", "comment": "Accepted in IEEE HOST 2026", "summary": "Generative Artificial Intelligence models, such as Large Language Models (LLMs) and Large Vision Models (VLMs), exhibit state-of-the-art performance but remain vulnerable to hardware-based threats, specifically bit-flip attacks (BFAs). Existing BFA discovery methods lack generalizability and struggle to scale, often failing to analyze the vast parameter space and complex interdependencies of modern foundation models in a reasonable time. This paper proposes FlipLLM, a reinforcement learning (RL) architecture-agnostic framework that formulates BFA discovery as a sequential decision-making problem. FlipLLM combines sensitivity-guided layer pruning with Q-learning to efficiently identify minimal, high-impact bit sets that can induce catastrophic failure. We demonstrate the effectiveness and generalizability of FlipLLM by applying it to a diverse set of models, including prominent text-only LLMs (GPT-2 Large, LLaMA 3.1 8B, and DeepSeek-V2 7B), VLMs such as LLaVA 1.6, and datasets, such as MMLU, MMLU-Pro, VQAv2, and TextVQA. Our results show that FlipLLM can identify critical bits that are vulnerable to BFAs up to 2.5x faster than SOTA methods. We demonstrate that flipping the FlipLLM-identified bits plummets the accuracy of LLaMA 3.1 8B from 69.9% to ~0.2%, and for LLaVA's VQA score from 78% to almost 0%, by flipping as few as 5 and 7 bits, respectively. Further analysis reveals that applying standard hardware protection mechanisms, such as ECC SECDED, to the FlipLLM-identified bit locations completely mitigates the BFA impact, demonstrating the practical value of our framework in guiding hardware-level defenses. FlipLLM offers the first scalable and adaptive methodology for exploring the BFA vulnerability of both language and multimodal foundation models, paving the way for comprehensive hardware-security evaluation.", "AI": {"tldr": "FlipLLM\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u6548\u53d1\u73b0\u5927\u578bAI\u6a21\u578b\u4e2d\u7684\u4f4d\u7ffb\u8f6c\u653b\u51fb\u6f0f\u6d1e\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb2.5\u500d\uff0c\u5e76\u80fd\u6307\u5bfc\u786c\u4ef6\u9632\u62a4\u63aa\u65bd", "motivation": "\u73b0\u6709\u7684\u4f4d\u7ffb\u8f6c\u653b\u51fb\u53d1\u73b0\u65b9\u6cd5\u7f3a\u4e4f\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u96be\u4ee5\u5728\u5408\u7406\u65f6\u95f4\u5185\u5206\u6790\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u7684\u5e9e\u5927\u53c2\u6570\u7a7a\u95f4\u548c\u590d\u6742\u4f9d\u8d56\u5173\u7cfb", "method": "FlipLLM\u5c06\u4f4d\u7ffb\u8f6c\u653b\u51fb\u53d1\u73b0\u5efa\u6a21\u4e3a\u987a\u5e8f\u51b3\u7b56\u95ee\u9898\uff0c\u7ed3\u5408\u7075\u654f\u5ea6\u5f15\u5bfc\u7684\u5c42\u526a\u679d\u548cQ\u5b66\u4e60\u6765\u8bc6\u522b\u6700\u5c0f\u4f46\u5f71\u54cd\u6700\u5927\u7684\u4f4d\u96c6\u5408", "result": "FlipLLM\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u8272\uff1aLLaMA 3.1 8B\u51c6\u786e\u7387\u4ece69.9%\u964d\u81f30.2%\uff08\u4ec5\u7ffb\u8f6c5\u4f4d\uff09\uff0cLLaVA\u7684VQA\u5206\u6570\u4ece78%\u964d\u81f3\u63a5\u8fd10%\uff08\u4ec5\u7ffb\u8f6c7\u4f4d\uff09", "conclusion": "FlipLLM\u4e3a\u8bed\u8a00\u548c\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a2\u7d22\u4f4d\u7ffb\u8f6c\u653b\u51fb\u6f0f\u6d1e\uff0c\u4e3a\u6807\u51c6\u786c\u4ef6\u9632\u62a4\u673a\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc"}}
{"id": "2512.09895", "categories": ["cs.AI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.09895", "abs": "https://arxiv.org/abs/2512.09895", "authors": ["Jane Greenberg", "Scott McClellan", "Addy Ireland", "Robert Sammarco", "Colton Gerber", "Christopher B. Rauch", "Mat Kelly", "John Kunze", "Yuan An", "Eric Toberer"], "title": "Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science", "comment": "Metadata and Semantics Research Conference 2025, 14 pages, 7 figures", "summary": "Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MatSci-YAMZ\u5e73\u53f0\uff0c\u8be5\u5e73\u53f0\u878d\u5408\u4eba\u5de5\u667a\u80fd\u548c\u4f17\u5305\u7b49\u4eba\u5728\u73af\u65b9\u6cd5\uff0c\u7528\u4e8e\u652f\u6301\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u5143\u6570\u636e\u8bcd\u6c47\u5f00\u53d1\u3002\u901a\u8fc7\u6982\u5ff5\u9a8c\u8bc1\u6848\u4f8b\uff0c\u5c55\u793a\u4e86AI-\u4eba\u5728\u73af\u6a21\u578b\u5728\u751f\u6210\u672f\u8bed\u5b9a\u4e49\u65b9\u9762\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u4e0eFAIR\u539f\u5219\u7684\u5951\u5408\u53ca\u8de8\u9886\u57df\u6269\u5c55\u6f5c\u529b\u3002", "motivation": "\u5143\u6570\u636e\u8bcd\u6c47\u5bf9\u63a8\u8fdbFAIR\u548cFARR\u6570\u636e\u539f\u5219\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u53d1\u5c55\u53d7\u9650\u4e8e\u4eba\u529b\u8d44\u6e90\u4e0d\u8db3\u548c\u6807\u51c6\u5316\u5b9e\u8df5\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "method": "\u5e73\u53f0\u91c7\u7528\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u5728\u73af\uff08\u5305\u62ec\u4f17\u5305\uff09\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u3002\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\uff0c6\u540d\u53c2\u4e0e\u8005\u901a\u8fc7\u5e73\u53f0\u8d21\u732e\u672f\u8bed\u5b9a\u4e49\u5e76\u63d0\u4f9b\u793a\u4f8b\uff0c\u4ee5\u4fc3\u8fdbAI\u751f\u6210\u5b9a\u4e49\u7684\u4f18\u5316\u3002", "result": "\u6210\u529f\u751f\u6210\u4e8619\u4e2aAI\u751f\u6210\u7684\u672f\u8bed\u5b9a\u4e49\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u53cd\u9988\u5faa\u73af\u9a8c\u8bc1\u4e86AI-\u4eba\u5728\u73af\u4f18\u5316\u7684\u53ef\u884c\u6027\u3002\u7814\u7a76\u8bc1\u5b9e\u4e86\u8be5\u6a21\u578b\u7684\u53ef\u884c\u6027\uff0c\u7a81\u51fa\u8868\u73b0\u5728\u6982\u5ff5\u9a8c\u8bc1\u6210\u529f\u3001\u4e0eFAIR\u548c\u5f00\u653e\u79d1\u5b66\u539f\u5219\u4e00\u81f4\u3001\u63d0\u4f9b\u4e86\u672a\u6765\u7814\u7a76\u6307\u5357\u4ee5\u53ca\u5177\u5907\u8de8\u9886\u57df\u6269\u5c55\u6f5c\u529b\u3002", "conclusion": "MatSci-YAMZ\u5e95\u5c42\u6a21\u578b\u80fd\u591f\u589e\u5f3a\u8bed\u4e49\u900f\u660e\u5ea6\uff0c\u5e76\u51cf\u5c11\u8fbe\u6210\u5171\u8bc6\u548c\u5f00\u53d1\u5143\u6570\u636e\u8bcd\u6c47\u6240\u9700\u7684\u65f6\u95f4\u3002"}}
{"id": "2512.09883", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09883", "abs": "https://arxiv.org/abs/2512.09883", "authors": ["Daniel Gibert", "Felip Many\u00e0"], "title": "ByteShield: Adversarially Robust End-to-End Malware Detection through Byte Masking", "comment": null, "summary": "Research has proven that end-to-end malware detectors are vulnerable to adversarial attacks. In response, the research community has proposed defenses based on randomized and (de)randomized smoothing. However, these techniques remain susceptible to attacks that insert large adversarial payloads. To address these limitations, we propose a novel defense mechanism designed to harden end-to-end malware detectors by leveraging masking at the byte level. This mechanism operates by generating multiple masked versions of the input file, independently classifying each version, and then applying a threshold-based voting mechanism to produce the final classification. Key to this defense is a deterministic masking strategy that systematically strides a mask across the entire input file. Unlike randomized smoothing defenses, which randomly mask or delete bytes, this structured approach ensures coverage of the file over successive versions. In the best-case scenario, this strategy fully occludes the adversarial payload, effectively neutralizing its influence on the model's decision. In the worst-case scenario, it partially occludes the adversarial payload, reducing its impact on the model's predictions. By occluding the adversarial payload in one or more masked versions, this defense ensures that some input versions remain representative of the file's original intent, allowing the voting mechanism to suppress the influence of the adversarial payload. Results achieved on the EMBER and BODMAS datasets demonstrate the suitability of our defense, outperforming randomized and (de)randomized smoothing defenses against adversarial examples generated with a wide range of functionality-preserving manipulations while maintaining high accuracy on clean examples.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u9632\u5fa1\u673a\u5236\uff0c\u901a\u8fc7\u5b57\u8282\u7ea7\u63a9\u7801\u548c\u9608\u503c\u6295\u7968\u6765\u589e\u5f3a\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u5bf9\u6297\u5bf9\u6297\u6027\u653b\u51fb\u7684\u80fd\u529b\u3002\u8be5\u673a\u5236\u4f18\u4e8e\u73b0\u6709\u7684\u968f\u673a\u5316\u548c\u53bb\u968f\u673a\u5316\u5e73\u6ed1\u9632\u5fa1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u968f\u673a\u5316\u548c\u53bb\u968f\u673a\u5316\u5e73\u6ed1\u7684\u7aef\u5230\u7aef\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u9632\u5fa1\u673a\u5236\u5728\u9762\u5bf9\u5927\u89c4\u6a21\u5bf9\u6297\u6027\u8f7d\u8377\u63d2\u5165\u653b\u51fb\u65f6\u4ecd\u7136\u8106\u5f31\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u786e\u5b9a\u6027\u63a9\u7801\u7b56\u7565\uff0c\u7cfb\u7edf\u6027\u5730\u5728\u8f93\u5165\u6587\u4ef6\u4e0a\u6ed1\u52a8\u63a9\u7801\u751f\u6210\u591a\u4e2a\u63a9\u7801\u7248\u672c\uff0c\u72ec\u7acb\u5206\u7c7b\u6bcf\u4e2a\u7248\u672c\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u9608\u503c\u7684\u6295\u7968\u673a\u5236\u4ea7\u751f\u6700\u7ec8\u5206\u7c7b\u3002", "result": "\u5728EMBER\u548cBODMAS\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u9632\u5fa1\u673a\u5236\u5728\u5bf9\u6297\u5404\u79cd\u529f\u80fd\u4fdd\u6301\u64cd\u4f5c\u751f\u6210\u7684\u5bf9\u6297\u6837\u672c\u65f6\u4f18\u4e8e\u968f\u673a\u5316\u548c\u53bb\u968f\u673a\u5316\u5e73\u6ed1\u9632\u5fa1\uff0c\u540c\u65f6\u5728\u5e72\u51c0\u6837\u672c\u4e0a\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5b57\u8282\u7ea7\u63a9\u7801\u9632\u5fa1\u673a\u5236\u80fd\u591f\u6709\u6548\u62b5\u6d88\u5bf9\u6297\u6027\u8f7d\u8377\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u5728\u6700\u4f73\u60c5\u51b5\u4e0b\u5b8c\u5168\u906e\u6321\u6216\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u90e8\u5206\u906e\u6321\u5bf9\u6297\u6027\u8f7d\u8377\uff0c\u786e\u4fdd\u6295\u7968\u673a\u5236\u80fd\u591f\u6291\u5236\u5176\u5f71\u54cd\uff0c\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u4fdd\u62a4\u3002"}}
{"id": "2512.09897", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09897", "abs": "https://arxiv.org/abs/2512.09897", "authors": ["Haoye Lu", "Pavan Seshadri", "Kaheer Suleman"], "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments", "comment": null, "summary": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.", "AI": {"tldr": "SCOPE\u662f\u4e00\u79cd\u4e00\u6b21\u6027\u5206\u5c42\u89c4\u5212\u5668\uff0c\u5229\u7528LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\u9884\u8bad\u7ec3\uff0c\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u6587\u672c\u7684\u73af\u5883\u4e2d\u957f\u671f\u89c4\u5212\u7684\u6311\u6218\uff1a\u5f00\u653e\u52a8\u4f5c\u7a7a\u95f4\u3001\u6a21\u7cca\u89c2\u5bdf\u548c\u7a00\u758f\u53cd\u9988\uff0c\u540c\u65f6\u964d\u4f4e\u5bf9LLM\u7684\u4f9d\u8d56\u4ee5\u63d0\u9ad8\u6548\u7387", "method": "\u91c7\u7528LLM\u751f\u6210\u5b50\u76ee\u6807\u8fdb\u884c\u4e00\u6b21\u6027\u521d\u59cb\u5316\u9884\u8bad\u7ec3\uff0c\u800c\u975e\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53cd\u590d\u67e5\u8be2LLM\uff0c\u901a\u8fc7\u793a\u4f8b\u8f68\u8ff9\u76f4\u63a5\u6d3e\u751f\u5b50\u76ee\u6807", "result": "\u5728TextCraft\u73af\u5883\u4e2d\u6210\u529f\u7387\u4ece0.52\u63d0\u5347\u81f30.56\uff0c\u63a8\u7406\u65f6\u95f4\u4ece164.4\u79d2\u5927\u5e45\u51cf\u5c11\u52303.0\u79d2", "conclusion": "LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u5373\u4f7f\u4e0d\u662f\u6700\u4f18\u7684\uff0c\u4ecd\u53ef\u4f5c\u4e3a\u6587\u672c\u89c4\u5212\u4efb\u52a1\u4e2d\u5206\u5c42\u76ee\u6807\u5206\u89e3\u7684\u826f\u597d\u8d77\u70b9\uff0c\u5728\u6548\u7387\u548c\u6027\u80fd\u95f4\u53d6\u5f97\u5e73\u8861"}}
