{"id": "2512.04120", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY", "cs.DB", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.04120", "abs": "https://arxiv.org/abs/2512.04120", "authors": ["Liang Telkamp", "Madelon Hulsebos"], "title": "Towards Contextual Sensitive Data Detection", "comment": null, "summary": "The emergence of open data portals necessitates more attention to protecting sensitive data before datasets get published and exchanged. While an abundance of methods for suppressing sensitive data exist, the conceptualization of sensitive data and methods to detect it, focus particularly on personal data that, if disclosed, may be harmful or violate privacy. We observe the need for refining and broadening our definitions of sensitive data, and argue that the sensitivity of data depends on its context. Based on this definition, we introduce two mechanisms for contextual sensitive data detection that con- sider the broader context of a dataset at hand. First, we introduce type contextualization, which first detects the semantic type of particular data values, then considers the overall context of the data values within the dataset or document. Second, we introduce domain contextualization which determines sensitivity of a given dataset in the broader context based on the retrieval of relevant rules from documents that specify data sensitivity (e.g., data topic and geographic origin). Experiments with these mechanisms, assisted by large language models (LLMs), confirm that: 1) type-contextualization significantly reduces the number of false positives for type-based sensitive data detection and reaches a recall of 94% compared to 63% with commercial tools, and 2) domain-contextualization leveraging sensitivity rule retrieval is effective for context-grounded sensitive data detection in non-standard data domains such as humanitarian datasets. Evaluation with humanitarian data experts also reveals that context-grounded LLM explanations provide useful guidance in manual data auditing processes, improving consistency. We open-source mechanisms and annotated datasets for contextual sensitive data detection at https://github.com/trl-lab/sensitive-data-detection.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u654f\u611f\u6570\u636e\u68c0\u6d4b\u673a\u5236\u2014\u2014\u7c7b\u578b\u60c5\u5883\u5316\u548c\u9886\u57df\u60c5\u5883\u5316\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u9886\u57df\u6709\u6548\u8bc6\u522b\u654f\u611f\u6570\u636e\uff0c\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002", "motivation": "\u5f00\u653e\u6570\u636e\u95e8\u6237\u7684\u5174\u8d77\u9700\u8981\u66f4\u597d\u5730\u4fdd\u62a4\u654f\u611f\u6570\u636e\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e2a\u4eba\u9690\u79c1\u6570\u636e\uff0c\u4f46\u6570\u636e\u654f\u611f\u6027\u53d6\u51b3\u4e8e\u4e0a\u4e0b\u6587\uff0c\u9700\u8981\u66f4\u5e7f\u6cdb\u548c\u7ec6\u5316\u7684\u654f\u611f\u6570\u636e\u5b9a\u4e49\u3002", "method": "1) \u7c7b\u578b\u60c5\u5883\u5316\uff1a\u68c0\u6d4b\u6570\u636e\u503c\u7684\u8bed\u4e49\u7c7b\u578b\uff0c\u5e76\u8003\u8651\u5176\u5728\u6570\u636e\u96c6\u4e2d\u7684\u6574\u4f53\u4e0a\u4e0b\u6587\u30022) \u9886\u57df\u60c5\u5883\u5316\uff1a\u57fa\u4e8e\u76f8\u5173\u89c4\u5219\u6587\u6863\u68c0\u7d22\uff0c\u5728\u66f4\u5e7f\u4e0a\u4e0b\u6587\u4e2d\u786e\u5b9a\u6570\u636e\u96c6\u7684\u654f\u611f\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a\u7c7b\u578b\u60c5\u5883\u5316\u663e\u8457\u51cf\u5c11\u8bef\u62a5\uff0c\u53ec\u56de\u7387\u8fbe\u523094%\uff08\u5546\u4e1a\u5de5\u5177\u4e3a63%\uff09\uff1b\u9886\u57df\u60c5\u5883\u5316\u5728\u4eba\u9053\u4e3b\u4e49\u6570\u636e\u7b49\u975e\u6807\u51c6\u9886\u57df\u6709\u6548\uff1bLLM\u89e3\u91ca\u63d0\u9ad8\u4e86\u4eba\u5de5\u6570\u636e\u5ba1\u8ba1\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u654f\u611f\u6570\u636e\u68c0\u6d4b\u65b9\u6cd5\u6709\u6548\uff0c\u5f00\u6e90\u5de5\u5177\u4fc3\u8fdb\u4e86\u8be5\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u3002"}}
{"id": "2512.04129", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04129", "abs": "https://arxiv.org/abs/2512.04129", "authors": ["Ruichao Liang", "Le Yin", "Jing Chen", "Cong Wu", "Xiaoyu Zhang", "Huangpeng Gu", "Zijian Zhang", "Yang Liu"], "title": "Tipping the Dominos: Topology-Aware Multi-Hop Attacks on LLM-Based Multi-Agent Systems", "comment": null, "summary": "LLM-based multi-agent systems (MASs) have reshaped the digital landscape with their emergent coordination and problem-solving capabilities. However, current security evaluations of MASs are still confined to limited attack scenarios, leaving their security issues unclear and likely underestimated. To fill this gap, we propose TOMA, a topology-aware multi-hop attack scheme targeting MASs. By optimizing the propagation of contamination within the MAS topology and controlling the multi-hop diffusion of adversarial payloads originating from the environment, TOMA unveils new and effective attack vectors without requiring privileged access or direct agent manipulation. Experiments demonstrate attack success rates ranging from 40% to 78% across three state-of-the-art MAS architectures: \\textsc{Magentic-One}, \\textsc{LangManus}, and \\textsc{OWL}, and five representative topologies, revealing intrinsic MAS vulnerabilities that may be overlooked by existing research. Inspired by these findings, we propose a conceptual defense framework based on topology trust, and prototype experiments show its effectiveness in blocking 94.8% of adaptive and composite attacks.", "AI": {"tldr": "\u63d0\u51faTOMA\u653b\u51fb\u65b9\u6848\u63ed\u793a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5b89\u5168\u6f0f\u6d1e\uff0c\u5b9e\u9a8c\u6210\u529f\u738740%-78%\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u62d3\u6251\u4fe1\u4efb\u7684\u9632\u5fa1\u6846\u67b6\u3002", "motivation": "\u5f53\u524dMAS\u5b89\u5168\u8bc4\u4f30\u5c40\u9650\u4e8e\u6709\u9650\u653b\u51fb\u573a\u666f\uff0c\u5b89\u5168\u95ee\u9898\u88ab\u4f4e\u4f30\u3002", "method": "\u63d0\u51faTOMA\u62d3\u6251\u611f\u77e5\u591a\u8df3\u653b\u51fb\u65b9\u6848\uff0c\u901a\u8fc7\u4f18\u5316\u6c61\u67d3\u4f20\u64ad\u548c\u5bf9\u6297\u8f7d\u8377\u6269\u6563\u3002", "result": "\u5728\u4e09\u79cd\u5148\u8fdbMAS\u67b6\u6784\u548c\u4e94\u79cd\u62d3\u6251\u4e0a\u653b\u51fb\u6210\u529f\u7387\u8fbe40%-78%\uff0c\u53d1\u73b0\u88ab\u5ffd\u89c6\u7684\u56fa\u6709\u6f0f\u6d1e\u3002", "conclusion": "MAS\u5b58\u5728\u56fa\u6709\u5b89\u5168\u6f0f\u6d1e\uff0c\u57fa\u4e8e\u62d3\u6251\u4fe1\u4efb\u7684\u9632\u5fa1\u6846\u67b6\u53ef\u6709\u6548\u963b\u632194.8%\u7684\u81ea\u9002\u5e94\u590d\u5408\u653b\u51fb\u3002"}}
{"id": "2512.04237", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04237", "abs": "https://arxiv.org/abs/2512.04237", "authors": ["G\u00fcl\u00e7in \u00c7\u0130V\u0130 B\u0130L\u0130R"], "title": "Primitive Vector Cipher(PVC): A Hybrid Encryption Scheme based on the Vector Computational Diffie-Hellman (V-CDH) Problem", "comment": "Submitted for publication. 19 pages", "summary": "This work introduces the Primitive Vector Cipher (PVC), a novel hybrid encryption scheme integrating matrix-based cryptography with advanced Diffie-Hellman key exchange. PVC's security is grounded on the established hardness of the Vector Computational Diffie- Hellman (V-CDH) problem. The two-layered design uses HKDF to mask plaintext via a DH-authenticated shared primitive vector and randomize cipher blocks with a per-block offset. This approach eliminates deterministic repetitions and provides strong resistance against linear and known-plaintext attacks. PVC's block-wise structure allows for massive parallelism and excellent linear scaling. Security is formally analyzed, demonstrating INDCPA security under V-CDH. STS protocol integration elevates security toward IND-CCA guarantees.", "AI": {"tldr": "PVC\u662f\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u52a0\u5bc6\u65b9\u6848\uff0c\u7ed3\u5408\u77e9\u9635\u5bc6\u7801\u5b66\u548cDiffie-Hellman\u5bc6\u94a5\u4ea4\u6362\uff0c\u63d0\u4f9b\u9ad8\u5b89\u5168\u6027\u548c\u5e76\u884c\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u52a0\u5bc6\u65b9\u6848\u5b58\u5728\u786e\u5b9a\u6027\u91cd\u590d\u548c\u7ebf\u6027\u653b\u51fb\u8106\u5f31\u6027\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u62b5\u6297\u5df2\u77e5\u660e\u6587\u653b\u51fb\u4e14\u652f\u6301\u9ad8\u6548\u5e76\u884c\u5904\u7406\u7684\u65b0\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e24\u5c42\u8bbe\u8ba1\uff1a\u4f7f\u7528HKDF\u901a\u8fc7DH\u8ba4\u8bc1\u7684\u5171\u4eab\u539f\u8bed\u5411\u91cf\u63a9\u76d6\u660e\u6587\uff0c\u5e76\u7528\u6bcf\u5757\u504f\u79fb\u968f\u673a\u5316\u5bc6\u6587\u5757\u3002", "result": "PVC\u6d88\u9664\u4e86\u786e\u5b9a\u6027\u91cd\u590d\uff0c\u5bf9\u7ebf\u6027\u548c\u5df2\u77e5\u660e\u6587\u653b\u51fb\u5177\u6709\u5f3a\u62b5\u6297\u529b\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u884c\u548c\u7ebf\u6027\u6269\u5c55\u3002", "conclusion": "PVC\u5728V-CDH\u5047\u8bbe\u4e0b\u5177\u5907IND-CPA\u5b89\u5168\u6027\uff0c\u7ed3\u5408STS\u534f\u8bae\u53ef\u8fbe\u5230IND-CCA\u5b89\u5168\u7ea7\u522b\uff0c\u662f\u4e00\u79cd\u5b89\u5168\u9ad8\u6548\u7684\u52a0\u5bc6\u65b9\u6848\u3002"}}
{"id": "2512.04254", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04254", "abs": "https://arxiv.org/abs/2512.04254", "authors": ["Ga\u00ebtan Michelet", "Janine Schneider", "Aruna Withanage", "Frank Breitinger"], "title": "Hey GPT-OSS, Looks Like You Got It - Now Walk Me Through It! An Assessment of the Reasoning Language Models Chain of Thought Mechanism for Digital Forensics", "comment": "Accept at DFRWS EU 2026", "summary": "The use of large language models in digital forensics has been widely explored. Beyond identifying potential applications, research has also focused on optimizing model performance for forensic tasks through fine-tuning. However, limited result explainability reduces their operational and legal usability. Recently, a new class of reasoning language models has emerged, designed to handle logic-based tasks through an `internal reasoning' mechanism. Yet, users typically see only the final answer, not the underlying reasoning. One of these reasoning models is gpt-oss, which can be deployed locally, providing full access to its underlying reasoning process. This article presents the first investigation into the potential of reasoning language models for digital forensics. Four test use cases are examined to assess the usability of the reasoning component in supporting result explainability. The evaluation combines a new quantitative metric with qualitative analysis. Findings show that the reasoning component aids in explaining and validating language model outputs in digital forensics at medium reasoning levels, but this support is often limited, and higher reasoning levels do not enhance response quality.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8c03\u67e5\u4e86\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u53d6\u8bc1\u4e2d\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u56db\u4e2a\u6d4b\u8bd5\u7528\u4f8b\u8bc4\u4f30\u63a8\u7406\u7ec4\u4ef6\u5728\u652f\u6301\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u53ef\u7528\u6027\uff0c\u53d1\u73b0\u4e2d\u7b49\u63a8\u7406\u6c34\u5e73\u6709\u52a9\u4e8e\u89e3\u91ca\u548c\u9a8c\u8bc1\u8f93\u51fa\uff0c\u4f46\u652f\u6301\u6709\u9650\u4e14\u66f4\u9ad8\u63a8\u7406\u6c34\u5e73\u4e0d\u4f1a\u63d0\u5347\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u53d6\u8bc1\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u6709\u9650\uff0c\u964d\u4f4e\u4e86\u5176\u64cd\u4f5c\u548c\u6cd5\u5f8b\u53ef\u7528\u6027\u3002\u65b0\u5174\u7684\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u5185\u90e8\u63a8\u7406\u673a\u5236\u5904\u7406\u903b\u8f91\u4efb\u52a1\uff0c\u4f46\u7528\u6237\u901a\u5e38\u53ea\u770b\u5230\u6700\u7ec8\u7b54\u6848\uff0c\u800c\u975e\u5e95\u5c42\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u53ef\u672c\u5730\u90e8\u7f72\u7684\u63a8\u7406\u6a21\u578bgpt-oss\uff0c\u8bbe\u8ba1\u56db\u4e2a\u6d4b\u8bd5\u7528\u4f8b\uff0c\u7ed3\u5408\u65b0\u7684\u5b9a\u91cf\u6307\u6807\u548c\u5b9a\u6027\u5206\u6790\u8bc4\u4f30\u63a8\u7406\u7ec4\u4ef6\u5728\u652f\u6301\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u53ef\u7528\u6027\u3002", "result": "\u63a8\u7406\u7ec4\u4ef6\u5728\u4e2d\u7b49\u63a8\u7406\u6c34\u5e73\u4e0a\u6709\u52a9\u4e8e\u89e3\u91ca\u548c\u9a8c\u8bc1\u6570\u5b57\u53d6\u8bc1\u4e2d\u7684\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\uff0c\u4f46\u8fd9\u79cd\u652f\u6301\u5f80\u5f80\u6709\u9650\uff0c\u66f4\u9ad8\u63a8\u7406\u6c34\u5e73\u4e0d\u4f1a\u63d0\u9ad8\u54cd\u5e94\u8d28\u91cf\u3002", "conclusion": "\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b57\u53d6\u8bc1\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5f53\u524d\u63a8\u7406\u7ec4\u4ef6\u7684\u652f\u6301\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.04106", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04106", "abs": "https://arxiv.org/abs/2512.04106", "authors": ["Fouad Trad", "Ali Chehab"], "title": "Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection", "comment": "Accepted in the 3rd International Conference on Foundation and Large Language Models (FLLM2025)", "summary": "Few-shot prompting has emerged as a practical alternative to fine-tuning for leveraging the capabilities of large language models (LLMs) in specialized tasks. However, its effectiveness depends heavily on the selection and quality of in-context examples, particularly in complex domains. In this work, we examine retrieval-augmented prompting as a strategy to improve few-shot performance in code vulnerability detection, where the goal is to identify one or more security-relevant weaknesses present in a given code snippet from a predefined set of vulnerability categories. We perform a systematic evaluation using the Gemini-1.5-Flash model across three approaches: (1) standard few-shot prompting with randomly selected examples, (2) retrieval-augmented prompting using semantically similar examples, and (3) retrieval-based labeling, which assigns labels based on retrieved examples without model inference. Our results show that retrieval-augmented prompting consistently outperforms the other prompting strategies. At 20 shots, it achieves an F1 score of 74.05% and a partial match accuracy of 83.90%. We further compare this approach against zero-shot prompting and several fine-tuned models, including Gemini-1.5-Flash and smaller open-source models such as DistilBERT, DistilGPT2, and CodeBERT. Retrieval-augmented prompting outperforms both zero-shot (F1 score: 36.35%, partial match accuracy: 20.30%) and fine-tuned Gemini (F1 score: 59.31%, partial match accuracy: 53.10%), while avoiding the training time and cost associated with model fine-tuning. On the other hand, fine-tuning CodeBERT yields higher performance (F1 score: 91.22%, partial match accuracy: 91.30%) but requires additional training, maintenance effort, and resources.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u5728\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u63d0\u5347\u5c11\u6837\u672c\u5b66\u4e60\u6027\u80fd\u7684\u6548\u679c\uff0c\u53d1\u73b0\u5176\u5728\u51cf\u5c11\u8bad\u7ec3\u6210\u672c\u7684\u540c\u65f6\u4f18\u4e8e\u6807\u51c6\u5c11\u6837\u672c\u63d0\u793a\u4e0e\u96f6\u6837\u672c\u65b9\u6cd5\u3002", "motivation": "\u5c11\u6837\u672c\u63d0\u793a\u867d\u80fd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4e13\u4e1a\u4efb\u52a1\uff0c\u4f46\u5176\u6548\u679c\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u8d28\u91cf\u4e0e\u9009\u62e9\uff0c\u5c24\u5176\u5728\u590d\u6742\u9886\u57df\u5982\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u3002\u6587\u7ae0\u65e8\u5728\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u7b56\u7565\u4f18\u5316\u793a\u4f8b\u9009\u62e9\uff0c\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u91c7\u7528Gemini-1.5-Flash\u6a21\u578b\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e09\u79cd\u65b9\u6cd5\uff1a\u968f\u673a\u793a\u4f8b\u7684\u5c11\u6837\u672c\u63d0\u793a\u3001\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\uff0c\u4ee5\u53ca\u65e0\u9700\u6a21\u578b\u63a8\u7406\u7684\u68c0\u7d22\u6807\u6ce8\u65b9\u6cd5\u3002", "result": "\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u572820\u6837\u672c\u4e0bF1\u5f97\u5206\u8fbe74.05%\uff0c\u90e8\u5206\u5339\u914d\u51c6\u786e\u738783.90%\uff0c\u663e\u8457\u4f18\u4e8e\u968f\u673a\u5c11\u6837\u672c\u63d0\u793a\u3001\u96f6\u6837\u672c\u63d0\u793a\u53ca\u5fae\u8c03Gemini\u6a21\u578b\u3002\u5fae\u8c03CodeBERT\u6027\u80fd\u66f4\u9ad8\uff08F1 91.22%\uff09\uff0c\u4f46\u9700\u989d\u5916\u8bad\u7ec3\u8d44\u6e90\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u63d0\u793a\u662f\u5e73\u8861\u6027\u80fd\u4e0e\u6210\u672c\u7684\u5b9e\u7528\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u7b49\u590d\u6742\u4efb\u52a1\uff0c\u5c24\u5176\u9002\u5408\u907f\u514d\u5fae\u8c03\u5f00\u9500\u7684\u573a\u666f\uff1b\u5fae\u8c03\u6a21\u578b\u867d\u6027\u80fd\u66f4\u4f18\uff0c\u4f46\u8d44\u6e90\u9700\u6c42\u8f83\u9ad8\u3002"}}
{"id": "2512.04751", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.04751", "abs": "https://arxiv.org/abs/2512.04751", "authors": ["Junhao Wei", "Yanzhao Gu", "Ran Zhang", "Mingjing Huang", "Jinhong Song", "Yanxiao Li", "Wenxuan Zhu", "Yapeng Wang", "Zikun Li", "Zhiwen Wang", "Xu Yang", "Ngai Cheong"], "title": "NAWOA-XGBoost: A Novel Model for Early Prediction of Academic Potential in Computer Science Students", "comment": null, "summary": "Whale Optimization Algorithm (WOA) suffers from limited global search ability, slow convergence, and tendency to fall into local optima, restricting its effectiveness in hyperparameter optimization for machine learning models. To address these issues, this study proposes a Nonlinear Adaptive Whale Optimization Algorithm (NAWOA), which integrates strategies such as Good Nodes Set initialization, Leader-Followers Foraging, Dynamic Encircling Prey, Triangular Hunting, and a nonlinear convergence factor to enhance exploration, exploitation, and convergence stability. Experiments on 23 benchmark functions demonstrate NAWOA's superior optimization capability and robustness. Based on this optimizer, an NAWOA-XGBoost model was developed to predict academic potential using data from 495 Computer Science undergraduates at Macao Polytechnic University (2009-2019). Results show that NAWOA-XGBoost outperforms traditional XGBoost and WOA-XGBoost across key metrics, including Accuracy (0.8148), Macro F1 (0.8101), AUC (0.8932), and G-Mean (0.8172), demonstrating strong adaptability on multi-class imbalanced datasets.", "AI": {"tldr": "\u63d0\u51fa\u975e\u7ebf\u6027\u81ea\u9002\u5e94\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\uff08NAWOA\uff09\u6539\u8fdb\u4f20\u7edfWOA\uff0c\u5e94\u7528\u4e8eXGBoost\u8d85\u53c2\u6570\u4f18\u5316\uff0c\u5728\u5b66\u672f\u6f5c\u529b\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\uff08WOA\uff09\u5b58\u5728\u5168\u5c40\u641c\u7d22\u80fd\u529b\u5f31\u3001\u6536\u655b\u901f\u5ea6\u6162\u3001\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u673a\u5668\u5b66\u4e60\u8d85\u53c2\u6570\u4f18\u5316\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u6574\u5408\u4f18\u8d28\u8282\u70b9\u96c6\u521d\u59cb\u5316\u3001\u9886\u5bfc\u8005-\u8ffd\u968f\u8005\u89c5\u98df\u3001\u52a8\u6001\u73af\u7ed5\u6355\u98df\u3001\u4e09\u89d2\u72e9\u730e\u7b56\u7565\u548c\u975e\u7ebf\u6027\u6536\u655b\u56e0\u5b50\uff0c\u589e\u5f3a\u7b97\u6cd5\u7684\u63a2\u7d22\u3001\u5f00\u53d1\u548c\u6536\u655b\u7a33\u5b9a\u6027\u3002", "result": "\u572823\u4e2a\u57fa\u51c6\u51fd\u6570\u4e0a\u9a8c\u8bc1NAWOA\u4f18\u8d8a\u6027\uff1bNAWOA-XGBoost\u6a21\u578b\u5728495\u540d\u8ba1\u7b97\u673a\u79d1\u5b66\u672c\u79d1\u751f\u6570\u636e\u4e0a\u53d6\u5f97Accuracy 0.8148\u3001Macro F1 0.8101\u3001AUC 0.8932\u3001G-Mean 0.8172\uff0c\u4f18\u4e8e\u4f20\u7edfXGBoost\u548cWOA-XGBoost\u3002", "conclusion": "NAWOA\u6709\u6548\u63d0\u5347\u4f18\u5316\u6027\u80fd\uff0c\u5728\u591a\u7c7b\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u5f3a\u9002\u5e94\u6027\uff0c\u4e3a\u8d85\u53c2\u6570\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.04139", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04139", "abs": "https://arxiv.org/abs/2512.04139", "authors": ["Susmita Sharma", "Aayush Shrestha", "Sitasma Thapa", "Prashant Timalsina", "Prakash Poudyal"], "title": "Solving N-Queen Problem using Las Vegas Algorithm with State Pruning", "comment": null, "summary": "The N-Queens problem, placing all N queens in a N x N chessboard where none attack the other, is a classic problem for constraint satisfaction algorithms. While complete methods like backtracking guarantee a solution, their exponential time complexity makes them impractical for large-scale instances thus, stochastic approaches, such as Las Vegas algorithm, are preferred. While it offers faster approximate solutions, it suffers from significant performance variance due to random placement of queens on the board. This research introduces a hybrid algorithm built on top of the standard Las Vegas framework through iterative pruning, dynamically eliminating invalid placements during the random assignment phase, thus this method effectively reduces the search space. The analysis results that traditional backtracking scales poorly with increasing N. In contrast, the proposed technique consistently generates valid solutions more rapidly, establishing it as a superior alternative to use where a single, timely solution is preferred over completeness. Although large N causes some performance variability, the algorithm demonstrates a highly effective trade-off between computational cost and solution fidelity, making it particularly suited for resource-constrained computing environments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Las Vegas\u7b97\u6cd5\u548c\u8fed\u4ee3\u526a\u679d\u7684\u6df7\u5408\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3N\u7687\u540e\u95ee\u9898\uff0c\u5728\u4fdd\u8bc1\u89e3\u7684\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u5b9e\u4f8b\u7684\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u5b8c\u5168\u65b9\u6cd5\uff08\u5982\u56de\u6eaf\uff09\u867d\u7136\u80fd\u4fdd\u8bc1\u627e\u5230\u89e3\uff0c\u4f46\u65f6\u95f4\u590d\u6742\u5ea6\u9ad8\uff0c\u4e0d\u9002\u7528\u4e8e\u5927\u89c4\u6a21N\u7687\u540e\u95ee\u9898\uff1b\u800c\u968f\u673a\u65b9\u6cd5\uff08\u5982Las Vegas\u7b97\u6cd5\uff09\u867d\u5feb\u4f46\u6027\u80fd\u6ce2\u52a8\u5927\u3002", "method": "\u5728\u6807\u51c6Las Vegas\u7b97\u6cd5\u6846\u67b6\u4e0a\u5f15\u5165\u8fed\u4ee3\u526a\u679d\uff0c\u5728\u968f\u673a\u653e\u7f6e\u7687\u540e\u65f6\u52a8\u6001\u6d88\u9664\u65e0\u6548\u4f4d\u7f6e\uff0c\u4ece\u800c\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u4e0e\u4f20\u7edf\u56de\u6eaf\u7b97\u6cd5\u76f8\u6bd4\uff0c\u8be5\u7b97\u6cd5\u80fd\u66f4\u5feb\u5730\u751f\u6210\u6709\u6548\u89e3\uff0c\u5c24\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8ba1\u7b97\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u8ba1\u7b97\u6210\u672c\u4e0e\u89e3\u7684\u8d28\u91cf\u5e73\u8861\u3002", "conclusion": "\u8be5\u6df7\u5408\u7b97\u6cd5\u5728\u5927\u89c4\u6a21N\u7687\u540e\u95ee\u9898\u4e0a\u63d0\u4f9b\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u89e3\u8d28\u91cf\u7684\u6709\u6548\u6298\u8877\uff0c\u662f\u8ffd\u6c42\u5355\u6b21\u53ca\u65f6\u89e3\u800c\u975e\u5b8c\u5168\u89e3\u7684\u4f18\u9009\u65b9\u6848\u3002"}}
{"id": "2512.04259", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04259", "abs": "https://arxiv.org/abs/2512.04259", "authors": ["Kobra Khanmohammadi", "Pooria Roy", "Raphael Khoury", "Abdelwahab Hamou-Lhadj", "Wilfried Patrick Konan"], "title": "WildCode: An Empirical Analysis of Code Generated by ChatGPT", "comment": null, "summary": "LLM models are increasingly used to generate code, but the quality and security of this code are often uncertain. Several recent studies have raised alarm bells, indicating that such AI-generated code may be particularly vulnerable to cyberattacks. However, most of these studies rely on code that is generated specifically for the study, which raises questions about the realism of such experiments. In this study, we perform a large-scale empirical analysis of real-life code generated by ChatGPT. We evaluate code generated by ChatGPT both with respect to correctness and security and delve into the intentions of users who request code from the model. Our research confirms previous studies that used synthetic queries and yielded evidence that LLM-generated code is often inadequate with respect to security. We also find that users exhibit little curiosity about the security features of the code they ask LLMs to generate, as evidenced by their lack of queries on this topic.", "AI": {"tldr": "\u5bf9ChatGPT\u751f\u6210\u7684\u771f\u5b9e\u4ee3\u7801\u8fdb\u884c\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u8bc1\u5b9e\u4e86\u5148\u524d\u7814\u7a76\uff1aAI\u751f\u6210\u7684\u4ee3\u7801\u5728\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u4e14\u7528\u6237\u5f88\u5c11\u8be2\u95ee\u4ee3\u7801\u7684\u5b89\u5168\u7279\u6027\u3002", "motivation": "\u5c3d\u7ba1LLM\u6a21\u578b\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u751f\u6210\u4ee3\u7801\uff0c\u4f46\u5176\u4ee3\u7801\u8d28\u91cf\u548c\u5b89\u5168\u6027\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u3002\u5148\u524d\u7814\u7a76\u591a\u4f7f\u7528\u5408\u6210\u4ee3\u7801\uff0c\u53ef\u80fd\u7f3a\u4e4f\u771f\u5b9e\u6027\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u9488\u5bf9ChatGPT\u751f\u6210\u7684\u771f\u5b9e\u4ee3\u7801\u8fdb\u884c\u5206\u6790\u3002", "method": "\u5bf9ChatGPT\u751f\u6210\u7684\u771f\u5b9e\u4ee3\u7801\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u8bc4\u4f30\u4ee3\u7801\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u5e76\u63a2\u7a76\u7528\u6237\u8bf7\u6c42\u4ee3\u7801\u7684\u610f\u56fe\u3002", "result": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u5148\u524d\u4f7f\u7528\u5408\u6210\u67e5\u8be2\u7684\u7814\u7a76\u7ed3\u679c\uff1aLLM\u751f\u6210\u7684\u4ee3\u7801\u5728\u5b89\u5168\u6027\u65b9\u9762\u5f80\u5f80\u4e0d\u8db3\u3002\u540c\u65f6\u53d1\u73b0\u7528\u6237\u5bf9\u4ee3\u7801\u5b89\u5168\u7279\u6027\u7f3a\u4e4f\u5173\u6ce8\uff0c\u5f88\u5c11\u5c31\u6b64\u63d0\u95ee\u3002", "conclusion": "LLM\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u4e14\u7528\u6237\u5b89\u5168\u610f\u8bc6\u8584\u5f31\uff0c\u9700\u52a0\u5f3a\u4ee3\u7801\u5b89\u5168\u9a8c\u8bc1\u548c\u7528\u6237\u6559\u80b2\u3002"}}
{"id": "2512.04776", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.04776", "abs": "https://arxiv.org/abs/2512.04776", "authors": ["Joaquin Luque", "Alejandro Carrasco", "Enrique Personal", "Francisco Perez", "Carlos Leon"], "title": "Customer Identification for Electricity Retailers Based on Monthly Demand Profiles by Activity Sectors and Locations", "comment": null, "summary": "The increasing competition in the electric sector is challenging retail companies as they must assign its commercial efforts to attract the most profitable customers. Those are whose energy demand best fit certain target profiles, which usually depend on generation or cost policies. But, even when the demand profile is available, it is in an anonymous way, preventing its association to a particular client. In this paper, we explore a large dataset containing several millions of monthly demand profiles in Spain and use the available information about the associated economic sector and location for an indirect identification of the customers. The distance of the demand profile from the target is used to define a key performance indicator (KPI) which is used as the main driver of the proposed marketing strategy. The combined use of activity and location has been revealed as a powerful tool for indirect identification of customers, as 100,000 customers are uniquely identified, while about 300,000 clients are identifiable in small sets containing 10 or less consumers. To assess the proposed marketing strategy, it has been compared to the random attraction of new clients, showing a reduction of distance from the target of 40% for 10,000 new customers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7535\u529b\u9700\u6c42\u7279\u5f81\u3001\u7ecf\u6d4e\u6d3b\u52a8\u90e8\u95e8\u53ca\u4f4d\u7f6e\u7684\u95f4\u63a5\u5ba2\u6237\u8bc6\u522b\u65b9\u6cd5\uff0c\u5e76\u5b9a\u4e49\u5173\u952e\u7ee9\u6548\u6307\u6807\uff08KPI\uff09\u6307\u5bfc\u8425\u9500\u7b56\u7565\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u6bd4\u968f\u673a\u83b7\u5ba2\u7b56\u7565\u6548\u679c\u63d0\u534740%", "motivation": "\u7535\u529b\u96f6\u552e\u7ade\u4e89\u52a0\u5267\uff0c\u516c\u53f8\u9700\u8981\u8bc6\u522b\u6700\u5339\u914d\u76ee\u6807\u7535\u529b\u9700\u6c42\u7279\u5f81\u7684\u5ba2\u6237\uff0c\u4f46\u9700\u6c42\u6570\u636e\u901a\u5e38\u533f\u540d\u65e0\u6cd5\u5173\u8054\u5230\u5177\u4f53\u5ba2\u6237", "method": "\u5229\u7528\u897f\u73ed\u7259\u6570\u767e\u4e07\u6708\u5ea6\u7535\u529b\u9700\u6c42\u6570\u636e\uff0c\u7ed3\u5408\u7ecf\u6d4e\u6d3b\u52a8\u90e8\u95e8\u548c\u5730\u7406\u4f4d\u7f6e\u4fe1\u606f\u8fdb\u884c\u95f4\u63a5\u5ba2\u6237\u8bc6\u522b\uff0c\u5b9a\u4e49\u5ba2\u6237\u9700\u6c42\u4e0e\u76ee\u6807\u9700\u6c42\u7684\u8ddd\u79bb\u4f5c\u4e3aKPI", "result": "\u901a\u8fc7\u6d3b\u52a8\u548c\u4f4d\u7f6e\u7ec4\u5408\u6210\u529f\u8bc6\u522b10\u4e07\u540d\u552f\u4e00\u5ba2\u6237\uff0c\u7ea630\u4e07\u5ba2\u6237\u53ef\u572810\u4eba\u4ee5\u5185\u7684\u5c0f\u96c6\u5408\u4e2d\u88ab\u8bc6\u522b\uff1b\u65b0\u8425\u9500\u7b56\u7565\u76f8\u6bd4\u968f\u673a\u83b7\u5ba2\u7b56\u7565\u4f7f\u76ee\u6807\u8ddd\u79bb\u51cf\u5c1140%", "conclusion": "\u6d3b\u52a8\u548c\u4f4d\u7f6e\u4fe1\u606f\u7684\u7ed3\u5408\u662f\u6709\u6548\u7684\u5ba2\u6237\u95f4\u63a5\u8bc6\u522b\u5de5\u5177\uff0c\u57fa\u4e8eKPI\u7684\u8425\u9500\u7b56\u7565\u80fd\u663e\u8457\u63d0\u9ad8\u5ba2\u6237\u83b7\u53d6\u6548\u7387"}}
{"id": "2512.04144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04144", "abs": "https://arxiv.org/abs/2512.04144", "authors": ["Roy Rinberg", "Usha Bhalla", "Igor Shilov", "Flavio P. Calmon", "Rohit Gandikota"], "title": "RippleBench: Capturing Ripple Effects Using Existing Knowledge Repositories", "comment": null, "summary": "Targeted interventions on language models, such as unlearning, debiasing, or model editing, are a central method for refining model behavior and keeping knowledge up to date. While these interventions aim to modify specific information within models (e.g., removing virology content), their effects often propagate to related but unintended areas (e.g., allergies); these side-effects are commonly referred to as the ripple effect. In this work, we present RippleBench-Maker, an automatic tool for generating Q&A datasets that allow for the measurement of ripple effects in any model-editing task. RippleBench-Maker builds on a Wikipedia-based RAG pipeline (WikiRAG) to generate multiple-choice questions at varying semantic distances from the target concept (e.g., the knowledge being unlearned). Using this framework, we construct RippleBench-Bio, a benchmark derived from the WMDP (Weapons of Mass Destruction Paper) dataset, a common unlearning benchmark. We evaluate eight state-of-the-art unlearning methods and find that all exhibit non-trivial accuracy drops on topics increasingly distant from the unlearned knowledge, each with distinct propagation profiles. To support ongoing research, we release our codebase for on-the-fly ripple evaluation, along with the benchmark, RippleBench-Bio.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86RippleBench-Maker\u5de5\u5177\uff0c\u7528\u4e8e\u751f\u6210\u95ee\u7b54\u6570\u636e\u96c6\u4ee5\u8861\u91cf\u6a21\u578b\u7f16\u8f91\u4efb\u52a1\u4e2d\u7684\u6d9f\u6f2a\u6548\u5e94\uff0c\u5e76\u901a\u8fc7WMDP\u6570\u636e\u96c6\u6784\u5efa\u4e86RippleBench-Bio\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e86\u516b\u79cd\u5148\u8fdb\u9057\u5fd8\u65b9\u6cd5\u3002", "motivation": "\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u5e72\u9884\uff08\u5982\u9057\u5fd8\u3001\u53bb\u504f\u6216\u6a21\u578b\u7f16\u8f91\uff09\u5e38\u4f1a\u5f15\u53d1\u6d9f\u6f2a\u6548\u5e94\uff0c\u5373\u4fee\u6539\u76ee\u6807\u4fe1\u606f\u65f6\u5bf9\u76f8\u5173\u4f46\u975e\u9884\u671f\u9886\u57df\u4ea7\u751f\u526f\u4f5c\u7528\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u57fa\u4e8eWikipedia\u7684RAG\u7ba1\u9053\uff08WikiRAG\uff09\u751f\u6210\u4e0e\u76ee\u6807\u6982\u5ff5\u4e0d\u540c\u8bed\u4e49\u8ddd\u79bb\u7684\u591a\u9009\u9898\uff0c\u6784\u5efaRippleBench-Bio\u57fa\u51c6\uff0c\u91cf\u5316\u516b\u79cd\u9057\u5fd8\u65b9\u6cd5\u7684\u6d9f\u6f2a\u6548\u5e94\u3002", "result": "\u6240\u6709\u9057\u5fd8\u65b9\u6cd5\u5728\u8ddd\u79bb\u88ab\u9057\u5fd8\u77e5\u8bc6\u8d8a\u8fdc\u7684\u4e3b\u9898\u4e0a\u5747\u51fa\u73b0\u663e\u8457\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u4e14\u4f20\u64ad\u6a21\u5f0f\u5404\u5f02\uff0c\u63ed\u793a\u4e86\u6d9f\u6f2a\u6548\u5e94\u7684\u666e\u904d\u6027\u548c\u65b9\u6cd5\u7279\u5f02\u6027\u3002", "conclusion": "RippleBench-Maker\u4e3a\u6a21\u578b\u7f16\u8f91\u4efb\u52a1\u7684\u6d9f\u6f2a\u6548\u5e94\u8bc4\u4f30\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u5f3a\u8c03\u4e86\u5e72\u9884\u526f\u4f5c\u7528\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5f00\u6e90\u4e86\u4ee3\u7801\u548c\u57fa\u51c6\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2512.04260", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04260", "abs": "https://arxiv.org/abs/2512.04260", "authors": ["Gaoning Pan", "Yiming Tao", "Qinying Wang", "Chunming Wu", "Mingde Hu", "Yizhi Ren", "Shouling Ji"], "title": "Breaking Isolation: A New Perspective on Hypervisor Exploitation via Cross-Domain Attacks", "comment": null, "summary": "Hypervisors are under threat by critical memory safety vulnerabilities, with pointer corruption being one of the most prevalent and severe forms. Existing exploitation frameworks depend on identifying highly-constrained structures in the host machine and accurately determining their runtime addresses, which is ineffective in hypervisor environments where such structures are rare and further obfuscated by Address Space Layout Randomization (ASLR). We instead observe that modern virtualization environments exhibit weak memory isolation -- guest memory is fully attacker-controlled yet accessible from the host, providing a reliable primitive for exploitation. Based on this observation, we present the first systematic characterization and taxonomy of Cross-Domain Attacks (CDA), a class of exploitation techniques that enable capability escalation through guest memory reuse. To automate this process, we develop a system that identifies cross-domain gadgets, matches them with corrupted pointers, synthesizes triggering inputs, and assembles complete exploit chains. Our evaluation on 15 real-world vulnerabilities across QEMU and VirtualBox shows that CDA is widely applicable and effective.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u8de8\u57df\u653b\u51fb\uff08CDA\uff09\u4f5c\u4e3ahypervisor\u5185\u5b58\u5b89\u5168\u6f0f\u6d1e\u7684\u65b0\u5229\u7528\u65b9\u5f0f\uff0c\u5229\u7528\u865a\u62df\u5316\u73af\u5883\u4e2d\u8f83\u5f31\u7684\u5185\u5b58\u9694\u79bb\u7279\u6027\uff0c\u901a\u8fc7guest\u5185\u5b58\u91cd\u7528\u6765\u5b9e\u73b0\u6743\u9650\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u6f0f\u6d1e\u5229\u7528\u6846\u67b6\u5728hypervisor\u73af\u5883\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u5b83\u4eec\u4f9d\u8d56\u4e8e\u8bc6\u522b\u4e3b\u673a\u4e2d\u7684\u7279\u5b9a\u7ed3\u6784\u5e76\u786e\u5b9a\u5176\u8fd0\u884c\u65f6\u5730\u5740\uff0c\u800c\u8fd9\u4e9b\u7ed3\u6784\u5728hypervisor\u4e2d\u7a00\u5c11\u4e14\u88abASLR\u8fdb\u4e00\u6b65\u6a21\u7cca\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u4ee3\u865a\u62df\u5316\u73af\u5883\u5b58\u5728\u5f31\u5185\u5b58\u9694\u79bb\u95ee\u9898\u3002", "method": "\u7cfb\u7edf\u5316\u5730\u8868\u5f81\u548c\u5206\u7c7b\u8de8\u57df\u653b\u51fb\uff08CDA\uff09\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u7cfb\u7edf\u6765\u8bc6\u522b\u8de8\u57df\u5c0f\u5de5\u5177\u3001\u5339\u914d\u635f\u574f\u6307\u9488\u3001\u5408\u6210\u89e6\u53d1\u8f93\u5165\u5e76\u7ec4\u88c5\u5b8c\u6574\u7684\u6f0f\u6d1e\u5229\u7528\u94fe\u3002", "result": "\u5728QEMU\u548cVirtualBox\u768415\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u8bc4\u4f30\u4e2d\uff0cCDA\u663e\u793a\u51fa\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8de8\u57df\u653b\u51fb\u4e3ahypervisor\u5185\u5b58\u5b89\u5168\u6f0f\u6d1e\u5229\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u63ed\u793a\u4e86\u865a\u62df\u5316\u73af\u5883\u4e2d\u5185\u5b58\u9694\u79bb\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2512.04117", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04117", "abs": "https://arxiv.org/abs/2512.04117", "authors": ["Joost Mertens", "Joachim Denil"], "title": "Reusing Model Validation Methods for the Continuous Validation of Digital Twins of Cyber-Physical Systems", "comment": null, "summary": "One of the challenges in twinned systems is ensuring the digital twin remains a valid representation of the system it twins. Depending on the type of twinning occurring, it is either trivial, such as in dashboarding/visualizations that mirror the system with real-time data, or challenging, in case the digital twin is a simulation model that reflects the behavior of a physical twinned system. The challenge in this latter case comes from the fact that in contrast to software systems, physical systems are not immutable once deployed, but instead they evolve through processes like maintenance, wear and tear or user error. It is therefore important to detect when changes occur in the physical system to evolve the twin alongside it. We employ and reuse validation techniques from model-based design for this goal. Model validation is one of the steps used to gain trust in the representativeness of a simulation model. In this work, we provide two contributions: (i) we provide a generic approach that, through the use of validation metrics, is able to detect anomalies in twinned systems, and (ii) we demonstrate these techniques with the help of an academic yet industrially relevant case study of a gantry crane such as found in ports. Treating anomalies also means correcting the error in the digital twin, which we do with a parameter estimation based on the historical data.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a8c\u8bc1\u6307\u6807\u7684\u901a\u7528\u65b9\u6cd5\u6765\u68c0\u6d4b\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u901a\u8fc7\u9f99\u95e8\u8d77\u91cd\u673a\u7684\u6848\u4f8b\u7814\u7a76\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u4f7f\u7528\u53c2\u6570\u4f30\u8ba1\u6765\u7ea0\u6b63\u6570\u5b57\u5b6a\u751f\u4e2d\u7684\u9519\u8bef\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u9762\u4e34\u7684\u6311\u6218\u662f\u786e\u4fdd\u6570\u5b57\u5b6a\u751f\u59cb\u7ec8\u662f\u5176\u6240\u6a21\u62df\u7269\u7406\u7cfb\u7edf\u7684\u6709\u6548\u4ee3\u8868\u3002\u7269\u7406\u7cfb\u7edf\u5728\u90e8\u7f72\u540e\u4f1a\u56e0\u7ef4\u62a4\u3001\u78e8\u635f\u6216\u7528\u6237\u9519\u8bef\u7b49\u8fc7\u7a0b\u800c\u6f14\u53d8\uff0c\u56e0\u6b64\u9700\u8981\u68c0\u6d4b\u7269\u7406\u7cfb\u7edf\u4e2d\u7684\u53d8\u5316\u4ee5\u4f7f\u6570\u5b57\u5b6a\u751f\u540c\u6b65\u66f4\u65b0\u3002", "method": "\u91cd\u7528\u57fa\u4e8e\u6a21\u578b\u8bbe\u8ba1\u4e2d\u7684\u9a8c\u8bc1\u6280\u672f\uff0c\u901a\u8fc7\u9a8c\u8bc1\u6307\u6807\u68c0\u6d4b\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u5386\u53f2\u6570\u636e\u7684\u53c2\u6570\u4f30\u8ba1\u6765\u7ea0\u6b63\u6570\u5b57\u5b6a\u751f\u4e2d\u7684\u9519\u8bef\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6cd5\uff0c\u80fd\u591f\u68c0\u6d4b\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\uff0c\u5e76\u901a\u8fc7\u9f99\u95e8\u8d77\u91cd\u673a\u7684\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u9a8c\u8bc1\u6307\u6807\u548c\u53c2\u6570\u4f30\u8ba1\uff0c\u53ef\u4ee5\u6709\u6548\u7ef4\u62a4\u6570\u5b57\u5b6a\u751f\u4e0e\u5176\u7269\u7406\u5bf9\u5e94\u7269\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u786e\u4fdd\u6570\u5b57\u5b6a\u751f\u7684\u6301\u7eed\u6709\u6548\u6027\u3002"}}
{"id": "2512.04338", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.04338", "abs": "https://arxiv.org/abs/2512.04338", "authors": ["Biagio Montaruli", "Luca Compagna", "Serena Elisa Ponta", "Davide Balzarotti"], "title": "One Detector Fits All: Robust and Adaptive Detection of Malicious Packages from PyPI to Enterprises", "comment": "Proceedings of the 2025 Annual Computer Security Applications Conference (ACSAC' 25), December 8-12, 2025, Honolulu, Hawaii, USA", "summary": "The rise of supply chain attacks via malicious Python packages demands robust detection solutions. Current approaches, however, overlook two critical challenges: robustness against adversarial source code transformations and adaptability to the varying false positive rate (FPR) requirements of different actors, from repository maintainers (requiring low FPR) to enterprise security teams (higher FPR tolerance).\n  We introduce a robust detector capable of seamless integration into both public repositories like PyPI and enterprise ecosystems. To ensure robustness, we propose a novel methodology for generating adversarial packages using fine-grained code obfuscation. Combining these with adversarial training (AT) enhances detector robustness by 2.5x. We comprehensively evaluate AT effectiveness by testing our detector against 122,398 packages collected daily from PyPI over 80 days, showing that AT needs careful application: it makes the detector more robust to obfuscations and allows finding 10% more obfuscated packages, but slightly decreases performance on non-obfuscated packages.\n  We demonstrate production adaptability of our detector via two case studies: (i) one for PyPI maintainers (tuned at 0.1% FPR) and (ii) one for enterprise teams (tuned at 10% FPR). In the former, we analyze 91,949 packages collected from PyPI over 37 days, achieving a daily detection rate of 2.48 malicious packages with only 2.18 false positives. In the latter, we analyze 1,596 packages adopted by a multinational software company, obtaining only 1.24 false positives daily. These results show that our detector can be seamlessly integrated into both public repositories like PyPI and enterprise ecosystems, ensuring a very low time budget of a few minutes to review the false positives.\n  Overall, we uncovered 346 malicious packages, now reported to the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u6076\u610fPython\u5305\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u5bf9\u6297\u8bad\u7ec3\u63d0\u53472.5\u500d\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8ePyPI\u548c\u4f01\u4e1a\u73af\u5883\uff0c\u53ef\u8c03\u8282\u8bef\u62a5\u7387\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u6709\u6548\u68c0\u6d4b346\u4e2a\u6076\u610f\u5305\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u89e3\u51b3\u5bf9\u6297\u6027\u6e90\u4ee3\u7801\u53d8\u6362\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u4e0d\u540c\u4f7f\u7528\u8005\uff08\u5982\u4ed3\u5e93\u7ef4\u62a4\u8005\u4e0e\u4f01\u4e1a\u5b89\u5168\u56e2\u961f\uff09\u5bf9\u8bef\u62a5\u7387\u7684\u5dee\u5f02\u5316\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7ec6\u7c92\u5ea6\u4ee3\u7801\u6df7\u6dc6\u751f\u6210\u5bf9\u6297\u6027\u5305\uff0c\u7ed3\u5408\u5bf9\u6297\u8bad\u7ec3\u589e\u5f3a\u68c0\u6d4b\u5668\u9c81\u68d2\u6027\uff1b\u652f\u6301\u6309\u9700\u8c03\u6574\u8bef\u62a5\u7387\u9608\u503c\uff080.1%\u621610%\uff09\u3002", "result": "\u572880\u5929\u6536\u96c6\u7684122,398\u4e2aPyPI\u5305\u4e0a\u6d4b\u8bd5\uff0c\u5bf9\u6297\u8bad\u7ec3\u4f7f\u68c0\u6d4b\u5668\u5bf9\u6df7\u6dc6\u5305\u7684\u9c81\u68d2\u6027\u63d0\u53472.5\u500d\uff0c\u591a\u68c0\u6d4b10%\u7684\u6df7\u6dc6\u5305\uff1b\u5728PyPI\u6848\u4f8b\uff080.1%\u8bef\u62a5\u7387\uff09\u4e2d\u6bcf\u65e5\u68c0\u6d4b2.48\u4e2a\u6076\u610f\u5305\u4ec52.18\u4e2a\u8bef\u62a5\uff0c\u4f01\u4e1a\u6848\u4f8b\uff0810%\u8bef\u62a5\u7387\uff09\u4e2d\u6bcf\u65e5\u4ec51.24\u4e2a\u8bef\u62a5\u3002", "conclusion": "\u68c0\u6d4b\u5668\u80fd\u65e0\u7f1d\u96c6\u6210\u5230PyPI\u548c\u4f01\u4e1a\u751f\u6001\u7cfb\u7edf\uff0c\u8bef\u62a5\u5ba1\u67e5\u65f6\u95f4\u4ec5\u9700\u51e0\u5206\u949f\uff0c\u5df2\u5411\u793e\u533a\u62a5\u544a346\u4e2a\u6076\u610f\u5305\uff0c\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.04250", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04250", "abs": "https://arxiv.org/abs/2512.04250", "authors": ["Shubham Somani", "Vanish Talwar", "Madhura Parikh", "Eduardo Hernandez", "Jimmy Wang", "Shreya Shah", "Chinmay Gandhi", "Sanjay Sundarajan", "Neeru Sharma", "Srikanth Kamath", "Nitin Gupta", "Benjamin Renard", "Ohad Yahalom", "Chris Davis"], "title": "DrP: Meta's Efficient Investigations Platform at Scale", "comment": null, "summary": "Investigations are a significant step in the operational workflows for large scale systems across multiple domains such as services, data, AI/ML, mobile. Investigation processes followed by on-call engineers are often manual or rely on ad-hoc scripts. This leads to inefficient investigations resulting in increased time to mitigate and isolate failures/SLO violations. It also contributes to on-call toil and poor productivity leading to multiple hours/days spent in triaging/debugging incidents. In this paper, we present DrP, an end-to-end framework and system to automate investigations that reduces the mean time to resolve incidents (MTTR) and reduces on-call toil. DrP consists of an expressive and flexible SDK to author investigation playbooks in code (called analyzers), a scalable backend system to execute these automated playbooks, plug-ins to integrate playbooks into mainstream workflows such as alerts and incident management tools, and a post-processing system to take actions on investigations including mitigation steps.\n  We have implemented and deployed DrP at large scale at Meta covering 300+ teams, 2000+ analyzers, across a large set of use cases across domains such as services, core infrastructure, AI/ML, hardware, mobile. DrP has been running in production for the past 5 years and executes 50K automated analyses per day. Overall, our results and experience show that DrP has been able to reduce average MTTR by 20 percent at large scale (with over 80 percent for some teams) and has significantly improved on-call productivity.", "AI": {"tldr": "DrP\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u81ea\u52a8\u5316\u8c03\u67e5\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u5199\u5206\u6790\u5668\u3001\u53ef\u6269\u5c55\u6267\u884c\u548c\u96c6\u6210\u4e3b\u6d41\u5de5\u4f5c\u6d41\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5e73\u5747\u89e3\u51b3\u65f6\u95f4\u548c\u503c\u73ed\u8d1f\u62c5\u3002", "motivation": "\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u7684\u4eba\u5de5\u6216\u4e34\u65f6\u811a\u672c\u8c03\u67e5\u6548\u7387\u4f4e\u4e0b\uff0c\u5bfc\u81f4\u89e3\u51b3\u6545\u969c\u65f6\u95f4\u957f\u3001\u503c\u73ed\u5de5\u4f5c\u7e41\u91cd\u3002", "method": "\u63d0\u4f9b\u7075\u6d3b\u7684SDK\u7f16\u5199\u8c03\u67e5\u624b\u518c\uff08\u5206\u6790\u5668\uff09\uff0c\u6784\u5efa\u53ef\u6269\u5c55\u7684\u540e\u7aef\u6267\u884c\u7cfb\u7edf\uff0c\u96c6\u6210\u8b66\u62a5\u548c\u4e8b\u4ef6\u7ba1\u7406\u5de5\u5177\uff0c\u5e76\u5b9e\u65bd\u540e\u5904\u7406\u884c\u52a8\u7cfb\u7edf\u3002", "result": "\u5728Meta\u90e8\u7f725\u5e74\uff0c\u8986\u76d6300+\u56e2\u961f\u30012000+\u5206\u6790\u5668\uff0c\u6bcf\u65e5\u6267\u884c5\u4e07\u6b21\u5206\u6790\uff0c\u5e73\u5747MTTR\u964d\u4f4e20%\uff08\u90e8\u5206\u56e2\u961f\u8d8580%\uff09\uff0c\u751f\u4ea7\u529b\u663e\u8457\u63d0\u5347\u3002", "conclusion": "DrP\u6709\u6548\u81ea\u52a8\u5316\u8c03\u67e5\u6d41\u7a0b\uff0c\u5927\u5e45\u51cf\u5c11\u89e3\u51b3\u65f6\u95f4\u548c\u503c\u73ed\u8d1f\u62c5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5927\u89c4\u6a21\u751f\u4ea7\u73af\u5883\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\u3002"}}
{"id": "2512.04210", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.04210", "abs": "https://arxiv.org/abs/2512.04210", "authors": ["Huy Nghiem", "Swetasudha Panda", "Devashish Khatwani", "Huy V. Nguyen", "Krishnaram Kenthapadi", "Hal Daum\u00e9"], "title": "Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment", "comment": "ML4H 2025 Proceedings, Best Paper Award", "summary": "Large Language Models (LLMs) are increasingly used in healthcare, yet ensuring their safety and trustworthiness remains a barrier to deployment. Conversational medical assistants must avoid unsafe compliance without over-refusing benign queries. We present an iterative post-deployment alignment framework that applies Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to refine models against domain-specific safety signals. Using the CARES-18K benchmark for adversarial robustness, we evaluate four LLMs (Llama-3B/8B, Meditron-8B, Mistral-7B) across multiple cycles. Our results show up to 42% improvement in safety-related metrics for harmful query detection, alongside interesting trade-offs against erroneous refusals, thereby exposing architecture-dependent calibration biases. We also perform ablation studies to identify when self-evaluation is reliable and when external or finetuned judges are necessary to maximize performance gains. Our findings underscore the importance of adopting best practices that balance patient safety, user trust, and clinical utility in the design of conversational medical assistants.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8fed\u4ee3\u90e8\u7f72\u540e\u5bf9\u9f50\u6846\u67b6\uff0c\u7ed3\u5408KTO\u548cDPO\u4f18\u5316\u533b\u7597\u5bf9\u8bdd\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u5728CARES-18K\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u6709\u5bb3\u67e5\u8be2\u68c0\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u63ed\u793a\u6a21\u578b\u67b6\u6784\u76f8\u5173\u7684\u6821\u51c6\u504f\u5dee\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5b89\u5168\u6027\u4e0e\u8fc7\u5ea6\u62d2\u7edd\u5408\u7406\u67e5\u8be2\u7684\u77db\u76fe\uff0c\u9700\u8981\u4e00\u79cd\u90e8\u7f72\u540e\u6301\u7eed\u4f18\u5316\u7684\u65b9\u6cd5\u6765\u5e73\u8861\u60a3\u8005\u5b89\u5168\u3001\u7528\u6237\u4fe1\u4efb\u548c\u4e34\u5e8a\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u540e\u90e8\u7f72\u5bf9\u9f50\u6846\u67b6\uff0c\u7ed3\u5408Kahneman-Tversky\u4f18\u5316\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6280\u672f\uff0c\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u5b89\u5168\u4fe1\u53f7\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5e76\u5728CARES-18K\u5bf9\u6297\u9c81\u68d2\u6027\u57fa\u51c6\u4e0a\u8bc4\u4f30\u56db\u79cdLLM\u6a21\u578b\u3002", "result": "\u6a21\u578b\u5728\u6709\u5bb3\u67e5\u8be2\u68c0\u6d4b\u65b9\u9762\u83b7\u5f97\u9ad8\u8fbe42%\u7684\u5b89\u5168\u6307\u6807\u63d0\u5347\uff0c\u540c\u65f6\u53d1\u73b0\u4e86\u9519\u8bef\u62d2\u7edd\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u5b58\u5728\u7684\u6821\u51c6\u504f\u5dee\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\u9700\u8981\u6839\u636e\u4e0d\u540c\u60c5\u51b5\u9009\u62e9\u81ea\u8bc4\u4f30\u6216\u5916\u90e8\u8bc4\u4f30\u65b9\u6cd5\u3002", "conclusion": "\u533b\u7597\u5bf9\u8bdd\u52a9\u624b\u7684\u8bbe\u8ba1\u9700\u8981\u91c7\u7528\u6700\u4f73\u5b9e\u8df5\u6765\u5e73\u8861\u60a3\u8005\u5b89\u5168\u3001\u7528\u6237\u4fe1\u4efb\u548c\u4e34\u5e8a\u6548\u7528\uff0c\u8fed\u4ee3\u540e\u90e8\u7f72\u5bf9\u9f50\u662f\u63d0\u5347\u6a21\u578b\u5b89\u5168\u6027\u7684\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2512.04256", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.04256", "abs": "https://arxiv.org/abs/2512.04256", "authors": ["Qiaolin Qin", "Ronnie de Souza Santos", "Rodrigo Spinola"], "title": "On the Role and Impact of GenAI Tools in Software Engineering Education", "comment": "Accepted at IEEE/ACM ICSE Software Engineering Education and Training (ICSE SEET 2026)", "summary": "Context. The rise of generative AI (GenAI) tools like ChatGPT and GitHub Copilot has transformed how software is learned and written. In software engineering (SE) education, these tools offer new opportunities for support, but also raise concerns about over-reliance, ethical use, and impacts on learning. Objective. This study investigates how undergraduate SE students use GenAI tools, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. Method. We conducted a survey with 130 undergraduate students from two universities. The survey combined structured Likert-scale items and open-ended questions to investigate five dimensions: usage context, perceived benefits, challenges, ethical and instructional perceptions. Results. Students most often use GenAI for incremental learning and advanced implementation, reporting benefits such as brainstorming support and confidence-building. At the same time, they face challenges including unclear rationales and difficulty adapting outputs. Students highlight ethical concerns around fairness and misconduct, and call for clearer instructional guidance. Conclusion. GenAI is reshaping SE education in nuanced ways. Our findings underscore the need for scaffolding, ethical policies, and adaptive instructional strategies to ensure that GenAI supports equitable and effective learning.", "AI": {"tldr": "\u672c\u79d1\u8f6f\u4ef6\u5de5\u7a0b\u5b66\u751f\u4f7f\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u5b66\u4e60\u4f53\u9a8c\u7814\u7a76\uff1a\u8c03\u67e5\u663e\u793a\u5b66\u751f\u4e3b\u8981\u5c06AI\u7528\u4e8e\u589e\u91cf\u5b66\u4e60\u548c\u9ad8\u7ea7\u5b9e\u73b0\uff0c\u8ba4\u4e3aAI\u80fd\u63d0\u4f9b\u5934\u8111\u98ce\u66b4\u652f\u6301\u5e76\u589e\u5f3a\u4fe1\u5fc3\uff0c\u4f46\u4e5f\u9762\u4e34\u8f93\u51fa\u7ed3\u679c\u96be\u4ee5\u9002\u5e94\u548c\u539f\u7406\u4e0d\u900f\u660e\u7b49\u6311\u6218\uff0c\u547c\u5401\u66f4\u660e\u786e\u7684\u6559\u5b66\u6307\u5bfc\u548c\u4f26\u7406\u653f\u7b56\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5de5\u5177\uff08\u5982ChatGPT\u548cGitHub Copilot\uff09\u6b63\u5728\u6539\u53d8\u8f6f\u4ef6\u5b66\u4e60\u548c\u7f16\u5199\u65b9\u5f0f\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u5e26\u6765\u65b0\u673a\u9047\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u5bf9\u8fc7\u5ea6\u4f9d\u8d56\u3001\u4f26\u7406\u4f7f\u7528\u53ca\u5b66\u4e60\u5f71\u54cd\u7684\u62c5\u5fe7\u3002", "method": "\u5bf9\u6765\u81ea\u4e24\u6240\u5927\u5b66\u7684130\u540d\u672c\u79d1\u8f6f\u4ef6\u5de5\u7a0b\u5b66\u751f\u8fdb\u884c\u95ee\u5377\u8c03\u67e5\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u674e\u514b\u7279\u91cf\u8868\u548c\u5f00\u653e\u5f0f\u95ee\u9898\uff0c\u63a2\u7a76\u4f7f\u7528\u60c5\u5883\u3001\u611f\u77e5\u76ca\u5904\u3001\u6311\u6218\u3001\u4f26\u7406\u53ca\u6559\u5b66\u8ba4\u77e5\u4e94\u4e2a\u7ef4\u5ea6\u3002", "result": "\u5b66\u751f\u6700\u5e38\u5c06\u751f\u6210\u5f0fAI\u7528\u4e8e\u589e\u91cf\u5b66\u4e60\u548c\u9ad8\u7ea7\u5b9e\u73b0\uff0c\u62a5\u544a\u76ca\u5904\u5305\u62ec\u5934\u8111\u98ce\u66b4\u652f\u6301\u548c\u4fe1\u5fc3\u5efa\u7acb\uff1b\u540c\u65f6\u9762\u4e34\u6311\u6218\u5982\u539f\u7406\u4e0d\u900f\u660e\u548c\u8f93\u51fa\u9002\u914d\u56f0\u96be\uff1b\u5b66\u751f\u5f3a\u8c03\u516c\u5e73\u548c\u4e0d\u5f53\u884c\u4e3a\u7b49\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u547c\u5401\u66f4\u6e05\u6670\u7684\u6559\u5b66\u6307\u5bfc\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u6b63\u4ee5\u5fae\u5999\u65b9\u5f0f\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u3002\u7814\u7a76\u53d1\u73b0\u5f3a\u8c03\u9700\u8981\u642d\u5efa\u652f\u67b6\u3001\u5236\u5b9a\u4f26\u7406\u653f\u7b56\u548c\u9002\u5e94\u6027\u6559\u5b66\u7b56\u7565\uff0c\u4ee5\u786e\u4fdd\u751f\u6210\u5f0fAI\u652f\u6301\u516c\u5e73\u6709\u6548\u7684\u5b66\u4e60\u3002"}}
{"id": "2512.04227", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.04227", "abs": "https://arxiv.org/abs/2512.04227", "authors": ["Yo Ehara"], "title": "Educational Cone Model in Embedding Vector Spaces", "comment": "Accepted to the 33rd International Conference on Computers in Education (ICCE 2025)", "summary": "Human-annotated datasets with explicit difficulty ratings are essential in intelligent educational systems. Although embedding vector spaces are widely used to represent semantic closeness and are promising for analyzing text difficulty, the abundance of embedding methods creates a challenge in selecting the most suitable method. This study proposes the Educational Cone Model, which is a geometric framework based on the assumption that easier texts are less diverse (focusing on fundamental concepts), whereas harder texts are more diverse. This assumption leads to a cone-shaped distribution in the embedding space regardless of the embedding method used. The model frames the evaluation of embeddings as an optimization problem with the aim of detecting structured difficulty-based patterns. By designing specific loss functions, efficient closed-form solutions are derived that avoid costly computation. Empirical tests on real-world datasets validated the model's effectiveness and speed in identifying the embedding spaces that are best aligned with difficulty-annotated educational texts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6559\u80b2\u9525\u6a21\u578b\uff0c\u4e00\u79cd\u57fa\u4e8e\u5d4c\u5165\u7a7a\u95f4\u7684\u51e0\u4f55\u6846\u67b6\uff0c\u901a\u8fc7\u9525\u5f62\u5206\u5e03\u5047\u8bbe\u5206\u6790\u6587\u672c\u96be\u5ea6\uff0c\u4f18\u5316\u9009\u62e9\u6700\u9002\u5408\u6559\u80b2\u6587\u672c\u7684\u5d4c\u5165\u65b9\u6cd5\u3002", "motivation": "\u4eba\u5de5\u6807\u6ce8\u96be\u5ea6\u7b49\u7ea7\u7684\u6570\u636e\u96c6\u5bf9\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f17\u591a\u5d4c\u5165\u65b9\u6cd5\u96be\u4ee5\u9009\u62e9\u6700\u5408\u9002\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6559\u80b2\u9525\u6a21\u578b\uff0c\u5047\u8bbe\u7b80\u5355\u6587\u672c\u591a\u6837\u6027\u4f4e\uff08\u805a\u7126\u57fa\u7840\u6982\u5ff5\uff09\uff0c\u590d\u6742\u6587\u672c\u591a\u6837\u6027\u9ad8\uff0c\u5f62\u6210\u9525\u5f62\u5206\u5e03\u3002\u901a\u8fc7\u8bbe\u8ba1\u635f\u5931\u51fd\u6570\u63a8\u5bfc\u95ed\u5f0f\u89e3\uff0c\u907f\u514d\u9ad8\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u8bc6\u522b\u4e0e\u96be\u5ea6\u6807\u6ce8\u6559\u80b2\u6587\u672c\u6700\u5339\u914d\u7684\u5d4c\u5165\u7a7a\u95f4\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u901f\u5ea6\u3002", "conclusion": "\u6559\u80b2\u9525\u6a21\u578b\u4e3a\u5d4c\u5165\u65b9\u6cd5\u8bc4\u4f30\u63d0\u4f9b\u4e86\u9ad8\u6548\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u667a\u80fd\u6559\u80b2\u7cfb\u7edf\u4e2d\u7684\u6587\u672c\u96be\u5ea6\u5206\u6790\u3002"}}
{"id": "2512.04436", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04436", "abs": "https://arxiv.org/abs/2512.04436", "authors": ["Chen Chen", "Zaiyan Xu", "Mohamadreza Rostami", "David Liu", "Dileep Kalathil", "Ahmad-Reza Sadeghi", "Jeyavijayan", "Rajendran"], "title": "ReFuzz: Reusing Tests for Processor Fuzzing with Contextual Bandits", "comment": "To be published in the proceedings of the Network and Distributed System Security (NDSS) Symposium, 2026", "summary": "Processor designs rely on iterative modifications and reuse well-established designs. However, this reuse of prior designs also leads to similar vulnerabilities across multiple processors. As processors grow increasingly complex with iterative modifications, efficiently detecting vulnerabilities from modern processors is critical. Inspired by software fuzzing, hardware fuzzing has recently demonstrated its effectiveness in detecting processor vulnerabilities. Yet, to our best knowledge, existing processor fuzzers fuzz each design individually, lacking the capability to understand known vulnerabilities in prior processors to fine-tune fuzzing to identify similar or new variants of vulnerabilities.\n  To address this gap, we present ReFuzz, an adaptive fuzzing framework that leverages contextual bandit to reuse highly effective tests from prior processors to fuzz a processor-under-test (PUT) within a given ISA. By intelligently mutating tests that trigger vulnerabilities in prior processors, ReFuzz effectively detects similar and new variants of vulnerabilities in PUTs. ReFuzz uncovered three new security vulnerabilities and two new functional bugs. ReFuzz detected one vulnerability by reusing a test that triggers a known vulnerability in a prior processor. One functional bug exists across three processors that share design modules. The second bug has two variants. Additionally, ReFuzz reuses highly effective tests to enhance efficiency in coverage, achieving an average 511.23x coverage speedup and up to 9.33% more total coverage, compared to existing fuzzers.", "AI": {"tldr": "ReFuzz\u662f\u4e00\u4e2a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u591a\u81c2\u8d4c\u535a\u673a\u7684\u81ea\u9002\u5e94\u786c\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u91cd\u7528\u5148\u524d\u5904\u7406\u5668\u7684\u9ad8\u6548\u6d4b\u8bd5\u6765\u68c0\u6d4b\u65b0\u5904\u7406\u5668\u4e2d\u7684\u7c7b\u4f3c\u6f0f\u6d1e\uff0c\u76f8\u6bd4\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u6709\u663e\u8457\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u5904\u7406\u5668\u8bbe\u8ba1\u901a\u5e38\u8fed\u4ee3\u4fee\u6539\u548c\u91cd\u7528\u73b0\u6709\u8bbe\u8ba1\uff0c\u5bfc\u81f4\u76f8\u4f3c\u6f0f\u6d1e\u5728\u591a\u4ee3\u5904\u7406\u5668\u4e2d\u4f20\u64ad\u3002\u73b0\u6709\u786c\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u7f3a\u4e4f\u5229\u7528\u5df2\u77e5\u6f0f\u6d1e\u4fe1\u606f\u6765\u4f18\u5316\u6d4b\u8bd5\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faReFuzz\u6846\u67b6\uff0c\u667a\u80fd\u53d8\u5f02\u89e6\u53d1\u5148\u524d\u5904\u7406\u5668\u6f0f\u6d1e\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u591a\u81c2\u8d4c\u535a\u673a\u7b97\u6cd5\u9009\u62e9\u6700\u4f18\u6d4b\u8bd5\u7b56\u7565\u6765\u6d4b\u8bd5\u76ee\u6807\u5904\u7406\u5668\u3002", "result": "\u53d1\u73b03\u4e2a\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u548c2\u4e2a\u529f\u80fd\u7f3a\u9677\uff0c\u5176\u4e2d\u4e00\u4e2a\u6f0f\u6d1e\u901a\u8fc7\u91cd\u7528\u5df2\u77e5\u6f0f\u6d1e\u6d4b\u8bd5\u68c0\u6d4b\u5230\u3002\u5e73\u5747\u5b9e\u73b0511.23\u500d\u8986\u76d6\u52a0\u901f\u548c\u6700\u9ad89.33%\u7684\u603b\u8986\u76d6\u63d0\u5347\u3002", "conclusion": "ReFuzz\u8bc1\u660e\u4e86\u91cd\u7528\u5148\u524d\u5904\u7406\u5668\u6d4b\u8bd5\u7528\u4f8b\u80fd\u6709\u6548\u68c0\u6d4b\u76f8\u4f3c\u548c\u65b0\u53d8\u79cd\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u9ad8\u786c\u4ef6\u6a21\u7cca\u6d4b\u8bd5\u6548\u7387\u3002"}}
{"id": "2512.04262", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.04262", "abs": "https://arxiv.org/abs/2512.04262", "authors": ["Nolan Platt", "Ethan Luchs", "Sehrish Nizamani"], "title": "Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage", "comment": "7 pages. Published in Proceedings of the 2025 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). DOI: 10.1109/VL-HCC65237.2025.00024", "summary": "Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen's ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI's GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen's Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen's Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff's Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u5728\u7f51\u7ad9\u5f00\u53d1\u9636\u6bb5\u8fdb\u884c\u53ef\u7528\u6027\u542f\u53d1\u5f0f\u8bc4\u4f30\u7684\u53ef\u884c\u6027\u4e0e\u5c40\u9650\u6027\u3002\u901a\u8fc7\u5206\u679030\u4e2a\u5f00\u6e90\u7f51\u7ad9\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u68c0\u6d4b\u53ef\u7528\u6027\u95ee\u9898\u65b9\u9762\u5177\u6709\u4e2d\u7b49\u4e00\u81f4\u6027\uff0c\u4f46\u5728\u4e25\u91cd\u6027\u5224\u65ad\u4e0a\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u9700\u8981\u4eba\u5de5\u76d1\u7763\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u5de5\u542f\u53d1\u5f0f\u8bc4\u4f30\u8017\u65f6\u4e14\u4e3b\u89c2\uff0c\u5c24\u5176\u5728\u5f00\u53d1\u65e9\u671f\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLMs\u80fd\u5426\u5728\u5f00\u53d1\u9636\u6bb5\u63d0\u4f9b\u53ef\u9760\u3001\u4e00\u81f4\u7684\u81ea\u52a8\u5316\u53ef\u7528\u6027\u8bc4\u4f30\uff0c\u4ee5\u63d0\u5347\u6548\u7387\u3002", "method": "\u91c7\u7528Jakob Nielsen\u7684\u5341\u9879\u53ef\u7528\u6027\u542f\u53d1\u5f0f\u539f\u5219\uff0c\u5bf930\u4e2a\u5f00\u6e90\u7f51\u7ad9\u8fdb\u884c\u4e09\u8f6e\u72ec\u7acb\u8bc4\u4f30\uff0c\u4f7f\u7528OpenAI\u7684GPT-4o\u751f\u6210850\u4f59\u6b21\u8bc4\u4f30\u3002\u901a\u8fc7Cohen's Kappa\u3001\u7cbe\u786e\u4e00\u81f4\u6027\u548cKrippendorff's Alpha\u7b49\u6307\u6807\u5206\u6790\u4e00\u81f4\u6027\u3002", "result": "\u95ee\u9898\u68c0\u6d4b\u65b9\u9762\uff1a\u5e73\u5747Cohen's Kappa\u4e3a0.50\uff08\u4e2d\u7b49\u4e00\u81f4\u6027\uff09\uff0c\u7cbe\u786e\u4e00\u81f4\u6027\u8fbe84%\u3002\u4e25\u91cd\u6027\u5224\u65ad\u65b9\u9762\uff1a\u52a0\u6743Cohen's Kappa\u5e73\u57470.63\uff0c\u4f46\u7cbe\u786e\u4e00\u81f4\u6027\u4ec556%\uff0cKrippendorff's Alpha\u63a5\u8fd1\u96f6\uff0c\u8868\u660e\u4e25\u91cd\u6027\u8bc4\u4f30\u53d8\u5f02\u8f83\u5927\u3002", "conclusion": "GPT-4o\u80fd\u751f\u6210\u5185\u90e8\u4e00\u81f4\u7684\u53ef\u7528\u6027\u95ee\u9898\u68c0\u6d4b\u7ed3\u679c\uff0c\u4f46\u4e25\u91cd\u6027\u5224\u65ad\u4e0d\u53ef\u9760\uff0c\u9700\u4eba\u5de5\u5e72\u9884\u3002\u7814\u7a76\u4e3a\u81ea\u52a8\u5316\u7528\u6237\u4f53\u9a8c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u521d\u6b65\u5b9a\u91cf\u5206\u6790\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u6539\u8fdb\u6a21\u578b\u4e00\u81f4\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.04228", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04228", "abs": "https://arxiv.org/abs/2512.04228", "authors": ["Peter B. Walker", "Hannah Davidson", "Aiden Foster", "Matthew Lienert", "Thomas Pardue", "Dale Russell"], "title": "Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework", "comment": "12 pages, 5 tables", "summary": "Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \\textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \\footnote{Code to recreate these experiments are at https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent'' as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u53cc\u63a8\u7406\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u80af\u5b9a\u751f\u6210\u548c\u7ed3\u6784\u5316\u53cd\u4e8b\u5b9e\u5426\u5b9a\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u903b\u8f91\u63a8\u7406\u7a33\u5065\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u4e3b\u8981\u57fa\u4e8e\u80af\u5b9a\u63a8\u7406\uff0c\u5bb9\u6613\u53d7\u5230\u903b\u8f91\u8c2c\u8bef\u3001\u5bf9\u6297\u6027\u653b\u51fb\u548c\u56e0\u679c\u63a8\u7406\u5931\u8d25\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5426\u5b9a\u3001\u53cd\u4f8b\u6216\u9519\u8bef\u524d\u63d0\u65f6\u8868\u73b0\u8106\u5f31\u3002", "method": "\u5f15\u5165\u53cc\u63a8\u7406\u8bad\u7ec3\u6846\u67b6\uff0c\u6574\u5408\u80af\u5b9a\u751f\u6210\u4e0e\u7ed3\u6784\u5316\u53cd\u4e8b\u5b9e\u5426\u5b9a\uff0c\u57fa\u4e8e\u5f62\u5f0f\u903b\u8f91\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u5bf9\u6297\u8bad\u7ec3\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u786e\u8ba4\u548c\u5426\u5b9a\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u5b9e\u73b0\u6709\u4e3b\u6d41\u5e73\u53f0\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u9886\u57df\u7684\u5426\u5b9a\u63a8\u7406\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u5f31\u70b9\uff0c\u65b0\u6846\u67b6\u4f7f\u6a21\u578b\u80fd\u62d2\u7edd\u65e0\u6548\u63a8\u7406\uff0c\u63d0\u9ad8\u7a33\u5065\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u53cc\u63a8\u7406\u8bad\u7ec3\u6846\u67b6\u63d0\u5347\u4e86\u6a21\u578b\u7684\u903b\u8f91\u4e00\u81f4\u6027\u548c\u6297\u5e72\u6270\u80fd\u529b\uff0c\u66f4\u7b26\u5408\u4eba\u7c7b\u63a8\u7406\u6a21\u5f0f\uff0c\u4e3a\u79d1\u5b66\u3001\u533b\u7597\u548c\u51b3\u7b56\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u6a21\u578b\u3002"}}
{"id": "2512.04580", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04580", "abs": "https://arxiv.org/abs/2512.04580", "authors": ["Huifeng Zhu", "Shijie Li", "Qinfeng Li", "Yier Jin"], "title": "A Light-Weight Large Language Model File Format for Highly-Secure Model Distribution", "comment": null, "summary": "To enhance the performance of large language models (LLMs) in various domain-specific applications, sensitive data such as healthcare, law, and finance are being used to privately customize or fine-tune these models. Such privately adapted LLMs are regarded as either personal privacy assets or corporate intellectual property. Therefore, protecting model weights and maintaining strict confidentiality during deployment and distribution have become critically important. However, existing model formats and deployment frameworks provide little to no built-in support for confidentiality, access control, or secure integration with trusted hardware. Current methods for securing model deployment either rely on computationally expensive cryptographic techniques or tightly controlled private infrastructure. Although these approaches can be effective in specific scenarios, they are difficult and costly for widespread deployment.\n  In this paper, we introduce CryptoTensors, a secure and format-compatible file structure for confidential LLM distribution. Built as an extension to the widely adopted Safetensors format, CryptoTensors incorporates tensor-level encryption and embedded access control policies, while preserving critical features such as lazy loading and partial deserialization. It enables transparent decryption and automated key management, supporting flexible licensing and secure model execution with minimal overhead. We implement a proof-of-concept library, benchmark its performance across serialization and runtime scenarios, and validate its compatibility with existing inference frameworks, including Hugging Face Transformers and vLLM. Our results highlight CryptoTensors as a light-weight, efficient, and developer-friendly solution for safeguarding LLM weights in real-world and widespread deployments.", "AI": {"tldr": "CryptoTensors\u662f\u4e00\u4e2a\u57fa\u4e8eSafetensors\u683c\u5f0f\u7684\u5b89\u5168\u6587\u4ef6\u7ed3\u6784\uff0c\u901a\u8fc7\u5f20\u91cf\u7ea7\u52a0\u5bc6\u548c\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\u4fdd\u62a4LLM\u6743\u91cd\uff0c\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u3001\u9ad8\u6548\u7684\u673a\u5bc6\u6a21\u578b\u5206\u53d1\u3002", "motivation": "\u968f\u7740LLM\u5728\u533b\u7597\u3001\u6cd5\u5f8b\u3001\u91d1\u878d\u7b49\u654f\u611f\u9886\u57df\u7684\u5b9a\u5236\u5316\u5e94\u7528\u589e\u52a0\uff0c\u6a21\u578b\u6743\u91cd\u4f5c\u4e3a\u9690\u79c1\u8d44\u4ea7\u6216\u77e5\u8bc6\u4ea7\u6743\u9700\u8981\u4fdd\u62a4\uff0c\u4f46\u73b0\u6709\u90e8\u7f72\u6846\u67b6\u7f3a\u4e4f\u5185\u7f6e\u7684\u673a\u5bc6\u6027\u548c\u8bbf\u95ee\u63a7\u5236\u652f\u6301\u3002", "method": "\u6269\u5c55Safetensors\u683c\u5f0f\uff0c\u96c6\u6210\u5f20\u91cf\u7ea7\u52a0\u5bc6\u548c\u5d4c\u5165\u5f0f\u8bbf\u95ee\u63a7\u5236\u7b56\u7565\uff0c\u4fdd\u7559\u5ef6\u8fdf\u52a0\u8f7d\u548c\u90e8\u5206\u53cd\u5e8f\u5217\u5316\u7279\u6027\uff0c\u63d0\u4f9b\u900f\u660e\u89e3\u5bc6\u548c\u81ea\u52a8\u5bc6\u94a5\u7ba1\u7406\u3002", "result": "\u5f00\u53d1\u4e86\u6982\u5ff5\u9a8c\u8bc1\u5e93\uff0c\u5728\u5e8f\u5217\u5316\u548c\u8fd0\u884c\u65f6\u573a\u666f\u4e2d\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u826f\u597d\uff0c\u4e0eHugging Face Transformers\u3001vLLM\u7b49\u63a8\u7406\u6846\u67b6\u517c\u5bb9\uff0c\u9a8c\u8bc1\u4e86\u5176\u8f7b\u91cf\u9ad8\u6548\u7279\u6027\u3002", "conclusion": "CryptoTensors\u4e3a\u5b9e\u9645\u5e7f\u6cdb\u90e8\u7f72\u4e2d\u7684LLM\u6743\u91cd\u4fdd\u62a4\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u3001\u9ad8\u6548\u4e14\u5f00\u53d1\u8005\u53cb\u597d\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.04263", "categories": ["cs.SE", "cs.LG", "cs.MS"], "pdf": "https://arxiv.org/pdf/2512.04263", "abs": "https://arxiv.org/abs/2512.04263", "authors": ["Hoang Duc Nguyen", "Anh Van Pham", "Hien D. Nguyen"], "title": "Polynomiogram: An Integrated Framework for Root Visualization and Generative Art", "comment": null, "summary": "This work presents the Polynomiogram framework, an integrated computational platform for exploring, visualizing, and generating art from polynomial root systems. The main innovation is a flexible sampling scheme in which two independent parameters are drawn from user defined domains and mapped to the polynomial coefficients through a generating function. This design allows the same mathematical foundation to support both scientific investigation and generative algorithmic art. The framework integrates two complementary numerical engines: NumPy companion matrix solver for fast, large scale computation and MPSolve for high precision, scientifically rigorous validation. This dual architecture enables efficient visualization for creative use and accurate computation for research and education. Numerical accuracy was verified using classical ensembles, including the Kac and Lucas polynomials. The method was applied to the cubic polynomial system to analyze its bifurcation structure, demonstrating its value as both a scientific tool for exploring root phenomena and an educational aid for visualizing fundamental concepts in algebra and dynamical systems. Beyond analysis, the Polynomiogram also demonstrated its potential as a tool for personalized generative art. Examples include the use of the platform to generate a natural form resembling a hibiscus flower and to create personalized artwork expressing gratitude toward advances in artificial intelligence and large language models through a tribute composition.", "AI": {"tldr": "\u63d0\u51fa\u4e86Polynomiogram\u6846\u67b6\uff0c\u4e00\u4e2a\u96c6\u6210\u8ba1\u7b97\u5e73\u53f0\uff0c\u7528\u4e8e\u63a2\u7d22\u3001\u53ef\u89c6\u5316\u548c\u4ece\u591a\u9879\u5f0f\u6839\u7cfb\u7edf\u751f\u6210\u827a\u672f\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u65e2\u80fd\u652f\u6301\u79d1\u5b66\u7814\u7a76\u53c8\u80fd\u652f\u6301\u751f\u6210\u7b97\u6cd5\u827a\u672f\u7684\u6570\u5b66\u57fa\u7840\u6846\u67b6\u3002", "method": "\u91c7\u7528\u7075\u6d3b\u91c7\u6837\u65b9\u6848\uff0c\u4ece\u7528\u6237\u5b9a\u4e49\u57df\u4e2d\u62bd\u53d6\u4e24\u4e2a\u72ec\u7acb\u53c2\u6570\uff0c\u901a\u8fc7\u751f\u6210\u51fd\u6570\u6620\u5c04\u5230\u591a\u9879\u5f0f\u7cfb\u6570\uff1b\u96c6\u6210NumPy\u540c\u4f34\u77e9\u9635\u6c42\u89e3\u5668\u548cMPSolve\u8fdb\u884c\u9ad8\u6548\u8ba1\u7b97\u548c\u9ad8\u7cbe\u5ea6\u9a8c\u8bc1\u3002", "result": "\u9a8c\u8bc1\u4e86\u6570\u503c\u51c6\u786e\u6027\uff0c\u5e94\u7528\u4e8e\u4e09\u6b21\u591a\u9879\u5f0f\u7cfb\u7edf\u5206\u6790\u5206\u5c94\u7ed3\u6784\uff1b\u5c55\u793a\u4e86\u4f5c\u4e3a\u79d1\u5b66\u5de5\u5177\u548c\u6559\u80b2\u8f85\u52a9\u7684\u4ef7\u503c\uff1b\u6210\u529f\u751f\u6210\u4e2a\u6027\u5316\u751f\u6210\u827a\u672f\u3002", "conclusion": "Polynomiogram\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u79d1\u5b66\u7814\u7a76\u4e0e\u827a\u672f\u751f\u6210\uff0c\u4e3a\u591a\u9879\u5f0f\u6839\u7cfb\u7edf\u7684\u63a2\u7d22\u548c\u6559\u80b2\u63d0\u4f9b\u4e86\u591a\u529f\u80fd\u5e73\u53f0\u3002"}}
{"id": "2512.04273", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04273", "abs": "https://arxiv.org/abs/2512.04273", "authors": ["Tyler Slater"], "title": "Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures", "comment": "Under review at the Journal of Systems and Software (Special Issue on Impactful Software Architecture)", "summary": "As Large Language Models (LLMs) transition from code completion tools to autonomous system architects, their impact on long-term software maintainability remains unquantified. While existing research benchmarks functional correctness (pass@k), this study presents the first empirical framework to measure \"Architectural Erosion\" and the accumulation of Technical Debt in AI-synthesized microservices. We conducted a comparative pilot study of three state-of-the-art models (GPT-5.1, Claude 4.5 Sonnet, and Llama 3 8B) by prompting them to implement a standardized Book Lending Microservice under strict Hexagonal Architecture constraints. Utilizing Abstract Syntax Tree (AST) parsing, we find that while proprietary models achieve high architectural conformance (0% violation rate for GPT-5.1), open-weights models exhibit critical divergence. Specifically, Llama 3 demonstrated an 80% Architectural Violation Rate, frequently bypassing interface adapters to create illegal circular dependencies between Domain and Infrastructure layers. Furthermore, we identified a phenomenon of \"Implementation Laziness,\" where open-weights models generated 60% fewer Logical Lines of Code (LLOC) than their proprietary counterparts, effectively omitting complex business logic to satisfy token constraints. These findings suggest that without automated architectural linting, utilizing smaller open-weights models for system scaffolding accelerates the accumulation of structural technical debt.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u8861\u91cfAI\u751f\u6210\u5fae\u670d\u52a1\u4e2d\u67b6\u6784\u8150\u8680\u548c\u6280\u672f\u503a\u52a1\u79ef\u7d2f\u7684\u5b9e\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9879\u5148\u8fdbLLM\u6a21\u578b\u7684\u5bf9\u6bd4\u7814\u7a76\u53d1\u73b0\u5f00\u6e90\u6a21\u578b\u5b58\u5728\u4e25\u91cd\u7684\u67b6\u6784\u8fdd\u89c4\u548c\u903b\u8f91\u7b80\u5316\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u8bc4\u4f30LLM\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u5bf9\u4e8eAI\u751f\u6210\u4ee3\u7801\u957f\u671f\u53ef\u7ef4\u62a4\u6027\u7684\u5f71\u54cd\u7f3a\u4e4f\u91cf\u5316\u7814\u7a76\uff0c\u7279\u522b\u662f\u67b6\u6784\u4fb5\u8680\u548c\u6280\u672f\u503a\u52a1\u79ef\u7d2f\u95ee\u9898\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u6700\u5148\u8fdb\u6a21\u578b\uff08GPT-5.1\u3001Claude 4.5 Sonnet\u3001Llama 3 8B\uff09\u5728\u4e25\u683c\u7684\u516d\u8fb9\u5f62\u67b6\u6784\u7ea6\u675f\u4e0b\u5b9e\u73b0\u6807\u51c6\u5316\u56fe\u4e66\u501f\u9605\u5fae\u670d\u52a1\uff0c\u901a\u8fc7\u62bd\u8c61\u8bed\u6cd5\u6811\u89e3\u6790\u8fdb\u884c\u67b6\u6784\u7b26\u5408\u6027\u5206\u6790\u3002", "result": "\u4e13\u6709\u6a21\u578b\u67b6\u6784\u7b26\u5408\u7387\u8fbe100%\uff0c\u800c\u5f00\u6e90\u6a21\u578bLlama 3\u51fa\u73b080%\u67b6\u6784\u8fdd\u89c4\u7387\uff0c\u7ecf\u5e38\u7ed5\u8fc7\u63a5\u53e3\u9002\u914d\u5668\u521b\u5efa\u975e\u6cd5\u5faa\u73af\u4f9d\u8d56\uff1b\u5f00\u6e90\u6a21\u578b\u751f\u6210\u7684\u903b\u8f91\u4ee3\u7801\u884c\u6570\u6bd4\u4e13\u6709\u6a21\u578b\u5c1160%\u3002", "conclusion": "\u5982\u679c\u4e0d\u91c7\u7528\u81ea\u52a8\u5316\u67b6\u6784\u68c0\u67e5\uff0c\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u67b6\u6784\u5efa\u6a21\u4f1a\u52a0\u901f\u7ed3\u6784\u6280\u672f\u503a\u52a1\u7684\u79ef\u7d2f\uff0c\u9700\u8981\u5efa\u7acb\u4e13\u95e8\u7684\u67b6\u6784\u9a8c\u8bc1\u673a\u5236\u3002"}}
{"id": "2512.04276", "categories": ["cs.AI", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.04276", "abs": "https://arxiv.org/abs/2512.04276", "authors": ["Przemyslaw Chojecki"], "title": "The Geometry of Benchmarks: A New Path Toward AGI", "comment": null, "summary": "Benchmarks are the primary tool for assessing progress in artificial intelligence (AI), yet current practice evaluates models on isolated test suites and provides little guidance for reasoning about generality or autonomous self-improvement. Here we introduce a geometric framework in which all psychometric batteries for AI agents are treated as points in a structured moduli space, and agent performance is described by capability functionals over this space. First, we define an Autonomous AI (AAI) Scale, a Kardashev-style hierarchy of autonomy grounded in measurable performance on batteries spanning families of tasks (for example reasoning, planning, tool use and long-horizon control). Second, we construct a moduli space of batteries, identifying equivalence classes of benchmarks that are indistinguishable at the level of agent orderings and capability inferences. This geometry yields determinacy results: dense families of batteries suffice to certify performance on entire regions of task space. Third, we introduce a general Generator-Verifier-Updater (GVU) operator that subsumes reinforcement learning, self-play, debate and verifier-based fine-tuning as special cases, and we define a self-improvement coefficient $\u03ba$ as the Lie derivative of a capability functional along the induced flow. A variance inequality on the combined noise of generation and verification provides sufficient conditions for $\u03ba> 0$. Our results suggest that progress toward artificial general intelligence (AGI) is best understood as a flow on moduli of benchmarks, driven by GVU dynamics rather than by scores on individual leaderboards.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\u6765\u8bc4\u4f30AI\u81ea\u4e3b\u6027\uff0c\u5c06AI\u8bc4\u4f30\u57fa\u51c6\u7ec4\u7ec7\u4e3a\u6a21\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u63d0\u51fa\u4e86\u81ea\u4e3bAI\u5c3a\u5ea6\u548cGVU\u7b97\u5b50\u6765\u91cf\u5316\u81ea\u6211\u6539\u8fdb\u80fd\u529b\u3002", "motivation": "\u5f53\u524dAI\u8bc4\u4f30\u5b9e\u8df5\u5c40\u9650\u4e8e\u5b64\u7acb\u6d4b\u8bd5\u5957\u4ef6\uff0c\u65e0\u6cd5\u8bc4\u4f30\u901a\u7528\u6027\u6216\u81ea\u4e3b\u81ea\u6211\u6539\u8fdb\u80fd\u529b\uff0c\u9700\u8981\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u7406\u89e3AGI\u8fdb\u5c55\u3002", "method": "\u6784\u5efa\u57fa\u51c6\u7684\u6a21\u7a7a\u95f4\uff0c\u5b9a\u4e49\u81ea\u4e3bAI\u5c42\u7ea7\uff08AAI Scale\uff09\uff0c\u63d0\u51faGenerator-Verifier-Updater\uff08GVU\uff09\u7b97\u5b50\uff0c\u5f15\u5165\u81ea\u6211\u6539\u8fdb\u7cfb\u6570\u03ba\u4f5c\u4e3a\u80fd\u529b\u6cdb\u51fd\u7684Lie\u5bfc\u6570\u3002", "result": "\u83b7\u5f97\u4e86\u786e\u5b9a\u6027\u7ed3\u679c\uff1a\u5bc6\u96c6\u57fa\u51c6\u65cf\u8db3\u4ee5\u8bc1\u660e\u6574\u4e2a\u4efb\u52a1\u533a\u57df\u7684\u6027\u80fd\uff1bGVU\u52a8\u6001\u7684\u65b9\u5dee\u4e0d\u7b49\u5f0f\u4e3a\u03ba>0\u63d0\u4f9b\u4e86\u5145\u5206\u6761\u4ef6\u3002", "conclusion": "AGI\u8fdb\u5c55\u5e94\u88ab\u89c6\u4e3a\u57fa\u51c6\u6a21\u7a7a\u95f4\u4e0a\u7684\u6d41\uff0c\u7531GVU\u52a8\u529b\u5b66\u9a71\u52a8\u800c\u975e\u5355\u4e2a\u6392\u884c\u699c\u5206\u6570\uff0c\u8fd9\u4e3aAI\u81ea\u4e3b\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.04319", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04319", "abs": "https://arxiv.org/abs/2512.04319", "authors": ["Zixiao Zhao", "Fatemeh H. Fard", "Jie JW Wu"], "title": "MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training", "comment": null, "summary": "The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning.", "AI": {"tldr": "\u63d0\u51faMANTRA\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u81ea\u9002\u5e94\u566a\u58f0\u5904\u7406\u63d0\u9ad8\u4ee3\u7801\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u9488\u5bf9\u566a\u58f0\u6807\u7b7e\u95ee\u9898\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u9700\u8981\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f46\u5927\u578b\u4ee3\u7801\u5e93\u4e2d\u5e38\u5b58\u5728\u566a\u58f0\u6807\u7b7e\uff0c\u5f71\u54cd\u6a21\u578b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002\u7136\u800c\uff0c\u566a\u58f0\u6807\u7b7e\u5b66\u4e60\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u7814\u7a76\u8f83\u5c11\u3002", "method": "MANTRA\u6846\u67b6\u96c6\u6210\u566a\u58f0\u8bca\u65ad\u548c\u7f13\u89e3\u5230\u6a21\u578b\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff1a\u5148\u7814\u7a76\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u5bf9\u6a21\u578b\u6536\u655b\u7684\u5f71\u54cd\uff0c\u518d\u57fa\u4e8e\u6837\u672c\u635f\u5931\u52a8\u6001\u548c\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\u5e94\u7528\u81ea\u9002\u5e94dropout\u7b56\u7565\u8fc7\u6ee4\u566a\u58f0\u6570\u636e\u3002", "result": "\u5728\u4ee3\u7801\u6458\u8981\u548c\u63d0\u4ea4\u610f\u56fe\u5206\u7c7b\u4efb\u52a1\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u67d0\u4e9b\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u566a\u58f0\u66f4\u654f\u611f\uff0c\u4f46\u4f7f\u7528MANTRA\u540e\u6240\u6709\u6a21\u578b\u6027\u80fd\u5747\u5f97\u5230\u63d0\u5347\u3002", "conclusion": "MANTRA\u80fd\u6709\u6548\u51cf\u5c11\u8bad\u7ec3\u6570\u636e\u4e2d\u566a\u58f0\u7684\u5f71\u54cd\uff0c\u8282\u7701\u6570\u636e\u6e05\u6d17\u65f6\u95f4\uff0c\u5e76\u6700\u5927\u5316\u5fae\u8c03\u6548\u679c\uff0c\u4e3a\u7814\u7a76\u548c\u5b9e\u8df5\u63d0\u4f9b\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.04287", "categories": ["cs.AI", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2512.04287", "abs": "https://arxiv.org/abs/2512.04287", "authors": ["Ian Miles", "Mayumi Wakimoto", "Wagner Meira", "Daniela Paula", "Daylene Ticiane", "Bruno Rosa", "Jane Biddulph", "Stelios Georgiou", "Valdir Ermida"], "title": "Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases", "comment": "21 pages, 1 box, 1 figure", "summary": "This review explores the integration of Artificial Intelligence into Horizon Scanning, focusing on identifying and responding to emerging threats and opportunities linked to Infectious Diseases. We examine how AI tools can enhance signal detection, data monitoring, scenario analysis, and decision support. We also address the risks associated with AI adoption and propose strategies for effective implementation and governance. The findings contribute to the growing body of Foresight literature by demonstrating the potential and limitations of AI in Public Health preparedness.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u4f20\u67d3\u75c5\u9886\u57df\u9884\u8b66\u626b\u63cf\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u548c\u98ce\u9669", "motivation": "\u968f\u7740\u4f20\u67d3\u75c5\u5a01\u80c1\u65e5\u76ca\u590d\u6742\uff0c\u9700\u63a2\u7d22AI\u5982\u4f55\u589e\u5f3a\u516c\u5171\u536b\u751f\u9884\u8b66\u80fd\u529b", "method": "\u901a\u8fc7\u7efc\u8ff0AI\u5de5\u5177\u5728\u4fe1\u53f7\u68c0\u6d4b\u3001\u6570\u636e\u76d1\u6d4b\u3001\u573a\u666f\u5206\u6790\u548c\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u5e94\u7528", "result": "\u53d1\u73b0AI\u80fd\u63d0\u5347\u5a01\u80c1\u8bc6\u522b\u6548\u7387\u4f46\u5b58\u5728\u5b9e\u65bd\u98ce\u9669", "conclusion": "\u9700\u5efa\u7acb\u6709\u6548\u5b9e\u65bd\u548c\u6cbb\u7406\u7b56\u7565\uff0cAI\u5728\u516c\u5171\u536b\u751f\u51c6\u5907\u4e2d\u65e2\u6709\u6f5c\u529b\u4e5f\u6709\u5c40\u9650"}}
{"id": "2512.04675", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04675", "abs": "https://arxiv.org/abs/2512.04675", "authors": ["Siwei Chen", "Peipei Xie", "Shengyuan Xu", "Xiutao Feng", "Zejun Xiang", "Xiangyong Zeng"], "title": "Cryptanalysis of Gleeok-128", "comment": "44 pages, 5 figures", "summary": "Gleeok is a family of low latency keyed pseudorandom functions (PRFs) consisting of three parallel SPN based permutations whose outputs are XORed to form the final value. Both Gleeok-128 and Gleeok-256 use a 256 bit key, with block sizes of 128 and 256 bits, respectively. Owing to its multi branch structure, evaluating security margins and mounting effective key recovery attacks present nontrivial challenges. This paper provides the first comprehensive third party cryptanalysis of Gleeok-128. We introduce a two stage MILP based framework for constructing branch wise and full cipher differential linear (DL) distinguishers, together with an integral based key recovery framework tailored to multi branch designs. Our DL analysis yields 7, 7, 8, and 4 round distinguishers for Branch 1, Branch 2, Branch 3, and Gleeok-128, respectively, with squared correlations approximately 2 to the power minus 88.12, 2 to the power minus 88.12, 2 to the power minus 38.73, and 2 to the power minus 49.04, outperforming those in the design document except for the full PRF case. By tightening algebraic degree bounds, we further derive 9, 9, and 7 round integral distinguishers for the three branches and a 7 round distinguisher for the full PRF, extending the designers results by 3, 3, and 2 rounds and by 2 rounds, respectively. These integral properties enable 7 round and 8 round key recovery attacks in the non full codebook and full codebook settings. In addition, we identify a flaw in the original linear security evaluation of Branch 3, showing that it can be distinguished over all 12 rounds with data complexity about 2 to the power 48. We also propose optimized linear layer parameters that significantly improve linear resistance without sacrificing diffusion. Our results advance the understanding of Gleeok-128 and provide general methods for analyzing multi branch symmetric designs.", "AI": {"tldr": "\u672c\u6587\u5bf9Gleeok-128\u8fdb\u884c\u4e86\u9996\u6b21\u5168\u9762\u7684\u7b2c\u4e09\u65b9\u5bc6\u7801\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eMILP\u7684\u5dee\u5206-\u7ebf\u6027\u533a\u5206\u5668\u6784\u5efa\u6846\u67b6\u548c\u79ef\u5206\u653b\u51fb\u6846\u67b6\uff0c\u53d1\u73b0\u4e86\u4f18\u4e8e\u8bbe\u8ba1\u6587\u6863\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u7684\u7ebf\u6027\u5c42\u53c2\u6570\u3002", "motivation": "\u7531\u4e8eGleeok\u7684\u591a\u5206\u652f\u7ed3\u6784\uff0c\u8bc4\u4f30\u5176\u5b89\u5168\u88d5\u5ea6\u548c\u5b9e\u65bd\u6709\u6548\u7684\u5bc6\u94a5\u6062\u590d\u653b\u51fb\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u7cfb\u7edf\u7684\u5bc6\u7801\u5206\u6790\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5MILP\u6846\u67b6\u6784\u5efa\u5206\u652f\u548c\u5168\u5bc6\u7801\u7684\u5dee\u5206-\u7ebf\u6027\u533a\u5206\u5668\uff0c\u7ed3\u5408\u79ef\u5206\u653b\u51fb\u6846\u67b6\u9488\u5bf9\u591a\u5206\u652f\u8bbe\u8ba1\u8fdb\u884c\u5b9a\u5236\u5316\u5206\u6790\u3002", "result": "\u83b7\u5f97\u4e867/7/8/4\u8f6e\u533a\u5206\u5668\uff08\u4e09\u4e2a\u5206\u652f\u548c\u5168\u5bc6\u7801\uff09\uff0c\u79ef\u5206\u533a\u5206\u5668\u6269\u5c55\u4e86\u8bbe\u8ba1\u8005\u7ed3\u679c3/3/2\u8f6e\u548c2\u8f6e\uff0c\u53d1\u73b0Branch 3\u7ebf\u6027\u5b89\u5168\u8bc4\u4f30\u7f3a\u9677\uff0812\u8f6e\u53ef\u533a\u5206\uff0c\u6570\u636e\u590d\u6742\u5ea62^48\uff09\u3002", "conclusion": "\u7814\u7a76\u63a8\u8fdb\u4e86\u5bf9Gleeok-128\u7684\u7406\u89e3\uff0c\u4e3a\u5206\u6790\u591a\u5206\u652f\u5bf9\u79f0\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u901a\u7528\u65b9\u6cd5\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4f18\u5316\u7ebf\u6027\u5c42\u53c2\u6570\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u3002"}}
{"id": "2512.04344", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04344", "abs": "https://arxiv.org/abs/2512.04344", "authors": ["Zitong Zhou", "Ben Limpanukorn", "Hong Jin Kang", "Jiyuan Wang", "Yaoxuan Wu", "Akos Kiss", "Renata Hodovan", "Miryung Kim"], "title": "Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles", "comment": null, "summary": "Ensuring the correctness of compiler optimizations is critical, but existing fuzzers struggle to test optimizations effectively. First, most fuzzers use optimization pipelines (heuristics-based, fixed sequences of passes) as their harness. The phase-ordering problem can enable or preempt transformations, so pipelines inevitably miss optimization interactions; moreover, many optimizations are not scheduled, even at aggressive levels. Second, optimizations typically fire only when inputs satisfy specific structural relationships, which existing generators and mutations struggle to produce. We propose targeted fuzzing of individual optimizations to complement pipeline-based testing. Our key idea is to exploit composition styles - structural relations over program constructs (adjacency, nesting, repetition, ordering) - that optimizations look for. We build a general-purpose, grammar-based mutational fuzzer, TargetFuzz, that (i) mines composition styles from an optimization-relevant corpus, then (ii) rebuilds them inside different contexts offered by a larger, generic corpus via synthesized mutations to test variations of optimization logic. TargetFuzz is adaptable to a new programming language by lightweight, grammar-based, construct annotations - and it automatically synthesizes mutators and crossovers to rebuild composition styles. No need for hand-coded generators or language-specific mutators, which is particularly useful for modular frameworks such as MLIR, whose dialect-based, rapidly evolving ecosystem makes optimizations difficult to fuzz. Our evaluation on LLVM and MLIR shows that TargetFuzz improves coverage by 8% and 11% and triggers optimizations 2.8$\\times$ and 2.6$\\times$, compared to baseline fuzzers under the targeted fuzzing mode. We show that targeted fuzzing is complementary: it effectively tests all 37 sampled LLVM optimizations, while pipeline-fuzzing missed 12.", "AI": {"tldr": "\u63d0\u51fa\u4e86TargetFuzz\uff0c\u4e00\u79cd\u9488\u5bf9\u5355\u4e2a\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u9488\u5bf9\u6027\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u4f18\u5316\u76f8\u5173\u7684\u7ec4\u5408\u6837\u5f0f\u6765\u63d0\u9ad8\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u89e6\u53d1\u4f18\u5316\u6b21\u6570", "motivation": "\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u6d4b\u8bd5\u7f16\u8bd1\u5668\u4f18\u5316\uff0c\u4e3b\u8981\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1) \u4f7f\u7528\u56fa\u5b9a\u4f18\u5316\u6d41\u6c34\u7ebf\u4f1a\u9519\u8fc7\u4f18\u5316\u95f4\u7684\u4ea4\u4e92\uff1b2) \u73b0\u6709\u751f\u6210\u5668\u96be\u4ee5\u4ea7\u751f\u6ee1\u8db3\u4f18\u5316\u89e6\u53d1\u6761\u4ef6\u7684\u7279\u5b9a\u7a0b\u5e8f\u7ed3\u6784", "method": "\u6784\u5efa\u57fa\u4e8e\u8bed\u6cd5\u7684\u53d8\u5f02\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177TargetFuzz\uff0c\u901a\u8fc7\u6316\u6398\u4f18\u5316\u76f8\u5173\u7684\u7ec4\u5408\u6837\u5f0f\uff08\u7a0b\u5e8f\u6784\u9020\u95f4\u7684\u7ed3\u6784\u5173\u7cfb\uff09\uff0c\u5e76\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u4e2d\u91cd\u5efa\u8fd9\u4e9b\u6837\u5f0f\u6765\u6d4b\u8bd5\u4f18\u5316\u7684\u53d8\u4f53", "result": "\u5728LLVM\u548cMLIR\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cTargetFuzz\u6bd4\u57fa\u7ebf\u6a21\u7cca\u6d4b\u8bd5\u5668\u5728\u8986\u76d6\u7387\u4e0a\u5206\u522b\u63d0\u9ad8\u4e868%\u548c11%\uff0c\u4f18\u5316\u89e6\u53d1\u6b21\u6570\u5206\u522b\u63d0\u9ad8\u4e862.8\u500d\u548c2.6\u500d", "conclusion": "\u9488\u5bf9\u6027\u6a21\u7cca\u6d4b\u8bd5\u662f\u5bf9\u57fa\u4e8e\u6d41\u6c34\u7ebf\u6d4b\u8bd5\u7684\u6709\u6548\u8865\u5145\uff0c\u80fd\u591f\u66f4\u5168\u9762\u5730\u6d4b\u8bd5\u7f16\u8bd1\u5668\u4f18\u5316\uff0c\u7279\u522b\u662f\u5728MLIR\u7b49\u6a21\u5757\u5316\u6846\u67b6\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c"}}
{"id": "2512.04302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04302", "abs": "https://arxiv.org/abs/2512.04302", "authors": ["Shuyuan Zhang"], "title": "Towards better dense rewards in Reinforcement Learning Applications", "comment": "arXiv admin note: substantial text overlap with arXiv:2505.20417", "summary": "Finding meaningful and accurate dense rewards is a fundamental task in the field of reinforcement learning (RL) that enables agents to explore environments more efficiently. In traditional RL settings, agents learn optimal policies through interactions with an environment guided by reward signals. However, when these signals are sparse, delayed, or poorly aligned with the intended task objectives, agents often struggle to learn effectively. Dense reward functions, which provide informative feedback at every step or state transition, offer a potential solution by shaping agent behavior and accelerating learning. Despite their benefits, poorly crafted reward functions can lead to unintended behaviors, reward hacking, or inefficient exploration. This problem is particularly acute in complex or high-dimensional environments where handcrafted rewards are difficult to specify and validate. To address this, recent research has explored a variety of approaches, including inverse reinforcement learning, reward modeling from human preferences, and self-supervised learning of intrinsic rewards. While these methods offer promising directions, they often involve trade-offs between generality, scalability, and alignment with human intent. This proposal explores several approaches to dealing with these unsolved problems and enhancing the effectiveness and reliability of dense reward construction in different RL applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\u4e2d\u5bc6\u96c6\u5956\u52b1\u51fd\u6570\u7684\u8bbe\u8ba1\u6311\u6218\u53ca\u89e3\u51b3\u65b9\u6848\uff0c\u5206\u6790\u4e86\u7a00\u758f\u5956\u52b1\u95ee\u9898\u5e76\u63d0\u51fa\u591a\u79cd\u6539\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7a00\u758f\u3001\u5ef6\u8fdf\u6216\u4e0d\u5339\u914d\u7684\u5956\u52b1\u4fe1\u53f7\u4f1a\u5bfc\u81f4\u667a\u80fd\u4f53\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u73af\u5883\u4e2d\u624b\u5de5\u8bbe\u8ba1\u5bc6\u96c6\u5956\u52b1\u51fd\u6570\u5341\u5206\u56f0\u96be\u4e14\u5bb9\u6613\u4ea7\u751f\u610f\u5916\u884c\u4e3a\u3002", "method": "\u8bba\u6587\u7efc\u8ff0\u4e86\u591a\u79cd\u65b9\u6cd5\uff0c\u5305\u62ec\u9006\u5f3a\u5316\u5b66\u4e60\u3001\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684\u5956\u52b1\u5efa\u6a21\u4ee5\u53ca\u81ea\u76d1\u7763\u5b66\u4e60\u5185\u5728\u5956\u52b1\u7b49\u65b9\u6cd5\u3002", "result": "\u5206\u6790\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u901a\u7528\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e0e\u4eba\u7c7b\u610f\u56fe\u5bf9\u9f50\u65b9\u9762\u7684\u6743\u8861\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u9ad8\u5bc6\u96c6\u5956\u52b1\u6784\u5efa\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u4e0d\u540cRL\u5e94\u7528\u63d0\u4f9b\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.04841", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04841", "abs": "https://arxiv.org/abs/2512.04841", "authors": ["Wei Zhao", "Zhe Li", "Jun Sun"], "title": "SoK: a Comprehensive Causality Analysis Framework for Large Language Model Security", "comment": null, "summary": "Large Language Models (LLMs) exhibit remarkable capabilities but remain vulnerable to adversarial manipulations such as jailbreaking, where crafted prompts bypass safety mechanisms. Understanding the causal factors behind such vulnerabilities is essential for building reliable defenses.\n  In this work, we introduce a unified causality analysis framework that systematically supports all levels of causal investigation in LLMs, ranging from token-level, neuron-level, and layer-level interventions to representation-level analysis. The framework enables consistent experimentation and comparison across diverse causality-based attack and defense methods. Accompanying this implementation, we provide the first comprehensive survey of causality-driven jailbreak studies and empirically evaluate the framework on multiple open-weight models and safety-critical benchmarks including jailbreaks, hallucination detection, backdoor identification, and fairness evaluation. Our results reveal that: (1) targeted interventions on causally critical components can reliably modify safety behavior; (2) safety-related mechanisms are highly localized (i.e., concentrated in early-to-middle layers with only 1--2\\% of neurons exhibiting causal influence); and (3) causal features extracted from our framework achieve over 95\\% detection accuracy across multiple threat types.\n  By bridging theoretical causality analysis and practical model safety, our framework establishes a reproducible foundation for research on causality-based attacks, interpretability, and robust attack detection and mitigation in LLMs. Code is available at https://github.com/Amadeuszhao/SOK_Casuality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u56e0\u679c\u5206\u6790\u6846\u67b6\uff0c\u7cfb\u7edf\u652f\u6301LLM\u4e2d\u4ece\u4ee4\u724c\u7ea7\u5230\u8868\u793a\u7ea7\u7684\u56e0\u679c\u8c03\u67e5\uff0c\u63ed\u793a\u5b89\u5168\u673a\u5236\u9ad8\u5ea6\u5c40\u90e8\u5316\uff08\u96c6\u4e2d\u5728\u65e9\u671f\u5230\u4e2d\u95f4\u5c42\uff0c\u4ec51-2%\u7684\u795e\u7ecf\u5143\u5177\u6709\u56e0\u679c\u5f71\u54cd\uff09\uff0c\u56e0\u679c\u7279\u5f81\u5728\u5a01\u80c1\u68c0\u6d4b\u4e2d\u51c6\u786e\u7387\u8d85\u8fc795%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u5353\u8d8a\u80fd\u529b\u4f46\u4ecd\u6613\u53d7\u5bf9\u6297\u6027\u64cd\u63a7\uff08\u5982\u8d8a\u72f1\uff09\uff0c\u7406\u89e3\u8fd9\u4e9b\u8106\u5f31\u6027\u7684\u56e0\u679c\u56e0\u7d20\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u9632\u5fa1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u56e0\u679c\u5206\u6790\u6846\u67b6\uff0c\u652f\u6301\u4ee4\u724c\u7ea7\u3001\u795e\u7ecf\u5143\u7ea7\u3001\u5c42\u7ea7\u5e72\u9884\u548c\u8868\u793a\u7ea7\u5206\u6790\uff0c\u5728\u591a\u5f00\u653e\u6743\u91cd\u6a21\u578b\u548c\u5b89\u5168\u5173\u952e\u57fa\u51c6\uff08\u8d8a\u72f1\u3001\u5e7b\u89c9\u68c0\u6d4b\u3001\u540e\u95e8\u8bc6\u522b\u3001\u516c\u5e73\u6027\u8bc4\u4f30\uff09\u4e0a\u8fdb\u884c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u9488\u5bf9\u6027\u5e72\u9884\u56e0\u679c\u5173\u952e\u7ec4\u4ef6\u53ef\u53ef\u9760\u4fee\u6539\u5b89\u5168\u884c\u4e3a\uff1b\u5b89\u5168\u76f8\u5173\u673a\u5236\u9ad8\u5ea6\u5c40\u90e8\u5316\uff1b\u4ece\u6846\u67b6\u63d0\u53d6\u7684\u56e0\u679c\u7279\u5f81\u5728\u591a\u79cd\u5a01\u80c1\u7c7b\u578b\u4e2d\u68c0\u6d4b\u51c6\u786e\u7387\u8d85\u8fc795%\u3002", "conclusion": "\u901a\u8fc7\u6865\u63a5\u7406\u8bba\u56e0\u679c\u5206\u6790\u548c\u5b9e\u9645\u6a21\u578b\u5b89\u5168\uff0c\u8be5\u6846\u67b6\u4e3a\u57fa\u4e8e\u56e0\u679c\u6027\u7684\u653b\u51fb\u3001\u53ef\u89e3\u91ca\u6027\u4ee5\u53ca\u9c81\u68d2\u653b\u51fb\u68c0\u6d4b\u4e0e\u7f13\u89e3\u7814\u7a76\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u57fa\u7840\u3002"}}
{"id": "2512.04474", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04474", "abs": "https://arxiv.org/abs/2512.04474", "authors": ["Jiaqi Sun", "Wei Li", "Heng Zhang", "Chutong Ding", "Shiyou Qian", "Jian Cao", "Guangtao Xue"], "title": "LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models", "comment": null, "summary": "Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.", "AI": {"tldr": "LLM-SrcLog\u662f\u4e00\u4e2a\u4e3b\u52a8\u7684\u65e5\u5fd7\u89e3\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u6e90\u4ee3\u7801\u5206\u6790\u548c\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u7ed3\u5408\uff0c\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5904\u7406\u901f\u5ea6", "motivation": "\u73b0\u6709\u65e5\u5fd7\u89e3\u6790\u5668\u4e3b\u8981\u88ab\u52a8\u5730\u4ece\u65e5\u5fd7\u4e2d\u63a8\u65ad\u6a21\u677f\uff0c\u5ffd\u7565\u4e86\u6e90\u4ee3\u7801\u4fe1\u606f\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u65e5\u5fd7\u7ed3\u6784\u53d8\u5316\uff0c\u4e14\u57fa\u4e8eLLM\u7684\u5355\u6761\u65e5\u5fd7\u89e3\u6790\u6210\u672c\u8fc7\u9ad8", "method": "\u6846\u67b6\u5305\u542b\uff1a\u8de8\u51fd\u6570\u9759\u6001\u4ee3\u7801\u5206\u6790\u5668\u91cd\u5efa\u65e5\u5fd7\u4e0a\u4e0b\u6587\uff0c\u57fa\u4e8eLLM\u7684\u767d\u76d2\u6a21\u677f\u63d0\u53d6\u5668\u533a\u5206\u5e38\u91cf\u53d8\u91cf\uff0c\u6570\u636e\u9a71\u52a8\u7684\u9ed1\u76d2\u6a21\u677f\u63d0\u53d6\u5668\u5904\u7406\u65e0\u6e90\u4ee3\u7801\u65e5\u5fd7", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u57fa\u51c6\u548c\u4e00\u4e2a\u5de5\u4e1a\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u76f8\u6bd4\u57fa\u4e8eLLM\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0cF1\u5206\u6570\u63d0\u53472-35%\uff0c\u5728\u7ebf\u89e3\u6790\u5ef6\u8fdf\u4e0e\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u76f8\u5f53\uff0c\u6bd4\u5355\u6761\u65e5\u5fd7LLM\u89e3\u6790\u5feb\u7ea61000\u500d", "conclusion": "LLM-SrcLog\u5728\u901f\u5ea6\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u7406\u60f3\u7684\u5e73\u8861\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u6848\u4f8b\u9a8c\u8bc1\u4e86\u6709\u6548\u6027"}}
{"id": "2512.04359", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04359", "abs": "https://arxiv.org/abs/2512.04359", "authors": ["Hongye Cao", "Zhixin Bai", "Ziyue Peng", "Boyan Wang", "Tianpei Yang", "Jing Huo", "Yuyao Zhang", "Yang Gao"], "title": "Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from entropy collapse, which reduces policy exploration and limits reasoning capabilities. To address this challenge, we propose an efficient reinforcement learning framework that leverages entropy signals at both the semantic and token levels to improve reasoning. From the data perspective, we introduce semantic entropy-guided curriculum learning, organizing training data from low to high semantic entropy to guide progressive optimization from easier to more challenging tasks. For the algorithmic design, we adopt non-uniform token treatment by imposing KL regularization on low-entropy tokens that critically impact policy exploration and applying stronger constraints on high-covariance portions within these tokens. By jointly optimizing data organization and algorithmic design, our method effectively mitigates entropy collapse and enhances LLM reasoning. Experimental results across 6 benchmarks with 3 different parameter-scale base models demonstrate that our method outperforms other entropy-based approaches in improving reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u8bed\u4e49\u71b5\u548c\u6807\u8bb0\u7ea7\u71b5\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u548c\u975e\u5747\u5300\u6807\u8bb0\u5904\u7406\u6765\u7f13\u89e3\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u80fd\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5bb9\u6613\u53d1\u751f\u71b5\u5d29\u6e83\uff0c\u9650\u5236\u7b56\u7565\u63a2\u7d22\u548c\u63a8\u7406\u80fd\u529b", "method": "\u4ece\u6570\u636e\u89d2\u5ea6\u5f15\u5165\u8bed\u4e49\u71b5\u5f15\u5bfc\u7684\u8bfe\u7a0b\u5b66\u4e60\uff0c\u4ece\u7b97\u6cd5\u89d2\u5ea6\u5bf9\u5173\u952e\u4f4e\u71b5\u6807\u8bb0\u5b9e\u65bdKL\u6b63\u5219\u5316\uff0c\u5bf9\u9ad8\u534f\u65b9\u5dee\u90e8\u5206\u65bd\u52a0\u66f4\u5f3a\u7ea6\u675f", "result": "\u57286\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c3\u79cd\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u7684\u57fa\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u63a8\u7406\u80fd\u529b\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u57fa\u4e8e\u71b5\u7684\u65b9\u6cd5", "conclusion": "\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6570\u636e\u7ec4\u7ec7\u548c\u7b97\u6cd5\u8bbe\u8ba1\uff0c\u6709\u6548\u7f13\u89e3\u71b5\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u589e\u5f3aLLM\u7684\u63a8\u7406\u6027\u80fd"}}
{"id": "2512.04538", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04538", "abs": "https://arxiv.org/abs/2512.04538", "authors": ["Xinkui Zhao", "Rongkai Liu", "Yifan Zhang", "Chen Zhi", "Lufei Zhang", "Guanjie Cheng", "Yueshen Xu", "Shuiguang Deng", "Jianwei Yin"], "title": "Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding", "comment": null, "summary": "As code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.", "AI": {"tldr": "CoCo\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u4ee3\u7801\u8865\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u7406\u89e3\u591a\u7c92\u5ea6\u4e0a\u4e0b\u6587\u6765\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u4ee3\u7801\u8865\u5168\u65b9\u6cd5\u4e3b\u8981\u5c06\u4ee3\u7801\u89c6\u4e3a\u7eaf\u81ea\u7136\u8bed\u8a00\uff0c\u4f9d\u8d56\u6d45\u5c42\u8bed\u4e49\u5339\u914d\u800c\u5ffd\u7565\u7ed3\u6784\u8bed\u4e49\u548c\u4ee3\u7801\u7279\u5b9a\u4f9d\u8d56\u5173\u7cfb\uff0c\u9650\u5236\u4e86\u6355\u6349\u63a7\u5236\u6d41\u548c\u5e95\u5c42\u610f\u56fe\u7684\u80fd\u529b\u3002", "method": "CoCo\u91c7\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u63d0\u53d6\u51fd\u6570\u3001\u6587\u4ef6\u548c\u9879\u76ee\u7ea7\u522b\u7684\u7ed3\u6784\u5316\u4e0a\u4e0b\u6587\uff0c\u4f7f\u7528\u57fa\u4e8e\u56fe\u7684\u591a\u7c92\u5ea6\u4e0a\u4e0b\u6587\u9009\u62e9\u673a\u5236\u8fc7\u6ee4\u5197\u4f59\u4fe1\u606f\uff0c\u5e76\u5c06\u4fe1\u606f\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u4f5c\u4e3a\u663e\u5f0f\u4e0a\u4e0b\u6587\u63d0\u793a\uff0c\u8f85\u4ee5\u7ed3\u6784\u611f\u77e5\u7684\u4ee3\u7801\u91cd\u65b0\u6392\u5e8f\u673a\u5236\u3002", "result": "\u5728CrossCodeEval\u548cRepoEval\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCoCo consistently\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728EM\u6307\u6807\u4e0a\u5b9e\u73b0\u9ad8\u8fbe20.2%\u7684\u63d0\u5347\u3002", "conclusion": "CoCo\u6846\u67b6\u662f\u6a21\u578b\u65e0\u5173\u7684\uff0c\u80fd\u591f\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u65b9\u6cd5\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u4ece\u51fd\u6570\u7ea7\u5230\u4ed3\u5e93\u7ea7\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u5229\u7528\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.04950", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04950", "abs": "https://arxiv.org/abs/2512.04950", "authors": ["\u00c9tienne Andr\u00e9", "Lydia Bakiri"], "title": "Opacity problems in multi-energy timed automata", "comment": "This is the author version (extended with all proofs) of the manuscript of the same name published in the proceedings of the 41st ACM/SIGAPP Symposium on Applied Computing (SAC 2026)", "summary": "Cyber-physical systems can be subject to information leakage; in the presence of continuous variables such as time and energy, these leaks can be subtle to detect. We study here the verification of opacity problems over systems with observation over both timing and energy information. We introduce guarded multi-energy timed automata as an extension of timed automata with multiple energy variables and guards over such variables. Despite undecidability of this general formalism, we establish positive results over a number of subclasses, notably when the attacker observes the final energy and/or the execution time, but also when they have access to the value of the energy variables every time unit.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.04673", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04673", "abs": "https://arxiv.org/abs/2512.04673", "authors": ["Gunjan Das", "Paheli Bhattacharya", "Rishabh Gupta"], "title": "Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model capabilities, a systematic cross-domain comparison that unifies linguistic, reasoning, and code understanding abilities remains underexplored. In this work, we present a comprehensive evaluation of five general-purpose and three code-specific state-of-the-art LLMs across six diverse benchmarks encompassing linguistic competence, mathematical reasoning, and trustworthiness. Additionally, we analyze model behavior on the CoNaLa dataset for code explanation, comparing natural language and code-specialized LLMs. Our findings reveal that models optimized for code (e.g., CodeLLaMA variants) exhibit strong reasoning and syntactic precision, that even for non-coding tasks can show measurable performance gains, in contrast to general-purpose models like Mistral-7B and Llama-3-8B.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf95\u4e2a\u901a\u7528\u548c3\u4e2a\u4ee3\u7801\u4e13\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u4e86\u8de8\u9886\u57df\u7efc\u5408\u8bc4\u4f30\uff0c\u8986\u76d6\u8bed\u8a00\u80fd\u529b\u3001\u6570\u5b66\u63a8\u7406\u548c\u53ef\u4fe1\u5ea6\u7b49\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u3002\u7814\u7a76\u53d1\u73b0\u4ee3\u7801\u4f18\u5316\u6a21\u578b\uff08\u5982CodeLLaMA\uff09\u5728\u63a8\u7406\u548c\u8bed\u6cd5\u7cbe\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u751a\u81f3\u5728\u975e\u4ee3\u7801\u4efb\u52a1\u4e2d\u4e5f\u4f18\u4e8e\u901a\u7528\u6a21\u578b\u3002", "motivation": "\u5df2\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5355\u4e2a\u6a21\u578b\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u3001\u63a8\u7406\u548c\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u7684\u7cfb\u7edf\u6027\u8de8\u9886\u57df\u6bd4\u8f83\u3002", "method": "\u4f7f\u7528\u516d\u4e2a\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u8bed\u8a00\u80fd\u529b\u3001\u6570\u5b66\u63a8\u7406\u3001\u53ef\u4fe1\u5ea6\uff09\u8bc4\u4f30\u4e94\u4e2a\u901a\u7528\u548c\u4e09\u4e2a\u4ee3\u7801\u4e13\u7528LLMs\uff0c\u5e76\u5206\u6790\u5b83\u4eec\u5728CoNaLa\u6570\u636e\u96c6\u4e0a\u7684\u4ee3\u7801\u89e3\u91ca\u884c\u4e3a\u3002", "result": "\u4ee3\u7801\u4e13\u7528\u6a21\u578b\uff08\u5982CodeLLaMA\u53d8\u4f53\uff09\u5728\u63a8\u7406\u548c\u8bed\u6cd5\u7cbe\u5ea6\u65b9\u9762\u8868\u73b0\u66f4\u5f3a\uff0c\u5373\u4f7f\u5728\u975e\u4ee3\u7801\u4efb\u52a1\u4e2d\u4e5f\u663e\u793a\u51fa\u53ef\u6d4b\u91cf\u7684\u6027\u80fd\u4f18\u52bf\uff0c\u800c\u901a\u7528\u6a21\u578b\uff08\u5982Mistral-7B\u548cLlama-3-8B\uff09\u8868\u73b0\u76f8\u5bf9\u8f83\u5f31\u3002", "conclusion": "\u4ee3\u7801\u4f18\u5316\u7684LLMs\u5728\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u8868\u660e\u4e13\u4e1a\u5316\u6a21\u578b\u5728\u7efc\u5408\u80fd\u529b\u8bc4\u4f30\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.04408", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04408", "abs": "https://arxiv.org/abs/2512.04408", "authors": ["Gautam Varma Datla", "Anudeep Vurity", "Tejaswani Dash", "Tazeem Ahmad", "Mohd Adnan", "Saima Rafi"], "title": "Executable Governance for AI: Translating Policies into Rules Using LLMs", "comment": "Accepted to AAAI-26 AI Governance Workshop (in-person presentation); 10 pages, 5 figures", "summary": "AI policy guidance is predominantly written as prose, which practitioners must first convert into executable rules before frameworks can evaluate or enforce them. This manual step is slow, error-prone, difficult to scale, and often delays the use of safeguards in real-world deployments. To address this gap, we present Policy-to-Tests (P2T), a framework that converts natural-language policy documents into normalized, machine-readable rules. The framework comprises a pipeline and a compact domain-specific language (DSL) that encodes hazards, scope, conditions, exceptions, and required evidence, yielding a canonical representation of extracted rules. To test the framework beyond a single policy, we apply it across general frameworks, sector guidance, and enterprise standards, extracting obligation-bearing clauses and converting them into executable rules. These AI-generated rules closely match strong human baselines on span-level and rule-level metrics, with robust inter-annotator agreement on the gold set. To evaluate downstream behavioral and safety impact, we add HIPAA-derived safeguards to a generative agent and compare it with an otherwise identical agent without guardrails. An LLM-based judge, aligned with gold-standard criteria, measures violation rates and robustness to obfuscated and compositional prompts. Detailed results are provided in the appendix. We release the codebase, DSL, prompts, and rule sets as open-source resources to enable reproducible evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86Policy-to-Tests (P2T)\u6846\u67b6\uff0c\u5c06\u81ea\u7136\u8bed\u8a00AI\u653f\u7b56\u81ea\u52a8\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u8bfb\u89c4\u5219\uff0c\u89e3\u51b3\u4e86\u4eba\u5de5\u8f6c\u6362\u7f13\u6162\u6613\u9519\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u653f\u7b56\u7c7b\u578b\u4e2d\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524dAI\u653f\u7b56\u6307\u5357\u591a\u4ee5\u6587\u672c\u5f62\u5f0f\u5b58\u5728\uff0c\u9700\u8981\u4eba\u5de5\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u89c4\u5219\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u7f13\u6162\u3001\u6613\u51fa\u9519\u3001\u96be\u4ee5\u6269\u5c55\uff0c\u963b\u788d\u4e86\u5b89\u5168\u63aa\u65bd\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u5305\u542b\u6d41\u6c34\u7ebf\u548c\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL)\u7684P2T\u6846\u67b6\uff0c\u80fd\u5c06\u653f\u7b56\u6587\u6863\u4e2d\u7684\u4e49\u52a1\u6761\u6b3e\u8f6c\u6362\u4e3a\u89c4\u8303\u5316\u89c4\u5219\uff0c\u6db5\u76d6\u5371\u5bb3\u3001\u8303\u56f4\u3001\u6761\u4ef6\u3001\u4f8b\u5916\u548c\u6240\u9700\u8bc1\u636e\u3002", "result": "\u5728\u901a\u7528\u6846\u67b6\u3001\u884c\u4e1a\u6307\u5357\u548c\u4f01\u4e1a\u6807\u51c6\u4e0a\u6d4b\u8bd5\uff0cAI\u751f\u6210\u7684\u89c4\u5219\u5728\u8de8\u5ea6\u548c\u89c4\u5219\u7ea7\u522b\u6307\u6807\u4e0a\u63a5\u8fd1\u4eba\u5de5\u57fa\u51c6\uff0c\u5e76\u5728HIPAA\u4fdd\u62a4\u5b9e\u9a8c\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u8fdd\u89c4\u7387\u3002", "conclusion": "P2T\u6846\u67b6\u80fd\u6709\u6548\u81ea\u52a8\u5316\u653f\u7b56\u5230\u89c4\u5219\u7684\u8f6c\u6362\uff0c\u63d0\u5347AI\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u6548\u7387\u548c\u4e00\u81f4\u6027\uff0c\u76f8\u5173\u8d44\u6e90\u5df2\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u53ef\u91cd\u590d\u8bc4\u4f30\u3002"}}
{"id": "2512.04680", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.04680", "abs": "https://arxiv.org/abs/2512.04680", "authors": ["Jialong Li", "Mingyue Zhang", "Nianyu Li", "Danny Weyns", "Zhi Jin", "Kenji Tei"], "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap", "comment": "Accepted by ACM Transactions on Autonomous and Adaptive Systems", "summary": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u81ea\u9002\u5e94\u7cfb\u7edf\u4e2d\u8fd0\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u6f5c\u5728\u4f18\u52bf\u548c\u6311\u6218\uff0c\u901a\u8fc7\u6587\u732e\u5206\u6790\u548c\u5206\u7c7b\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8def\u7ebf\u56fe\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u6570\u636e\u7406\u89e3\u548c\u903b\u8f91\u63a8\u7406\u65b9\u9762\u7684\u5353\u8d8a\u80fd\u529b\u4e0e\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u53cd\u9988\u5faa\u73af\u9700\u6c42\u9ad8\u5ea6\u5951\u5408\uff0c\u4f46\u5177\u4f53\u5e94\u7528\u4e2d\u7684\u5229\u5f0a\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u4ece\u56db\u4e2a\u4e0d\u540c\u7814\u7a76\u9886\u57df\u6536\u96c6\u3001\u7b5b\u9009\u5e76\u5206\u6790\u6587\u732e\uff0c\u5c06\u6f5c\u5728\u4f18\u52bf\u5206\u7c7b\u4e3a\u81ea\u9002\u5e94\u7cfb\u7edf\u81ea\u4e3b\u6027\u589e\u5f3a\u548c\u4eba\u673a\u4ea4\u4e92\u6539\u8fdb\u4e24\u5927\u65b9\u5411\u3002", "result": "\u8bba\u6587\u8bc6\u522b\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u81ea\u9002\u5e94\u7cfb\u7edf\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u6307\u51fa\u96c6\u6210\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u7814\u7a76\u6311\u6218\u548c\u6280\u672f\u77ed\u677f\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u5f3a\u8c03\u4e86\u89e3\u51b3\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u5c40\u9650\u6027\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u5efa\u8bae\u4e86\u7f13\u89e3\u7b56\u7565\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2512.04416", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04416", "abs": "https://arxiv.org/abs/2512.04416", "authors": ["Zhou Liu", "Zhaoyang Han", "Guochen Yan", "Hao Liang", "Bohan Zeng", "Xing Chen", "Yuanfeng Song", "Wentao Zhang"], "title": "GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows", "comment": "Equal contribution: Zhou Liu and Zhaoyang Han. Corresponding authors: Yuanfeng Song and Wentao Zhang", "summary": "Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel \"reversed-objective\" methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.", "AI": {"tldr": "GovBench\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u5f53\u524dAI\u6a21\u578b\u5728\u6570\u636e\u6cbb\u7406\u81ea\u52a8\u5316\u65b9\u9762\u7684\u4e0d\u8db3\uff0cDataGovAgent\u6846\u67b6\u901a\u8fc7\u89c4\u5212-\u6267\u884c-\u8bc4\u4f30\u67b6\u6784\u663e\u8457\u63d0\u5347\u590d\u6742\u4efb\u52a1\u6027\u80fd", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u6570\u636e\u79d1\u5b66\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u6570\u636e\u6cbb\u7406\u7279\u6709\u7684\u6570\u636e\u6b63\u786e\u6027\u548c\u8d28\u91cf\u4fdd\u8bc1\u6311\u6218", "method": "\u5f15\u5165GovBench\u57fa\u51c6\uff08150\u4e2a\u771f\u5b9e\u573a\u666f\u4efb\u52a1\uff09\uff0c\u91c7\u7528\u9006\u5411\u76ee\u6807\u65b9\u6cd5\u5408\u6210\u566a\u58f0\uff0c\u63d0\u51faDataGovAgent\u6846\u67b6\uff08\u89c4\u5212\u5668-\u6267\u884c\u5668-\u8bc4\u4f30\u5668\u67b6\u6784\uff09", "result": "DataGovAgent\u5c06\u590d\u6742\u4efb\u52a1\u5e73\u5747\u5206\u4ece39.7\u63d0\u5347\u81f354.9\uff0c\u8c03\u8bd5\u8fed\u4ee3\u51cf\u5c1177.9%", "conclusion": "\u4e13\u95e8\u7684\u6570\u636e\u6cbb\u7406\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u5f53\u524d\u6a21\u578b\u5728\u591a\u6b65\u5de5\u4f5c\u6d41\u548c\u9519\u8bef\u7ea0\u6b63\u65b9\u9762\u7684\u5c40\u9650\u6027"}}
{"id": "2512.04702", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04702", "abs": "https://arxiv.org/abs/2512.04702", "authors": ["Divyansh Pandey", "Vyakhya Gupta", "Prakhar Singhal", "Karthik Vaidhyanathan"], "title": "POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?", "comment": "Accepted as a short paper at SEAMS 2026", "summary": "The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal partnership between AI and adaptive systems, merging learning-driven intelligence with adaptive control for predictive and proactive behavior. Building on this foundation, we introduce POLARIS, a three-layer multi-agentic self-adaptation framework that advances beyond reactive adaptation. POLARIS integrates: (1) a low-latency Adapter layer for monitoring and safe execution, (2) a transparent Reasoning layer that generates and verifies plans using tool-aware, explainable agents, and (3) a Meta layer that records experiences and meta-learns improved adaptation policies over time. Through shared knowledge and predictive models, POLARIS handles uncertainty, learns from past actions, and evolves its strategies, enabling systems that anticipate change and maintain resilient, goal-directed behavior. Preliminary evaluation on two self-adaptive exemplars, SWIM and SWITCH, shows that POLARIS consistently outperforms state-of-the-art baselines. We argue this marks a shift toward Self-Adaptation 3.0, akin to Software 3.0: a paradigm where systems not only learn from their environment but also reason about and evolve their own adaptation processes, continuously improving to meet novel challenges.", "AI": {"tldr": "POLARIS\u6846\u67b6\u901a\u8fc7\u4e09\u5c42\u591a\u667a\u80fd\u4f53\u67b6\u6784\u5b9e\u73b0\u9884\u6d4b\u6027\u81ea\u9002\u5e94\uff0c\u8d85\u8d8a\u4f20\u7edf\u53cd\u5e94\u5f0f\u65b9\u6cd5\uff0c\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u7684\u89c4\u6a21\u3001\u590d\u6742\u6027\u548c\u81ea\u4e3b\u6027\u5e26\u6765\u524d\u6240\u672a\u6709\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4f20\u7edf\u81ea\u9002\u5e94\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u65b0\u60c5\u5883\u548c\u5206\u5e03\u5f0f\u534f\u8c03\u3002", "method": "\u63d0\u51faPOLARIS\u4e09\u5c42\u6846\u67b6\uff1a\u4f4e\u5ef6\u8fdf\u9002\u914d\u5c42\uff08\u76d1\u63a7\u4e0e\u5b89\u5168\u6267\u884c\uff09\u3001\u900f\u660e\u63a8\u7406\u5c42\uff08\u5de5\u5177\u611f\u77e5\u7684\u53ef\u89e3\u91ca\u667a\u80fd\u4f53\u751f\u6210\u9a8c\u8bc1\u8ba1\u5212\uff09\u3001\u5143\u5c42\uff08\u7ecf\u9a8c\u8bb0\u5f55\u4e0e\u5143\u5b66\u4e60\u6539\u8fdb\u7b56\u7565\uff09\u3002", "result": "\u5728SWIM\u548cSWITCH\u4e24\u4e2a\u81ea\u9002\u5e94\u7cfb\u7edf\u793a\u4f8b\u4e0a\u7684\u521d\u6b65\u8bc4\u4f30\u8868\u660e\uff0cPOLARIS\u6301\u7eed\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8fd9\u6807\u5fd7\u7740\u5411Self-Adaptation 3.0\u7684\u8f6c\u53d8\uff0c\u7cfb\u7edf\u4e0d\u4ec5\u80fd\u4ece\u73af\u5883\u4e2d\u5b66\u4e60\uff0c\u8fd8\u80fd\u63a8\u7406\u548c\u8fdb\u5316\u81ea\u8eab\u9002\u5e94\u8fc7\u7a0b\uff0c\u6301\u7eed\u6539\u8fdb\u4ee5\u5e94\u5bf9\u65b0\u6311\u6218\u3002"}}
{"id": "2512.04419", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04419", "abs": "https://arxiv.org/abs/2512.04419", "authors": ["Weiwei Wang", "Weijie Zou", "Jiyong Min"], "title": "Solving LLM Repetition Problem in Production: A Comprehensive Study of Multiple Solutions", "comment": null, "summary": "The repetition problem, where Large Language Models (LLMs) continuously generate repetitive content without proper termination, poses a critical challenge in production deployments, causing severe performance degradation and system stalling. This paper presents a comprehensive investigation and multiple practical solutions for the repetition problem encountered in real-world batch code interpretation tasks.\n  We identify three distinct repetition patterns: (1) business rule generation repetition, (2) method call relationship analysis repetition, and (3) PlantUML diagram syntax generation repetition. Through rigorous theoretical analysis based on Markov models, we establish that the root cause lies in greedy decoding's inability to escape repetitive loops, exacerbated by self-reinforcement effects.\n  Our comprehensive experimental evaluation demonstrates three viable solutions: (1) Beam Search decoding with early_stopping=True serves as a universal post-hoc mechanism that effectively resolves all three repetition patterns; (2) presence_penalty hyperparameter provides an effective solution specifically for BadCase 1; and (3) Direct Preference Optimization (DPO) fine-tuning offers a universal model-level solution for all three BadCases.\n  The primary value of this work lies in combining first-hand production experience with extensive experimental validation. Our main contributions include systematic theoretical analysis of repetition mechanisms, comprehensive evaluation of multiple solutions with task-specific applicability mapping, identification of early_stopping as the critical parameter for Beam Search effectiveness, and practical production-ready solutions validated in real deployment environments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9LLM\u5728\u6279\u91cf\u4ee3\u7801\u89e3\u91ca\u4efb\u52a1\u4e2d\u7684\u91cd\u590d\u5185\u5bb9\u751f\u6210\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u63d0\u51fa\u4e86\u4e09\u79cd\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u89e3\u51b3LLM\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u6301\u7eed\u751f\u6210\u91cd\u590d\u5185\u5bb9\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u548c\u7cfb\u7edf\u505c\u6ede\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff0c\u8bc6\u522b\u4e09\u79cd\u91cd\u590d\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u6ce2\u675f\u641c\u7d22\u3001\u5b58\u5728\u60e9\u7f5a\u548cDPO\u5fae\u8c03\u4e09\u79cd\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6ce2\u675f\u641c\u7d22\u53ef\u4f5c\u4e3a\u901a\u7528\u540e\u5904\u7406\u673a\u5236\u89e3\u51b3\u6240\u6709\u91cd\u590d\u6a21\u5f0f\uff1b\u5b58\u5728\u60e9\u7f5a\u4e13\u95e8\u89e3\u51b3\u4e1a\u52a1\u89c4\u5219\u751f\u6210\u91cd\u590d\uff1bDPO\u5fae\u8c03\u63d0\u4f9b\u6a21\u578b\u7ea7\u901a\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7ed3\u5408\u751f\u4ea7\u7ecf\u9a8c\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63d0\u51fa\u4e86\u7cfb\u7edf\u5316\u7684\u91cd\u590d\u673a\u5236\u7406\u8bba\u5206\u6790\u548c\u7ecf\u8fc7\u5b9e\u9645\u90e8\u7f72\u9a8c\u8bc1\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.04785", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.04785", "abs": "https://arxiv.org/abs/2512.04785", "authors": ["Eranga Bandara", "Amin Hass", "Ross Gore", "Sachin Shetty", "Ravi Mukkamala", "Safdar H. Bouk", "Xueping Liang", "Ng Wee Keong", "Kasun De Zoysa", "Aruna Withanage", "Nilaan Loganathan"], "title": "ASTRIDE: A Security Threat Modeling Platform for Agentic-AI Applications", "comment": null, "summary": "AI agent-based systems are becoming increasingly integral to modern software architectures, enabling autonomous decision-making, dynamic task execution, and multimodal interactions through large language models (LLMs). However, these systems introduce novel and evolving security challenges, including prompt injection attacks, context poisoning, model manipulation, and opaque agent-to-agent communication, that are not effectively captured by traditional threat modeling frameworks. In this paper, we introduce ASTRIDE, an automated threat modeling platform purpose-built for AI agent-based systems. ASTRIDE extends the classical STRIDE framework by introducing a new threat category, A for AI Agent-Specific Attacks, which encompasses emerging vulnerabilities such as prompt injection, unsafe tool invocation, and reasoning subversion, unique to agent-based applications. To automate threat modeling, ASTRIDE combines a consortium of fine-tuned vision-language models (VLMs) with the OpenAI-gpt-oss reasoning LLM to perform end-to-end analysis directly from visual agent architecture diagrams, such as data flow diagrams(DFDs). LLM agents orchestrate the end-to-end threat modeling automation process by coordinating interactions between the VLM consortium and the reasoning LLM. Our evaluations demonstrate that ASTRIDE provides accurate, scalable, and explainable threat modeling for next-generation intelligent systems. To the best of our knowledge, ASTRIDE is the first framework to both extend STRIDE with AI-specific threats and integrate fine-tuned VLMs with a reasoning LLM to fully automate diagram-driven threat modeling in AI agent-based applications.", "AI": {"tldr": "ASTRIDE\u662f\u4e00\u4e2a\u4e13\u4e3aAI\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u5a01\u80c1\u5efa\u6a21\u5e73\u53f0\uff0c\u6269\u5c55\u4e86STRIDE\u6846\u67b6\uff0c\u65b0\u589eAI\u7279\u5b9a\u5a01\u80c1\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4ece\u67b6\u6784\u56fe\u81ea\u52a8\u5206\u6790\u5a01\u80c1\u3002", "motivation": "AI\u667a\u80fd\u4f53\u7cfb\u7edf\u5e26\u6765\u4e86\u4f20\u7edf\u5a01\u80c1\u5efa\u6a21\u6846\u67b6\u65e0\u6cd5\u6709\u6548\u6355\u6349\u7684\u65b0\u578b\u5b89\u5168\u6311\u6218\uff0c\u5982\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u3001\u4e0a\u4e0b\u6587\u6c61\u67d3\u7b49\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9AI\u667a\u80fd\u4f53\u7684\u5a01\u80c1\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\u3002", "method": "ASTRIDE\u7ed3\u5408\u5fae\u8c03\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8054\u76df\u548cOpenAI GPT\u63a8\u7406\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u76f4\u63a5\u4ece\u89c6\u89c9\u67b6\u6784\u56fe\uff08\u5982\u6570\u636e\u6d41\u56fe\uff09\u8fdb\u884c\u7aef\u5230\u7aef\u5a01\u80c1\u5206\u6790\uff0cLLM\u667a\u80fd\u4f53\u534f\u8c03VLM\u8054\u76df\u4e0e\u63a8\u7406LLM\u7684\u4ea4\u4e92\u3002", "result": "\u8bc4\u4f30\u8868\u660eASTRIDE\u80fd\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u51c6\u786e\u3001\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u5a01\u80c1\u5efa\u6a21\u3002", "conclusion": "ASTRIDE\u662f\u9996\u4e2a\u540c\u65f6\u6269\u5c55STRIDE\u6846\u67b6\u4ee5\u6db5\u76d6AI\u7279\u5b9a\u5a01\u80c1\uff0c\u5e76\u96c6\u6210\u5fae\u8c03VLM\u4e0e\u63a8\u7406LLM\u5b9e\u73b0AI\u667a\u80fd\u4f53\u5e94\u7528\u4e2d\u56fe\u9a71\u52a8\u5a01\u80c1\u5efa\u6a21\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6846\u67b6\u3002"}}
{"id": "2512.05062", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05062", "abs": "https://arxiv.org/abs/2512.05062", "authors": ["Yue Zhang", "Uchswas Paul", "Marcelo d'Amorim", "Akond Rahman"], "title": "Configuration Defects in Kubernetes", "comment": null, "summary": "Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Kubernetes\u914d\u7f6e\u7f3a\u9677\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u67902260\u4e2a\u914d\u7f6e\u811a\u672c\u8bc6\u522b\u51fa15\u7c7b\u7f3a\u9677\uff0c\u8bc4\u4f30\u4e86\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684linter\u5de5\u5177\u68c0\u6d4b\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u53d1\u73b0\u7684\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "Kubernetes\u914d\u7f6e\u5bb9\u6613\u51fa\u9519\u4e14\u53ef\u80fd\u9020\u6210\u4e25\u91cd\u540e\u679c\uff0c\u9700\u8981\u7cfb\u7edf\u7814\u7a76\u914d\u7f6e\u7f3a\u9677\u4ee5\u5e2e\u52a9\u4ece\u4e1a\u8005\u68c0\u6d4b\u548c\u9884\u9632\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4ece\u5f00\u6e90\u4ed3\u5e93\u63d0\u53d62260\u4e2aKubernetes\u914d\u7f6e\u811a\u672c\u4e2d\u7684719\u4e2a\u7f3a\u9677\uff0c\u901a\u8fc7\u5b9a\u6027\u5206\u6790\u8bc6\u522b\u7f3a\u9677\u7c7b\u522b\uff0c\u8bc4\u4f308\u4e2a\u9759\u6001\u5206\u6790\u5de5\u5177\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u65b0\u7684linter\u5de5\u5177\u3002", "result": "\u8bc6\u522b\u51fa15\u7c7b\u914d\u7f6e\u7f3a\u9677\uff0c\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u68c0\u6d4b\u5176\u4e2d8\u7c7b\u3002\u65b0\u5f00\u53d1\u7684linter\u53d1\u73b0\u4e8626\u4e2a\u5148\u524d\u672a\u77e5\u7684\u7f3a\u9677\uff0819\u4e2a\u5df2\u4fee\u590d\uff09\uff0c\u5728\u6570\u636e\u5b57\u6bb5\u76f8\u5173\u7f3a\u9677\u68c0\u6d4b\u4e0a\u8868\u73b0\u51fa\u6700\u9ad8\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u3002", "conclusion": "\u4e3aKubernetes\u914d\u7f6e\u811a\u672c\u7684\u7f3a\u9677\u68c0\u6d4b\u548c\u4fee\u590d\u6280\u672f\u63d0\u4f9b\u4e86\u5177\u4f53\u5efa\u8bae\uff0c\u76f8\u5173\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2512.04442", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.04442", "abs": "https://arxiv.org/abs/2512.04442", "authors": ["Dilani Widanapathiranage", "Scott Barnett", "Stefanus Kurniawan", "Wannita Takerngsaksiri"], "title": "TaskEval: Synthesised Evaluation for Foundation-Model Tasks", "comment": "5 pages, 3 figures", "summary": "Hallucinations are a key concern when creating applications that rely on Foundation models (FMs). Understanding where and how these subtle failures occur in an application relies on evaluation methods known as \\textit{evals}. Prior work focuses on defining new eval methods or benchmark datasets for specific tasks. However, neither helps a software team with a task-specific FM application when there is no metric or dataset. The demand for both automated approaches and deep integration of human insight makes this a challenging problem. We address this gap by proposing an approach to synthesise a FM task-specific evaluator program that provides automation and a custom UI for capturing feedback. The core novelty of our approach lies in: (1) a task-agnostic meta-model that captures properties of any FM task, (2) an interaction protocol for efficient use of human feedback, and (3) an eval synthesiser that selects or generates an appropriate set of evals. We implement our approach in \\toolname and demonstrate the concept on two diverse FM tasks: chart data extraction and document question answering. A preliminary evaluation on the quality of our selected evals shows 93\\% and 90\\% accuracy respectively. Our research tackles a growing problem facing engineering teams, how to evaluate and review outputs from FM tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5408\u6210\u57fa\u7840\u6a21\u578b\u4efb\u52a1\u7279\u5b9a\u8bc4\u4f30\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4efb\u52a1\u65e0\u5173\u5143\u6a21\u578b\u3001\u4eba\u673a\u4ea4\u4e92\u534f\u8bae\u548c\u8bc4\u4f30\u5408\u6210\u5668\u6765\u89e3\u51b3\u7f3a\u4e4f\u8bc4\u4f30\u6307\u6807\u7684FM\u5e94\u7528\u8bc4\u4f30\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5b9a\u4e49\u65b0\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u4f46\u65e0\u6cd5\u89e3\u51b3\u8f6f\u4ef6\u56e2\u961f\u5728\u6ca1\u6709\u73b0\u6210\u6307\u6807\u6216\u6570\u636e\u96c6\u65f6\u8bc4\u4f30\u7279\u5b9aFM\u5e94\u7528\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4efb\u52a1\u65e0\u5173\u7684\u5143\u6a21\u578b\u6765\u6355\u6349FM\u4efb\u52a1\u7279\u6027\uff0c\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u4eba\u673a\u53cd\u9988\u4ea4\u4e92\u534f\u8bae\uff0c\u5e76\u521b\u5efa\u4e86\u8bc4\u4f30\u5408\u6210\u5668\u6765\u81ea\u52a8\u9009\u62e9\u6216\u751f\u6210\u5408\u9002\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "result": "\u5728\u56fe\u8868\u6570\u636e\u63d0\u53d6\u548c\u6587\u6863\u95ee\u7b54\u4e24\u4e2a\u4efb\u52a1\u4e0a\u7684\u521d\u6b65\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u9009\u8bc4\u4f30\u65b9\u6cd5\u7684\u51c6\u786e\u7387\u5206\u522b\u8fbe\u523093%\u548c90%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u89e3\u51b3\u5de5\u7a0b\u56e2\u961f\u9762\u4e34\u7684FM\u8f93\u51fa\u8bc4\u4f30\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u8bc4\u4f30\u4e0e\u4eba\u5de5\u53cd\u9988\u7684\u6df1\u5ea6\u878d\u5408\u3002"}}
{"id": "2512.04463", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.04463", "abs": "https://arxiv.org/abs/2512.04463", "authors": ["Price Allman", "Lian Thang", "Dre Simmons", "Salmon Riaz"], "title": "MARL Warehouse Robots", "comment": "6 pages, 4 tables. Project documentation: https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/", "summary": "We present a comparative study of multi-agent reinforcement learning (MARL) algorithms for cooperative warehouse robotics. We evaluate QMIX and IPPO on the Robotic Warehouse (RWARE) environment and a custom Unity 3D simulation. Our experiments reveal that QMIX's value decomposition significantly outperforms independent learning approaches (achieving 3.25 mean return vs. 0.38 for advanced IPPO), but requires extensive hyperparameter tuning -- particularly extended epsilon annealing (5M+ steps) for sparse reward discovery. We demonstrate successful deployment in Unity ML-Agents, achieving consistent package delivery after 1M training steps. While MARL shows promise for small-scale deployments (2-4 robots), significant scaling challenges remain. Code and analyses: https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/", "AI": {"tldr": "\u5bf9\u6bd4\u7814\u7a76QMIX\u548cIPPO\u4e24\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u4ed3\u5e93\u673a\u5668\u4eba\u534f\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0QMIX\u901a\u8fc7\u4ef7\u503c\u5206\u89e3\u663e\u8457\u4f18\u4e8e\u72ec\u7acb\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f46\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e0b\u9700\u8981\u5927\u91cf\u8d85\u53c2\u6570\u8c03\u4f18\u3002", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u73b0\u5b9e\u4e16\u754c\u4ed3\u5e93\u673a\u5668\u4eba\u534f\u540c\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u6bd4\u8f83\u4e0d\u540c\u7b97\u6cd5\u7684\u6027\u80fd\u5dee\u5f02\u3002", "method": "\u5728Robotic Warehouse (RWARE)\u73af\u5883\u548c\u81ea\u5b9a\u4e49Unity 3D\u4eff\u771f\u4e2d\u8bc4\u4f30QMIX\u548cIPPO\u7b97\u6cd5\uff0c\u5206\u6790\u8d85\u53c2\u6570\u8c03\u4f18\u9700\u6c42\u3002", "result": "QMIX\u5e73\u5747\u56de\u62a53.25\u663e\u8457\u4f18\u4e8eIPPO\u76840.38\uff0c\u4f46\u5728\u7a00\u758f\u5956\u52b1\u73af\u5883\u4e0b\u9700\u8981500\u4e07\u6b65\u4ee5\u4e0a\u7684epsilon\u9000\u706b\u8bad\u7ec3\uff1b\u5728Unity ML-Agents\u4e2d\u7ecf\u8fc7100\u4e07\u6b65\u8bad\u7ec3\u540e\u5b9e\u73b0\u7a33\u5b9a\u5305\u88f9\u914d\u9001\u3002", "conclusion": "MARL\u5728\u5c0f\u89c4\u6a21\u90e8\u7f72\uff082-4\u4e2a\u673a\u5668\u4eba\uff09\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4ecd\u9762\u4e34\u663e\u8457\u7684\u6269\u5c55\u6027\u6311\u6218\u3002"}}
{"id": "2512.04469", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.04469", "abs": "https://arxiv.org/abs/2512.04469", "authors": ["Philip Stephens", "Emmanuel Salawu"], "title": "Mathematical Framing for Different Agent Strategies", "comment": null, "summary": "We introduce a unified mathematical and probabilistic framework for understanding and comparing diverse AI agent strategies. We bridge the gap between high-level agent design concepts, such as ReAct, multi-agent systems, and control flows, and a rigorous mathematical formulation. Our approach frames agentic processes as a chain of probabilities, enabling a detailed analysis of how different strategies manipulate these probabilities to achieve desired outcomes. Our framework provides a common language for discussing the trade-offs inherent in various agent architectures. One of our many key contributions is the introduction of the \"Degrees of Freedom\" concept, which intuitively differentiates the optimizable levers available for each approach, thereby guiding the selection of appropriate strategies for specific tasks. This work aims to enhance the clarity and precision in designing and evaluating AI agents, offering insights into maximizing the probability of successful actions within complex agentic systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6982\u7387\u6846\u67b6\u6765\u5206\u6790\u6bd4\u8f83\u4e0d\u540cAI\u667a\u80fd\u4f53\u7b56\u7565\uff0c\u5f15\u5165\u81ea\u7531\u5ea6\u6982\u5ff5\u5e2e\u52a9\u9009\u62e9\u5408\u9002\u7684\u667a\u80fd\u4f53\u67b6\u6784\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u6765\u7406\u89e3\u4e0d\u540cAI\u667a\u80fd\u4f53\u7b56\u7565\uff08\u5982ReAct\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7b49\uff09\u4e4b\u95f4\u7684\u672c\u8d28\u8054\u7cfb\u548c\u5dee\u5f02\u3002", "method": "\u5efa\u7acb\u6982\u7387\u94fe\u6a21\u578b\u6765\u5206\u6790\u667a\u80fd\u4f53\u8fc7\u7a0b\uff0c\u5c06\u5404\u79cd\u7b56\u7565\u8868\u793a\u4e3a\u5bf9\u6982\u7387\u5206\u5e03\u7684\u4e0d\u540c\u64cd\u4f5c\u65b9\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u80fd\u591f\u91cf\u5316\u5206\u6790\u4e0d\u540c\u667a\u80fd\u4f53\u7b56\u7565\u5982\u4f55\u64cd\u7eb5\u6982\u7387\u6765\u5b9e\u73b0\u76ee\u6807\uff0c\u5e76\u63d0\u4f9b\u4e86\u9009\u62e9\u7b56\u7565\u7684\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3aAI\u667a\u80fd\u4f53\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u6e05\u6670\u7cbe\u786e\u7684\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u6700\u5927\u5316\u6210\u529f\u884c\u52a8\u7684\u6982\u7387\u3002"}}
{"id": "2512.04500", "categories": ["cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.04500", "abs": "https://arxiv.org/abs/2512.04500", "authors": ["Edervaldo Melo"], "title": "A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework", "comment": "6 pages, 1 figure. First version", "summary": "This paper presents the Nemosine Framework, a modular cognitive architecture designed to support assisted reasoning, structured thinking, and systematic analysis. The model operates through functional cognitive modules (\"personas\") that organize tasks such as planning, evaluation, cross-checking, and narrative synthesis. The framework combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for assisted problem-solving and decision support. The architecture is documented through formal specification, internal consistency criteria, and reproducible structural components. The goal is to provide a clear conceptual basis for future computational implementations and to contribute to the study of symbolic-modular architectures for reasoning.", "AI": {"tldr": "Nemosine Framework\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u529f\u80fd\u8ba4\u77e5\u6a21\u5757\u652f\u6301\u8f85\u52a9\u63a8\u7406\u3001\u7ed3\u6784\u5316\u601d\u7ef4\u548c\u7cfb\u7edf\u5206\u6790\uff0c\u7ed3\u5408\u5143\u8ba4\u77e5\u3001\u5206\u5e03\u5f0f\u8ba4\u77e5\u548c\u6a21\u5757\u5316\u8ba4\u77e5\u7cfb\u7edf\u539f\u7406\u3002", "motivation": "\u65e8\u5728\u4e3a\u8f85\u52a9\u95ee\u9898\u89e3\u51b3\u548c\u51b3\u7b56\u652f\u6301\u63d0\u4f9b\u64cd\u4f5c\u7ed3\u6784\uff0c\u4e3a\u672a\u6765\u7684\u8ba1\u7b97\u5b9e\u73b0\u5960\u5b9a\u6e05\u6670\u7684\u6982\u5ff5\u57fa\u7840\uff0c\u5e76\u4fc3\u8fdb\u7b26\u53f7\u6a21\u5757\u5316\u63a8\u7406\u67b6\u6784\u7684\u7814\u7a76\u3002", "method": "\u6a21\u578b\u901a\u8fc7\u529f\u80fd\u8ba4\u77e5\u6a21\u5757\uff08\u201c\u89d2\u8272\u201d\uff09\u8fd0\u4f5c\uff0c\u7ec4\u7ec7\u89c4\u5212\u3001\u8bc4\u4f30\u3001\u4ea4\u53c9\u6838\u5bf9\u548c\u53d9\u4e8b\u5408\u6210\u7b49\u4efb\u52a1\uff0c\u91c7\u7528\u5f62\u5f0f\u5316\u89c4\u8303\u3001\u5185\u90e8\u4e00\u81f4\u6027\u6807\u51c6\u548c\u53ef\u590d\u73b0\u7ed3\u6784\u7ec4\u4ef6\u8fdb\u884c\u67b6\u6784\u8bb0\u5f55\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u8ba4\u77e5\u67b6\u6784\u6846\u67b6\uff0c\u5177\u5907\u660e\u786e\u7684\u89c4\u8303\u6807\u51c6\u548c\u53ef\u590d\u73b0\u7ec4\u4ef6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8ba1\u7b97\u5b9e\u73b0\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u7b26\u53f7\u6a21\u5757\u5316\u63a8\u7406\u67b6\u6784\u7684\u7814\u7a76\u548c\u53d1\u5c55\u3002"}}
{"id": "2512.04513", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04513", "abs": "https://arxiv.org/abs/2512.04513", "authors": ["Yu-Wei Zhan", "Xin Wang", "Pengzhe Mao", "Tongtong Feng", "Ren Wang", "Wenwu Zhu"], "title": "BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models", "comment": null, "summary": "Building generalist embodied agents requires a unified system that can interpret multimodal goals, model environment dynamics, and execute reliable actions across diverse real-world tasks. Multimodal large language models (MLLMs) offer strong semantic priors and cross-modal generalization, while world models (WMs) provide actionable latent dynamics for prediction and control. Their combination holds promise for open-ended embodied intelligence, yet introduces two key challenges: (1) establishing a tight coupling between the semantic intent from MLLMs and the dynamic state representations within the WM's latent space, and (2) achieving task-aware adaptability that supports multi-task learning and cross-environment generalization. To address these limitations, we propose BiTAgent, a task-aware dynamic joint framework that enables bidirectional coupling between MLLMs and WMs. BiTAgent establishes two complementary pathways: a forward path that injects MLLM representations into the WM's latent space for semantically guided imagination, and a backward path where WM-generated feedback refines the MLLM's semantic space via dense text-conditioned rewards. This bidirectional interaction is realized through three synergistic components: Task-Aware Dynamic Joint Learning, Task-Aware Behavior Learning, and MLLM-WM Joint Optimization, which together harmonize semantic reasoning and dynamic prediction. Extensive experiments across multi-task and cross-environment settings demonstrate superior stability and generalization over state-of-the-art baselines, marking a step toward open-ended embodied learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faBiTAgent\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u5411\u8026\u5408\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e16\u754c\u6a21\u578b\uff0c\u89e3\u51b3\u5f00\u653e\u4e16\u754c\u5177\u8eab\u667a\u80fd\u4e2d\u7684\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u6001\u72b6\u6001\u8868\u793a\u5bf9\u9f50\u95ee\u9898\uff0c\u5728\u591a\u4efb\u52a1\u548c\u8de8\u73af\u5883\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u6784\u5efa\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u9700\u8981\u7edf\u4e00\u7cfb\u7edf\u6765\u89e3\u8bfb\u591a\u6a21\u6001\u76ee\u6807\u3001\u5efa\u6a21\u73af\u5883\u52a8\u6001\u5e76\u6267\u884c\u53ef\u9760\u52a8\u4f5c\u3002MLLMs\u63d0\u4f9b\u8bed\u4e49\u5148\u9a8c\uff0cWMs\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6f5c\u5728\u52a8\u6001\uff0c\u4f46\u4e8c\u8005\u7684\u7ed3\u5408\u9762\u4e34\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u6001\u72b6\u6001\u8868\u793a\u7d27\u5bc6\u8026\u5408\u3001\u4efb\u52a1\u611f\u77e5\u9002\u5e94\u6027\u4e24\u5927\u6311\u6218\u3002", "method": "BiTAgent\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u534f\u540c\u7ec4\u4ef6\uff1a\u4efb\u52a1\u611f\u77e5\u52a8\u6001\u8054\u5408\u5b66\u4e60\uff08\u5efa\u7acbMLLM\u8868\u793a\u5230WM\u6f5c\u5728\u7a7a\u95f4\u7684\u524d\u5411\u8def\u5f84\uff09\u3001\u4efb\u52a1\u611f\u77e5\u884c\u4e3a\u5b66\u4e60\uff08WM\u53cd\u9988\u901a\u8fc7\u5bc6\u96c6\u6587\u672c\u6761\u4ef6\u5956\u52b1\u4f18\u5316MLLM\u8bed\u4e49\u7a7a\u95f4\u7684\u53cd\u5411\u8def\u5f84\uff09\u3001MLLM-WM\u8054\u5408\u4f18\u5316\uff0c\u5b9e\u73b0\u8bed\u4e49\u63a8\u7406\u4e0e\u52a8\u6001\u9884\u6d4b\u7684\u534f\u8c03\u3002", "result": "\u5728\u591a\u4efb\u52a1\u548c\u8de8\u73af\u5883\u8bbe\u7f6e\u4e0b\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cBiTAgent\u5728\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u6027\u4e0a\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "BiTAgent\u901a\u8fc7\u53cc\u5411\u8026\u5408\u673a\u5236\u63a8\u8fdb\u4e86\u5f00\u653e\u4e16\u754c\u5177\u8eab\u5b66\u4e60\uff0c\u4e3a\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.04529", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04529", "abs": "https://arxiv.org/abs/2512.04529", "authors": ["Xin Liang", "Xiang Zhang", "Yiwei Xu", "Siqi Sun", "Chenyu You"], "title": "SlideGen: Collaborative Multimodal Agents for Scientific Slide Generation", "comment": null, "summary": "Generating academic slides from scientific papers is a challenging multimodal reasoning task that requires both long context understanding and deliberate visual planning. Existing approaches largely reduce it to text only summarization, overlooking the visual component and design intensive nature of slide creation. In this paper we introduce SlideGen, an agentic, modular, and visual in the loop framework for scientific paper to slide generation. SlideGen orchestrates a group of vision language agents that reason collaboratively over the document structure and semantics, producing editable PPTX slides with logical flow and compelling visual presentation. By integrating coordinated outlining, mapping, arrangement, note synthesis, and iterative refinement, our system consistently delivers slides of expert level quality. Across diverse benchmarks and strong baselines, SlideGen outperforms existing methods in visual quality, content faithfulness, and readability, positioning it as the new state of the art in automated slide generation. Our work establishes a foundation for design aware multimodal slide generation, demonstrating how agentic collaboration can bridge understanding and presentation in complex multimodal reasoning tasks.", "AI": {"tldr": "SlideGen\u662f\u4e00\u4e2a\u667a\u80fd\u3001\u6a21\u5757\u5316\u3001\u89c6\u89c9\u5728\u73af\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u5c06\u79d1\u5b66\u8bba\u6587\u81ea\u52a8\u8f6c\u6362\u4e3a\u9ad8\u8d28\u91cfPPT\u5e7b\u706f\u7247\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5927\u591a\u5c06\u5e7b\u706f\u7247\u751f\u6210\u7b80\u5316\u4e3a\u6587\u672c\u6458\u8981\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u5e7b\u706f\u7247\u521b\u5efa\u7684\u89c6\u89c9\u7ec4\u4ef6\u548c\u8bbe\u8ba1\u5bc6\u96c6\u578b\u7279\u6027\u3002", "method": "SlideGen\u534f\u8c03\u4e00\u7ec4\u89c6\u89c9\u8bed\u8a00\u667a\u80fd\u4f53\uff0c\u534f\u4f5c\u63a8\u7406\u6587\u6863\u7ed3\u6784\u548c\u8bed\u4e49\uff0c\u901a\u8fc7\u534f\u8c03\u7684\u5927\u7eb2\u521b\u5efa\u3001\u6620\u5c04\u3001\u5e03\u5c40\u5b89\u6392\u3001\u7b14\u8bb0\u5408\u6210\u548c\u8fed\u4ee3\u4f18\u5316\u6765\u751f\u6210\u53ef\u7f16\u8f91\u7684PPTX\u5e7b\u706f\u7247\u3002", "result": "\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f3a\u57fa\u7ebf\u5bf9\u6bd4\u4e2d\uff0cSlideGen\u5728\u89c6\u89c9\u8d28\u91cf\u3001\u5185\u5bb9\u5fe0\u5b9e\u5ea6\u548c\u53ef\u8bfb\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u611f\u77e5\u7684\u591a\u6a21\u6001\u5e7b\u706f\u7247\u751f\u6210\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u667a\u80fd\u4f53\u534f\u4f5c\u5982\u4f55\u5728\u590d\u6742\u591a\u6a21\u6001\u63a8\u7406\u4efb\u52a1\u4e2d\u5f25\u5408\u7406\u89e3\u4e0e\u5448\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2512.04598", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04598", "abs": "https://arxiv.org/abs/2512.04598", "authors": ["Michael Klenk"], "title": "The Ethics of Generative AI", "comment": "Draft version to appear as a chapter in the Encyclopedia of Applied Ethics, 3rd Edition, edited by Ruth Chadwick", "summary": "This chapter discusses the ethics of generative AI. It provides a technical primer to show how generative AI affords experiencing technology as if it were human, and this affordance provides a fruitful focus for the philosophical ethics of generative AI. It then shows how generative AI can both aggravate and alleviate familiar ethical concerns in AI ethics, including responsibility, privacy, bias and fairness, and forms of alienation and exploitation. Finally, the chapter examines ethical questions that arise specifically from generative AI's mimetic generativity, such as debates about authorship and credit, the emergence of as-if social relationships with machines, and new forms of influence, persuasion, and manipulation.", "AI": {"tldr": "\u672c\u7ae0\u8ba8\u8bba\u751f\u6210\u5f0fAI\u7684\u4f26\u7406\u95ee\u9898\uff0c\u5206\u6790\u5176\u6280\u672f\u7279\u6027\u5982\u4f55\u5f71\u54cd\u4f26\u7406\u8003\u91cf\uff0c\u63a2\u8ba8\u5176\u52a0\u5267\u6216\u7f13\u89e3\u4f20\u7edfAI\u4f26\u7406\u95ee\u9898\u7684\u53cc\u91cd\u4f5c\u7528\uff0c\u5e76\u7814\u7a76\u7531\u5176\u6a21\u4eff\u751f\u6210\u80fd\u529b\u5f15\u53d1\u7684\u7279\u6b8a\u4f26\u7406\u6311\u6218\u3002", "motivation": "\u751f\u6210\u5f0fAI\u80fd\u591f\u6a21\u62df\u4eba\u7c7b\u4f53\u9a8c\uff0c\u8fd9\u4e3a\u54f2\u5b66\u4f26\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u7126\u70b9\uff0c\u9700\u8981\u7cfb\u7edf\u5206\u6790\u5176\u4e0e\u4f20\u7edfAI\u4f26\u7406\u7684\u5f02\u540c\u53ca\u7279\u6709\u4f26\u7406\u95ee\u9898\u3002", "method": "\u63d0\u4f9b\u6280\u672f\u5165\u95e8\u4ecb\u7ecd\uff0c\u5206\u6790\u751f\u6210\u5f0fAI\u5982\u4f55\u5f71\u54cd\u8d23\u4efb\u3001\u9690\u79c1\u3001\u504f\u89c1\u7b49\u4f20\u7edf\u4f26\u7406\u95ee\u9898\uff0c\u5e76\u8003\u5bdf\u7531\u5176\u6a21\u4eff\u80fd\u529b\u5f15\u53d1\u7684\u4f5c\u8005\u6743\u3001\u4eba\u673a\u5173\u7cfb\u7b49\u65b0\u95ee\u9898\u3002", "result": "\u751f\u6210\u5f0fAI\u65e2\u53ef\u80fd\u52a0\u5267\u8d23\u4efb\u5f52\u5c5e\u6a21\u7cca\u3001\u9690\u79c1\u4fb5\u72af\u7b49\u73b0\u6709\u4f26\u7406\u95ee\u9898\uff0c\u4e5f\u53ef\u80fd\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u7f13\u89e3\u90e8\u5206\u504f\u89c1\uff1b\u540c\u65f6\u50ac\u751f\u4e86\u5173\u4e8e\u4f5c\u54c1\u7f72\u540d\u3001\u4eba\u673a\u793e\u4ea4\u5173\u7cfb\u7b49\u65b0\u4f26\u7406\u4e89\u8bae\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u7684\u4f26\u7406\u7814\u7a76\u9700\u517c\u987e\u4f20\u7edf\u6846\u67b6\u4e0e\u65b0\u5174\u6311\u6218\uff0c\u5176\u62df\u4eba\u5316\u7279\u6027\u8981\u6c42\u4f26\u7406\u89c4\u8303\u66f4\u5177\u524d\u77bb\u6027\uff0c\u4ee5\u5e94\u5bf9\u6280\u672f\u5feb\u901f\u53d1\u5c55\u5e26\u6765\u7684\u9053\u5fb7\u56f0\u5883\u3002"}}
{"id": "2512.04632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04632", "abs": "https://arxiv.org/abs/2512.04632", "authors": ["Thibaut Boissin", "Thomas Massena", "Franck Mamalet", "Mathieu Serrurier"], "title": "Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning", "comment": null, "summary": "Orthogonality-based optimizers, such as Muon, have recently shown strong performance across large-scale training and community-driven efficiency challenges. However, these methods rely on a costly gradient orthogonalization step. Even efficient iterative approximations such as Newton-Schulz remain expensive, typically requiring dozens of matrix multiplications to converge. We introduce a preconditioning procedure that accelerates Newton-Schulz convergence and reduces its computational cost. We evaluate its impact and show that the overhead of our preconditioning can be made negligible. Furthermore, the faster convergence it enables allows us to remove one iteration out of the usual five without degrading approximation quality. Our publicly available implementation achieves up to a 2.8x speedup in the Newton-Schulz approximation. We also show that this has a direct impact on end-to-end training runtime with 5-10% improvement in realistic training scenarios across two efficiency-focused tasks. On challenging language or vision tasks, we validate that our method maintains equal or superior model performance while improving runtime. Crucially, these improvements require no hyperparameter tuning and can be adopted as a simple drop-in replacement. Our code is publicly available on github.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u9884\u6761\u4ef6\u52a0\u901f\u65b9\u6cd5\u4ee5\u51cf\u5c11\u725b\u987f-\u8212\u5c14\u8328\u68af\u5ea6\u6b63\u4ea4\u5316\u4f18\u5316\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u73b02.8\u500d\u52a0\u901f\u548c5-10%\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u63d0\u5347\uff0c\u4e14\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u3002", "motivation": "\u73b0\u6709\u6b63\u4ea4\u5316\u4f18\u5316\u5668\uff08\u5982Muon\uff09\u4f9d\u8d56\u6602\u8d35\u7684\u68af\u5ea6\u6b63\u4ea4\u5316\u6b65\u9aa4\uff0c\u5373\u4f7f\u9ad8\u6548\u7684\u725b\u987f-\u8212\u5c14\u8328\u8fed\u4ee3\u8fd1\u4f3c\u4e5f\u9700\u8981\u6570\u5341\u6b21\u77e9\u9635\u4e58\u6cd5\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5f15\u5165\u9884\u6761\u4ef6\u5904\u7406\u7a0b\u5e8f\u52a0\u901f\u725b\u987f-\u8212\u5c14\u8328\u6536\u655b\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\uff0c\u5e76\u53ef\u51cf\u5c11\u4e00\u6b21\u8fed\u4ee3\u800c\u4e0d\u964d\u4f4e\u8fd1\u4f3c\u8d28\u91cf\u3002", "result": "\u516c\u5f00\u5b9e\u73b0\u5b9e\u73b0\u725b\u987f-\u8212\u5c14\u8328\u8fd1\u4f3c2.8\u500d\u52a0\u901f\uff0c\u5728\u771f\u5b9e\u8bad\u7ec3\u573a\u666f\u4e2d\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u63d0\u53475-10%\uff0c\u6a21\u578b\u6027\u80fd\u4fdd\u6301\u5e73\u7b49\u6216\u66f4\u4f18\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u8d85\u53c2\u6570\u8c03\u6574\u5373\u53ef\u4f5c\u4e3a\u7b80\u5355\u66ff\u4ee3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u4e14\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2512.04691", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.04691", "abs": "https://arxiv.org/abs/2512.04691", "authors": ["Jae Hee Lee", "Anne Lauscher", "Stefano V. Albrecht"], "title": "Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective", "comment": "Accepted to LaMAS 2026@AAAI'26 (https://sites.google.com/view/lamas2026)", "summary": "Large language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u673a\u5236\u53ef\u89e3\u91ca\u6027\u7814\u7a76MALMs\u4f26\u7406\u884c\u4e3a\u7684\u8bae\u7a0b\u6846\u67b6", "motivation": "LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u867d\u589e\u5f3a\u80fd\u529b\u4f46\u5f15\u53d1\u4f26\u7406\u6311\u6218\u9700\u7cfb\u7edf\u6027\u7814\u7a76", "method": "\u673a\u5236\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u7ed3\u5408\u8bc4\u4f30\u6846\u67b6\u4e0e\u53c2\u6570\u9ad8\u6548\u5bf9\u9f50\u6280\u672f", "result": "\u786e\u7acb\u4e2a\u4f53/\u4ea4\u4e92/\u7cfb\u7edf\u4e09\u7ea7\u8bc4\u4f30\u6307\u6807\u4e0e\u884c\u4e3a\u5e72\u9884\u8def\u5f84", "conclusion": "\u9700\u8de8\u5b66\u79d1\u5408\u4f5c\u5b9e\u73b0\u53ef\u4fe1MALMs\u5e76\u5efa\u7acb\u76f8\u5e94\u4f26\u7406\u89c4\u8303\u4f53\u7cfb"}}
{"id": "2512.04714", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.04714", "abs": "https://arxiv.org/abs/2512.04714", "authors": ["Andrew Paterson", "Carl Sanders"], "title": "Playing the Player: A Heuristic Framework for Adaptive Poker AI", "comment": "49 pages, 39 figures. White Paper by Spiderdime Systems", "summary": "For years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick's architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPatrick\u7684\u521b\u65b0\u6251\u514bAI\uff0c\u6311\u6218\u4e86\u5bf9\u65e0\u61c8\u53ef\u51fbAI\u7684\u8ffd\u6c42\uff0c\u5f3a\u8c03\u901a\u8fc7\u6700\u5927\u5316\u5229\u7528\u4eba\u7c7b\u5bf9\u624b\u7684\u5f31\u70b9\u6765\u83b7\u80dc\u3002", "motivation": "\u4f20\u7edf\u6251\u514bAI\u7814\u7a76\u96c6\u4e2d\u4e8e\u5f00\u53d1\u65e0\u61c8\u53ef\u51fb\u7684\u6c42\u89e3\u5668\uff0c\u4f46\u672c\u6587\u8ba4\u4e3a\u771f\u6b63\u7684\u6311\u6218\u5728\u4e8e\u7406\u89e3\u5e76\u5229\u7528\u4eba\u7c7b\u5bf9\u624b\u7684\u5fc3\u7406\u548c\u8ba4\u77e5\u7f3a\u9677\u3002", "method": "Patrick AI\u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9884\u6d4b\u951a\u5b9a\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u5206\u6790\u548c\u653b\u51fb\u4eba\u7c7b\u5bf9\u624b\u7684\u975e\u7406\u6027\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u572864,267\u624b\u724c\u7684\u8bd5\u9a8c\u4e2d\uff0cPatrick AI\u8868\u73b0\u51fa\u4e86\u76c8\u5229\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5229\u7528\u5bf9\u624b\u5f31\u70b9\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\u8ffd\u6c42\u65e0\u61c8\u53ef\u51fb\u7684AI\u662f\u4e00\u79cd\u8bef\u5bfc\uff0c\u771f\u6b63\u7684\u6311\u6218\u5728\u4e8e\u521b\u9020\u80fd\u591f\u638c\u63e1\u4eba\u7c7b\u4e0d\u5b8c\u7f8e\u827a\u672f\u7684\u4eba\u5de5\u667a\u80fd\u3002"}}
{"id": "2512.04797", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.04797", "abs": "https://arxiv.org/abs/2512.04797", "authors": ["SIMA team", "Adrian Bolton", "Alexander Lerchner", "Alexandra Cordell", "Alexandre Moufarek", "Andrew Bolt", "Andrew Lampinen", "Anna Mitenkova", "Arne Olav Hallingstad", "Bojan Vujatovic", "Bonnie Li", "Cong Lu", "Daan Wierstra", "Daniel P. Sawyer", "Daniel Slater", "David Reichert", "Davide Vercelli", "Demis Hassabis", "Drew A. Hudson", "Duncan Williams", "Ed Hirst", "Fabio Pardo", "Felix Hill", "Frederic Besse", "Hannah Openshaw", "Harris Chan", "Hubert Soyer", "Jane X. Wang", "Jeff Clune", "John Agapiou", "John Reid", "Joseph Marino", "Junkyung Kim", "Karol Gregor", "Kaustubh Sridhar", "Kay McKinney", "Laura Kampis", "Lei M. Zhang", "Loic Matthey", "Luyu Wang", "Maria Abi Raad", "Maria Loks-Thompson", "Martin Engelcke", "Matija Kecman", "Matthew Jackson", "Maxime Gazeau", "Ollie Purkiss", "Oscar Knagg", "Peter Stys", "Piermaria Mendolicchio", "Raia Hadsell", "Rosemary Ke", "Ryan Faulkner", "Sarah Chakera", "Satinder Singh Baveja", "Shane Legg", "Sheleem Kashem", "Tayfun Terzi", "Thomas Keck", "Tim Harley", "Tim Scholtes", "Tyson Roberts", "Volodymyr Mnih", "Yulan Liu", "Zhengdong Wang", "Zoubin Ghahramani"], "title": "SIMA 2: A Generalist Embodied Agent for Virtual Worlds", "comment": null, "summary": "We introduce SIMA 2, a generalist embodied agent that understands and acts in a wide variety of 3D virtual worlds. Built upon a Gemini foundation model, SIMA 2 represents a significant step toward active, goal-directed interaction within an embodied environment. Unlike prior work (e.g., SIMA 1) limited to simple language commands, SIMA 2 acts as an interactive partner, capable of reasoning about high-level goals, conversing with the user, and handling complex instructions given through language and images. Across a diverse portfolio of games, SIMA 2 substantially closes the gap with human performance and demonstrates robust generalization to previously unseen environments, all while retaining the base model's core reasoning capabilities. Furthermore, we demonstrate a capacity for open-ended self-improvement: by leveraging Gemini to generate tasks and provide rewards, SIMA 2 can autonomously learn new skills from scratch in a new environment. This work validates a path toward creating versatile and continuously learning agents for both virtual and, eventually, physical worlds.", "AI": {"tldr": "SIMA 2\u662f\u4e00\u4e2a\u57fa\u4e8eGemini\u57fa\u7840\u6a21\u578b\u6784\u5efa\u7684\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u5728\u591a\u79cd3D\u865a\u62df\u4e16\u754c\u4e2d\u7406\u89e3\u548c\u884c\u52a8\uff0c\u652f\u6301\u590d\u6742\u8bed\u8a00\u548c\u56fe\u50cf\u6307\u4ee4\u7684\u7406\u89e3\u3001\u63a8\u7406\u548c\u4ea4\u4e92\uff0c\u5927\u5e45\u7f29\u5c0f\u4e86\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u5dee\u8ddd\uff0c\u5e76\u5177\u5907\u81ea\u4e3b\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u5177\u8eab\u667a\u80fd\u4f53\uff08\u5982SIMA 1\uff09\u4ec5\u80fd\u5904\u7406\u7b80\u5355\u8bed\u8a00\u6307\u4ee4\u7684\u5c40\u9650\u6027\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u4f5c\u4e3a\u4ea4\u4e92\u4f19\u4f34\u3001\u7406\u89e3\u9ad8\u5c42\u6b21\u76ee\u6807\u3001\u5904\u7406\u590d\u6742\u591a\u6a21\u6001\u6307\u4ee4\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u63a8\u52a8\u865a\u62df\u548c\u7269\u7406\u4e16\u754c\u4e2d\u6301\u7eed\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8eGemini\u57fa\u7840\u6a21\u578b\u6784\u5efaSIMA 2\uff0c\u4f7f\u5176\u80fd\u591f\u901a\u8fc7\u8bed\u8a00\u548c\u56fe\u50cf\u63a5\u6536\u6307\u4ee4\uff0c\u8fdb\u884c\u76ee\u6807\u63a8\u7406\u548c\u7528\u6237\u5bf9\u8bdd\uff1b\u5229\u7528Gemini\u751f\u6210\u4efb\u52a1\u548c\u5956\u52b1\uff0c\u5b9e\u73b0\u667a\u80fd\u4f53\u5728\u65b0\u73af\u5883\u4e2d\u4ece\u96f6\u5f00\u59cb\u81ea\u4e3b\u5b66\u4e60\u65b0\u6280\u80fd\u3002", "result": "\u5728\u591a\u79cd\u6e38\u620f\u6d4b\u8bd5\u4e2d\uff0cSIMA 2\u663e\u8457\u7f29\u5c0f\u4e86\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u5dee\u8ddd\uff0c\u5c55\u793a\u4e86\u5728\u672a\u89c1\u8fc7\u7684\u73af\u5883\u4e2d\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u57fa\u7840\u6a21\u578b\u7684\u6838\u5fc3\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "SIMA 2\u9a8c\u8bc1\u4e86\u521b\u5efa\u591a\u529f\u80fd\u3001\u6301\u7eed\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u53ef\u884c\u8def\u5f84\uff0c\u4e3a\u672a\u6765\u5728\u865a\u62df\u548c\u7269\u7406\u4e16\u754c\u4e2d\u90e8\u7f72\u901a\u7528\u5177\u8eab\u667a\u80fd\u4f53\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.04829", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04829", "abs": "https://arxiv.org/abs/2512.04829", "authors": ["Rasul Tutunov", "Alexandre Maraval", "Antoine Grosnit", "Xihan Li", "Jun Wang", "Haitham Bou-Ammar"], "title": "Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing", "comment": null, "summary": "Sphere packing, Hilbert's eighteenth problem, asks for the densest arrangement of congruent spheres in n-dimensional Euclidean space. Although relevant to areas such as cryptography, crystallography, and medical imaging, the problem remains unresolved: beyond a few special dimensions, neither optimal packings nor tight upper bounds are known. Even a major breakthrough in dimension $n=8$, later recognised with a Fields Medal, underscores its difficulty. A leading technique for upper bounds, the three-point method, reduces the problem to solving large, high-precision semidefinite programs (SDPs). Because each candidate SDP may take days to evaluate, standard data-intensive AI approaches are infeasible. We address this challenge by formulating SDP construction as a sequential decision process, the SDP game, in which a policy assembles SDP formulations from a set of admissible components. Using a sample-efficient model-based framework that combines Bayesian optimisation with Monte Carlo Tree Search, we obtain new state-of-the-art upper bounds in dimensions $4-16$, showing that model-based search can advance computational progress in longstanding geometric problems. Together, these results demonstrate that sample-efficient, model-based search can make tangible progress on mathematically rigid, evaluation limited problems, pointing towards a complementary direction for AI-assisted discovery beyond large-scale LLM-driven exploration.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u9ad8\u6548\u641c\u7d22\u65b9\u6cd5\uff08\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u7ef4\u7403\u4f53\u5806\u79ef\u95ee\u9898\u7684\u4e0a\u754c\u8ba1\u7b97\uff0c\u57284-16\u7ef4\u7a7a\u95f4\u53d6\u5f97\u4e86\u65b0\u7684\u6700\u4f18\u4e0a\u754c\u7ed3\u679c\u3002", "motivation": "\u9ad8\u7ef4\u7403\u4f53\u5806\u79ef\u95ee\u9898\u662f\u5e0c\u5c14\u4f2f\u7279\u7b2c\u5341\u516b\u95ee\u9898\uff0c\u5728\u5bc6\u7801\u5b66\u3001\u6676\u4f53\u5b66\u548c\u533b\u5b66\u6210\u50cf\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u8be5\u95ee\u9898\u6781\u5176\u56f0\u96be\uff0c\u73b0\u6709\u7684\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff08\u6bcf\u4e2a\u5019\u9009SDP\u53ef\u80fd\u9700\u8981\u6570\u5929\u8bc4\u4f30\uff09\uff0c\u4f20\u7edf\u6570\u636e\u5bc6\u96c6\u578bAI\u65b9\u6cd5\u4e0d\u53ef\u884c\u3002", "method": "\u5c06SDP\u6784\u5efa\u5efa\u6a21\u4e3a\u987a\u5e8f\u51b3\u7b56\u8fc7\u7a0b\uff08SDP\u6e38\u620f\uff09\uff0c\u4f7f\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u6837\u672c\u9ad8\u6548\u6846\u67b6\uff08\u7ed3\u5408\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff09\u6765\u7ec4\u88c5SDP\u516c\u5f0f\u3002", "result": "\u57284-16\u7ef4\u7a7a\u95f4\u83b7\u5f97\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u4e0a\u754c\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u641c\u7d22\u5728\u957f\u671f\u51e0\u4f55\u95ee\u9898\u4e2d\u7684\u8ba1\u7b97\u8fdb\u5c55\u3002", "conclusion": "\u6837\u672c\u9ad8\u6548\u7684\u57fa\u4e8e\u6a21\u578b\u641c\u7d22\u80fd\u591f\u5728\u6570\u5b66\u4e25\u683c\u3001\u8bc4\u4f30\u53d7\u9650\u7684\u95ee\u9898\u4e0a\u53d6\u5f97\u5b9e\u8d28\u6027\u8fdb\u5c55\uff0c\u4e3aAI\u8f85\u52a9\u53d1\u73b0\u63d0\u4f9b\u4e86\u4e0e\u5927\u89c4\u6a21\u5f0f\u63a2\u7d22\u4e92\u8865\u7684\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.04834", "categories": ["cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.04834", "abs": "https://arxiv.org/abs/2512.04834", "authors": ["Vignesh Kumar Kembu", "Pierandrea Morandini", "Marta Bianca Maria Ranzini", "Antonino Nocera"], "title": "Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case", "comment": null, "summary": "Large Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5f00\u6e90\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u610f\u5927\u5229\u8bed\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u5b9e\u65f6\u4fe1\u606f\u62bd\u53d6\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u96f6\u6837\u672c\u672c\u5730\u90e8\u7f72\u73af\u5883\u4e0b\u8868\u73b0\u4e0d\u4e00\u3002", "motivation": "\u4e34\u5e8a\u8bb0\u5f55\u4e2d\u7684\u4fe1\u606f\u62bd\u53d6\u5bf9\u6570\u5b57\u533b\u7597\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edfNLP\u6280\u672f\u56e0\u4e34\u5e8a\u8bed\u8a00\u7684\u590d\u6742\u6027\u548c\u53d8\u5f02\u6027\u800c\u6548\u679c\u6709\u9650\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\u3002", "method": "\u901a\u8fc7\u8be6\u7ec6\u7684\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u6bd4\u8f83\u5f00\u6e90\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u5e76\u53d1\u75c7\u4fe1\u606f\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u539f\u751f\u6a21\u5f0f\u5339\u914d\u548c\u4eba\u5de5\u6807\u6ce8\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u90e8\u5206\u5927\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u672c\u5730\u8bbe\u7f6e\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u96be\u4ee5\u5728\u4e0d\u540c\u75be\u75c5\u95f4\u6cdb\u5316\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u4fe1\u606f\u62bd\u53d6\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u5728\u96f6\u6837\u672c\u548c\u672c\u5730\u90e8\u7f72\u573a\u666f\u4e0b\u4ecd\u9700\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.04854", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04854", "abs": "https://arxiv.org/abs/2512.04854", "authors": ["Lukas Weidener", "Marko Brki\u0107", "Chiara Bacci", "Mihailo Jovanovi\u0107", "Emre Ulgac", "Alex Dobrin", "Johannes Weniger", "Martin Vlas", "Ritvik Singh", "Aakaash Meduri"], "title": "From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research", "comment": null, "summary": "Artificial intelligence systems are increasingly deployed in biomedical research. However, current evaluation frameworks may inadequately assess their effectiveness as research collaborators. This rapid review examines benchmarking practices for AI systems in preclinical biomedical research. Three major databases and two preprint servers were searched from January 1, 2018 to October 31, 2025, identifying 14 benchmarks that assess AI capabilities in literature understanding, experimental design, and hypothesis generation. The results revealed that all current benchmarks assess isolated component capabilities, including data analysis quality, hypothesis validity, and experimental protocol design. However, authentic research collaboration requires integrated workflows spanning multiple sessions, with contextual memory, adaptive dialogue, and constraint propagation. This gap implies that systems excelling on component benchmarks may fail as practical research co-pilots. A process-oriented evaluation framework is proposed that addresses four critical dimensions absent from current benchmarks: dialogue quality, workflow orchestration, session continuity, and researcher experience. These dimensions are essential for evaluating AI systems as research co-pilots rather than as isolated task executors.", "AI": {"tldr": "\u672c\u6587\u5bf9\u4e34\u5e8a\u524d\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2dAI\u7cfb\u7edf\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u8fdb\u884c\u4e86\u5feb\u901f\u56de\u987e\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u4ec5\u8bc4\u4f30\u5b64\u7acb\u80fd\u529b\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30AI\u4f5c\u4e3a\u7814\u7a76\u5408\u4f5c\u4f19\u4f34\u7684\u6574\u4f53\u6548\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u6d41\u7a0b\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5728\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5f53\u524d\u7684\u8bc4\u4f30\u6846\u67b6\u53ef\u80fd\u4e0d\u8db3\u4ee5\u6709\u6548\u8bc4\u4f30\u5176\u4f5c\u4e3a\u7814\u7a76\u5408\u4f5c\u4f19\u4f34\u7684\u5b9e\u9645\u6548\u80fd\u3002\u9700\u8981\u5ba1\u89c6\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u8df5\u4ee5\u53d1\u73b0\u6f5c\u5728\u7684\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u68c0\u7d22\u4e09\u4e2a\u4e3b\u8981\u6570\u636e\u5e93\u548c\u4e24\u4e2a\u9884\u5370\u672c\u670d\u52a1\u5668\uff082018\u5e741\u67081\u65e5\u81f32025\u5e7410\u670831\u65e5\uff09\uff0c\u8bc6\u522b\u51fa14\u4e2a\u8bc4\u4f30AI\u5728\u6587\u732e\u7406\u89e3\u3001\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u5047\u8bbe\u751f\u6210\u65b9\u9762\u80fd\u529b\u7684\u57fa\u51c6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6240\u6709\u73b0\u6709\u57fa\u51c6\u90fd\u53ea\u8bc4\u4f30\u5b64\u7acb\u7684\u7ec4\u4ef6\u80fd\u529b\uff08\u5982\u6570\u636e\u5206\u6790\u8d28\u91cf\u3001\u5047\u8bbe\u6709\u6548\u6027\u3001\u5b9e\u9a8c\u65b9\u6848\u8bbe\u8ba1\uff09\uff0c\u4f46\u771f\u5b9e\u7684\u7814\u7a76\u5408\u4f5c\u9700\u8981\u5305\u542b\u60c5\u5883\u8bb0\u5fc6\u3001\u81ea\u9002\u5e94\u5bf9\u8bdd\u548c\u7ea6\u675f\u4f20\u64ad\u7684\u96c6\u6210\u5de5\u4f5c\u6d41\u7a0b\u3002", "conclusion": "\u5f53\u524d\u57fa\u51c6\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u7cfb\u7edf\u5728\u7ec4\u4ef6\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u53ef\u80fd\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5931\u8d25\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5bf9\u8bdd\u8d28\u91cf\u3001\u5de5\u4f5c\u6d41\u7a0b\u7f16\u6392\u3001\u4f1a\u8bdd\u8fde\u7eed\u6027\u548c\u7814\u7a76\u4eba\u5458\u4f53\u9a8c\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u7684\u6d41\u7a0b\u5bfc\u5411\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u8bc4\u4f30AI\u4f5c\u4e3a\u7814\u7a76\u5408\u4f5c\u8005\u7684\u80fd\u529b\u3002"}}
{"id": "2512.04871", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.04871", "abs": "https://arxiv.org/abs/2512.04871", "authors": ["Junjie Fan", "Hongye Zhao", "Linduo Wei", "Jiayu Rao", "Guijia Li", "Jiaxin Yuan", "Wenqi Xu", "Yong Qi"], "title": "STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Recent adaptations of Large Language Models (LLMs) for time series forecasting often fail to effectively enhance information for raw series, leaving LLM reasoning capabilities underutilized. Existing prompting strategies rely on static correlations rather than generative interpretations of dynamic behavior, lacking critical global and instance-specific context. To address this, we propose STELLA (Semantic-Temporal Alignment with Language Abstractions), a framework that systematically mines and injects structured supplementary and complementary information. STELLA employs a dynamic semantic abstraction mechanism that decouples input series into trend, seasonality, and residual components. It then translates intrinsic behavioral features of these components into Hierarchical Semantic Anchors: a Corpus-level Semantic Prior (CSP) for global context and a Fine-grained Behavioral Prompt (FBP) for instance-level patterns. Using these anchors as prefix-prompts, STELLA guides the LLM to model intrinsic dynamics. Experiments on eight benchmark datasets demonstrate that STELLA outperforms state-of-the-art methods in long- and short-term forecasting, showing superior generalization in zero-shot and few-shot settings. Ablation studies further validate the effectiveness of our dynamically generated semantic anchors.", "AI": {"tldr": "\u63d0\u51fa\u7684STELLA\u6846\u67b6\u901a\u8fc7\u52a8\u6001\u8bed\u4e49\u62bd\u8c61\u548c\u65f6\u95f4\u5bf9\u51c6\u589e\u5f3aLLM\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u80fd\u529b\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u589e\u5f3a\u539f\u59cb\u5e8f\u5217\u4fe1\u606f\uff0c\u4f9d\u8d56\u9759\u6001\u76f8\u5173\u6027\u800c\u975e\u52a8\u6001\u884c\u4e3a\u751f\u6210\u89e3\u91ca\uff0c\u7f3a\u4e4f\u5168\u5c40\u548c\u5b9e\u4f8b\u7279\u5b9a\u4e0a\u4e0b\u6587\u3002", "method": "STELLA\u6846\u67b6\u5c06\u8f93\u5165\u5e8f\u5217\u89e3\u8026\u4e3a\u8d8b\u52bf\u3001\u5b63\u8282\u6027\u548c\u6b8b\u5dee\u5206\u91cf\uff0c\u751f\u6210\u5c42\u6b21\u5316\u8bed\u4e49\u951a\u70b9\uff08\u5168\u5c40\u8bed\u6599\u7ea7\u5148\u9a8c\u548c\u7ec6\u7c92\u5ea6\u884c\u4e3a\u63d0\u793a\uff09\u4f5c\u4e3a\u524d\u7f00\u63d0\u793a\u5f15\u5bfcLLM\u5efa\u6a21\u3002", "result": "\u57288\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cSTELLA\u5728\u957f\u77ed\u671f\u9884\u6d4b\u4e2d\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u573a\u666f\u4e0b\u5c55\u73b0\u4f18\u5f02\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u52a8\u6001\u751f\u6210\u7684\u8bed\u4e49\u951a\u70b9\u80fd\u6709\u6548\u63d0\u5347LLM\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u8bed\u4e49-\u65f6\u95f4\u5bf9\u51c6\u6846\u67b6\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2512.04895", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.04895", "abs": "https://arxiv.org/abs/2512.04895", "authors": ["M Zeeshan", "Saud Satti"], "title": "Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems", "comment": "5 pages, 2 figures, IEEE Transactions on Dependable and Secure Computing", "summary": "Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs), have become integral to critical applications ranging from autonomous decision-making to automated document processing. As these systems scale, they rely heavily on preprocessing pipelines to handle diverse inputs efficiently. However, this dependency on standard preprocessing operations, specifically image downscaling, creates a significant yet often overlooked security vulnerability. While intended for computational optimization, scaling algorithms can be exploited to conceal malicious visual prompts that are invisible to human observers but become active semantic instructions once processed by the model. Current adversarial strategies remain largely static, failing to account for the dynamic nature of modern agentic workflows. To address this gap, we propose Chameleon, a novel, adaptive adversarial framework designed to expose and exploit scaling vulnerabilities in production VLMs. Unlike traditional static attacks, Chameleon employs an iterative, agent-based optimization mechanism that dynamically refines image perturbations based on the target model's real-time feedback. This allows the framework to craft highly robust adversarial examples that survive standard downscaling operations to hijack downstream execution. We evaluate Chameleon against Gemini 2.5 Flash model. Our experiments demonstrate that Chameleon achieves an Attack Success Rate (ASR) of 84.5% across varying scaling factors, significantly outperforming static baseline attacks which average only 32.1%. Furthermore, we show that these attacks effectively compromise agentic pipelines, reducing decision-making accuracy by over 45% in multi-step tasks. Finally, we discuss the implications of these vulnerabilities and propose multi-scale consistency checks as a necessary defense mechanism.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aChameleon\u7684\u81ea\u9002\u5e94\u5bf9\u6297\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLMs)\u4e2d\u7684\u56fe\u50cf\u9884\u5904\u7406\u6f0f\u6d1e\u8fdb\u884c\u653b\u51fb\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u653b\u51fb\u5927\u5e45\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387", "motivation": "\u5f53\u524d\u591a\u6a21\u6001AI\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u9884\u5904\u7406\u7ba1\u9053\uff0c\u7279\u522b\u662f\u56fe\u50cf\u7f29\u653e\u64cd\u4f5c\uff0c\u8fd9\u5e26\u6765\u4e86\u88ab\u5ffd\u89c6\u7684\u5b89\u5168\u6f0f\u6d1e\u2014\u2014\u6076\u610f\u89c6\u89c9\u63d0\u793a\u53ef\u901a\u8fc7\u7f29\u653e\u9690\u85cf\uff0c\u5728\u4eba\u773c\u4e0d\u53ef\u89c1\u7684\u60c5\u51b5\u4e0b\u6fc0\u6d3b\u6a21\u578b\u8bed\u4e49\u6307\u4ee4", "method": "\u91c7\u7528\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u8fed\u4ee3\u4f18\u5316\u673a\u5236\uff0c\u6839\u636e\u76ee\u6807\u6a21\u578b\u7684\u5b9e\u65f6\u53cd\u9988\u52a8\u6001\u8c03\u6574\u56fe\u50cf\u6270\u52a8\uff0c\u751f\u6210\u80fd\u7ecf\u53d7\u6807\u51c6\u7f29\u653e\u64cd\u4f5c\u7684\u5bf9\u6297\u6837\u672c", "result": "\u5728Gemini 2.5 Flash\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cChameleon\u653b\u51fb\u6210\u529f\u7387\u8fbe\u523084.5%\uff0c\u8fdc\u8d85\u9759\u6001\u57fa\u51c6\u653b\u51fb\u768432.1%\uff1b\u5728\u591a\u6b65\u4efb\u52a1\u4e2d\u4f7f\u51b3\u7b56\u51c6\u786e\u7387\u4e0b\u964d\u8d85\u8fc745%", "conclusion": "\u63ed\u793a\u4e86VLMs\u9884\u5904\u7406\u9636\u6bb5\u7684\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u51fa\u591a\u5c3a\u5ea6\u4e00\u81f4\u6027\u68c0\u67e5\u4f5c\u4e3a\u5fc5\u8981\u7684\u9632\u5fa1\u673a\u5236\uff0c\u5f3a\u8c03\u9700\u8981\u5173\u6ce8\u52a8\u6001\u5bf9\u6297\u5a01\u80c1"}}
{"id": "2512.04923", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.04923", "abs": "https://arxiv.org/abs/2512.04923", "authors": ["MohammadHossein Bateni", "Vincent Cohen-Addad", "Yuzhou Gu", "Silvio Lattanzi", "Simon Meierhans", "Christopher Mohri"], "title": "Algorithmic Thinking Theory", "comment": null, "summary": "Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle.\n  We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.", "AI": {"tldr": "LLMs\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u751f\u6210\u7b54\u6848\u7684\u80fd\u529b\u53ef\u88ab\u89c6\u4e3a\u6982\u7387\u63a8\u7406\u7b97\u6cd5\u3002\u672c\u6587\u63d0\u51fa\u4e86\u7406\u8bba\u6846\u67b6\u5206\u6790\u6b64\u7c7b\u63a8\u7406\u7b97\u6cd5\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u5f3a\u5927\u7684\u63a8\u7406\u65b9\u6cd5\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u89c2\u5bdf\u5230LLMs\u901a\u8fc7\u8fed\u4ee3\u6539\u8fdb\u89e3\u51b3\u65b9\u6848\u80fd\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7406\u8bba\u6846\u67b6\u5206\u6790\u8fd9\u79cd\u63a8\u7406\u7b97\u6cd5\u7684\u539f\u7406\u548c\u6548\u679c\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u6982\u7387\u9884\u8a00\u673a\u7684\u7406\u8bba\u6846\u67b6\uff0c\u5f62\u5f0f\u5316\u8fed\u4ee3\u6539\u8fdb\u548c\u7b54\u6848\u805a\u5408\u7b49\u6d41\u884c\u6280\u672f\u7684\u539f\u7406\uff0c\u4e0d\u4f9d\u8d56\u5177\u4f53\u6a21\u578b\u67b6\u6784\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0e\u5b9e\u9a8c\u8bc1\u636e\u76f8\u7b26\u7684\u901a\u7528\u5206\u6790\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u91ca\u73b0\u6709\u6280\u672f\u5e76\u4e3a\u65b0\u4e00\u4ee3\u63a8\u7406\u65b9\u6cd5\u7684\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u5f53\u524d\u548c\u672a\u6765\u63a8\u7406\u9884\u8a00\u673a\u7684\u5de5\u4f5c\u539f\u7406\u63d0\u4f9b\u4e86\u666e\u904d\u89c6\u89d2\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5f3a\u5927\u63a8\u7406\u65b9\u6cd5\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.04938", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04938", "abs": "https://arxiv.org/abs/2512.04938", "authors": ["Raquel Norel", "Michele Merler", "Pavitra Modi"], "title": "Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases", "comment": null, "summary": "Patients with rare neurological diseases report cognitive symptoms -\"brain fog\"- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived \"Proficiency in Verbal Discourse\" correlates with blood phenylalanine (p = -0.50, p < 0.005) but not standard cognitive tests (all |r| < 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.", "AI": {"tldr": "\u4f7f\u7528\u667a\u80fd\u624b\u673a\u8bed\u97f3\u5206\u6790\u548c\u5173\u7cfb\u56fe\u8f6c\u6362\u5668\u67b6\u6784\u76d1\u6d4b\u7f55\u89c1\u795e\u7ecf\u75be\u75c5\u60a3\u8005\u7684\u8ba4\u77e5\u75c7\u72b6\uff0c\u8bc1\u660e\u6bd4\u4f20\u7edf\u6d4b\u8bd5\u66f4\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u8ba4\u77e5\u6d4b\u8bd5\u65e0\u6cd5\u68c0\u6d4b\u5230\u7f55\u89c1\u795e\u7ecf\u75be\u75c5\u60a3\u8005\u62a5\u544a\u7684\"\u8111\u96fe\"\u75c7\u72b6\uff0c\u9700\u8981\u66f4\u654f\u611f\u7684\u76d1\u6d4b\u65b9\u6cd5\u3002", "method": "\u6574\u5408\u667a\u80fd\u624b\u673a\u8bed\u97f3\u5206\u6790\u4e0e\u5173\u7cfb\u56fe\u8f6c\u6362\u5668\uff08RELGT\uff09\u67b6\u6784\u8fdb\u884c\u8fde\u7eed\u795e\u7ecf\u8ba4\u77e5\u76d1\u6d4b\u3002", "result": "\u5728\u82ef\u4e19\u916e\u5c3f\u75c7\u6982\u5ff5\u9a8c\u8bc1\u4e2d\uff0c\u8bed\u97f3\u884d\u751f\u7684\"\u8a00\u8bed\u6d41\u7545\u5ea6\"\u4e0e\u8840\u6db2\u82ef\u4e19\u6c28\u9178\u6c34\u5e73\u663e\u8457\u76f8\u5173\uff08p = -0.50, p < 0.005\uff09\uff0c\u800c\u4f20\u7edf\u8ba4\u77e5\u6d4b\u8bd5\u65e0\u663e\u8457\u76f8\u5173\u6027\uff08\u6240\u6709|r| < 0.35\uff09\u3002", "conclusion": "RELGT\u80fd\u591f\u514b\u670d\u5f02\u8d28\u6027\u533b\u7597\u6570\u636e\u7684\u4fe1\u606f\u74f6\u9888\uff0c\u5b9e\u73b0\u5931\u4ee3\u507f\u524d\u6570\u5468\u7684\u9884\u6d4b\u9884\u8b66\uff0c\u6709\u671b\u5c06\u95f4\u6b47\u6027\u795e\u7ecf\u5b66\u8f6c\u53d8\u4e3a\u5168\u7403\u6570\u767e\u4e07\u4eba\u7684\u8fde\u7eed\u4e2a\u6027\u5316\u76d1\u6d4b\u3002"}}
{"id": "2512.05013", "categories": ["cs.AI", "cs.MA", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.05013", "abs": "https://arxiv.org/abs/2512.05013", "authors": ["Eric Bridgeford", "Hayden Helm"], "title": "Detecting Perspective Shifts in Multi-agent Systems", "comment": null, "summary": "Generative models augmented with external tools and update mechanisms (or \\textit{agents}) have demonstrated capabilities beyond intelligent prompting of base models. As agent use proliferates, dynamic multi-agent systems have naturally emerged. Recent work has investigated the theoretical and empirical properties of low-dimensional representations of agents based on query responses at a single time point. This paper introduces the Temporal Data Kernel Perspective Space (TDKPS), which jointly embeds agents across time, and proposes several novel hypothesis tests for detecting behavioral change at the agent- and group-level in black-box multi-agent systems. We characterize the empirical properties of our proposed tests, including their sensitivity to key hyperparameters, in simulations motivated by a multi-agent system of evolving digital personas. Finally, we demonstrate via natural experiment that our proposed tests detect changes that correlate sensitively, specifically, and significantly with a real exogenous event. As far as we are aware, TDKPS is the first principled framework for monitoring behavioral dynamics in black-box multi-agent systems -- a critical capability as generative agent deployment continues to scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7528\u4e8e\u76d1\u6d4b\u9ed1\u76d2\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u884c\u4e3a\u52a8\u6001\u7684\u65f6\u6001\u6570\u636e\u6838\u89c6\u89d2\u7a7a\u95f4\uff08TDKPS\uff09\uff0c\u80fd\u591f\u8de8\u65f6\u95f4\u8054\u5408\u5d4c\u5165\u667a\u80fd\u4f53\u5e76\u68c0\u6d4b\u884c\u4e3a\u548c\u7fa4\u4f53\u5c42\u9762\u7684\u53d8\u5316\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4f53\u4f7f\u7528\u6fc0\u589e\uff0c\u52a8\u6001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u7136\u6d8c\u73b0\uff0c\u9700\u8981\u76d1\u6d4b\u667a\u80fd\u4f53\u884c\u4e3a\u7684\u52a8\u6001\u53d8\u5316\u3002\u73b0\u6709\u7814\u7a76\u4ec5\u9650\u4e8e\u57fa\u4e8e\u5355\u65f6\u95f4\u70b9\u67e5\u8be2\u54cd\u5e94\u7684\u4f4e\u7ef4\u8868\u793a\u3002", "method": "\u4ecb\u7ecd\u4e86TDKPS\u6846\u67b6\uff0c\u63d0\u51fa\u51e0\u79cd\u65b0\u9896\u7684\u5047\u8bbe\u68c0\u9a8c\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u9ed1\u76d2\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u667a\u80fd\u4f53\u548c\u7fa4\u4f53\u5c42\u9762\u7684\u884c\u4e3a\u53d8\u5316\u3002\u901a\u8fc7\u6a21\u62df\u548c\u81ea\u7136\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u7279\u6027\u3002", "result": "\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u68c0\u9a8c\u65b9\u6cd5\u5bf9\u5173\u952e\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\uff0c\u5e76\u901a\u8fc7\u81ea\u7136\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u7075\u654f\u3001\u7279\u5f02\u4e14\u663e\u8457\u5730\u68c0\u6d4b\u5230\u4e0e\u771f\u5b9e\u5916\u90e8\u4e8b\u4ef6\u76f8\u5173\u7684\u53d8\u5316\u3002", "conclusion": "TDKPS\u662f\u9996\u4e2a\u7528\u4e8e\u76d1\u6d4b\u9ed1\u76d2\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u884c\u4e3a\u52a8\u6001\u7684\u539f\u5219\u6027\u6846\u67b6\uff0c\u5bf9\u4e8e\u751f\u6210\u5f0f\u667a\u80fd\u4f53\u90e8\u7f72\u89c4\u6a21\u5316\u81f3\u5173\u91cd\u8981\u3002"}}
