{"id": "2512.11273", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11273", "abs": "https://arxiv.org/abs/2512.11273", "authors": ["Qi Deng", "Yuxuan Linghu", "Zhiyuan Liu"], "title": "Integrated Prediction and Multi-period Portfolio Optimization", "comment": "23 pages, 6 figures, and 4 tables", "summary": "Multi-period portfolio optimization is important for real portfolio management, as it accounts for transaction costs, path-dependent risks, and the intertemporal structure of trading decisions that single-period models cannot capture. Classical methods usually follow a two-stage framework: machine learning algorithms are employed to produce forecasts that closely fit the realized returns, and the predicted values are then used in a downstream portfolio optimization problem to determine the asset weights. This separation leads to a fundamental misalignment between predictions and decision outcomes, while also ignoring the impact of transaction costs. To bridge this gap, recent studies have proposed the idea of end-to-end learning, integrating the two stages into a single pipeline. This paper introduces IPMO (Integrated Prediction and Multi-period Portfolio Optimization), a model for multi-period mean-variance portfolio optimization with turnover penalties. The predictor generates multi-period return forecasts that parameterize a differentiable convex optimization layer, which in turn drives learning via portfolio performance. For scalability, we introduce a mirror-descent fixed-point (MDFP) differentiation scheme that avoids factorizing the Karush-Kuhn-Tucker (KKT) systems, which thus yields stable implicit gradients and nearly scale-insensitive runtime as the decision horizon grows. In experiments with real market data and two representative time-series prediction models, the IPMO method consistently outperforms the two-stage benchmarks in risk-adjusted performance net of transaction costs and achieves more coherent allocation paths. Our results show that integrating machine learning prediction with optimization in the multi-period setting improves financial outcomes and remains computationally tractable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIPMO\u6a21\u578b\uff0c\u5c06\u591a\u5468\u671f\u6536\u76ca\u9884\u6d4b\u4e0e\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u6574\u5408\u4e3a\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5fae\u51f8\u4f18\u5316\u5c42\u548cMDFP\u5fae\u5206\u65b9\u6848\u89e3\u51b3\u4f20\u7edf\u4e24\u9636\u6bb5\u65b9\u6cd5\u4e2d\u7684\u9884\u6d4b\u4e0e\u51b3\u7b56\u9519\u4f4d\u95ee\u9898\uff0c\u5728\u771f\u5b9e\u5e02\u573a\u6570\u636e\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u98ce\u9669\u8c03\u6574\u540e\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u5468\u671f\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff08\u5148\u9884\u6d4b\u540e\u4f18\u5316\uff09\uff0c\u5bfc\u81f4\u9884\u6d4b\u4e0e\u51b3\u7b56\u7ed3\u679c\u4e0d\u5339\u914d\uff0c\u4e14\u5ffd\u7565\u4ea4\u6613\u6210\u672c\u5f71\u54cd\uff0c\u9700\u8981\u7aef\u5230\u7aef\u7684\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51faIPMO\u6a21\u578b\uff0c\u5305\u542b\u591a\u5468\u671f\u6536\u76ca\u9884\u6d4b\u5668\u548c\u53ef\u5fae\u51f8\u4f18\u5316\u5c42\uff0c\u91c7\u7528\u955c\u50cf\u4e0b\u964d\u56fa\u5b9a\u70b9\uff08MDFP\uff09\u5fae\u5206\u65b9\u6848\u907f\u514dKKT\u7cfb\u7edf\u5206\u89e3\uff0c\u5b9e\u73b0\u7a33\u5b9a\u7684\u9690\u5f0f\u68af\u5ea6\u548c\u8fd1\u4f3c\u89c4\u6a21\u4e0d\u654f\u611f\u7684\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u771f\u5b9e\u5e02\u573a\u6570\u636e\u548c\u4e24\u79cd\u5178\u578b\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cIPMO\u5728\u6263\u9664\u4ea4\u6613\u6210\u672c\u540e\u7684\u98ce\u9669\u8c03\u6574\u8868\u73b0\u6301\u7eed\u4f18\u4e8e\u4e24\u9636\u6bb5\u57fa\u51c6\u65b9\u6cd5\uff0c\u5e76\u4ea7\u751f\u66f4\u4e00\u81f4\u7684\u8d44\u91d1\u5206\u914d\u8def\u5f84\u3002", "conclusion": "\u591a\u5468\u671f\u8bbe\u7f6e\u4e0b\u5c06\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u4e0e\u4f18\u5316\u96c6\u6210\u53ef\u6539\u5584\u8d22\u52a1\u7ed3\u679c\uff0c\u5e76\u4fdd\u6301\u8ba1\u7b97\u53ef\u63a7\u6027\uff0cIPMO\u4e3a\u5b9e\u9645\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7aef\u5230\u7aef\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11412", "categories": ["cs.CE", "cs.AI", "cs.CL", "cs.LG", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2512.11412", "abs": "https://arxiv.org/abs/2512.11412", "authors": ["Kwun Sy Lee", "Jiawei Chen", "Fuk Sheng Ford Chung", "Tianyu Zhao", "Zhenyuan Chen", "Debby D. Wang"], "title": "Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models", "comment": "6 pages, 4 figures", "summary": "Reliable in silico molecular toxicity prediction is a cornerstone of modern drug discovery, offering a scalable alternative to experimental screening. However, the black-box nature of state-of-the-art models remains a significant barrier to adoption, as high-stakes safety decisions demand verifiable structural insights alongside predictive performance. To address this, we propose a novel multi-task learning (MTL) framework designed to jointly enhance accuracy and interpretability. Our architecture integrates a shared chemical language model with task-specific attention modules. By imposing an L1 sparsity penalty on these modules, the framework is constrained to focus on a minimal set of salient molecular fragments for each distinct toxicity endpoint. The resulting framework is trained end-to-end and is readily adaptable to various transformer-based backbones. Evaluated on the ClinTox, SIDER, and Tox21 benchmark datasets, our approach consistently outperforms both single-task and standard MTL baselines. Crucially, the sparse attention weights provide chemically intuitive visualizations that reveal the specific fragments influencing predictions, thereby enhancing insight into the model's decision-making process.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.11473", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.11473", "abs": "https://arxiv.org/abs/2512.11473", "authors": ["Fan Gu", "Xiangyu Hu"], "title": "Contiguous Storage of Grid Data for Heterogeneous Computing", "comment": "26 pages, 6 figures and 1 table", "summary": "Structured Cartesian grids are a fundamental component in numerical simulations. Although these grids facilitate straightforward discretization schemes, their na\u00efve use in sparse domains leads to excessive memory overhead and inefficient computation. Existing frameworks address are primarily optimized for CPU execution and exhibit performance bottlenecks on GPU architectures due to limited parallelism and high memory access latency. This work presents a redesigned storage architecture optimized for GPU compatibility and efficient execution across heterogeneous platforms. By abstracting low-level GPU-specific details and adopting a unified programming model based on SYCL, the proposed data structure enables seamless integration across host and device environments. This architecture simplifies GPU programming for end-users while improving scalability and portability in sparse-grid and gird-particle coupling numerical simulations.", "AI": {"tldr": "\u9488\u5bf9GPU\u4f18\u5316\u7684\u7a00\u758f\u7ed3\u6784\u5316\u7b1b\u5361\u5c14\u7f51\u683c\u5b58\u50a8\u67b6\u6784\uff0c\u91c7\u7528SYCL\u7edf\u4e00\u7f16\u7a0b\u6a21\u578b\uff0c\u63d0\u5347\u5f02\u6784\u5e73\u53f0\u6027\u80fd\u548c\u7f16\u7a0b\u4fbf\u6377\u6027\u3002", "motivation": "\u4f20\u7edf\u7ed3\u6784\u5316\u7b1b\u5361\u5c14\u7f51\u683c\u5728\u7a00\u758f\u57df\u4e2d\u5185\u5b58\u6548\u7387\u4f4e\uff0c\u73b0\u6709CPU\u4f18\u5316\u6846\u67b6\u5728GPU\u4e0a\u5b58\u5728\u5e76\u884c\u6027\u4e0d\u8db3\u548c\u5185\u5b58\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u91cd\u65b0\u8bbe\u8ba1\u5b58\u50a8\u67b6\u6784\uff0c\u62bd\u8c61GPU\u5e95\u5c42\u7ec6\u8282\uff0c\u57fa\u4e8eSYCL\u5b9e\u73b0\u7edf\u4e00\u7f16\u7a0b\u6a21\u578b\uff0c\u652f\u6301\u4e3b\u673a-\u8bbe\u5907\u65e0\u7f1d\u96c6\u6210\u3002", "result": "\u63d0\u5347\u4e86GPU\u7f16\u7a0b\u7684\u7b80\u6613\u6027\uff0c\u5728\u7a00\u758f\u7f51\u683c\u548c\u7f51\u683c-\u7c92\u5b50\u8026\u5408\u6570\u503c\u6a21\u62df\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u79fb\u690d\u6027\u3002", "conclusion": "\u8be5\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86GPU\u4e0a\u7a00\u758f\u7ed3\u6784\u5316\u7f51\u683c\u7684\u8ba1\u7b97\u6548\u7387\u95ee\u9898\uff0c\u4e3a\u5f02\u6784\u5e73\u53f0\u6570\u503c\u6a21\u62df\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11748", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11748", "abs": "https://arxiv.org/abs/2512.11748", "authors": ["Mohammed El Fallaki Idrissi", "Jad Mounayer", "Sebastian Rodriguez", "Fodil Meraghni", "Francisco Chinesta"], "title": "Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation", "comment": null, "summary": "This paper presents a novel paradigm in simulation-based engineering sciences by introducing a new framework called Generative Parametric Design (GPD). The GPD framework enables the generation of new designs along with their corresponding parametric solutions given as a reduced basis. To achieve this, two Rank Reduction Autoencoders (RRAEs) are employed, one for encoding and generating the design or geometry, and the other for encoding the sparse Proper Generalized Decomposition (sPGD) mode solutions. These models are linked in the latent space using regression techniques, allowing efficient transitions between design and their associated sPGD modes. By empowering design exploration and optimization, this framework also advances digital and hybrid twin development, enhancing predictive modeling and real-time decision-making in engineering applications. The developed framework is demonstrated on two-phase microstructures, in which the multiparametric solutions account for variations in two key material parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u751f\u6210\u53c2\u6570\u8bbe\u8ba1(GPD)\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u4e2a\u79e9\u51cf\u5c11\u81ea\u52a8\u7f16\u7801\u5668\u548c\u56de\u5f52\u6280\u672f\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fde\u63a5\u8bbe\u8ba1\u4e0e\u53c2\u6570\u89e3\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u8bbe\u8ba1\u63a2\u7d22\u548c\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u7684\u4eff\u771f\u5de5\u7a0b\u79d1\u5b66\u65b9\u6cd5\u5728\u8bbe\u8ba1\u4f18\u5316\u548c\u53c2\u6570\u89e3\u51b3\u65b9\u6848\u751f\u6210\u65b9\u9762\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u751f\u6210\u65b0\u8bbe\u8ba1\u53ca\u5176\u5bf9\u5e94\u53c2\u6570\u89e3\u51b3\u65b9\u6848\u7684\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u79e9\u51cf\u5c11\u81ea\u52a8\u7f16\u7801\u5668(RRAE)\uff0c\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u548c\u751f\u6210\u8bbe\u8ba1\u51e0\u4f55\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u7f16\u7801\u7a00\u758f\u9002\u5f53\u5e7f\u4e49\u5206\u89e3(sPGD)\u6a21\u5f0f\u89e3\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4f7f\u7528\u56de\u5f52\u6280\u672f\u8fde\u63a5\u8fd9\u4e24\u4e2a\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u51fa\u7684GPD\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u65b0\u8bbe\u8ba1\u53ca\u5176\u5bf9\u5e94\u7684\u53c2\u6570\u89e3\uff0c\u5e76\u5728\u4e24\u76f8\u5fae\u89c2\u7ed3\u6784\u4e0a\u5f97\u5230\u9a8c\u8bc1\uff0c\u80fd\u591f\u5904\u7406\u4e24\u4e2a\u5173\u952e\u6750\u6599\u53c2\u6570\u7684\u53d8\u5316\u3002", "conclusion": "GPD\u6846\u67b6\u4e3a\u4eff\u771f\u5de5\u7a0b\u79d1\u5b66\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u4e0d\u4ec5\u4fc3\u8fdb\u8bbe\u8ba1\u63a2\u7d22\u548c\u4f18\u5316\uff0c\u8fd8\u63a8\u52a8\u4e86\u6570\u5b57\u548c\u6df7\u5408\u5b6a\u751f\u6280\u672f\u7684\u53d1\u5c55\uff0c\u589e\u5f3a\u4e86\u5de5\u7a0b\u5e94\u7528\u4e2d\u7684\u9884\u6d4b\u5efa\u6a21\u548c\u5b9e\u65f6\u51b3\u7b56\u80fd\u529b\u3002"}}
{"id": "2512.11223", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11223", "abs": "https://arxiv.org/abs/2512.11223", "authors": ["Sasara Shimizu", "Yoshiki Higo"], "title": "Coverage Isn't Enough: SBFL-Driven Insights into Manually Created vs. Automatically Generated Tests", "comment": null, "summary": "The testing phase is an essential part of software development, but manually creating test cases can be time-consuming. Consequently, there is a growing need for more efficient testing methods. To reduce the burden on developers, various automated test generation tools have been developed, and several studies have been conducted to evaluate the effectiveness of the tests they produce. However, most of these studies focus primarily on coverage metrics, and only a few examine how well the tests support fault localization-particularly using artificial faults introduced through mutation testing. In this study, we compare the SBFL (Spectrum-Based Fault Localization) score and code coverage of automatically generated tests with those of manually created tests. The SBFL score indicates how accurately faults can be localized using SBFL techniques. By employing SBFL score as an evaluation metric-an approach rarely used in prior studies on test generation-we aim to provide new insights into the respective strengths and weaknesses of manually created and automatically generated tests. Our experimental results show that automatically generated tests achieve higher branch coverage than manually created tests, but their SBFL score is lower, especially for code with deeply nested structures. These findings offer guidance on how to effectively combine automatically generated and manually created testing approaches.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4e0e\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u5728SBFL\u5206\u6570\u548c\u4ee3\u7801\u8986\u76d6\u7387\u4e0a\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u81ea\u52a8\u6d4b\u8bd5\u8986\u76d6\u7387\u66f4\u9ad8\u4f46\u6545\u969c\u5b9a\u4f4d\u80fd\u529b\u8f83\u5f31", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u5f88\u5c11\u8bc4\u4f30\u6d4b\u8bd5\u5bf9\u6545\u969c\u5b9a\u4f4d\u7684\u652f\u6301\u6548\u679c\uff0c\u7279\u522b\u662f\u4f7f\u7528\u53d8\u5f02\u6d4b\u8bd5\u5f15\u5165\u4eba\u5de5\u6545\u969c\u7684\u60c5\u51b5", "method": "\u6bd4\u8f83\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u4e0e\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u7684SBFL\u5206\u6570\u548c\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u4f7f\u7528SBFL\u5206\u6570\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807", "result": "\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7684\u5206\u652f\u8986\u76d6\u7387\u9ad8\u4e8e\u624b\u52a8\u6d4b\u8bd5\uff0c\u4f46SBFL\u5206\u6570\u8f83\u4f4e\uff0c\u7279\u522b\u662f\u5728\u6df1\u5ea6\u5d4c\u5957\u7ed3\u6784\u7684\u4ee3\u7801\u4e2d", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5982\u4f55\u6709\u6548\u7ed3\u5408\u81ea\u52a8\u751f\u6210\u548c\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc"}}
{"id": "2512.10998", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10998", "abs": "https://arxiv.org/abs/2512.10998", "authors": ["Mohamed Afane", "Abhishek Satyam", "Ke Chen", "Tao Li", "Junaid Farooq", "Juntao Chen"], "title": "SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models", "comment": "9 pages, 3 figures", "summary": "Backdoor attacks create significant security threats to language models by embedding hidden triggers that manipulate model behavior during inference, presenting critical risks for AI systems deployed in healthcare and other sensitive domains. While existing defenses effectively counter obvious threats such as out-of-context trigger words and safety alignment violations, they fail against sophisticated attacks using contextually-appropriate triggers that blend seamlessly into natural language. This paper introduces three novel contextually-aware attack scenarios that exploit domain-specific knowledge and semantic plausibility: the ViralApp attack targeting social media addiction classification, the Fever attack manipulating medical diagnosis toward hypertension, and the Referral attack steering clinical recommendations. These attacks represent realistic threats where malicious actors exploit domain-specific vocabulary while maintaining semantic coherence, demonstrating how adversaries can weaponize contextual appropriateness to evade conventional detection methods. To counter both traditional and these sophisticated attacks, we present \\textbf{SCOUT (Saliency-based Classification Of Untrusted Tokens)}, a novel defense framework that identifies backdoor triggers through token-level saliency analysis rather than traditional context-based detection methods. SCOUT constructs a saliency map by measuring how the removal of individual tokens affects the model's output logits for the target label, enabling detection of both conspicuous and subtle manipulation attempts. We evaluate SCOUT on established benchmark datasets (SST-2, IMDB, AG News) against conventional attacks (BadNet, AddSent, SynBkd, StyleBkd) and our novel attacks, demonstrating that SCOUT successfully detects these sophisticated threats while preserving accuracy on clean inputs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u578b\u4e0a\u4e0b\u6587\u611f\u77e5\u540e\u95e8\u653b\u51fb\u573a\u666f\uff0c\u5e76\u5f00\u53d1\u4e86SCOUT\u9632\u5fa1\u6846\u67b6\u6765\u68c0\u6d4b\u4f20\u7edf\u548c\u590d\u6742\u540e\u95e8\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5bf9\u6297\u4f7f\u7528\u4e0a\u4e0b\u6587\u9002\u5f53\u89e6\u53d1\u5668\u7684\u590d\u6742\u540e\u95e8\u653b\u51fb\uff0c\u8fd9\u4e9b\u653b\u51fb\u80fd\u65e0\u7f1d\u878d\u5165\u81ea\u7136\u8bed\u8a00\u4e2d\uff0c\u5bf9\u533b\u7597\u7b49\u654f\u611f\u9886\u57df\u7684AI\u7cfb\u7edf\u6784\u6210\u4e25\u91cd\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b0\u578b\u653b\u51fb\u573a\u666f\uff08ViralApp\u3001Fever\u3001Referral\uff09\uff0c\u5e76\u5f00\u53d1\u4e86SCOUT\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u663e\u8457\u6027\u7684\u4ee4\u724c\u7ea7\u5206\u6790\u6765\u8bc6\u522b\u540e\u95e8\u89e6\u53d1\u5668\u3002SCOUT\u901a\u8fc7\u6d4b\u91cf\u79fb\u9664\u5355\u4e2a\u4ee4\u724c\u5bf9\u76ee\u6807\u6807\u7b7e\u8f93\u51fa\u903b\u8f91\u7684\u5f71\u54cd\u6765\u6784\u5efa\u663e\u8457\u56fe\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6570\u636e\u96c6\uff08SST-2\u3001IMDB\u3001AG News\uff09\u4e0a\u8bc4\u4f30SCOUT\u5bf9\u6297\u4f20\u7edf\u653b\u51fb\uff08BadNet\u3001AddSent\u7b49\uff09\u548c\u65b0\u578b\u653b\u51fb\u7684\u6548\u679c\uff0c\u8bc1\u660eSCOUT\u80fd\u6210\u529f\u68c0\u6d4b\u590d\u6742\u5a01\u80c1\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5e72\u51c0\u8f93\u5165\u7684\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "SCOUT\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u540e\u95e8\u653b\u51fb\u9632\u5fa1\u7684\u5c40\u9650\u6027\uff0c\u80fd\u591f\u68c0\u6d4b\u4f7f\u7528\u4e0a\u4e0b\u6587\u9002\u5f53\u89e6\u53d1\u5668\u7684\u590d\u6742\u653b\u51fb\uff0c\u4e3aAI\u7cfb\u7edf\u5728\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
{"id": "2512.11169", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "\u63d0\u51faCORL\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\uff0c\u4ee5\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u6700\u5927\u5316\u64cd\u4f5c\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5efa\u6a21\u968f\u673a\u95ee\u9898\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4f20\u7edfMILP\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u5efa\u6a21\u968f\u673a\u771f\u5b9e\u4e16\u754c\u95ee\u9898\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0d\u4f73\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\uff0c\u9700\u8981\u771f\u5b9e\u6700\u4f18\u51b3\u7b56\uff0c\u5e76\u4f7f\u7528MILP\u68af\u5ea6\u7684\u66ff\u4ee3\u65b9\u6cd5\u3002", "method": "\u5c06MILP\u5efa\u6a21\u4e3a\u53ef\u5fae\u5206\u7684\u968f\u673a\u7b56\u7565\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u8fdb\u884c\u7aef\u5230\u7aef\u5fae\u8c03\uff0c\u4ee5\u6700\u5927\u5316\u64cd\u4f5c\u6027\u80fd\u3002", "result": "\u5728\u7b80\u5355\u7684\u7ec4\u5408\u5e8f\u5217\u51b3\u7b56\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86CORL\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "CORL\u6846\u67b6\u901a\u8fc7\u5c06MILP\u5efa\u6a21\u4e3a\u53ef\u5fae\u5206\u7684\u968f\u673a\u7b56\u7565\uff0c\u6210\u529f\u5730\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u7ec4\u5408\u5e8f\u5217\u51b3\u7b56\u95ee\u9898\u7684\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11112", "categories": ["cs.CR", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11112", "abs": "https://arxiv.org/abs/2512.11112", "authors": ["Tianye Dai", "Hammurabi Mendes", "Heuichan Lim"], "title": "An LLVM-Based Optimization Pipeline for SPDZ", "comment": null, "summary": "Actively secure arithmetic MPC is now practical for real applications, but performance and usability are still limited by framework-specific compilation stacks, the need for programmers to explicitly express parallelism, and high communication overhead. We design and implement a proof-of-concept LLVM-based optimization pipeline for the SPDZ protocol that addresses these bottlenecks. Our front end accepts a subset of C with lightweight privacy annotations and lowers it to LLVM IR, allowing us to reuse mature analyses and transformations to automatically batch independent arithmetic operations. Our back end performs data-flow and control-flow analysis on the optimized IR to drive a non-blocking runtime scheduler that overlaps independent operations and aggressively overlaps communication with computation; when enabled, it can map batched operations to GPU kernels. This design preserves a low learning curve by using a mainstream language and hiding optimization and hardware-specific mechanics from programmers. We evaluate the system on controlled microbenchmarks against MP-SPDZ, focusing on online phase performance. Our CPU back end achieves up to 5.56 times speedup under intermediate and heavy algebraic workloads, shows strong scaling with thread count, and our GPU back end scales better as the input size increases. Overall, these results indicate that leveraging LLVM with protocol-aware scheduling is an effective architectural direction for extracting parallelism without sacrificing usability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eLLVM\u7684SPDZ\u534f\u8bae\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u6279\u5904\u7406\u3001\u975e\u963b\u585e\u8c03\u5ea6\u548cGPU\u52a0\u901f\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u591a\u65b9\u8ba1\u7b97\u7684\u6027\u80fd\u800c\u4e0d\u727a\u7272\u53ef\u7528\u6027", "motivation": "\u73b0\u6709\u5b89\u5168\u7b97\u672fMPC\u6846\u67b6\u5b58\u5728\u7f16\u8bd1\u6808\u4f9d\u8d56\u3001\u9700\u663e\u5f0f\u5e76\u884c\u7f16\u7a0b\u3001\u901a\u4fe1\u5f00\u9500\u9ad8\u7b49\u9650\u5236\u6027\u80fd\u548c\u4f7f\u7528\u7684\u95ee\u9898", "method": "\u8bbe\u8ba1LLVM\u524d\u7aef\u63a5\u53d7\u5e26\u9690\u79c1\u6ce8\u91ca\u7684C\u5b50\u96c6\uff0c\u540e\u7aef\u8fdb\u884c\u6570\u636e\u6d41\u548c\u63a7\u5236\u6d41\u5206\u6790\u9a71\u52a8\u975e\u963b\u585e\u8c03\u5ea6\u5668\uff0c\u652f\u6301CPU/GPU\u5e76\u884c\u8ba1\u7b97", "result": "CPU\u540e\u7aef\u5728\u4e2d\u7b49\u548c\u91cd\u5ea6\u4ee3\u6570\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u6700\u9ad85.56\u500d\u52a0\u901f\uff0cGPU\u540e\u7aef\u968f\u8f93\u5165\u89c4\u6a21\u6269\u5927\u5c55\u73b0\u66f4\u597d\u6269\u5c55\u6027", "conclusion": "\u7ed3\u5408LLVM\u548c\u534f\u8bae\u611f\u77e5\u8c03\u5ea6\u662f\u6709\u6548\u63d0\u53d6\u5e76\u884c\u6027\u540c\u65f6\u4fdd\u6301\u53ef\u7528\u6027\u7684\u67b6\u6784\u65b9\u5411"}}
{"id": "2512.11402", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11402", "abs": "https://arxiv.org/abs/2512.11402", "authors": ["Aryan Gupta", "Y. Raghu Reddy"], "title": "REMODEL-LLM: Transforming C code to Java using LLMs", "comment": null, "summary": "The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.", "AI": {"tldr": "\u672c\u7814\u7a76\u68c0\u9a8c\u4e8619\u4e2a\u5c0f\u53c2\u6570\u91cf\u5316LLM\u5728C\u5230Java\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u91c7\u7528AST\u8bed\u4e49\u5206\u89e3\u548c\u89c4\u5219\u7ea6\u675f\u63d0\u793a\u7b56\u7565\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u6027\u80fd\u5206\u4e3a\u4e09\u4e2a\u5c42\u7ea7\uff0c\u4ec5\u4e09\u4e2a\u6a21\u578b\u901a\u8fc7\u8d85\u8fc750%\u6d4b\u8bd5\uff0c\u4f46\u5bf9\u590d\u6742C\u6982\u5ff5\u4ecd\u5b58\u5728\u660e\u663e\u5c40\u9650\u3002", "motivation": "C\u5230Java\u7684\u81ea\u52a8\u7ffb\u8bd1\u56e0\u7f16\u7a0b\u8303\u5f0f\u3001\u5185\u5b58\u6a21\u578b\u548c\u6570\u636e\u7c7b\u578b\u5dee\u5f02\u800c\u5177\u6709\u6311\u6218\u6027\uff0c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5c0f\u53c2\u6570\u91cf\u5316LLM\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u5b9e\u9645\u6548\u80fd\u3002", "method": "\u6784\u5efa\u6df7\u5408\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u62bd\u8c61\u8bed\u6cd5\u6811\u8fdb\u884c\u8bed\u4e49\u5206\u89e3\uff0c\u5e76\u91c7\u7528\u9ad8\u5ea6\u7ea6\u675f\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u7b56\u7565\uff0c\u5bf919\u4e2a\u53c2\u6570\u91cf\u5c0f\u4e8e200\u4ebf\u7684\u91cf\u5316LLM\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u6027\u80fd\u5448\u73b0\u4e09\u7ea7\u5206\u5316\uff1a\u7b2c\u4e09\u68af\u961f\u6a21\u578b\u5b8c\u5168\u5931\u8d25\uff1b\u7b2c\u4e8c\u68af\u961f\u751f\u6210\u53ef\u8fd0\u884c\u4ee3\u7801\u4f46\u5b58\u5728\u8bed\u4e49\u9519\u8bef\uff1b\u4ec5\u7b2c\u4e00\u68af\u961f\u4e09\u4e2a\u6a21\u578b\u901a\u8fc7\u8d8550%\u6d4b\u8bd5\uff0c\u4f46\u5728\u5904\u7406\u51fd\u6570\u6307\u9488\u7b49\u590d\u6742\u6982\u5ff5\u65f6\u5168\u90e8\u5931\u8d25\u3002", "conclusion": "\u5f53\u524d\u5c0f\u53c2\u6570\u91cf\u5316LLM\u5728C\u5230Java\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u5b58\u5728\u660e\u663e\u80fd\u529b\u4e0a\u9650\uff0c\u4ec5\u5c11\u6570\u6a21\u578b\u8868\u73b0\u53ef\u884c\uff0c\u4f46\u5bf9\u590d\u6742C\u8bed\u8a00\u7279\u6027\u4ecd\u7f3a\u4e4f\u8db3\u591f\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2512.11213", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver\u6846\u67b6\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u53cc\u5c42\u89c4\u5212\u67b6\u6784\uff0c\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u6280\u672f\u96be\u4ee5\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6709\u6548\u5e94\u7528\uff0c\u7f3a\u4e4f\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u4fc3\u8fdb\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u8ba1\u7b97\u5206\u914d\u673a\u5236\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u534f\u4f5c\uff08\u53ef\u8c03\u7528\u51fd\u6570\u5c01\u88c5\u53ef\u91cd\u7528\u5de5\u4f5c\u6d41\uff09\u548c\u53cc\u5c42\u89c4\u5212\u67b6\u6784\uff08\u57fa\u4e8e\u5f53\u524d\u72b6\u6001\u63a8\u7406\u540c\u65f6\u63a8\u6d4b\u672a\u6765\u6b65\u9aa4\u6765\u4f18\u5316\u8ba1\u7b97\u5206\u914d\uff09\u3002", "result": "\u5728\u590d\u6742\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFutureWeaver\u5728\u4e0d\u540c\u9884\u7b97\u8bbe\u7f6e\u4e0b consistently \u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "FutureWeaver\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e2d\u7684\u63a8\u7406\u65f6\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8ba1\u7b97\u5206\u914d\u6846\u67b6\u3002"}}
{"id": "2512.11482", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11482", "abs": "https://arxiv.org/abs/2512.11482", "authors": ["Melih Catal", "Pooja Rani", "Harald C. Gall"], "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models", "comment": null, "summary": "Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.11135", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11135", "abs": "https://arxiv.org/abs/2512.11135", "authors": ["Karthik Garimella", "Negar Neda", "Austin Ebel", "Nandan Kumar Jha", "Brandon Reagen"], "title": "Network and Compiler Optimizations for Efficient Linear Algebra Kernels in Private Transformer Inference", "comment": "10 pages, 6 figures", "summary": "Large language model (LLM) based services are primarily structured as client-server interactions, with clients sending queries directly to cloud providers that host LLMs. This approach currently compromises data privacy as all queries must be processed in the cloud and in the clear. Fully Homomorphic Encryption (FHE) is a solution to this data privacy issue by enabling computations directly upon encrypted queries. However, running encrypted transformer inference is challenging as programmers must map standard kernels to the constrained instruction set provided by FHE. In this work, we explore implementations of linear algebra kernels needed for transformer inference in FHE and understand how network optimization can help mitigate FHE costs while remaining performant.\n  We leverage the Orion PyTorch to FHE framework to benchmark several linear algebra kernels in order to profile two linear transformation methods, packed row and BSGS, and find that BSGS outperforms packed row methods by up to $13.7 \\times$ at transformer-level scales. We also incorporate network-level pruning strategies that reduce FHE runtimes of feed forward layers by up to $11.46\\times$. Furthermore, we extend Orion to include ciphertext-ciphertext matrix-matrix products, a key component in the self-attention blocks. Finally, we perform a roofline analysis of FHE primitives and encrypted linear transformations and find that (SIMD encoded) implementations are memory-bound with primitives having roughly $0.1$ integer operations per byte of DRAM traffic. These findings illustrate the need for exploring alternative encoding schemes and models of computation within CKKS to unlock scalable private transformer inference. We conduct all experiments using the Orion framework which can be found at: https://github.com/baahl-nyu/orion.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.11270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11270", "abs": "https://arxiv.org/abs/2512.11270", "authors": ["Hong Je-Gal", "Chan-Bin Yi", "Hyun-Suk Lee"], "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation", "comment": "NeurIPS 2025 Workshop: Multi-Turn Interactions in Large Language Models. 26 pages, 8 figures", "summary": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.", "AI": {"tldr": "A-LAMP\u6846\u67b6\u4f7f\u7528LLM\u81ea\u52a8\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3aMDP\u5efa\u6a21\u548c\u7b56\u7565\u8bad\u7ec3\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u9a8c\u8bc1\u786e\u4fdd\u8bed\u4e49\u5bf9\u9f50\uff0c\u5728\u591a\u9886\u57df\u8868\u73b0\u4f18\u4e8e\u5355\u4e00\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u5c06RL\u5e94\u7528\u4e8e\u73b0\u5b9e\u4efb\u52a1\u9700\u8981\u624b\u52a8\u5c06\u975e\u6b63\u5f0f\u63cf\u8ff0\u8f6c\u5316\u4e3aMDP\u3001\u5b9e\u73b0\u53ef\u6267\u884c\u73af\u5883\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u6613\u53d7\u5efa\u6a21\u9519\u8bef\u3001\u4ee3\u7801\u8106\u5f31\u548c\u76ee\u6807\u4e0d\u5bf9\u9f50\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eLLM\u7684A-LAMP\u6846\u67b6\uff0c\u5c06\u5efa\u6a21\u3001\u7f16\u7801\u548c\u8bad\u7ec3\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u9636\u6bb5\uff0c\u81ea\u52a8\u5b8c\u6210\u4ece\u81ea\u7136\u8bed\u8a00\u5230MDP\u516c\u5f0f\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u8f6c\u5316\u3002", "result": "\u5728\u7ecf\u5178\u63a7\u5236\u4efb\u52a1\u548c\u81ea\u5b9a\u4e49RL\u9886\u57df\u4e2d\uff0cA-LAMP\u7684\u7b56\u7565\u751f\u6210\u80fd\u529b\u6301\u7eed\u4f18\u4e8e\u5355\u4e00\u6700\u5148\u8fdbLLM\u6a21\u578b\uff0c\u5176\u8f7b\u91cf\u7248\u751a\u81f3\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "A-LAMP\u901a\u8fc7\u81ea\u52a8\u5316\u6d41\u7a0b\u548c\u5206\u9636\u6bb5\u9a8c\u8bc1\u63d0\u9ad8\u4e86RL\u5e94\u7528\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u9760\u6027\uff0c\u5931\u8d25\u5206\u6790\u63ed\u793a\u4e86\u6539\u8fdb\u539f\u56e0\uff0c\u6848\u4f8b\u7814\u7a76\u8bc1\u5b9e\u4e86\u5176\u6b63\u786e\u6027\u3002"}}
{"id": "2512.11271", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11271", "abs": "https://arxiv.org/abs/2512.11271", "authors": ["Yuxing Chen", "Basem Suleiman", "Qifan Chen"], "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning", "comment": "4 pages, 3 figures", "summary": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.", "AI": {"tldr": "TriFlow\uff1a\u4e00\u79cd\u6e10\u8fdb\u5f0f\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u6d41\u7a0b\u89e3\u51b3\u73b0\u5b9e\u65c5\u884c\u89c4\u5212\u4e2d\u7684\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523091.1%-97%\u7684\u6210\u529f\u7387\uff0c\u6548\u7387\u63d0\u534710\u500d", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u5728\u65c5\u884c\u89c4\u5212\u4e2d\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u7a7a\u95f4\u3001\u65f6\u95f4\u548c\u9884\u7b97\u7ea6\u675f\uff0c\u4e14\u5b58\u5728\u5de5\u5177\u534f\u8c03\u548c\u6548\u7387\u95ee\u9898", "method": "\u63d0\u51fa\u4e09\u9636\u6bb5\u6d41\u7a0b\uff08\u68c0\u7d22-\u89c4\u5212-\u6cbb\u7406\uff09\uff0c\u901a\u8fc7\u89c4\u5219\u4e0eLLM\u534f\u4f5c\u6e10\u8fdb\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u6784\u5efa\u7ea6\u675f\u4e00\u81f4\u7684\u884c\u7a0b\uff0c\u5e76\u8fdb\u884c\u6709\u754c\u8fed\u4ee3\u4f18\u5316", "result": "\u5728TravelPlanner\u548cTripTailor\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u523091.1%\u548c97%\u7684\u6700\u7ec8\u901a\u8fc7\u7387\uff0c\u8fd0\u884c\u6548\u7387\u6bd4\u73b0\u6709SOTA\u63d0\u534710\u500d\u4ee5\u4e0a", "conclusion": "TriFlow\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u590d\u6742\u7ea6\u675f\u4e0b\u7684\u65c5\u884c\u89c4\u5212\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7ea6\u675f\u6ee1\u8db3\u4e0e\u4e2a\u6027\u5316\u9700\u6c42\u7684\u5e73\u8861"}}
{"id": "2512.11589", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11589", "abs": "https://arxiv.org/abs/2512.11589", "authors": ["Lukas Twist"], "title": "A Study of Library Usage in Agent-Authored Pull Requests", "comment": "5 pages, 3 tables", "summary": "Coding agents are becoming increasingly capable of completing end-to-end software engineering workflows that previously required a human developer, including raising pull requests (PRs) to propose their changes. However, we still know little about how these agents use libraries when generating code, a core part of real-world software development. To fill this gap, we study 26,760 agent-authored PRs from the AIDev dataset to examine three questions: how often do agents import libraries, how often do they introduce new dependencies (and with what versioning), and which specific libraries do they choose? We find that agents often import libraries (29.5% of PRs) but rarely add new dependencies (1.3% of PRs); and when they do, they follow strong versioning practices (75.0% specify a version), an improvement on direct LLM usage where versions are rarely mentioned. Generally, agents draw from a surprisingly diverse set of external libraries, contrasting with the limited \"library preferences\" seen in prior non-agentic LLM studies. Our results offer an early empirical view into how AI coding agents interact with today's software ecosystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e8626,760\u4e2aAI\u7f16\u7a0b\u667a\u80fd\u4f53\u64b0\u5199\u7684PRs\uff0c\u53d1\u73b0\u667a\u80fd\u4f53\u5728\u5e93\u4f7f\u7528\u4e0a\u8868\u73b0\u4e13\u4e1a\uff1a\u7ecf\u5e38\u5bfc\u5165\u5e93\u4f46\u5f88\u5c11\u6dfb\u52a0\u65b0\u4f9d\u8d56\uff0c\u7248\u672c\u63a7\u5236\u5b9e\u8df5\u826f\u597d\uff0c\u4e14\u5e93\u9009\u62e9\u591a\u6837\u5316\uff0c\u4e3aAI\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u652f\u6301\u3002", "motivation": "\u586b\u8865\u5bf9\u7f16\u7a0b\u667a\u80fd\u4f53\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4f7f\u7528\u5e93\u884c\u4e3a\u7684\u7406\u89e3\u7a7a\u767d\uff0c\u73b0\u6709\u7814\u7a76\u5bf9\u6b64\u4e86\u89e3\u751a\u5c11\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u6765\u81eaAIDev\u6570\u636e\u96c6\u768426,760\u4e2a\u667a\u80fd\u4f53\u64b0\u5199\u7684\u62c9\u53d6\u8bf7\u6c42\uff0c\u91cd\u70b9\u8003\u5bdf\u4e09\u4e2a\u95ee\u9898\uff1a\u667a\u80fd\u4f53\u5bfc\u5165\u5e93\u7684\u9891\u7387\u3001\u5f15\u5165\u65b0\u4f9d\u8d56\u7684\u9891\u7387\uff08\u53ca\u7248\u672c\u63a7\u5236\u60c5\u51b5\uff09\u4ee5\u53ca\u5177\u4f53\u9009\u62e9\u7684\u5e93\u7c7b\u578b\u3002", "result": "\u667a\u80fd\u4f53\u7ecf\u5e38\u5bfc\u5165\u5e93\uff0829.5%\u7684PRs\uff09\uff0c\u4f46\u5f88\u5c11\u6dfb\u52a0\u65b0\u4f9d\u8d56\uff081.3%\u7684PRs\uff09\uff1b\u5f53\u6dfb\u52a0\u65b0\u4f9d\u8d56\u65f6\uff0c75.0%\u4f1a\u6307\u5b9a\u7248\u672c\uff0c\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528LLM\u65f6\u5f88\u5c11\u63d0\u53ca\u7248\u672c\u7684\u60c5\u51b5\uff1b\u667a\u80fd\u4f53\u4f7f\u7528\u7684\u5916\u90e8\u5e93\u79cd\u7c7b\u975e\u5e38\u591a\u6837\u5316\uff0c\u4e0e\u5148\u524d\u975e\u667a\u80fd\u4f53LLM\u7814\u7a76\u4e2d\u89c2\u5bdf\u5230\u7684\u6709\u9650\"\u5e93\u504f\u597d\"\u5f62\u6210\u5bf9\u6bd4\u3002", "conclusion": "AI\u7f16\u7a0b\u667a\u80fd\u4f53\u5728\u5e93\u4f7f\u7528\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9075\u5faa\u826f\u597d\u7684\u7248\u672c\u63a7\u5236\u5b9e\u8df5\uff0c\u5e76\u4e14\u80fd\u591f\u5229\u7528\u591a\u6837\u5316\u7684\u5916\u90e8\u5e93\u751f\u6001\u7cfb\u7edf\uff0c\u8fd9\u4e3aAI\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u96c6\u6210\u63d0\u4f9b\u4e86\u79ef\u6781\u7684\u65e9\u671f\u5b9e\u8bc1\u4f9d\u636e\u3002"}}
{"id": "2512.11323", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11323", "abs": "https://arxiv.org/abs/2512.11323", "authors": ["Jianyi Zhang", "Ziyin Zhou", "Xu Ji", "Shizhao Liu", "Zhangchi Zhao"], "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving", "comment": null, "summary": "Benefiting from strong and efficient multi-modal alignment strategies, Large Visual Language Models (LVLMs) are able to simulate human visual and reasoning capabilities, such as solving CAPTCHAs. However, existing benchmarks based on visual CAPTCHAs still face limitations. Previous studies, when designing benchmarks and datasets, customized them according to their research objectives. Consequently, these benchmarks cannot comprehensively cover all CAPTCHA types. Notably, there is a dearth of dedicated benchmarks for LVLMs. To address this problem, we introduce a novel CAPTCHA benchmark for the first time, named CAPTURE CAPTCHA for Testing Under Real-world Experiments, specifically for LVLMs. Our benchmark encompasses 4 main CAPTCHA types and 25 sub-types from 31 vendors. The diversity enables a multi-dimensional and thorough evaluation of LVLM performance. CAPTURE features extensive class variety, large-scale data, and unique LVLM-tailored labels, filling the gaps in previous research in terms of data comprehensiveness and labeling pertinence. When evaluated by this benchmark, current LVLMs demonstrate poor performance in solving CAPTCHAs.", "AI": {"tldr": "\u7814\u7a76\u8005\u9996\u6b21\u4e3aLVLMs\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aCAPTURE\u7684\u7efc\u5408\u6027CAPTCHA\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d64\u5927\u7c7b\u578b25\u79cd\u5b50\u7c7b\u578b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u73b0\u6709CAPTCHA\u57fa\u51c6\u6d4b\u8bd5\u5c40\u9650\u4e8e\u7279\u5b9a\u7814\u7a76\u76ee\u6807\uff0c\u65e0\u6cd5\u5168\u9762\u8986\u76d6\u6240\u6709\u9a8c\u8bc1\u7801\u7c7b\u578b\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9LVLMs\u7684\u4e13\u7528\u57fa\u51c6\u3002", "method": "\u5f15\u5165CAPTURE\u57fa\u51c6\uff0c\u5305\u542b\u6765\u81ea31\u4e2a\u4f9b\u5e94\u5546\u76844\u79cd\u4e3b\u8981CAPTCHA\u7c7b\u578b\u548c25\u79cd\u5b50\u7c7b\u578b\uff0c\u5177\u6709\u5e7f\u6cdb\u7c7b\u522b\u591a\u6837\u6027\u3001\u5927\u89c4\u6a21\u6570\u636e\u548c\u4e13\u95e8\u9488\u5bf9LVLMs\u7684\u6807\u7b7e\u3002", "result": "\u5f53\u524dLVLMs\u5728\u89e3\u51b3CAPTCHAs\u65b9\u9762\u8868\u73b0\u8f83\u5dee\uff0c\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u6027\u80fd\u4e0d\u8db3\u3002", "conclusion": "CAPTURE\u57fa\u51c6\u586b\u8865\u4e86\u73b0\u6709\u7814\u7a76\u5728\u6570\u636e\u5168\u9762\u6027\u548c\u6807\u7b7e\u9488\u5bf9\u6027\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3aLVLMs\u63d0\u4f9b\u4e86\u591a\u7ef4\u5ea6\u7684\u5168\u9762\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2512.11269", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11269", "abs": "https://arxiv.org/abs/2512.11269", "authors": ["Siddharth Jayashankar", "Joshua Kim", "Michael B. Sullivan", "Wenting Zheng", "Dimitrios Skarlatos"], "title": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference", "comment": null, "summary": "Encrypted AI using fully homomorphic encryption (FHE) provides strong privacy guarantees; but its slow performance has limited practical deployment. Recent works proposed ASICs to accelerate FHE, but require expensive advanced manufacturing processes that constrain their accessibility. GPUs are a far more accessible platform, but achieving ASIC-level performance using GPUs has remained elusive. Furthermore, state-of-the-art approaches primarily focus on small models that fit comfortably within a single device. Supporting large models such as LLMs in FHE introduces a dramatic increase in computational complexity that requires optimized GPU kernels, along with managing terabyte-scale memory footprints that far exceed the capacity of a single GPU. This paper presents Cerium, a multi-GPU framework for FHE inference on large models. Cerium integrates a domain-specific language, an optimizing compiler, and a runtime system to automatically generate high-performance GPU kernels, manage terabyte-scale memory footprints, and parallelize computation across multiple GPUs. It introduces new IR constructs, compiler passes, sparse polynomial representations, memory-efficient data layouts, and communication-aware parallelization techniques that together enable encrypted inference for models ranging from small CNNs to Llama3-8B. We build Cerium on NVIDIA GPUs and demonstrate significant performance gains. For small models, Cerium outperforms expert-written hand-optimized GPU libraries by up to 2.25 times. Cerium achieves performance competitive with state-of-the-art FHE ASICs, outright matching prior FHE ASIC CraterLake. It is the first GPU system to execute bootstrapping in under 10 milliseconds, achieving 7.5 milliseconds, and is the first to demonstrate encrypted inference for BERT-Base and Llama3-8B in 8 seconds and 134 seconds, respectively.", "AI": {"tldr": "Cerium\u662f\u4e00\u4e2a\u7528\u4e8e\u5927\u578b\u6a21\u578b\u5168\u540c\u6001\u52a0\u5bc6\u63a8\u7406\u7684\u591aGPU\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\u3001\u7ba1\u7406TB\u7ea7\u5185\u5b58\u548c\u8de8GPU\u5e76\u884c\u8ba1\u7b97\uff0c\u9996\u6b21\u5728GPU\u4e0a\u5b9e\u73b0BERT-Base\u548cLlama3-8B\u7684\u52a0\u5bc6\u63a8\u7406\u3002", "motivation": "\u5168\u540c\u6001\u52a0\u5bc6\u867d\u63d0\u4f9b\u5f3a\u9690\u79c1\u4fdd\u969c\uff0c\u4f46\u6027\u80fd\u6162\u4e14\u73b0\u6709ASIC\u65b9\u6848\u6210\u672c\u9ad8\u3001\u53ef\u8bbf\u95ee\u6027\u5dee\uff1bGPU\u5e73\u53f0\u66f4\u6613\u83b7\u53d6\u4f46\u96be\u4ee5\u8fbe\u5230ASIC\u7ea7\u6027\u80fd\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u4ec5\u652f\u6301\u5c0f\u6a21\u578b\uff0c\u7f3a\u4e4f\u5bf9\u5927\u6a21\u578b\uff08\u5982LLMs\uff09\u52a0\u5bc6\u63a8\u7406\u7684\u652f\u6301\u3002", "method": "\u96c6\u6210\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u3001\u4f18\u5316\u7f16\u8bd1\u5668\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u5f15\u5165\u65b0IR\u7ed3\u6784\u3001\u7f16\u8bd1\u5668\u4f20\u9012\u3001\u7a00\u758f\u591a\u9879\u5f0f\u8868\u793a\u3001\u5185\u5b58\u9ad8\u6548\u6570\u636e\u5e03\u5c40\u548c\u901a\u4fe1\u611f\u77e5\u5e76\u884c\u6280\u672f\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\u5e76\u7ba1\u7406\u591aGPU\u8ba1\u7b97\u3002", "result": "\u5728NVIDIA GPU\u4e0a\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1a\u5c0f\u6a21\u578b\u6bd4\u624b\u5de5\u4f18\u5316\u5e93\u5feb2.25\u500d\uff1b\u6027\u80fd\u4e0e\u5148\u8fdbFHE ASIC\u7ade\u4e89\uff0c\u5339\u914dCraterLake\uff1b\u9996\u6b21\u5728GPU\u4e0a10\u6beb\u79d2\u5185\u5b8c\u6210\u5f15\u5bfc\uff087.5\u6beb\u79d2\uff09\uff0c\u9996\u6b21\u5b9e\u73b0BERT-Base\uff088\u79d2\uff09\u548cLlama3-8B\uff08134\u79d2\uff09\u52a0\u5bc6\u63a8\u7406\u3002", "conclusion": "Cerium\u7a81\u7834\u4e86GPU\u52a0\u901fFHE\u7684\u6027\u80fd\u9650\u5236\uff0c\u4f7f\u5927\u6a21\u578b\u52a0\u5bc6\u63a8\u7406\u53d8\u5f97\u53ef\u884c\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4AI\u63d0\u4f9b\u4e86\u53ef\u8bbf\u95ee\u7684\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11421", "abs": "https://arxiv.org/abs/2512.11421", "authors": ["Gonca G\u00fcrsun"], "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance", "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u4efb\u52a1\u5b8c\u6210\u6846\u67b6\uff0c\u4f7f\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u80fd\u591f\u5728\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e2d\u6309\u7167\u660e\u786e\u7684\u884c\u4e3a\u6307\u5bfc\u884c\u52a8\uff0c\u63d0\u9ad8\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u7f3a\u4e4f\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u8f7b\u91cf\u7ea7\u4efb\u52a1\u5206\u6790\u5668\uff08\u9009\u62e9\u63a8\u7406\u548c\u751f\u6210\u7b56\u7565\uff09\u3001\u63a8\u7406\u6a21\u5757\uff08\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\u89c2\u5bdf-\u884c\u52a8\u6620\u5c04\uff09\u548c\u751f\u6210\u6a21\u5757\uff08\u901a\u8fc7\u9a8c\u8bc1\u6216\u786e\u5b9a\u6027\u5408\u6210\u5f3a\u5236\u6267\u884c\u7ea6\u675f\u517c\u5bb9\u8f93\u51fa\uff09\u3002", "result": "\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u65f6\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u5171\u540c\u8fdb\u5316\uff0c\u4ea7\u751f\u53ef\u4fe1\u8d56\u7684\u884c\u4e3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u4f7fLLM\u667a\u80fd\u4f53\u5728\u7ed3\u6784\u5316\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u53ef\u9760\u548c\u53ef\u9a8c\u8bc1\u7684\u884c\u4e3a\u3002"}}
{"id": "2512.11316", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11316", "abs": "https://arxiv.org/abs/2512.11316", "authors": ["Zhenshuo Zhao", "Maria Spichkova", "Duttkumari Champavat", "Juilee N. Kulkarni", "Sahil Singla", "Muhammad A. Zulkefli", "Pradhuman Khandelwal"], "title": "Visualisation for the CIS benchmark scanning results", "comment": "Preprint. Accepted to the ICICT'26. Final version to be published by in conference proceedings by Springer LNNS", "summary": "In this paper, we introduce GraphSecure, a web application that provides advanced analysis and visualisation of security scanning results. GraphSecure enables users to initiate scans for their AWS account, validate them against specific Center for Internet Security (CIS) Benchmarks and return results, showcase those returned results in the form of statistical charts and warn the users about their account status.", "AI": {"tldr": "GraphSecure\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u6790AWS\u5b89\u5168\u626b\u63cf\u7ed3\u679c\u7684\u53ef\u89c6\u5316WEB\u5e94\u7528\uff0c\u652f\u6301CIS\u57fa\u51c6\u9a8c\u8bc1\u548c\u8d26\u6237\u72b6\u6001\u9884\u8b66\u3002", "motivation": "\u5f53\u524d\u4e91\u5b89\u5168\u5206\u6790\u5de5\u5177\u7f3a\u4e4f\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u754c\u9762\u548cCIS\u57fa\u51c6\u96c6\u6210\uff0c\u7528\u6237\u96be\u4ee5\u5feb\u901f\u8bc4\u4f30AWS\u8d26\u6237\u5b89\u5168\u6027\u3002", "method": "\u5f00\u53d1WEB\u5e94\u7528\uff0c\u96c6\u6210AWS\u5b89\u5168\u626b\u63cf\u3001CIS\u57fa\u51c6\u9a8c\u8bc1\u3001\u6570\u636e\u7edf\u8ba1\u56fe\u8868\u751f\u6210\u548c\u9884\u8b66\u529f\u80fd\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u6267\u884c\u626b\u63cf\u3001\u57fa\u51c6\u9a8c\u8bc1\u3001\u53ef\u89c6\u5316\u5c55\u793a\u548c\u72b6\u6001\u9884\u8b66\u7684\u4e00\u4f53\u5316\u5b89\u5168\u5206\u6790\u5e73\u53f0\u3002", "conclusion": "GraphSecure\u6709\u6548\u63d0\u5347\u4e86\u4e91\u5b89\u5168\u8bc4\u4f30\u7684\u6548\u7387\u548c\u76f4\u89c2\u6027\uff0c\u4e3aAWS\u7528\u6237\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u5b89\u5168\u7ba1\u7406\u5de5\u5177\u3002"}}
{"id": "2512.11426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance\u6846\u67b6\uff1a\u4e00\u79cd\u5728\u660e\u786e\u4ee4\u724c\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9aa8\u5e72\u4f18\u5148\u62d3\u6251\u8bbe\u8ba1\u65b9\u6cd5", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e3b\u8981\u5173\u6ce8\u901a\u4fe1\u62d3\u6251\u4f18\u5316\u548c\u667a\u80fd\u4f53\u9aa8\u5e72\u9009\u62e9\uff0c\u4f46\u7f3a\u4e4f\u5728\u660e\u786e\u4ee4\u724c\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u5efa\u6a21\u548c\u4f18\u5316\uff0c\u5bfc\u81f4\u9884\u7b97\u7ea6\u675f\u65f6\u6210\u672c\u6548\u76ca\u4e0d\u4f73", "method": "1) \u9aa8\u5e72\u5bfc\u5411\u7684\u667a\u80fd\u4f53\u751f\u6210\uff1a\u901a\u8fc7LLM\u6c60\u6784\u5efa\u3001\u6c60\u9009\u62e9\u548c\u89d2\u8272-\u9aa8\u5e72\u5339\u914d\u6784\u5efa\u5f02\u6784\u9aa8\u5e72\u667a\u80fd\u4f53\uff1b2) \u81ea\u9002\u5e94MAS\u62d3\u6251\u751f\u6210\uff1a\u901a\u8fc7\u667a\u80fd\u4f53\u8868\u793a\u5b66\u4e60\u3001\u95e8\u63a7\u548c\u5ef6\u8fdf\u611f\u77e5\u62d3\u6251\u5408\u6210\u6307\u5bfc\u667a\u80fd\u4f53\u95f4\u901a\u4fe1", "result": "\u572814\u4e2a\u5019\u9009LLM\u9aa8\u5e72\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentBalance\u5728\u5339\u914d\u4ee4\u724c\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5206\u522b\u5b9e\u73b010%\u548c22%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u6027\u80fd-\u9884\u7b97\u66f2\u7ebf\u4e0a\u8868\u73b0\u4f18\u5f02", "conclusion": "AgentBalance\u53ef\u4f5c\u4e3a\u73b0\u6709MAS\u7684\u63d2\u4ef6\uff0c\u5728\u76f8\u540c\u7ea6\u675f\u4e0b\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684LLM\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u7684\u9884\u7b97\u611f\u77e5\u90e8\u7f72"}}
{"id": "2512.11433", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11433", "abs": "https://arxiv.org/abs/2512.11433", "authors": ["Agustin Martin Picard", "Thibaut Boissin", "Varshini Subhash", "R\u00e9mi Cad\u00e8ne", "Thomas Fel"], "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics", "comment": null, "summary": "Attribution methods are among the most prevalent techniques in Explainable Artificial Intelligence (XAI) and are usually evaluated and compared using Fidelity metrics, with Insertion and Deletion being the most popular. These metrics rely on a baseline function to alter the pixels of the input image that the attribution map deems most important. In this work, we highlight a critical problem with these metrics: the choice of a given baseline will inevitably favour certain attribution methods over others. More concerningly, even a simple linear model with commonly used baselines contradicts itself by designating different optimal methods. A question then arises: which baseline should we use? We propose to study this problem through two desirable properties of a baseline: (i) that it removes information and (ii) that it does not produce overly out-of-distribution (OOD) images. We first show that none of the tested baselines satisfy both criteria, and there appears to be a trade-off among current baselines: either they remove information or they produce a sequence of OOD images. Finally, we introduce a novel baseline by leveraging recent work in feature visualisation to artificially produce a model-dependent baseline that removes information without being overly OOD, thus improving on the trade-off when compared to other existing baselines. Our code is available at https://github.com/deel-ai-papers/Back-to-the-Baseline", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u73b0\u6709XAI\u57fa\u51c6\u7ebf\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u65b0\u7684\u6a21\u578b\u4f9d\u8d56\u57fa\u51c6\u7ebf", "motivation": "\u73b0\u6709\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u4e2d\u7684\u57fa\u51c6\u7ebf\u9009\u62e9\u5b58\u5728\u95ee\u9898\uff0c\u4e0d\u540c\u57fa\u51c6\u7ebf\u4f1a\u504f\u597d\u4e0d\u540c\u5f52\u56e0\u65b9\u6cd5", "method": "\u901a\u8fc7\u5206\u6790\u57fa\u51c6\u7ebf\u7684\u4e24\u4e2a\u7406\u60f3\u7279\u6027\uff08\u79fb\u9664\u4fe1\u606f\u4e14\u4e0d\u8fc7\u5ea6\u4ea7\u751f\u5206\u5e03\u5916\u56fe\u50cf\uff09\uff0c\u63d0\u51fa\u57fa\u4e8e\u7279\u5f81\u53ef\u89c6\u5316\u7684\u65b0\u57fa\u51c6\u7ebf", "result": "\u8bc1\u660e\u73b0\u6709\u57fa\u51c6\u7ebf\u5747\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e24\u4e2a\u6807\u51c6\uff0c\u65b0\u57fa\u51c6\u7ebf\u5728\u6743\u8861\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5", "conclusion": "\u57fa\u51c6\u7ebf\u9009\u62e9\u5bf9\u5f52\u56e0\u65b9\u6cd5\u8bc4\u4f30\u6709\u663e\u8457\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u4e25\u8c28\u7684\u57fa\u51c6\u7ebf\u8bbe\u8ba1\u6807\u51c6"}}
{"id": "2512.11431", "categories": ["cs.CR", "cs.FL", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11431", "abs": "https://arxiv.org/abs/2512.11431", "authors": ["Qifan Zhang", "Zilin Shen", "Imtiaz Karim", "Elisa Bertino", "Zhou Li"], "title": "Proving DNSSEC Correctness: A Formal Approach to Secure Domain Name Resolution", "comment": null, "summary": "The Domain Name System Security Extensions (DNSSEC) are critical for preventing DNS spoofing, yet its specifications contain ambiguities and vulnerabilities that elude traditional \"break-and-fix\" approaches. A holistic, foundational security analysis of the protocol has thus remained an open problem. This paper introduces DNSSECVerif, the first framework for comprehensive, automated formal security analysis of the DNSSEC protocol suite. Built on the SAPIC+ symbolic verifier, our high-fidelity model captures protocol-level interactions, including cryptographic operations and stateful caching with fine-grained concurrency control. Using DNSSECVerif, we formally prove four of DNSSEC's core security guarantees and uncover critical ambiguities in the standards--notably, the insecure coexistence of NSEC and NSEC3. Our model also automatically rediscovers three classes of known attacks, demonstrating fundamental weaknesses in the protocol design. To bridge the model-to-reality gap, we validate our findings through targeted testing of mainstream DNS software and a large-scale measurement study of over 2.2 million open resolvers, confirming the real-world impact of these flaws. Our work provides crucial, evidence-based recommendations for hardening DNSSEC specifications and implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DNSSECVerif\u2014\u2014\u9996\u4e2a\u9488\u5bf9DNSSEC\u534f\u8bae\u5957\u4ef6\u7684\u81ea\u52a8\u5316\u5f62\u5f0f\u5316\u5b89\u5168\u5206\u6790\u6846\u67b6\uff0c\u7528\u4e8e\u53d1\u73b0\u534f\u8bae\u89c4\u8303\u4e2d\u7684\u6a21\u7cca\u6027\u548c\u6f0f\u6d1e\u3002", "motivation": "DNSSEC\u5bf9\u9632\u6b62DNS\u6b3a\u9a97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u89c4\u8303\u5b58\u5728\u6a21\u7cca\u6027\u548c\u6f0f\u6d1e\uff0c\u4f20\u7edf'\u6253\u7834-\u4fee\u590d'\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\uff0c\u6025\u9700\u7cfb\u7edf\u6027\u5b89\u5168\u5206\u6790\u3002", "method": "\u57fa\u4e8eSAPIC+\u7b26\u53f7\u9a8c\u8bc1\u5668\u6784\u5efa\u9ad8\u4fdd\u771f\u6a21\u578b\uff0c\u6355\u6349\u534f\u8bae\u7ea7\u4ea4\u4e92\uff08\u5305\u62ec\u52a0\u5bc6\u64cd\u4f5c\u548c\u7ec6\u7c92\u5ea6\u5e76\u53d1\u63a7\u5236\u7684\u72b6\u6001\u7f13\u5b58\uff09\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u5f62\u5f0f\u9a8c\u8bc1\u3002", "result": "\u6b63\u5f0f\u8bc1\u660e\u4e86DNSSEC\u7684\u56db\u4e2a\u6838\u5fc3\u5b89\u5168\u4fdd\u8bc1\uff0c\u53d1\u73b0\u6807\u51c6\u4e2d\u7684\u5173\u952e\u6a21\u7cca\u6027\uff08\u5982NSEC\u4e0eNSEC3\u7684\u4e0d\u5b89\u5168\u5171\u5b58\uff09\uff0c\u81ea\u52a8\u91cd\u65b0\u53d1\u73b0\u4e09\u7c7b\u5df2\u77e5\u653b\u51fb\u3002", "conclusion": "\u901a\u8fc7\u4e3b\u6d41DNS\u8f6f\u4ef6\u9488\u5bf9\u6027\u6d4b\u8bd5\u548c220\u4e07\u5f00\u653e\u89e3\u6790\u5668\u7684\u5927\u89c4\u6a21\u6d4b\u91cf\u9a8c\u8bc1\u4e86\u53d1\u73b0\u7684\u73b0\u5b9e\u5f71\u54cd\uff0c\u4e3a\u5f3a\u5316DNSSEC\u89c4\u8303\u548c\u5b9e\u73b0\u63d0\u4f9b\u4e86\u5173\u952e\u8bc1\u636e\u5efa\u8bae\u3002"}}
{"id": "2512.11463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11463", "abs": "https://arxiv.org/abs/2512.11463", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Taehyun Kim", "Eunhwan Park", "Jeesoo Lee", "Jeongdoo Lee", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Minsu Ha", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Minjae Kim", "Taewhan Kim", "Youngrok Kim", "Hyukjin Kweon", "Haesol Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Dongjoo Weon"], "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes", "comment": null, "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.", "AI": {"tldr": "Motif-2-12.7B-Reasoning\u662f\u4e00\u4e2a12.7B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u5f25\u5408\u5f00\u6e90\u6a21\u578b\u4e0e\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u7684\u5dee\u8ddd\u3002\u5b83\u901a\u8fc7\u7cfb\u7edf\u3001\u6570\u636e\u548c\u7b97\u6cd5\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u590d\u73b0\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u4e0e\u66f4\u5927\u53c2\u6570\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5f00\u6e90\u6743\u91cd\u7cfb\u7edf\u4e0e\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u540c\u65f6\u5728\u63a8\u7406\u9002\u5e94\u8fc7\u7a0b\u4e2d\u666e\u904d\u9762\u4e34\u6a21\u578b\u5d29\u6e83\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u6027\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1\uff09\u4f7f\u7528\u6df7\u5408\u5e76\u884c\u548c\u5185\u6838\u7ea7\u4f18\u5316\u7684\u5185\u5b58\u9ad8\u6548\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u630164K\u6807\u8bb0\u7684\u957f\u4e0a\u4e0b\u6587\uff1b2\uff09\u4e24\u9636\u6bb5\u76d1\u7763\u5fae\u8c03\u8bfe\u7a0b\uff0c\u901a\u8fc7\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u5bf9\u9f50\u5408\u6210\u6570\u636e\u7f13\u89e3\u5206\u5e03\u4e0d\u5339\u914d\uff1b3\uff09\u7a33\u5065\u7684\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6d41\u7a0b\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u6570\u636e\u8fc7\u6ee4\u548c\u6df7\u5408\u7b56\u7565\u8f68\u8ff9\u91cd\u7528\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cMotif-2-12.7B-Reasoning\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u53c2\u6570\u6570\u91cf\u663e\u8457\u66f4\u591a\u7684\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u4e3a\u5728\u73b0\u5b9e\u8ba1\u7b97\u7ea6\u675f\u4e0b\u6269\u5c55\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u84dd\u56fe\u3002"}}
{"id": "2512.11484", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11484", "abs": "https://arxiv.org/abs/2512.11484", "authors": ["Yukun Cheng", "Shiyu Zhu", "Changhai Ou", "Xingshuo Han", "Yuan Li", "Shihui Zheng"], "title": "Capacitive Touchscreens at Risk: Recovering Handwritten Trajectory on Smartphone via Electromagnetic Emanations", "comment": null, "summary": "This paper reveals and exploits a critical security vulnerability: the electromagnetic (EM) side channel of capacitive touchscreens leaks sufficient information to recover fine-grained, continuous handwriting trajectories. We present Touchscreen Electromagnetic Side-channel Leakage Attack (TESLA), a non-contact attack framework that captures EM signals generated during on-screen writing and regresses them into two-dimensional (2D) handwriting trajectories in real time. Extensive evaluations across a variety of commercial off-the-shelf (COTS) smartphones show that TESLA achieves 77% character recognition accuracy and a Jaccard index of 0.74, demonstrating its capability to recover highly recognizable motion trajectories that closely resemble the original handwriting under realistic attack conditions.", "AI": {"tldr": "TESLA\u653b\u51fb\u5229\u7528\u89e6\u6478\u5c4f\u7535\u78c1\u4fa7\u4fe1\u9053\u975e\u63a5\u89e6\u5f0f\u7a83\u53d6\u624b\u5199\u8f68\u8ff9\uff0c\u5728\u5546\u7528\u624b\u673a\u4e0a\u5b9e\u73b077%\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u7535\u5bb9\u5f0f\u89e6\u6478\u5c4f\u7535\u78c1\u4fa7\u4fe1\u9053\u6cc4\u9732\u8db3\u591f\u4fe1\u606f\u6765\u6062\u590d\u7cbe\u7ec6\u624b\u5199\u8f68\u8ff9\u7684\u5b89\u5168\u6f0f\u6d1e", "method": "\u63d0\u51faTESLA\u653b\u51fb\u6846\u67b6\uff0c\u6355\u83b7\u5c4f\u5e55\u4e66\u5199\u65f6\u7684\u7535\u78c1\u4fe1\u53f7\u5e76\u5b9e\u65f6\u56de\u5f52\u4e3a\u4e8c\u7ef4\u624b\u5199\u8f68\u8ff9", "result": "\u5728\u591a\u79cd\u5546\u7528\u624b\u673a\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cTESLA\u8fbe\u523077%\u5b57\u7b26\u8bc6\u522b\u51c6\u786e\u7387\u548c0.74\u6770\u5361\u5fb7\u6307\u6570", "conclusion": "\u7535\u78c1\u4fa7\u4fe1\u9053\u653b\u51fb\u80fd\u6709\u6548\u6062\u590d\u9ad8\u5ea6\u53ef\u8bc6\u522b\u7684\u624b\u5199\u8f68\u8ff9\uff0c\u66b4\u9732\u89e6\u6478\u5c4f\u5b89\u5168\u98ce\u9669"}}
{"id": "2512.11469", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11469", "abs": "https://arxiv.org/abs/2512.11469", "authors": ["Pranav Ramanathan", "Thomas Prellberg", "Matthew Lewis", "Prathamesh Dinesh Joshi", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line", "comment": null, "summary": "The No-Three-In-Line problem asks for the maximum number of points that can be placed on an n by n grid with no three collinear, representing a famous problem in combinatorial geometry. While classical methods like Integer Linear Programming (ILP) guarantee optimal solutions, they face exponential scaling with grid size, and recent advances in machine learning offer promising alternatives for pattern-based approximation. This paper presents the first systematic comparison of classical optimization and AI approaches to this problem, evaluating their performance against traditional algorithms. We apply PatternBoost transformer learning and reinforcement learning (PPO) to this problem for the first time, comparing them against ILP. ILP achieves provably optimal solutions up to 19 by 19 grids, while PatternBoost matches optimal performance up to 14 by 14 grids with 96% test loss reduction. PPO achieves perfect solutions on 10 by 10 grids but fails at 11 by 11 grids, where constraint violations prevent valid configurations. These results demonstrate that classical optimization remains essential for exact solutions while AI methods offer competitive performance on smaller instances, with hybrid approaches presenting the most promising direction for scaling to larger problem sizes.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u7ecf\u5178\u4f18\u5316\u7b97\u6cd5\uff08\u6574\u6570\u7ebf\u6027\u89c4\u5212ILP\uff09\u4e0e\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\uff08PatternBoost\u53d8\u538b\u5668\u5b66\u4e60\u548cPPO\u5f3a\u5316\u5b66\u4e60\uff09\u5728\u89e3\u51b3No-Three-In-Line\u7ec4\u5408\u51e0\u4f55\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0cILP\u572819x19\u7f51\u683c\u5185\u53ef\u5f97\u5230\u6700\u4f18\u89e3\uff0c\u800cAI\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\u95ee\u9898\u4e0a\u8868\u73b0\u5177\u6709\u7ade\u4e89\u529b\uff0c\u6df7\u5408\u65b9\u6cd5\u6709\u671b\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u95ee\u9898\u3002", "motivation": "No-Three-In-Line\u95ee\u9898\u662f\u4e00\u4e2a\u8457\u540d\u7684\u7ec4\u5408\u51e0\u4f55\u95ee\u9898\uff0c\u4f46\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u5982ILP\u5728\u5904\u7406\u5927\u89c4\u6a21\u7f51\u683c\u65f6\u9762\u4e34\u6307\u6570\u7ea7\u590d\u6742\u5ea6\u6311\u6218\u3002\u8fd1\u5e74\u6765\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u6a21\u5f0f\u8bc6\u522b\u548c\u8fd1\u4f3c\u6c42\u89e3\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u9700\u8981\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u6765\u8bc4\u4f30\u4e0d\u540c\u65b9\u6cd5\u7684\u9002\u7528\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "1. \u4f7f\u7528\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff08ILP\uff09\u4f5c\u4e3a\u7ecf\u5178\u4f18\u5316\u57fa\u51c6\n2. \u9996\u6b21\u5e94\u7528PatternBoost\u53d8\u538b\u5668\u5b66\u4e60\u65b9\u6cd5\n3. \u9996\u6b21\u5e94\u7528PPO\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\n4. \u572810x10\u81f319x19\u7684\u4e0d\u540c\u89c4\u6a21\u7f51\u683c\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u6bd4\u8f83", "result": "ILP\u572819x19\u7f51\u683c\u5185\u83b7\u5f97\u53ef\u8bc1\u660e\u7684\u6700\u4f18\u89e3\uff1bPatternBoost\u572814x14\u7f51\u683c\u5185\u8fbe\u5230\u6700\u4f18\u6027\u80fd\uff0c\u6d4b\u8bd5\u635f\u5931\u51cf\u5c1196%\uff1bPPO\u572810x10\u7f51\u683c\u4e0a\u83b7\u5f97\u5b8c\u7f8e\u89e3\uff0c\u4f46\u572811x11\u7f51\u683c\u4e0a\u56e0\u7ea6\u675f\u8fdd\u89c4\u800c\u5931\u6548\u3002", "conclusion": "\u7ecf\u5178\u4f18\u5316\u65b9\u6cd5\u5bf9\u4e8e\u7cbe\u786e\u89e3\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0c\u800cAI\u65b9\u6cd5\u5728\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u5177\u6709\u7ade\u4e89\u529b\u3002\u6df7\u5408\u65b9\u6cd5\u662f\u5c06\u95ee\u9898\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u7684\u6700\u6709\u524d\u9014\u7684\u65b9\u5411\u3002"}}
{"id": "2512.11690", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.11690", "abs": "https://arxiv.org/abs/2512.11690", "authors": ["Grant Bosworth", "Keewoo Lee", "Sunwoong Kim"], "title": "Leveraging FPGAs for Homomorphic Matrix-Vector Multiplication in Oblivious Message Retrieval", "comment": null, "summary": "While end-to-end encryption protects the content of messages, it does not secure metadata, which exposes sender and receiver information through traffic analysis. A plausible approach to protecting this metadata is to have senders post encrypted messages on a public bulletin board and receivers scan it for relevant messages. Oblivious message retrieval (OMR) leverages homomorphic encryption (HE) to improve user experience in this solution by delegating the scan to a resource-rich server while preserving privacy. A key process in OMR is the homomorphic detection of pertinent messages for the receiver from the bulletin board. It relies on a specialized matrix-vector multiplication algorithm, which involves extensive multiplications between ciphertext vectors and plaintext matrices, as well as homomorphic rotations. The computationally intensive nature of this process limits the practicality of OMR. To address this challenge, this paper proposes a hardware architecture to accelerate the matrix-vector multiplication algorithm. The building homomorphic operators in this algorithm are implemented using high-level synthesis, with design parameters for different parallelism levels. These operators are then deployed on a field-programmable gate array platform using an efficient design space exploration strategy to accelerate homomorphic matrix-vector multiplication. Compared to a software implementation, the proposed hardware accelerator achieves a 13.86x speedup.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u786c\u4ef6\u52a0\u901f\u5668\u67b6\u6784\uff0c\u7528\u4e8e\u52a0\u901f\u4e0d\u7ecf\u610f\u6d88\u606f\u68c0\u7d22\u4e2d\u7684\u540c\u6001\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u64cd\u4f5c\uff0c\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\u83b7\u5f97\u4e8613.86\u500d\u7684\u52a0\u901f\u6bd4\u3002", "motivation": "\u7aef\u5230\u7aef\u52a0\u5bc6\u867d\u7136\u4fdd\u62a4\u6d88\u606f\u5185\u5bb9\uff0c\u4f46\u5143\u6570\u636e\u5bb9\u6613\u901a\u8fc7\u6d41\u91cf\u5206\u6790\u66b4\u9732\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u4f7f\u7528\u53d1\u9001\u8005\u5728\u516c\u5171\u516c\u544a\u677f\u53d1\u5e03\u52a0\u5bc6\u6d88\u606f\uff0c\u63a5\u6536\u8005\u626b\u63cf\u76f8\u5173\u6d88\u606f\u7684\u65b9\u5f0f\u4fdd\u62a4\u5143\u6570\u636e\u9690\u79c1\uff0c\u4f46\u5176\u4e2d\u7684\u540c\u6001\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u8ba1\u7b97\u5f00\u9500\u9650\u5236\u4e86\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u9ad8\u5c42\u6b21\u7efc\u5408\u5b9e\u73b0\u540c\u6001\u8fd0\u7b97\u5668\uff0c\u8bbe\u8ba1\u4e0d\u540c\u5e76\u884c\u5ea6\u7684\u53c2\u6570\uff0c\u901a\u8fc7\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7b56\u7565\u90e8\u7f72\u5230FPGA\u5e73\u53f0\u4e0a\uff0c\u6784\u5efa\u4e13\u95e8\u7684\u786c\u4ef6\u67b6\u6784\u6765\u52a0\u901f\u540c\u6001\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u3002", "result": "\u76f8\u6bd4\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u63d0\u51fa\u7684\u786c\u4ef6\u52a0\u901f\u5668\u5b9e\u73b0\u4e8613.86\u500d\u7684\u52a0\u901f\u6027\u80fd\u3002", "conclusion": "\u8be5\u786c\u4ef6\u52a0\u901f\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4e0d\u7ecf\u610f\u6d88\u606f\u68c0\u7d22\u4e2d\u540c\u6001\u77e9\u9635-\u5411\u91cf\u4e58\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5b9e\u7528\u6027\u3002"}}
{"id": "2512.11505", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11505", "abs": "https://arxiv.org/abs/2512.11505", "authors": ["Priyam Basu", "Yunfeng Zhang", "Vipul Raheja"], "title": "BAID: A Benchmark for Bias Assessment of AI Detectors", "comment": "Accepted at the workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks at AAAI 2026", "summary": "AI-generated text detectors have recently gained adoption in educational and professional contexts. Prior research has uncovered isolated cases of bias, particularly against English Language Learners (ELLs) however, there is a lack of systematic evaluation of such systems across broader sociolinguistic factors. In this work, we propose BAID, a comprehensive evaluation framework for AI detectors across various types of biases. As a part of the framework, we introduce over 200k samples spanning 7 major categories: demographics, age, educational grade level, dialect, formality, political leaning, and topic. We also generated synthetic versions of each sample with carefully crafted prompts to preserve the original content while reflecting subgroup-specific writing styles. Using this, we evaluate four open-source state-of-the-art AI text detectors and find consistent disparities in detection performance, particularly low recall rates for texts from underrepresented groups. Our contributions provide a scalable, transparent approach for auditing AI detectors and emphasize the need for bias-aware evaluation before these tools are deployed for public use.", "AI": {"tldr": "\u63d0\u51faBAID\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30AI\u6587\u672c\u68c0\u6d4b\u5668\u7684\u504f\u89c1\uff0c\u53d1\u73b0\u4e3b\u6d41AI\u68c0\u6d4b\u5668\u5bf9\u8fb9\u7f18\u7fa4\u4f53\u6587\u672c\u8bc6\u522b\u51c6\u786e\u7387\u663e\u8457\u504f\u4f4e", "motivation": "\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u5668\u5728\u6559\u80b2\u53ca\u4e13\u4e1a\u573a\u666f\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u793e\u4f1a\u8bed\u8a00\u5b66\u56e0\u7d20\u7684\u504f\u89c1\u7cfb\u7edf\u6027\u8bc4\u4f30", "method": "\u6784\u5efa\u5305\u542b7\u5927\u7c7b200k+\u6837\u672c\u7684\u6d4b\u8bd5\u96c6\uff0c\u91c7\u7528\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u751f\u6210\u4fdd\u6301\u5185\u5bb9\u4f46\u4f53\u73b0\u4e9a\u7fa4\u5199\u4f5c\u98ce\u683c\u7684\u5408\u6210\u6587\u672c\uff0c\u8bc4\u4f304\u4e2a\u5f00\u6e90AI\u68c0\u6d4b\u5668", "result": "AI\u68c0\u6d4b\u5668\u5728\u6240\u6709\u504f\u89c1\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5bf9\u4ee3\u8868\u6027\u4e0d\u8db3\u7fa4\u4f53\u7684\u6587\u672c\u53ec\u56de\u7387\u7279\u522b\u4f4e", "conclusion": "BAID\u4e3aAI\u68c0\u6d4b\u5668\u5ba1\u8ba1\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u900f\u660e\u7684\u65b9\u6cd5\uff0c\u5f3a\u8c03\u90e8\u7f72\u524d\u8fdb\u884c\u504f\u89c1\u8bc4\u4f30\u7684\u5fc5\u8981\u6027"}}
{"id": "2512.11699", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11699", "abs": "https://arxiv.org/abs/2512.11699", "authors": ["Roberta De Viti", "Vaastav Anand", "Pierfrancesco Ingo", "Deepak Garg"], "title": "SoK: Demystifying the multiverse of MPC protocols", "comment": null, "summary": "This paper systematizes knowledge on the performance of Multi-Party Computation (MPC) protocols. Despite strong privacy and correctness guarantees, MPC adoption in real-world applications remains limited by high costs (especially in the malicious setting) and lack of guidance on choosing suitable protocols for concrete workloads. We identify the theoretical and practical parameters that shape MPC efficiency and conduct an extensive experimental study across diverse benchmarks. Our analysis discusses the trade-offs between protocols, and highlights which techniques align best with different application scenarios and needs. By providing actionable guidance for developers and outlining open challenges for researchers, this work seeks to narrow the gap between MPC theory and practice.", "AI": {"tldr": "\u5bf9\u591a\u65b9\u8ba1\u7b97(MPC)\u534f\u8bae\u6027\u80fd\u8fdb\u884c\u7cfb\u7edf\u6027\u5206\u6790\uff0c\u6307\u51fa\u5b9e\u9645\u5e94\u7528\u969c\u788d\u5e76\u63d0\u4f9b\u534f\u8bae\u9009\u62e9\u6307\u5bfc", "motivation": "MPC\u534f\u8bae\u867d\u7136\u5177\u6709\u5f3a\u9690\u79c1\u548c\u6b63\u786e\u6027\u4fdd\u8bc1\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u56e0\u9ad8\u6210\u672c\u548c\u7f3a\u4e4f\u5177\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u7684\u534f\u8bae\u9009\u62e9\u6307\u5bfc\u800c\u53d7\u5230\u9650\u5236", "method": "\u8bc6\u522b\u5f71\u54cdMPC\u6548\u7387\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u53c2\u6570\uff0c\u901a\u8fc7\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\u7814\u7a76", "result": "\u5206\u6790\u4e86\u4e0d\u540c\u534f\u8bae\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u786e\u5b9a\u4e86\u6700\u9002\u5408\u4e0d\u540c\u5e94\u7528\u573a\u666f\u548c\u9700\u6c42\u7684\u6280\u672f", "conclusion": "\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u6307\u51fa\u5f00\u653e\u6311\u6218\uff0c\u65e8\u5728\u7f29\u5c0fMPC\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd"}}
{"id": "2512.11783", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11783", "abs": "https://arxiv.org/abs/2512.11783", "authors": ["Andrew Adiletta", "Kathryn Adiletta", "Kemal Derya", "Berk Sunar"], "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously", "comment": "13 pages, 5 Figures", "summary": "The rapid deployment of Large Language Models (LLMs) has created an urgent need for enhanced security and privacy measures in Machine Learning (ML). LLMs are increasingly being used to process untrusted text inputs and even generate executable code, often while having access to sensitive system controls. To address these security concerns, several companies have introduced guard models, which are smaller, specialized models designed to protect text generation models from adversarial or malicious inputs. In this work, we advance the study of adversarial inputs by introducing Super Suffixes, suffixes capable of overriding multiple alignment objectives across various models with different tokenization schemes. We demonstrate their effectiveness, along with our joint optimization technique, by successfully bypassing the protection mechanisms of Llama Prompt Guard 2 on five different text generation models for malicious text and code generation. To the best of our knowledge, this is the first work to reveal that Llama Prompt Guard 2 can be compromised through joint optimization.\n  Additionally, by analyzing the changing similarity of a model's internal state to specific concept directions during token sequence processing, we propose an effective and lightweight method to detect Super Suffix attacks. We show that the cosine similarity between the residual stream and certain concept directions serves as a distinctive fingerprint of model intent. Our proposed countermeasure, DeltaGuard, significantly improves the detection of malicious prompts generated through Super Suffixes. It increases the non-benign classification rate to nearly 100%, making DeltaGuard a valuable addition to the guard model stack and enhancing robustness against adversarial prompt attacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSuper Suffix\u653b\u51fb\u65b9\u6cd5\u53ef\u7ed5\u8fc7Llama Prompt Guard 2\u9632\u62a4\uff0c\u540c\u65f6\u5f00\u53d1\u4e86\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u72b6\u6001\u5206\u6790\u7684DeltaGuard\u68c0\u6d4b\u6280\u672f\uff0c\u6709\u6548\u8bc6\u522b\u6076\u610f\u63d0\u793a\uff0c\u63d0\u5347\u9632\u62a4\u80fd\u529b\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u90e8\u7f72\uff0c\u5904\u7406\u4e0d\u53ef\u4fe1\u6587\u672c\u8f93\u5165\u548c\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u73b0\u6709\u4fdd\u62a4\u673a\u5236\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\u3002\u7814\u7a76\u53d1\u73b0Llama Prompt Guard 2\u7b49\u9632\u62a4\u6a21\u578b\u53ef\u80fd\u88ab\u8054\u5408\u4f18\u5316\u6280\u672f\u7ed5\u8fc7\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u72b6\u6001\u5728\u5904\u7406token\u5e8f\u5217\u8fc7\u7a0b\u4e2d\u4e0e\u7279\u5b9a\u6982\u5ff5\u65b9\u5411\u7684\u4f59\u5f26\u76f8\u4f3c\u5ea6\u53d8\u5316\uff0c\u63d0\u51fa\u4e86DeltaGuard\u68c0\u6d4b\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6b8b\u5dee\u6d41\u4e0e\u6982\u5ff5\u65b9\u5411\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u6a21\u578b\u610f\u56fe\u7684\u7279\u5f81\u6307\u7eb9\u3002", "result": "Super Suffix\u653b\u51fb\u80fd\u591f\u6210\u529f\u7ed5\u8fc7Llama Prompt Guard 2\u5bf9\u4e94\u4e2a\u4e0d\u540c\u6587\u672c\u751f\u6210\u6a21\u578b\u7684\u4fdd\u62a4\u673a\u5236\u3002DeltaGuard\u68c0\u6d4b\u65b9\u6cd5\u5c06\u6076\u610f\u63d0\u793a\u7684\u975e\u826f\u6027\u5206\u7c7b\u7387\u63d0\u5347\u81f3\u8fd1100%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5bf9\u6297\u6027\u63d0\u793a\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5bf9\u6297\u6027\u653b\u51fb\u68c0\u6d4b\u65b9\u6cd5DeltaGuard\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5185\u90e8\u72b6\u6001\u4e0e\u7279\u5b9a\u6982\u5ff5\u65b9\u5411\u7684\u76f8\u4f3c\u6027\u53d8\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9Super Suffix\u653b\u51fb\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u5c06\u975e\u826f\u6027\u5206\u7c7b\u7387\u63d0\u5347\u81f3\u8fd1100%\uff0c\u4e3a\u4fdd\u62a4\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11544", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11544", "abs": "https://arxiv.org/abs/2512.11544", "authors": ["Yuan Shen", "Xiaojun Wu", "Linghua Yu"], "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives", "comment": "47 pages, 2 figures", "summary": "This study aims to simulate real-world clinical scenarios to systematically evaluate the ability of Large Language Models (LLMs) to extract core medical information from patient chief complaints laden with noise and redundancy, and to verify whether they exhibit a functional decline analogous to Metabolic Dysfunction-Associated Steatotic Liver Disease (MASLD). We employed a cross-sectional analysis design based on standardized medical probes, selecting four mainstream LLMs as research subjects: GPT-4o, Gemini 2.5, DeepSeek 3.1, and Qwen3-Max. An evaluation system comprising twenty medical probes across five core dimensions was used to simulate a genuine clinical communication environment. All probes had gold-standard answers defined by clinical experts and were assessed via a double-blind, inverse rating scale by two independent clinicians. The results show that all tested models exhibited functional defects to varying degrees, with Qwen3-Max demonstrating the best overall performance and Gemini 2.5 the worst. Under conditions of extreme noise, most models experienced a functional collapse. Notably, GPT-4o made a severe misjudgment in the risk assessment for pulmonary embolism (PE) secondary to deep vein thrombosis (DVT). This research is the first to empirically confirm that LLMs exhibit features resembling metabolic dysfunction when processing clinical information, proposing the innovative concept of \"AI-Metabolic Dysfunction-Associated Steatotic Liver Disease (AI-MASLD)\". These findings offer a crucial safety warning for the application of Artificial Intelligence (AI) in healthcare, emphasizing that current LLMs must be used as auxiliary tools under human expert supervision, as there remains a significant gap between their theoretical knowledge and practical clinical application.", "AI": {"tldr": "\u8fd9\u7bc7\u7814\u7a76\u6a21\u62df\u771f\u5b9e\u4e34\u5e8a\u573a\u666f\uff0c\u8bc4\u4f30LLMs\u4ece\u5608\u6742\u5197\u4f59\u7684\u60a3\u8005\u4e3b\u8bc9\u4e2d\u63d0\u53d6\u6838\u5fc3\u533b\u5b66\u4fe1\u606f\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u529f\u80fd\u7f3a\u9677\uff0c\u5e76\u9996\u6b21\u63d0\u51fa\"AI-\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u76f8\u5173\u6027\u8102\u80aa\u809d\u75c5\"\u7684\u521b\u65b0\u6982\u5ff5\u3002", "motivation": "\u9a8c\u8bc1LLMs\u5728\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u662f\u5426\u4f1a\u8868\u73b0\u51fa\u7c7b\u4f3c\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7684\u529f\u80fd\u4e0b\u964d\uff0c\u4e3aAI\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u5b89\u5168\u8b66\u793a\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6807\u51c6\u5316\u533b\u5b66\u63a2\u9488\u7684\u6a2a\u65ad\u9762\u5206\u6790\u8bbe\u8ba1\uff0c\u9009\u62e9\u56db\u79cd\u4e3b\u6d41LLMs\u4f5c\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u4f7f\u7528\u5305\u542b\u4e94\u4e2a\u6838\u5fc3\u7ef4\u5ea6\u768420\u4e2a\u533b\u5b66\u63a2\u9488\u8bc4\u4f30\u7cfb\u7edf\uff0c\u91c7\u7528\u53cc\u76f2\u53cd\u5411\u8bc4\u5206\u91cf\u8868\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u90fd\u8868\u73b0\u51fa\u4e0d\u540c\u7a0b\u5ea6\u7684\u529f\u80fd\u7f3a\u9677\uff0cQwen3-Max\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0cGemini 2.5\u6700\u5dee\u3002\u6781\u7aef\u566a\u97f3\u6761\u4ef6\u4e0b\u5927\u591a\u6570\u6a21\u578b\u51fa\u73b0\u529f\u80fd\u5d29\u6e83\uff0cGPT-4o\u5728\u80ba\u6813\u585e\u98ce\u9669\u8bc4\u4f30\u4e2d\u51fa\u73b0\u4e25\u91cd\u8bef\u5224\u3002", "conclusion": "\u9996\u6b21\u5b9e\u8bc1\u786e\u8ba4LLMs\u5904\u7406\u4e34\u5e8a\u4fe1\u606f\u65f6\u8868\u73b0\u51fa\u4ee3\u8c22\u529f\u80fd\u969c\u788d\u7279\u5f81\uff0c\u5f3a\u8c03\u5f53\u524dLLMs\u5fc5\u987b\u5728\u4eba\u7c7b\u4e13\u5bb6\u76d1\u7763\u4e0b\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u4f7f\u7528\uff0c\u5176\u7406\u8bba\u77e5\u8bc6\u4e0e\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2512.11588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11588", "abs": "https://arxiv.org/abs/2512.11588", "authors": ["Gregor von Laszewski", "Wesley Brewer", "Jeyan Thiyagalingam", "Juri Papay", "Armstrong Foundjem", "Piotr Luszczek", "Murali Emani", "Shirley V. Moore", "Vijay Janapa Reddi", "Matthew D. Sinclair", "Sebastian Lobentanzer", "Sujata Goswami", "Benjamin Hawks", "Marco Colombo", "Nhan Tran", "Christine R. Kirkpatrick", "Abdulkareem Alsudais", "Gregg Barrett", "Tianhao Li", "Kirsten Morehouse", "Shivaram Venkataraman", "Rutwik Jain", "Kartik Mathur", "Victor Lu", "Tejinder Singh", "Khojasteh Z. Mirza", "Kongtao Chen", "Sasidhar Kunapuli", "Gavin Farrell", "Renato Umeton", "Geoffrey C. Fox"], "title": "AI Benchmark Democratization and Carpentry", "comment": "43 pages, 2 figures, 7 tables", "summary": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance.\n  Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This calls for skills and education in AI Benchmark Carpentry. From our experience with MLCommons, educational initiatives, and programs like the DOE's Trillion Parameter Consortium, key barriers include high resource demands, limited access to specialized hardware, lack of benchmark design expertise, and uncertainty in relating results to application domains. Current benchmarks often emphasize peak performance on top-tier hardware, offering limited guidance for diverse, real-world scenarios.\n  Benchmarking must become dynamic, incorporating evolving models, updated data, and heterogeneous platforms while maintaining transparency, reproducibility, and interpretability. Democratization requires both technical innovation and systematic education across levels, building sustained expertise in benchmark design and use. Benchmarks should support application-relevant comparisons, enabling informed, context-sensitive decisions. Dynamic, inclusive benchmarking will ensure evaluation keeps pace with AI evolution and supports responsible, reproducible, and accessible AI deployment. Community efforts can provide a foundation for AI Benchmark Carpentry.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faAI\u57fa\u51c6\u6d4b\u8bd5\u9700\u8981\u4ece\u9759\u6001\u5411\u52a8\u6001\u81ea\u9002\u5e94\u8f6c\u53d8\uff0c\u4ee5\u89e3\u51b3\u6a21\u578b\u8bb0\u5fc6\u57fa\u51c6\u3001\u8bc4\u4f30\u4e0e\u73b0\u5b9e\u5dee\u8ddd\u7b49\u95ee\u9898\uff0c\u5e76\u5f3a\u8c03\u9700\u8981AI\u57fa\u51c6\u6728\u5de5\u6280\u80fd\u6559\u80b2\u548c\u793e\u533a\u52aa\u529b\u3002", "motivation": "\u5f53\u524dAI\u57fa\u51c6\u6d4b\u8bd5\u8fc7\u4e8e\u9759\u6001\uff0c\u65e0\u6cd5\u8ddf\u4e0a\u6a21\u578b\u67b6\u6784\u3001\u6570\u636e\u548c\u90e8\u7f72\u73af\u5883\u7684\u5feb\u901f\u6f14\u53d8\uff0c\u5bfc\u81f4\u57fa\u51c6\u7ed3\u679c\u4e0e\u5b9e\u9645\u6027\u80fd\u8131\u8282\u3002", "method": "\u901a\u8fc7MLCommons\u3001\u6559\u80b2\u9879\u76ee\u548cDOE\u4e07\u4ebf\u53c2\u6570\u8054\u76df\u7b49\u5b9e\u8df5\u7ecf\u9a8c\uff0c\u8bc6\u522b\u8d44\u6e90\u9700\u6c42\u9ad8\u3001\u786c\u4ef6\u8bbf\u95ee\u6709\u9650\u3001\u8bbe\u8ba1\u4e13\u5bb6\u7f3a\u4e4f\u7b49\u969c\u788d\uff0c\u5021\u5bfc\u52a8\u6001\u57fa\u51c6\u6846\u67b6\u3002", "result": "\u52a8\u6001\u57fa\u51c6\u6d4b\u8bd5\u5e94\u6574\u5408\u6f14\u5316\u6a21\u578b\u3001\u66f4\u65b0\u6570\u636e\u548c\u5f02\u6784\u5e73\u53f0\uff0c\u4fdd\u6301\u900f\u660e\u6027\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u652f\u6301\u5e94\u7528\u76f8\u5173\u6bd4\u8f83\u3002", "conclusion": "\u52a8\u6001\u5305\u5bb9\u7684\u57fa\u51c6\u6d4b\u8bd5\u5c06\u786e\u4fdd\u8bc4\u4f30\u4e0eAI\u53d1\u5c55\u540c\u6b65\uff0c\u652f\u6301\u8d1f\u8d23\u4efb\u3001\u53ef\u91cd\u590d\u548c\u53ef\u8bbf\u95ee\u7684AI\u90e8\u7f72\uff0c\u793e\u533a\u52aa\u529b\u53ef\u4e3aAI\u57fa\u51c6\u6728\u5de5\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2512.11653", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11653", "abs": "https://arxiv.org/abs/2512.11653", "authors": ["Chutian Ma", "Grigorii Pomazkin", "Giacinto Paolo Saggese", "Paul Smith"], "title": "Causal Inference in Energy Demand Prediction", "comment": null, "summary": "Energy demand prediction is critical for grid operators, industrial energy\n  consumers, and service providers. Energy demand is influenced by multiple\n  factors, including weather conditions (e.g. temperature, humidity, wind\n  speed, solar radiation), and calendar information (e.g. hour of day and\n  month of year), which further affect daily work and life schedules. These\n  factors are causally interdependent, making the problem more complex than\n  simple correlation-based learning techniques satisfactorily allow for. We\n  propose a structural causal model that explains the causal relationship\n  between these variables. A full analysis is performed to validate our causal\n  beliefs, also revealing important insights consistent with prior studies.\n  For example, our causal model reveals that energy demand responds to\n  temperature fluctuations with season-dependent sensitivity. Additionally, we\n  find that energy demand exhibits lower variance in winter due to the\n  decoupling effect between temperature changes and daily activity patterns.\n  We then build a Bayesian model, which takes advantage of the causal insights\n  we learned as prior knowledge. The model is trained and tested on unseen\n  data and yields state-of-the-art performance in the form of a 3.84 percent MAPE on\n  the test set. The model also demonstrates strong robustness, as the\n  cross-validation across two years of data yields an average MAPE of 3.88 percent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u65b0\u578b\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u65b9\u6cd5\uff0c\u7ed3\u5408\u8d1d\u53f6\u65af\u5efa\u6a21\u83b7\u5f97\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u53d7\u591a\u79cd\u56e0\u679c\u76f8\u5173\u56e0\u7d20\u5f71\u54cd\uff0c\u5355\u7eaf\u7684\u76f8\u5173\u6027\u5b66\u4e60\u96be\u4ee5\u5145\u5206\u6355\u83b7\u590d\u6742\u5173\u7cfb\uff0c\u9700\u8981\u56e0\u679c\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u63ed\u793a\u53d8\u91cf\u95f4\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u57fa\u4e8e\u56e0\u679c\u6d1e\u5bdf\u6784\u5efa\u8d1d\u53f6\u65af\u6a21\u578b\u4f5c\u4e3a\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u52303.84% MAPE\uff0c\u8de8\u4e24\u5e74\u6570\u636e\u4ea4\u53c9\u9a8c\u8bc1\u5e73\u5747MAPE\u4e3a3.88%\uff0c\u663e\u793a\u51fa\u8272\u9c81\u68d2\u6027\u3002", "conclusion": "\u56e0\u679c\u5efa\u6a21\u80fd\u6709\u6548\u63d0\u5347\u80fd\u6e90\u9700\u6c42\u9884\u6d4b\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u6e29\u5ea6\u654f\u611f\u5ea6\u7684\u5b63\u8282\u6027\u5dee\u5f02\u7b49\u6709\u4ef7\u503c\u6d1e\u5bdf\u3002"}}
{"id": "2512.11682", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11682", "abs": "https://arxiv.org/abs/2512.11682", "authors": ["Tim Cofala", "Christian Kalfar", "Jingge Xiao", "Johanna Schrader", "Michelle Tang", "Wolfgang Nejdl"], "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition", "comment": "7 pages, 3 figures", "summary": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.", "AI": {"tldr": "TxAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u7684AI\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6574\u5408\u751f\u7269\u533b\u5b66\u5de5\u5177\uff0c\u5728CURE-Bench\u6311\u6218\u8d5b\u4e2d\u56e0\u4f18\u5f02\u7684\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u83b7\u5956", "motivation": "\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u9700\u8981\u7ed3\u5408\u60a3\u8005\u7279\u5f81\u3001\u75be\u75c5\u8fdb\u7a0b\u548c\u836f\u7269\u4fe1\u606f\u7684\u590d\u6742\u63a8\u7406\uff0c\u4f46\u73b0\u6709AI\u7cfb\u7edf\u5728\u5b89\u5168\u6027\u548c\u63a8\u7406\u8f68\u8ff9\u51c6\u786e\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3", "method": "\u4f7f\u7528\u5fae\u8c03\u7684Llama-3.1-8B\u6a21\u578b\uff0c\u52a8\u6001\u8c03\u7528\u7edf\u4e00\u751f\u7269\u533b\u5b66\u5de5\u5177\u5957\u4ef6\uff08FDA Drug API\u3001OpenTargets\u3001Monarch\uff09\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5", "result": "\u5728CURE-Bench\u795e\u7ecf\u4fe1\u606f\u5904\u7406\u7cfb\u7edf2025\u6311\u6218\u8d5b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u6539\u8fdb\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u5bf9\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u83b7\u5f97\u5f00\u653e\u79d1\u5b66\u4f18\u79c0\u5956", "conclusion": "\u533b\u7597AI\u5e94\u7528\u9700\u8981\u4e25\u683c\u7684\u5b89\u5168\u6027\u7ea6\u675f\uff0c\u5de5\u5177\u8c03\u7528\u548c\u63a8\u7406\u8f68\u8ff9\u7684\u51c6\u786e\u6027\u81f3\u5173\u91cd\u8981\uff0c\u8fed\u4ee3\u5f0fRAG\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u6cbb\u7597\u63a8\u7406\u7cfb\u7edf\u7684\u6027\u80fd"}}
