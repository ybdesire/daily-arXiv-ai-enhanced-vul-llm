{"id": "2511.20679", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20679", "abs": "https://arxiv.org/abs/2511.20679", "authors": ["Melika Ayoughi", "Pascal Mettes", "Paul Groth"], "title": "Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring", "comment": null, "summary": "Hyperbolic geometry is an effective geometry for embedding hierarchical data structures. Hyperbolic learning has therefore become increasingly prominent in machine learning applications where data is hierarchically organized or governed by hierarchical semantics, ranging from recommendation systems to computer vision. The quality of hyperbolic embeddings is tightly coupled to the structure of the input hierarchy, which is often derived from knowledge graphs or ontologies. Recent work has uncovered that for an optimal hyperbolic embedding, a high branching factor and single inheritance are key, while embedding algorithms are robust to imbalance and hierarchy size. To assist knowledge engineers in reorganizing hierarchical knowledge, this paper investigates whether Large Language Models (LLMs) have the ability to automatically restructure hierarchies to meet these criteria. We propose a prompt-based approach to transform existing hierarchies using LLMs, guided by known desiderata for hyperbolic embeddings. Experiments on 16 diverse hierarchies show that LLM-restructured hierarchies consistently yield higher-quality hyperbolic embeddings across several standard embedding quality metrics. Moreover, we show how LLM-guided hierarchy restructuring enables explainable reorganizations, providing justifications to knowledge engineers.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u91cd\u6784\u5c42\u7ea7\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\u6548\u679c\uff0c\u5b9e\u9a8c\u8868\u660eLLM\u91cd\u6784\u7684\u5c42\u7ea7\u5728\u591a\u4e2a\u6807\u51c6\u6307\u6807\u4e0a\u5747\u80fd\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u66f2\u5d4c\u5165\u3002", "motivation": "\u53cc\u66f2\u5d4c\u5165\u7684\u8d28\u91cf\u4e0e\u8f93\u5165\u5c42\u7ea7\u7ed3\u6784\u5bc6\u5207\u76f8\u5173\uff0c\u800c\u73b0\u6709\u5c42\u7ea7\u5f80\u5f80\u6765\u81ea\u77e5\u8bc6\u56fe\u8c31\u6216\u672c\u4f53\uff0c\u53ef\u80fd\u4e0d\u7b26\u5408\u53cc\u66f2\u5d4c\u5165\u7684\u6700\u4f73\u6761\u4ef6\uff08\u9ad8\u5206\u652f\u56e0\u5b50\u548c\u5355\u7ee7\u627f\uff09\u3002\u9700\u8981\u5e2e\u52a9\u77e5\u8bc6\u5de5\u7a0b\u5e08\u91cd\u6784\u5c42\u7ea7\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u6807\u51c6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53cc\u66f2\u5d4c\u5165\u671f\u671b\u6807\u51c6\u7684\u6307\u5bfc\u4e0b\u81ea\u52a8\u8f6c\u6362\u73b0\u6709\u5c42\u7ea7\u7ed3\u6784\u3002\u572816\u4e2a\u591a\u6837\u5316\u5c42\u7ea7\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u7ecf\u8fc7LLM\u91cd\u6784\u7684\u5c42\u7ea7\u5728\u591a\u4e2a\u6807\u51c6\u5d4c\u5165\u8d28\u91cf\u6307\u6807\u4e0a\u4e00\u81f4\u4ea7\u751f\u66f4\u9ad8\u8d28\u91cf\u7684\u53cc\u66f2\u5d4c\u5165\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u81ea\u52a8\u91cd\u6784\u5c42\u7ea7\u7ed3\u6784\u4ee5\u4f18\u5316\u53cc\u66f2\u5d4c\u5165\uff0c\u540c\u65f6\u8fd8\u80fd\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u91cd\u7ec4\u65b9\u6848\uff0c\u4e3a\u77e5\u8bc6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u5408\u7406\u6027\u8bf4\u660e\u3002"}}
{"id": "2511.20686", "categories": ["cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20686", "abs": "https://arxiv.org/abs/2511.20686", "authors": ["Chae-Gyun Lim", "Seung-Ho Han", "EunYoung Byun", "Jeongyun Han", "Soohyun Cho", "Eojin Joo", "Heehyeon Kim", "Sieun Kim", "Juhoon Lee", "Hyunsoo Lee", "Dongkun Lee", "Jonghwan Hyeon", "Yechan Hwang", "Young-Jun Lee", "Kyeongryul Lee", "Minhyeong An", "Hyunjun Ahn", "Jeongwoo Son", "Junho Park", "Donggyu Yoon", "Taehyung Kim", "Jeemin Kim", "Dasom Choi", "Kwangyoung Lee", "Hyunseung Lim", "Yeohyun Jung", "Jongok Hong", "Sooyohn Nam", "Joonyoung Park", "Sungmin Na", "Yubin Choi", "Jeanne Choi", "Yoojin Hong", "Sueun Jang", "Youngseok Seo", "Somin Park", "Seoungung Jo", "Wonhye Chae", "Yeeun Jo", "Eunyoung Kim", "Joyce Jiyoung Whang", "HwaJung Hong", "Joseph Seering", "Uichin Lee", "Juho Kim", "Sunna Choi", "Seokyeon Ko", "Taeho Kim", "Kyunghoon Kim", "Myungsik Ha", "So Jung Lee", "Jemin Hwang", "JoonHo Kwak", "Ho-Jin Choi"], "title": "AssurAI: Experience with Constructing Korean Socio-cultural Datasets to Discover Potential Risks of Generative AI", "comment": "16 pages, HuggingFace: https://huggingface.co/datasets/TTA01/AssurAI", "summary": "The rapid evolution of generative AI necessitates robust safety evaluations. However, current safety datasets are predominantly English-centric, failing to capture specific risks in non-English, socio-cultural contexts such as Korean, and are often limited to the text modality. To address this gap, we introduce AssurAI, a new quality-controlled Korean multimodal dataset for evaluating the safety of generative AI. First, we define a taxonomy of 35 distinct AI risk factors, adapted from established frameworks by a multidisciplinary expert group to cover both universal harms and relevance to the Korean socio-cultural context. Second, leveraging this taxonomy, we construct and release AssurAI, a large-scale Korean multimodal dataset comprising 11,480 instances across text, image, video, and audio. Third, we apply the rigorous quality control process used to ensure data integrity, featuring a two-phase construction (i.e., expert-led seeding and crowdsourced scaling), triple independent annotation, and an iterative expert red-teaming loop. Our pilot study validates AssurAI's effectiveness in assessing the safety of recent LLMs. We release AssurAI to the public to facilitate the development of safer and more reliable generative AI systems for the Korean community.", "AI": {"tldr": "AssurAI\u662f\u4e00\u4e2a\u97e9\u56fd\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u751f\u6210\u5f0fAI\u7684\u5b89\u5168\u6027\uff0c\u586b\u8865\u4e86\u5f53\u524d\u82f1\u8bed\u4e2d\u5fc3\u5b89\u5168\u6570\u636e\u96c6\u7684\u4e0d\u8db3", "motivation": "\u5f53\u524d\u5b89\u5168\u6570\u636e\u96c6\u4e3b\u8981\u662f\u82f1\u8bed\u4e2d\u5fc3\u7684\uff0c\u65e0\u6cd5\u6355\u6349\u97e9\u8bed\u7b49\u975e\u82f1\u8bed\u793e\u4f1a\u6587\u5316\u80cc\u666f\u4e0b\u7684\u7279\u5b9a\u98ce\u9669\uff0c\u4e14\u901a\u5e38\u4ec5\u9650\u4e8e\u6587\u672c\u6a21\u6001", "method": "\u5b9a\u4e49\u4e8635\u4e2aAI\u98ce\u9669\u56e0\u7d20\u5206\u7c7b\u6cd5\uff0c\u6784\u5efa\u4e86\u5305\u542b11,480\u4e2a\u5b9e\u4f8b\u7684\u97e9\u8bed\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6784\u5efa\u3001\u4e09\u91cd\u72ec\u7acb\u6807\u6ce8\u548c\u8fed\u4ee3\u4e13\u5bb6\u7ea2\u961f\u6d4b\u8bd5\u7684\u8d28\u91cf\u63a7\u5236\u6d41\u7a0b", "result": "\u521b\u5efa\u4e86AssurAI\u6570\u636e\u96c6\uff0c\u8bd5\u70b9\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5728\u8bc4\u4f30\u6700\u65b0LLM\u5b89\u5168\u6027\u65b9\u9762\u7684\u6709\u6548\u6027", "conclusion": "AssurAI\u6709\u52a9\u4e8e\u4e3a\u97e9\u56fd\u793e\u533a\u5f00\u53d1\u66f4\u5b89\u5168\u53ef\u9760\u7684\u751f\u6210\u5f0fAI\u7cfb\u7edf"}}
{"id": "2511.20693", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.20693", "abs": "https://arxiv.org/abs/2511.20693", "authors": ["Mingming Zhao", "Xiaokang Wei", "Yuanqi Shao", "Kaiwen Zhou", "Lin Yang", "Siwei Rao", "Junhui Zhan", "Zhitang Chen"], "title": "$A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators", "comment": "Accepted by AAAI-2026", "summary": "Large language models (LLMs) have shown strong potential in automating the design of agentic workflows. However, existing methods still rely heavily on manually predefined operators, limiting generalization and scalability. To address this issue, we propose $A^2Flow$, a fully automated framework for agentic workflow generation based on self-adaptive abstraction operators. $A^2Flow$ employs a three-stage operator extraction process: 1) Case-based Initial Operator Generation: leveraging expert demonstrations and LLM reasoning to generate case-specific operators; 2) Operator Clustering and Preliminary Abstraction: grouping similar operators across tasks to form preliminary abstractions; and 3) Deep Extraction for Abstract Execution Operators: applying long chain-of-thought prompting and multi-path reasoning to derive compact and generalizable execution operators. These operators serve as reusable building blocks for workflow construction without manual predefinition. Furthermore, we enhance node-level workflow search with an operator memory mechanism, which retains historical outputs to enrich context and improve decision-making. Experiments on general and embodied benchmarks show that $A^2Flow$ achieves a 2.4\\% and 19.3\\% average performance improvement and reduces resource usage by 37\\% over state-of-the-art baselines. Homepage:https://github.com/pandawei-ele/A2FLOW", "AI": {"tldr": "\u63d0\u51fa\u4e86A\u00b2Flow\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u62bd\u8c61\u7b97\u5b50\u5b9e\u73b0\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u751f\u6210\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u9884\u5b9a\u4e49\u7b97\u5b50\uff0c\u9650\u5236\u4e86\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4e09\u9636\u6bb5\u7b97\u5b50\u63d0\u53d6\u8fc7\u7a0b\uff1a\u57fa\u4e8e\u6848\u4f8b\u7684\u521d\u59cb\u7b97\u5b50\u751f\u6210\u3001\u7b97\u5b50\u805a\u7c7b\u548c\u521d\u6b65\u62bd\u8c61\u3001\u6df1\u5ea6\u63d0\u53d6\u62bd\u8c61\u6267\u884c\u7b97\u5b50\uff1b\u5e76\u91c7\u7528\u7b97\u5b50\u8bb0\u5fc6\u673a\u5236\u589e\u5f3a\u5de5\u4f5c\u6d41\u641c\u7d22\u3002", "result": "\u5728\u901a\u7528\u548c\u5177\u8eab\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u57fa\u7ebf\u5e73\u5747\u6027\u80fd\u63d0\u53472.4%\u548c19.3%\uff0c\u8d44\u6e90\u4f7f\u7528\u51cf\u5c1137%\u3002", "conclusion": "A\u00b2Flow\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u751f\u6210\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u62bd\u8c61\u7b97\u5b50\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2511.20694", "categories": ["cs.AI", "astro-ph.SR", "cs.LG", "physics.space-ph"], "pdf": "https://arxiv.org/pdf/2511.20694", "abs": "https://arxiv.org/abs/2511.20694", "authors": ["Kevin Lee", "Russell Spiewak", "James Walsh"], "title": "Reasoning With a Star: A Heliophysics Dataset and Benchmark for Agentic Scientific Reasoning", "comment": "Accepted at NeurIPS 2025 Machine Learning and the Physical Sciences (ML4PS) Workshop. Dataset: https://huggingface.co/datasets/SpaceML/ReasoningWithAStar", "summary": "Scientific reasoning through Large Language Models in heliophysics involves more than just recalling facts: it requires incorporating physical assumptions, maintaining consistent units, and providing clear scientific formats through coordinated approaches. To address these challenges, we present Reasoning With a Star, a newly contributed heliophysics dataset applicable to reasoning; we also provide an initial benchmarking approach. Our data are constructed from National Aeronautics and Space Administration & University Corporation for Atmospheric Research Living With a Star summer school problem sets and compiled into a readily consumable question-and-answer structure with question contexts, reasoning steps, expected answer type, ground-truth targets, format hints, and metadata. A programmatic grader checks the predictions using unit-aware numerical tolerance, symbolic equivalence, and schema validation. We benchmark a single-shot baseline and four multi-agent patterns, finding that decomposing workflows through systems engineering principles outperforms direct prompting on problems requiring deductive reasoning rather than pure inductive recall.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86Reasoning With a Star\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u592a\u9633\u7269\u7406\u79d1\u5b66\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5305\u62ec\u7269\u7406\u5047\u8bbe\u3001\u5355\u4f4d\u4e00\u81f4\u6027\u548c\u79d1\u5b66\u683c\u5f0f\u8981\u6c42\uff0c\u5e76\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u7f3a\u4e4f\u5bf9\u7269\u7406\u5047\u8bbe\u3001\u5355\u4f4d\u4e00\u81f4\u6027\u548c\u79d1\u5b66\u683c\u5f0f\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u592a\u9633\u7269\u7406\u9886\u57df\u9700\u8981\u66f4\u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eNASA\u548cUCAR\u7684Living With a Star\u6691\u671f\u5b66\u6821\u95ee\u9898\u96c6\u6784\u5efa\u6570\u636e\u96c6\uff0c\u5305\u542b\u95ee\u9898\u4e0a\u4e0b\u6587\u3001\u63a8\u7406\u6b65\u9aa4\u3001\u7b54\u6848\u7c7b\u578b\u548c\u5143\u6570\u636e\uff1b\u5f00\u53d1\u7a0b\u5e8f\u5316\u8bc4\u5206\u5668\u8fdb\u884c\u6570\u503c\u5bb9\u5dee\u3001\u7b26\u53f7\u7b49\u4ef7\u548c\u6a21\u5f0f\u9a8c\u8bc1\uff1b\u8bc4\u4f30\u5355\u6b21\u63d0\u793a\u548c\u56db\u79cd\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u5de5\u7a0b\u539f\u7406\u5206\u89e3\u5de5\u4f5c\u6d41\u7a0b\u7684\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u5728\u9700\u8981\u6f14\u7ece\u63a8\u7406\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4f18\u4e8e\u76f4\u63a5\u63d0\u793a\uff0c\u800c\u5bf9\u7eaf\u5f52\u7eb3\u56de\u5fc6\u95ee\u9898\u6548\u679c\u4e0d\u660e\u663e\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u590d\u6742\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u4e25\u683c\u903b\u8f91\u63a8\u5bfc\u7684\u9886\u57df\uff0c\u4e3a\u592a\u9633\u7269\u7406\u9886\u57df\u7684AI\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2511.21449", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.21449", "abs": "https://arxiv.org/abs/2511.21449", "authors": ["Steffen Tillmann", "Felipe A. Gonz\u00e1lez", "Stefanie Elgeti"], "title": "Numerical Optimization of Nozzle Shapes for Fused Deposition Modeling", "comment": null, "summary": "Purpose: In fused deposition modeling (FDM), the nozzle plays a critical role in enabling high printing speeds while maintaining precision. Despite its importance, most applications still rely on standard nozzle designs. This work investigates the influence of nozzle geometry on pressure loss inside the nozzle, a key factor in high-speed printing performance. Design/methodology/approach: We focus on optimizing the nozzle shape to minimize the pressure loss and establish a framework that allows both sim- ple angle-based optimization and more advanced spline-based parametrization. To model the polymer melt flow, we compare two constitutive descriptions commonly employed in the literature: a temperature-dependent, shear-thinning viscous model and an isothermal viscoelastic model. Findings: For the viscous model, the optimal half-opening angle exhibits a strong dependence on the feeding rate, with higher rates favoring half-opening angles near 30\u00b0, whereas lower rates are more efficient at larger angles. In con- trast, the viscoelastic model predicts a weaker dependence of the optimal angle on the feeding rate. For both models, spline-based parametrization yields only marginal improvements over angle optimization in terms of reducing pressure loss. Originality/value: This paper presents a comparative study of FDM nozzle shape optimization using different simulation models. We introduce a flexible optimization framework that accommodates both simple and advanced geomet- ric parametrizations. The results highlight the impact of model choice on the optimal nozzle geometry and provide support for improving nozzle design in high-speed printing applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf9\u6bd4\u4e0d\u540c\u6a21\u62df\u6a21\u578b\u4e0bFDM\u55b7\u5634\u51e0\u4f55\u5f62\u72b6\u4f18\u5316\uff0c\u53d1\u73b0\u6700\u4f73\u5f00\u53e3\u89d2\u968f\u8fdb\u6599\u901f\u7387\u53d8\u5316\uff1b\u7c98\u6027\u6a21\u578b\u5f71\u54cd\u663e\u8457\uff0c\u7c98\u5f39\u6027\u6a21\u578b\u5f71\u54cd\u8f83\u5f31\uff1b\u57fa\u4e8e\u6837\u6761\u7684\u53c2\u6570\u5316\u76f8\u6bd4\u89d2\u5ea6\u4f18\u5316\u6539\u8fdb\u6709\u9650\u3002", "motivation": "\u5c3d\u7ba1\u55b7\u5634\u5728FDM\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u591a\u6570\u5e94\u7528\u4ecd\u4f9d\u8d56\u6807\u51c6\u8bbe\u8ba1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u55b7\u5634\u51e0\u4f55\u5f62\u72b6\u5bf9\u5185\u90e8\u538b\u529b\u635f\u5931\u7684\u5f71\u54cd\uff0c\u4ee5\u63d0\u5347\u9ad8\u901f\u6253\u5370\u6027\u80fd\u3002", "method": "\u805a\u7126\u4f18\u5316\u55b7\u5634\u5f62\u72b6\u4ee5\u6700\u5c0f\u5316\u538b\u529b\u635f\u5931\uff0c\u5efa\u7acb\u5141\u8bb8\u7b80\u5355\u89d2\u5ea6\u4f18\u5316\u548c\u9ad8\u7ea7\u6837\u6761\u53c2\u6570\u5316\u7684\u6846\u67b6\u3002\u6bd4\u8f83\u4e24\u79cd\u805a\u5408\u7269\u7194\u4f53\u6d41\u52a8\u6a21\u578b\uff1a\u6e29\u5ea6\u4f9d\u8d56\u526a\u5207\u7a00\u5316\u7c98\u6027\u6a21\u578b\u548c\u7b49\u6e29\u7c98\u5f39\u6027\u6a21\u578b\u3002", "result": "\u7c98\u6027\u6a21\u578b\u4e2d\u6700\u4f73\u534a\u5f00\u53e3\u89d2\u4f9d\u8d56\u8fdb\u6599\u901f\u7387\uff0c\u9ad8\u901f\u7387\u4e0b\u504f\u597d\u7ea630\u00b0\uff0c\u4f4e\u901f\u7387\u4e0b\u5927\u89d2\u5ea6\u66f4\u9ad8\u6548\uff1b\u7c98\u5f39\u6027\u6a21\u578b\u9884\u6d4b\u6700\u4f73\u89d2\u5bf9\u8fdb\u6599\u901f\u7387\u4f9d\u8d56\u8f83\u5f31\u3002\u4e24\u79cd\u6a21\u578b\u4e0b\u57fa\u4e8e\u6837\u6761\u53c2\u6570\u5316\u76f8\u6bd4\u89d2\u5ea6\u4f18\u5316\u5728\u538b\u529b\u635f\u5931\u51cf\u5c11\u65b9\u9762\u6539\u8fdb\u6709\u9650\u3002", "conclusion": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e0d\u540c\u6a21\u62df\u6a21\u578b\u4e0bFDM\u55b7\u5634\u5f62\u72b6\u4f18\u5316\uff0c\u5f15\u5165\u4e86\u7075\u6d3b\u7684\u4f18\u5316\u6846\u67b6\uff0c\u7ed3\u679c\u5f3a\u8c03\u4e86\u6a21\u578b\u9009\u62e9\u5bf9\u6700\u4f18\u51e0\u4f55\u7684\u5f71\u54cd\uff0c\u5e76\u4e3a\u9ad8\u901f\u6253\u5370\u4e2d\u55b7\u5634\u8bbe\u8ba1\u6539\u8fdb\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2511.20709", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20709", "abs": "https://arxiv.org/abs/2511.20709", "authors": ["Abhijeet Pathak", "Suvadra Barua", "Dinesh Gudimetla", "Rupam Patir", "Jiawei Guo", "Hongxin Hu", "Haipeng Cai"], "title": "DUALGUAGE: Automated Joint Security-Functionality Benchmarking for Secure Code Generation", "comment": null, "summary": "Large language models (LLMs) and autonomous coding agents are increasingly used to generate software across a wide range of domains. Yet a core requirement remains unmet: ensuring that generated code is secure without compromising its functional correctness. Existing benchmarks and evaluations for secure code generation fall short-many measure only vulnerability reduction, disregard correctness preservation, or evaluate security and functionality on separate datasets, violating the fundamental need for simultaneous joint evaluation. We present DUALGAUGE, the first fully automated benchmarking framework designed to rigorously evaluate the security and correctness of LLM-generated code in unison. Given the lack of datasets enabling joint evaluation of secure code generation, we also present DUALGAUGE-BENCH, a curated benchmark suite of diverse coding tasks, each paired with manually validated test suites for both security and functionality, designed for full coverage of specification requirements. At the core of DUALGAUGE is an agentic program executor, which runs a program against given tests in sandboxed environments, and an LLM-based evaluator, which assesses both correctness and vulnerability behavior against expected outcomes. We rigorously evaluated and ensured the quality of DUALGAUGE-BENCH and the accuracy of DUALGAUGE, and applied DUALGAUGE to benchmarking ten leading LLMs on DUALGAUGE-BENCH across thousands of test scenarios. Our results reveal critical gaps in correct and secure code generation by these LLMs, for which our open-source system and datasets help accelerate progress via reproducible, scalable, and rigorous evaluation.", "AI": {"tldr": "DUALGAUGE\u662f\u9996\u4e2a\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u540c\u65f6\u8bc4\u4f30LLM\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u548c\u6b63\u786e\u6027\u3002\u5b83\u5305\u542b\u4e00\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u548c\u4e00\u4e2a\u8bc4\u4f30\u7cfb\u7edf\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u5728\u5b89\u5168\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u4e25\u91cd\u7f3a\u9677\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8981\u4e48\u53ea\u8bc4\u4f30\u5b89\u5168\u6027\u800c\u5ffd\u89c6\u529f\u80fd\u6027\uff0c\u8981\u4e48\u5728\u5206\u79bb\u7684\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e24\u8005\uff0c\u65e0\u6cd5\u6ee1\u8db3\u540c\u65f6\u8bc4\u4f30\u5b89\u5168\u6027\u548c\u6b63\u786e\u6027\u7684\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u4e86DUALGAUGE-BENCH\u57fa\u51c6\u5957\u4ef6\uff08\u5305\u542b\u591a\u6837\u5316\u7f16\u7a0b\u4efb\u52a1\u53ca\u624b\u52a8\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u5957\u4ef6\uff09\u548cDUALGAUGE\u6846\u67b6\uff08\u5305\u542b\u6c99\u76d2\u7a0b\u5e8f\u6267\u884c\u5668\u548c\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u5668\uff09\u3002", "result": "\u5bf9\u5341\u4e2a\u4e3b\u6d41LLM\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5b83\u4eec\u5728\u751f\u6210\u6b63\u786e\u4e14\u5b89\u5168\u7684\u4ee3\u7801\u65b9\u9762\u5b58\u5728\u91cd\u5927\u7f3a\u9677\u3002", "conclusion": "DUALGAUGE\u4e3a\u53ef\u91cd\u590d\u3001\u53ef\u6269\u5c55\u7684\u4e25\u683c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5f00\u6e90\u7cfb\u7edf\u548c\u6570\u636e\u96c6\uff0c\u6709\u52a9\u4e8e\u52a0\u901f\u5b89\u5168\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u8fdb\u5c55\u3002"}}
{"id": "2511.20695", "categories": ["cs.AI", "cs.CY", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.20695", "abs": "https://arxiv.org/abs/2511.20695", "authors": ["Yunqi Zhang", "Kuangyu Shi", "Biao Li"], "title": "A Brief History of Digital Twin Technology", "comment": "21 pages, 1 figure, 1 table", "summary": "Emerging from NASA's spacecraft simulations in the 1960s, digital twin technology has advanced through industrial adoption to spark a healthcare transformation. A digital twin is a dynamic, data-driven virtual counterpart of a physical system, continuously updated through real-time data streams and capable of bidirectional interaction. In medicine, digital twin integrates imaging, biosensors, and computational models to generate patient-specific simulations that support diagnosis, treatment planning, and drug development. Representative applications include cardiac digital twin for predicting arrhythmia treatment outcomes, oncology digital twin for tracking tumor progression and optimizing radiotherapy, and pharmacological digital twin for accelerating drug discovery. Despite rapid progress, major challenges, including interoperability, data privacy, and model fidelity, continue to limit widespread clinical integration. Emerging solutions such as explainable AI, federated learning, and harmonized regulatory frameworks offer promising pathways forward. Looking ahead, advances in multi-organ digital twin, genomics integration, and ethical governance will be essential to ensure that digital twin shifts healthcare from reactive treatment to predictive, preventive, and truly personalized medicine.", "AI": {"tldr": "\u6570\u5b57\u5b6a\u751f\u6280\u672f\u901a\u8fc7\u521b\u5efa\u60a3\u8005\u7279\u5f02\u6027\u865a\u62df\u6a21\u578b\u6b63\u5728\u6539\u53d8\u533b\u7597\u5065\u5eb7\uff0c\u4f46\u5728\u5e7f\u6cdb\u4e34\u5e8a\u6574\u5408\u524d\u4ecd\u9700\u89e3\u51b3\u6570\u636e\u4e92\u64cd\u4f5c\u6027\u548c\u9690\u79c1\u7b49\u6311\u6218\u3002", "motivation": "\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4eceNASA\u822a\u5929\u5668\u6a21\u62df\u53d1\u5c55\u5230\u533b\u7597\u5065\u5eb7\u9886\u57df\uff0c\u6709\u671b\u63a8\u52a8\u533b\u7597\u4ece\u88ab\u52a8\u6cbb\u7597\u5411\u9884\u6d4b\u6027\u3001\u9884\u9632\u6027\u548c\u4e2a\u6027\u5316\u533b\u5b66\u8f6c\u53d8\u3002", "method": "\u901a\u8fc7\u6574\u5408\u5f71\u50cf\u5b66\u3001\u751f\u7269\u4f20\u611f\u5668\u548c\u8ba1\u7b97\u6a21\u578b\u521b\u5efa\u60a3\u8005\u7279\u5b9a\u7684\u865a\u62df\u526f\u672c\uff0c\u652f\u6301\u8bca\u65ad\u3001\u6cbb\u7597\u89c4\u5212\u548c\u836f\u7269\u5f00\u53d1\u3002", "result": "\u5f00\u53d1\u4e86\u5fc3\u810f\u6570\u5b57\u5316\u5b6a\u751f\u9884\u6d4b\u5fc3\u5f8b\u5931\u5e38\u6cbb\u7597\u6548\u679c\u3001\u80bf\u7624\u6570\u5b57\u5316\u5b6a\u751f\u8ddf\u8e2a\u80bf\u7624\u8fdb\u5c55\u548c\u4f18\u5316\u653e\u7597\u3001\u836f\u7269\u6570\u5b57\u5316\u5b6a\u751f\u52a0\u901f\u836f\u7269\u53d1\u73b0\u7b49\u4ee3\u8868\u6027\u5e94\u7528\u3002", "conclusion": "\u867d\u7136\u9762\u4e34\u4e92\u64cd\u4f5c\u6027\u3001\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u4fdd\u771f\u5ea6\u7b49\u6311\u6218\uff0c\u4f46\u53ef\u89e3\u91caAI\u3001\u8054\u90a6\u5b66\u4e60\u548c\u7edf\u4e00\u76d1\u7ba1\u6846\u67b6\u7b49\u65b0\u5174\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u524d\u8fdb\u65b9\u5411\u3002\u672a\u6765\u9700\u8981\u591a\u5668\u5b98\u6570\u5b57\u5b6a\u751f\u3001\u57fa\u56e0\u7ec4\u5b66\u6574\u5408\u548c\u4f26\u7406\u6cbb\u7406\u65b9\u9762\u7684\u8fdb\u5c55\u3002"}}
{"id": "2511.20878", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20878", "abs": "https://arxiv.org/abs/2511.20878", "authors": ["Jaehwan Park", "Kyungchan Lim", "Seonhye Park", "Doowon Kim"], "title": "Supporting Students in Navigating LLM-Generated Insecure Code", "comment": "7 pages", "summary": "The advent of Artificial Intelligence (AI), particularly large language models (LLMs), has revolutionized software development by enabling developers to specify tasks in natural language and receive corresponding code, boosting productivity. However, this shift also introduces security risks, as LLMs may generate insecure code that can be exploited by adversaries. Current educational approaches emphasize efficiency while overlooking these risks, leaving students underprepared to identify and mitigate security issues in AI-assisted workflows.\n  To address this gap, we present Bifr\u00f6st, an educational framework that cultivates security awareness in AI-augmented development. Bifr\u00f6st integrates (1) a Visual Studio Code extension simulating realistic environments, (2) adversarially configured LLMs that generate insecure code, and (3) a feedback system highlighting vulnerabilities. By immersing students in tasks with compromised LLMs and providing targeted security analysis, Bifr\u00f6st cultivates critical evaluation skills; classroom deployments (n=61) show vulnerability to insecure code, while a post-intervention survey (n=21) indicates increased skepticism toward LLM outputs.", "AI": {"tldr": "Bifr\u00f6st\u662f\u4e00\u4e2a\u6559\u80b2\u6846\u67b6\uff0c\u901a\u8fc7\u5728AI\u8f85\u52a9\u5f00\u53d1\u73af\u5883\u4e2d\u6a21\u62df\u4e0d\u5b89\u5168\u4ee3\u7801\u751f\u6210\u5e76\u5206\u6790\u6f0f\u6d1e\u6765\u57f9\u517b\u5b66\u751f\u7684\u5b89\u5168\u610f\u8bc6\u3002", "motivation": "AI\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u63d0\u5347\u4e86\u6548\u7387\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u5b89\u5168\u9690\u60a3\u2014\u2014LLMs\u53ef\u80fd\u751f\u6210\u4e0d\u5b89\u5168\u7684\u4ee3\u7801\u3002\u5f53\u524d\u6559\u80b2\u65b9\u6cd5\u4fa7\u91cd\u6548\u7387\u800c\u5ffd\u89c6\u5b89\u5168\u95ee\u9898\uff0c\u4f7f\u5b66\u751f\u7f3a\u4e4f\u8bc6\u522b\u548c\u7f13\u89e3AI\u8f85\u52a9\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u5b89\u5168\u95ee\u9898\u7684\u80fd\u529b\u3002", "method": "Bifr\u00f6st\u6846\u67b6\u6574\u5408\u4e86\u4e09\u90e8\u5206\uff1a(1) Visual Studio Code\u6269\u5c55\u6a21\u62df\u771f\u5b9eAI\u8f85\u52a9\u5f00\u53d1\u73af\u5883\uff0c(2) \u5bf9\u6297\u6027\u914d\u7f6e\u7684LLMs\u4ee5\u751f\u6210\u4e0d\u5b89\u5168\u4ee3\u7801\uff0c(3) \u53cd\u9988\u7cfb\u7edf\u9ad8\u4eae\u663e\u793a\u6f0f\u6d1e\u3002\u901a\u8fc7\u8ba9\u5b66\u751f\u5728\u53d7\u635fLLMs\u73af\u5883\u4e0b\u5b8c\u6210\u4efb\u52a1\u5e76\u63d0\u4f9b\u5b9a\u5411\u5b89\u5168\u5206\u6790\uff0c\u57f9\u517b\u5176\u6279\u5224\u6027\u8bc4\u4f30\u6280\u80fd\u3002", "result": "\u8bfe\u5802\u90e8\u7f72\uff08n=61\uff09\u663e\u793a\u5b66\u751f\u5bf9\u4e0d\u5b89\u5168\u4ee3\u7801\u7684\u6f0f\u6d1e\u6027\uff0c\u800c\u5e72\u9884\u540e\u8c03\u67e5\uff08n=21\uff09\u8868\u660e\u5b66\u751f\u5bf9LLM\u8f93\u51fa\u66f4\u52a0\u6000\u7591\u3002", "conclusion": "Bifr\u00f6st\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u5bf9AI\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u610f\u8bc6\uff0c\u5f3a\u8c03\u4e86\u5728AI\u8f85\u52a9\u5f00\u53d1\u6559\u80b2\u4e2d\u878d\u5408\u5b89\u5168\u57f9\u8bad\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.20813", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.20813", "abs": "https://arxiv.org/abs/2511.20813", "authors": ["Simon Hacks"], "title": "Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms", "comment": "17 pages, submitted to CAiSE - International Conference on Advanced information Systems Engineering 2026", "summary": "\"Train While You Fight\" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.", "AI": {"tldr": "TWYF advocates continuous learning during operations. The paper examines technical requirements for ADL platforms to support TWYF using design science research.", "motivation": "Address the gap in supporting continuous learning during military operations through advanced distributed learning platforms.", "method": "Design Science Research approach involving challenge derivation from PfPC/NATO docs, solution objective definition, and systematic pattern mapping.", "result": "Identified seven technical challenges: interoperability, resilience, multilingual support, data security/privacy, scalability, platform independence, and modularity.", "conclusion": "Proposes pattern-based solutions validated through a German armed forces use case, demonstrating practical applicability of TWYF framework."}}
{"id": "2511.20701", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20701", "abs": "https://arxiv.org/abs/2511.20701", "authors": ["Nitya Tiwari", "Parv Maheshwari", "Vidisha Agarwal"], "title": "Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework", "comment": null, "summary": "While recent work has extended CoT to multimodal settings, achieving state-of-the-art results on science question answering benchmarks like ScienceQA, the generalizability of these approaches across diverse domains remains underexplored. This work presents a comprehensive analysis of Multimodal Chain-of-Thought (Multimodal-CoT) reasoning, evaluating its effectiveness on the A-OKVQA, OKVQA and ChartQA datasets, which requires broad commonsense and world knowledge beyond scientific reasoning. We implement the two-stage framework proposed by Zhang et al. [3], which separates rationale generation from answer inference and integrates vision features through a gated fusion mechanism with T5-based language models. Through systematic ablation studies, we analyze the contributions of vision features, rationale quality, and architectural choices. Our findings reveal that while vision integration significantly reduces hallucination in rationale generation, the effectiveness of CoT reasoning varies substantially across question types, with commonsense reasoning presenting particular challenges. This work provides practical insights for researchers implementing multimodal reasoning systems and identifies key areas for future improvement in cross-domain generalization.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u591a\u6a21\u6001\u601d\u7ef4\u94fe(Multimodal-CoT)\u5728\u4e0d\u540c\u9886\u57df\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u6d88\u878d\u5b9e\u9a8c\u63ed\u793a\u4e86\u89c6\u89c9\u7279\u5f81\u6574\u5408\u548c\u95ee\u9898\u7c7b\u578b\u5bf9\u63a8\u7406\u6548\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001CoT\u5728\u79d1\u5b66\u95ee\u7b54\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u5148\u8fdb\u6210\u679c\uff0c\u4f46\u5176\u5728\u4e0d\u540c\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u4ecd\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u591a\u6a21\u6001CoT\u5728\u9700\u8981\u5e38\u8bc6\u63a8\u7406\u7684\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u91c7\u7528Zhang\u7b49\u4eba\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5c06\u539f\u7406\u751f\u6210\u4e0e\u7b54\u6848\u63a8\u7406\u5206\u79bb\uff0c\u5e76\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u673a\u5236\u5c06\u89c6\u89c9\u7279\u5f81\u4e0eT5\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u3002\u5728A-OKVQA\u3001OKVQA\u548cChartQA\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6027\u6d88\u878d\u7814\u7a76\u3002", "result": "\u89c6\u89c9\u7279\u5f81\u6574\u5408\u663e\u8457\u51cf\u5c11\u4e86\u539f\u7406\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\uff0c\u4f46CoT\u63a8\u7406\u6548\u679c\u5728\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u95f4\u5dee\u5f02\u5f88\u5927\uff0c\u5e38\u8bc6\u63a8\u7406\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u7684\u5b9e\u65bd\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u5e76\u786e\u5b9a\u4e86\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u6539\u8fdb\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2511.20902", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.20902", "abs": "https://arxiv.org/abs/2511.20902", "authors": ["Glener Lanes Pizzolato", "Brenda Medeiros Lopes", "Claudio Schepke", "Diego Kreutz"], "title": "A Taxonomy of Pix Fraud in Brazil: Attack Methodologies, AI-Driven Amplification, and Defensive Strategies", "comment": "5 pages, 1 figure, 2 tables, submitted to ERRC/WRSeg 2025", "summary": "This work presents a review of attack methodologies targeting Pix, the instant payment system launched by the Central Bank of Brazil in 2020. The study aims to identify and classify the main types of fraud affecting users and financial institutions, highlighting the evolution and increasing sophistication of these techniques. The methodology combines a structured literature review with exploratory interviews conducted with professionals from the banking sector. The results show that fraud schemes have evolved from purely social engineering approaches to hybrid strategies that integrate human manipulation with technical exploitation. The study concludes that security measures must advance at the same pace as the growing complexity of attack methodologies, with particular emphasis on adaptive defenses and continuous user awareness.", "AI": {"tldr": "\u56de\u987e\u9488\u5bf9\u5df4\u897fPix\u5373\u65f6\u652f\u4ed8\u7cfb\u7edf\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5206\u7c7b\u4e3b\u8981\u6b3a\u8bc8\u7c7b\u578b\uff0c\u5206\u6790\u5176\u6f14\u53d8\u8d8b\u52bf\u3002\u7ed3\u5408\u6587\u732e\u7efc\u8ff0\u548c\u94f6\u884c\u4e13\u4e1a\u4eba\u58eb\u8bbf\u8c08\uff0c\u53d1\u73b0\u8bc8\u9a97\u624b\u6bb5\u4ece\u7eaf\u793e\u4f1a\u5de5\u7a0b\u8f6c\u5411\u6df7\u5408\u7b56\u7565\u3002", "motivation": "\u8bc6\u522b\u548c\u5206\u7c7b\u5f71\u54cd\u7528\u6237\u53ca\u91d1\u878d\u673a\u6784\u7684\u4e3b\u8981\u6b3a\u8bc8\u7c7b\u578b\uff0c\u63ed\u793a\u653b\u51fb\u6280\u672f\u7684\u6f14\u53d8\u548c\u65e5\u76ca\u590d\u6742\u5316\u8d8b\u52bf\u3002", "method": "\u7ed3\u5408\u7ed3\u6784\u5316\u6587\u732e\u7efc\u8ff0\u4e0e\u5bf9\u94f6\u884c\u884c\u4e1a\u4e13\u4e1a\u4eba\u58eb\u7684\u63a2\u7d22\u6027\u8bbf\u8c08\u3002", "result": "\u6b3a\u8bc8\u65b9\u6848\u5df2\u4ece\u7eaf\u7cb9\u7684\u793e\u4f1a\u5de5\u7a0b\u65b9\u6cd5\u53d1\u5c55\u4e3a\u6574\u5408\u4eba\u4e3a\u64cd\u7eb5\u4e0e\u6280\u672f\u5229\u7528\u7684\u6df7\u5408\u7b56\u7565\u3002", "conclusion": "\u5b89\u5168\u63aa\u65bd\u5fc5\u987b\u4e0e\u653b\u51fb\u65b9\u6cd5\u65e5\u76ca\u589e\u957f\u7684\u590d\u6742\u6027\u540c\u6b65\u53d1\u5c55\uff0c\u7279\u522b\u5f3a\u8c03\u9002\u5e94\u6027\u9632\u5fa1\u548c\u6301\u7eed\u7684\u7528\u6237\u610f\u8bc6\u6559\u80b2\u3002"}}
{"id": "2511.20920", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.20920", "abs": "https://arxiv.org/abs/2511.20920", "authors": ["Herman Errico", "Jiquan Ngiam", "Shanita Sojan"], "title": "Securing the Model Context Protocol (MCP): Risks, Controls, and Governance", "comment": null, "summary": "The Model Context Protocol (MCP) replaces static, developer-controlled API integrations with more dynamic, user-driven agent systems, which also introduces new security risks. As MCP adoption grows across community servers and major platforms, organizations encounter threats that existing AI governance frameworks (such as NIST AI RMF and ISO/IEC 42001) do not yet cover in detail. We focus on three types of adversaries that take advantage of MCP s flexibility: content-injection attackers that embed malicious instructions into otherwise legitimate data; supply-chain attackers who distribute compromised servers; and agents who become unintentional adversaries by over-stepping their role. Based on early incidents and proof-of-concept attacks, we describe how MCP can increase the attack surface through data-driven exfiltration, tool poisoning, and cross-system privilege escalation. In response, we propose a set of practical controls, including per-user authentication with scoped authorization, provenance tracking across agent workflows, containerized sandboxing with input/output checks, inline policy enforcement with DLP and anomaly detection, and centralized governance using private registries or gateway layers. The aim is to help organizations ensure that unvetted code does not run outside a sandbox, tools are not used beyond their intended scope, data exfiltration attempts are detectable, and actions can be audited end-to-end. We close by outlining open research questions around verifiable registries, formal methods for these dynamic systems, and privacy-preserving agent operations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.20933", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.20933", "abs": "https://arxiv.org/abs/2511.20933", "authors": ["Mootez Saad", "Boqi Chen", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "D\u00e1niel Varr\u00f3", "Tushar Sharma"], "title": "Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code", "comment": "18 figures", "summary": "Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \\textit{Verification} to \\textit{Guided} and \\textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \\textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.", "AI": {"tldr": "\u8bc4\u4f30DeepSeek-R1\u6a21\u578b\u7cfb\u5217\u5bf9\u8f6f\u4ef6\u8bbe\u8ba1\u6982\u5ff5\uff08\u5185\u805a\u6027\u548c\u8026\u5408\u6027\uff09\u7684\u7406\u89e3\u3002\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5b9e\u9645\u5608\u6742\u73af\u5883\u4e2d\u8868\u73b0\u8106\u5f31\u4e14\u4e0d\u5bf9\u79f0\u3002\u8026\u5408\u6027\u63a8\u7406\u5bb9\u6613\u5d29\u6e83\uff0c\u800c\u5185\u805a\u6027\u5206\u6790\u5728\u6307\u5bfc\u4efb\u52a1\u4e2d\u76f8\u5bf9\u7a33\u5065\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5176\u5bf9\u6838\u5fc3\u8f6f\u4ef6\u8bbe\u8ba1\u6982\u5ff5\u7684\u9c81\u68d2\u6027\u7406\u89e3\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u7a0b\u5e8f\u751f\u6210\u8bbe\u8ba1\u4e0d\u826f\u7684\u4ee3\u7801\u7247\u6bb5\uff0c\u6d4b\u8bd5DeepSeek-R1\u6a21\u578b\u5bb6\u65cf\uff0814B\u300132B\u300170B\uff09\u5728\u4e0d\u540c\u6307\u5bfc\u7ea7\u522b\uff08\u9a8c\u8bc1\u3001\u6307\u5bfc\u3001\u5f00\u653e\u751f\u6210\uff09\u548c\u4e0d\u540c\u4e0a\u4e0b\u6587\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6a21\u578b\u5bf9\u8026\u5408\u6027\u63a8\u7406\u8106\u5f31\uff0c\u5728\u5608\u6742\u5f00\u653e\u573a\u666f\u4e2dF1\u5206\u6570\u4e0b\u964d\u8d85\u8fc750%\uff1b\u800c\u5bf9\u5185\u805a\u6027\u5206\u6790\u5728\u6307\u5bfc\u4efb\u52a1\u4e2d\u9c81\u68d2\uff0c\u6027\u80fd\u4e0b\u964d\u5c0f\u3002\u63a8\u7406\u8f68\u8ff9\u5206\u6790\u663e\u793a\u8026\u5408\u6027\u5b58\u5728\u8ba4\u77e5\u6377\u5f84\uff0c\u5185\u805a\u6027\u5206\u6790\u66f4\u8be6\u5c3d\u4f46\u4ecd\u5931\u8d25\u3002", "conclusion": "LLMs\u53ef\u53ef\u9760\u534f\u52a9\u8bc6\u522b\u8bbe\u8ba1\u7f3a\u9677\uff0c\u4f46\u5728\u5608\u6742\u73b0\u5b9e\u73af\u5883\u4e2d\u81ea\u4e3b\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u51f8\u663e\u9700\u8981\u66f4\u53ef\u6269\u5c55\u548c\u9c81\u68d2\u7684\u7a0b\u5e8f\u7406\u89e3\u80fd\u529b\u3002"}}
{"id": "2511.20922", "categories": ["cs.CR", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20922", "abs": "https://arxiv.org/abs/2511.20922", "authors": ["Guilin Zhang", "Wulan Guo", "Ziqi Tan", "Hongyang He", "Hailong Jiang"], "title": "Readout-Side Bypass for Residual Hybrid Quantum-Classical Models", "comment": "5 pages, 1 figure, 6 tables", "summary": "Quantum machine learning (QML) promises compact and expressive representations, but suffers from the measurement bottleneck - a narrow quantum-to-classical readout that limits performance and amplifies privacy risk. We propose a lightweight residual hybrid architecture that concatenates quantum features with raw inputs before classification, bypassing the bottleneck without increasing quantum complexity. Experiments show our model outperforms pure quantum and prior hybrid models in both centralized and federated settings. It achieves up to +55% accuracy improvement over quantum baselines, while retaining low communication cost and enhanced privacy robustness. Ablation studies confirm the effectiveness of the residual connection at the quantum-classical interface. Our method offers a practical, near-term pathway for integrating quantum models into privacy-sensitive, resource-constrained settings like federated edge learning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5c06\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u5728\u5206\u7c7b\u524d\u62fc\u63a5\uff0c\u7ed5\u8fc7\u6d4b\u91cf\u74f6\u9888\uff0c\u5728\u4e2d\u5fc3\u5316\u548c\u8054\u90a6\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u7eaf\u91cf\u5b50\u6a21\u578b\u548c\u73b0\u6709\u6df7\u5408\u6a21\u578b\u3002", "motivation": "\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u5b58\u5728\u6d4b\u91cf\u74f6\u9888\u95ee\u9898 - \u72ed\u7a84\u7684\u91cf\u5b50-\u7ecf\u5178\u8bfb\u51fa\u9650\u5236\u4e86\u6027\u80fd\u5e76\u653e\u5927\u4e86\u9690\u79c1\u98ce\u9669\u3002", "method": "\u91c7\u7528\u6b8b\u5dee\u6df7\u5408\u67b6\u6784\uff0c\u5728\u91cf\u5b50-\u7ecf\u5178\u63a5\u53e3\u5904\u6dfb\u52a0\u6b8b\u5dee\u8fde\u63a5\uff0c\u5c06\u91cf\u5b50\u7279\u5f81\u4e0e\u539f\u59cb\u8f93\u5165\u62fc\u63a5\u540e\u8fdb\u884c\u5206\u7c7b\uff0c\u4e0d\u589e\u52a0\u91cf\u5b50\u590d\u6742\u5ea6\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u5728\u4e2d\u5fc3\u5316\u548c\u8054\u90a6\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u7eaf\u91cf\u5b50\u6a21\u578b\u548c\u73b0\u6709\u6df7\u5408\u6a21\u578b\uff0c\u76f8\u6bd4\u91cf\u5b50\u57fa\u7ebf\u7cbe\u5ea6\u63d0\u5347\u9ad8\u8fbe+55%\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u901a\u4fe1\u6210\u672c\u548c\u589e\u5f3a\u7684\u9690\u79c1\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u9690\u79c1\u654f\u611f\u3001\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\uff08\u5982\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\uff09\u4e2d\u96c6\u6210\u91cf\u5b50\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u8fd1\u671f\u5b9e\u73b0\u8def\u5f84\u3002"}}
{"id": "2511.20955", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20955", "abs": "https://arxiv.org/abs/2511.20955", "authors": ["Sanchit Kaul", "Kevin Nhu", "Jason Eissayou", "Ivan Eser", "Victor Borup"], "title": "SpaceX: Exploring metrics with the SPACE model for developer productivity", "comment": "Code available at https://github.com/knhu/ECS260Project", "summary": "This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7SPACE\u6846\u67b6\u548c\u5f00\u6e90\u4ed3\u5e93\u6570\u636e\u5206\u6790\uff0c\u5f00\u53d1\u4e86\u7efc\u5408\u751f\u4ea7\u529b\u8bc4\u5206(CPS)\u6765\u514b\u670d\u4f20\u7edf\u5355\u7ef4\u751f\u4ea7\u529b\u6307\u6807\u7684\u5c40\u9650\u6027", "motivation": "\u4f20\u7edf\u786e\u5b9a\u6027\u5355\u7ef4\u751f\u4ea7\u529b\u542f\u53d1\u5f0f\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u591a\u7ef4\u5ea6\u751f\u4ea7\u529b\u8bc4\u4f30\u6846\u67b6", "method": "\u8fd0\u7528\u5e7f\u4e49\u7ebf\u6027\u6df7\u5408\u6a21\u578b(GLM)\u548cRoBERTa\u60c5\u611f\u5206\u7c7b\u5bf9\u5f00\u6e90\u4ed3\u5e93\u6570\u636e\u8fdb\u884c\u7edf\u8ba1\u5206\u6790", "result": "\u53d1\u73b0\u8d1f\u9762\u60c5\u611f\u72b6\u6001\u4e0e\u63d0\u4ea4\u9891\u7387\u5448\u663e\u8457\u6b63\u76f8\u5173\uff1b\u57fa\u4e8e\u8d21\u732e\u8005\u4ea4\u4e92\u62d3\u6251\u7684\u5206\u6790\u6bd4\u4f20\u7edf\u57fa\u4e8e\u6570\u91cf\u7684\u6307\u6807\u66f4\u80fd\u51c6\u786e\u6620\u5c04\u534f\u4f5c\u52a8\u6001", "conclusion": "\u63d0\u51fa\u590d\u5408\u751f\u4ea7\u529b\u8bc4\u5206(CPS)\u6765\u89e3\u51b3\u5f00\u53d1\u8005\u6548\u80fd\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u751f\u4ea7\u529b\u8bc4\u4f30\u63d0\u4f9b\u65b0\u7684\u591a\u7ef4\u89c6\u89d2"}}
{"id": "2511.20892", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20892", "abs": "https://arxiv.org/abs/2511.20892", "authors": ["Xuyuan Liu", "Zhengzhang Chen", "Xinshuai Dong", "Yanchi Liu", "Xujiang Zhao", "Shengyu Chen", "Haoyu Wang", "Yujun Yan", "Haifeng Chen"], "title": "Representation Interventions Enable Lifelong Unstructured Knowledge Control", "comment": "18 Page", "summary": "Large language models (LLMs) often produce incorrect or outdated content. Updating their knowledge efficiently and accurately without costly retraining is a major challenge. This problem is especially hard for complex, unstructured knowledge in a lifelong setting, where many edits must coexist without interference. We introduce RILKE (Representation Intervention for Lifelong KnowledgE Control), a robust and scalable method that treats knowledge control as interventions within the model's representation space. Leveraging representation-space expressiveness, we identify two properties enabling RILKE to deliver fine-grained control over complex, unstructured knowledge while maintaining general utility with frozen base weights. During training, RILKE learns paraphrase-robust and edit-localized modules that limit each update to a low-dimensional subspace to minimize cross-edit interference. In inference, a query-adaptive router selects the appropriate module to guide the model's generation. In evaluation on knowledge editing benchmarks with LLaMA and Qwen models, RILKE is scalable to large-scale datasets, demonstrating high edit success, strong paraphrase generalization, and preserving general utility with modest memory overhead. These results show RILKE is an effective and scalable solution for lifelong knowledge control in LLMs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86RILKE\u6a21\u578b\u6765\u5904\u7406LLMs\u77e5\u8bc6\u66f4\u65b0\u95ee\u9898\uff0c\u91c7\u7528\u8868\u793a\u7a7a\u95f4\u5e72\u9884\u7684\u65b9\u6cd5\u5728\u7ec8\u8eab\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u5b9e\u73b0\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u77e5\u8bc6\u63a7\u5236\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3LLMs\u4ea7\u751f\u9519\u8bef\u6216\u8fc7\u65f6\u5185\u5bb9\u7684\u77e5\u8bc6\u66f4\u65b0\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u7ec8\u8eab\u5b66\u4e60\u73af\u5883\u4e0b\u9700\u8981\u9ad8\u6548\u66f4\u65b0\u590d\u6742\u975e\u7ed3\u6784\u5316\u77e5\u8bc6\u4e14\u907f\u514d\u5e72\u6270\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u8868\u793a\u7a7a\u95f4\u5e72\u9884\u6280\u672f\uff0c\u8bad\u7ec3\u5b66\u4e60\u5177\u6709\u6297\u6539\u8ff0\u548c\u5c40\u90e8\u5316\u7f16\u8f91\u80fd\u529b\u7684\u6a21\u5757\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u4f7f\u7528\u67e5\u8be2\u81ea\u9002\u5e94\u8def\u7531\u5668\u9009\u62e9\u5408\u9002\u6a21\u5757\u6765\u6307\u5bfc\u751f\u6210\u3002", "result": "\u5728LLaMA\u548cQwen\u6a21\u578b\u7684\u77e5\u8bc6\u7f16\u8f91\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRILKE\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u9ad8\u7f16\u8f91\u6210\u529f\u7387\u3001\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4fdd\u6301\u901a\u7528\u6027\u80fd\u3002", "conclusion": "RILKE\u662fLLMs\u7ec8\u8eab\u77e5\u8bc6\u63a7\u5236\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u63a7\u5236\u540c\u65f6\u6700\u5c0f\u5316\u5185\u5b58\u5f00\u9500\u3002"}}
{"id": "2511.21020", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21020", "abs": "https://arxiv.org/abs/2511.21020", "authors": ["Minghui Min", "Jiahui Liu", "Mingge Cao", "Shiyin Li", "Hongliang Zhang", "Miao Pan", "Zhu Han"], "title": "Road Network-Aware Personalized Trajectory Protection with Differential Privacy under Spatiotemporal Correlations", "comment": "13 pages,10 figures", "summary": "Location-Based Services (LBSs) offer significant convenience to mobile users but pose significant privacy risks, as attackers can infer sensitive personal information through spatiotemporal correlations in user trajectories. Since users' sensitivity to location data varies based on factors such as stay duration, access frequency, and semantic sensitivity, implementing personalized privacy protection is imperative. This paper proposes a Personalized Trajectory Privacy Protection Mechanism (PTPPM) to address these challenges. Our approach begins by modeling an attacker's knowledge of a user's trajectory spatiotemporal correlations, which enables the attacker to identify possible location sets and disregard low-probability location sets. To combat this, we integrate geo-indistinguishability with distortion privacy, allowing users to customize their privacy preferences through a configurable privacy budget and expected inference error bound. This approach provides the theoretical framework for constructing a Protection Location Set (PLS) that obscures users' actual locations. Additionally, we introduce a Personalized Privacy Budget Allocation Algorithm (PPBA), which assesses the sensitivity of locations based on trajectory data and allocates privacy budgets accordingly. This algorithm considers factors such as location semantics and road network constraints. Furthermore, we propose a Permute-and-Flip mechanism that generates perturbed locations while minimizing perturbation distance, thus balancing privacy protection and Quality of Service (QoS). Simulation results demonstrate that our mechanism outperforms existing benchmarks, offering superior privacy protection while maintaining user QoS requirements.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e2a\u6027\u5316\u8f68\u8ff9\u9690\u79c1\u4fdd\u62a4\u673a\u5236(PTPPM)\uff0c\u901a\u8fc7\u7ed3\u5408\u5730\u7406\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5931\u771f\u9690\u79c1\uff0c\u8ba9\u7528\u6237\u53ef\u914d\u7f6e\u9690\u79c1\u9884\u7b97\u548c\u63a8\u65ad\u8bef\u5dee\u754c\u9650\uff0c\u5728\u4fdd\u62a4\u4f4d\u7f6e\u9690\u79c1\u7684\u540c\u65f6\u7ef4\u6301\u670d\u52a1\u8d28\u91cf\u3002", "motivation": "\u57fa\u4e8e\u4f4d\u7f6e\u7684\u670d\u52a1(LBS)\u4e3a\u7528\u6237\u5e26\u6765\u4fbf\u5229\u4f46\u5b58\u5728\u9690\u79c1\u98ce\u9669\uff0c\u653b\u51fb\u8005\u53ef\u901a\u8fc7\u65f6\u7a7a\u76f8\u5173\u6027\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002\u7531\u4e8e\u7528\u6237\u5bf9\u4e0d\u540c\u4f4d\u7f6e\u6570\u636e\u7684\u654f\u611f\u5ea6\u5b58\u5728\u5dee\u5f02\uff0c\u9700\u8981\u4e2a\u6027\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6848\u3002", "method": "1) \u5efa\u6a21\u653b\u51fb\u8005\u5bf9\u7528\u6237\u8f68\u8ff9\u65f6\u7a7a\u76f8\u5173\u6027\u7684\u77e5\u8bc6 2) \u7ed3\u5408\u5730\u7406\u4e0d\u53ef\u533a\u5206\u6027\u548c\u5931\u771f\u9690\u79c1\u6784\u5efa\u4fdd\u62a4\u4f4d\u7f6e\u96c6 3) \u63d0\u51fa\u4e2a\u6027\u5316\u9690\u79c1\u9884\u7b97\u5206\u914d\u7b97\u6cd5 4) \u4f7f\u7528Permute-and-Flip\u673a\u5236\u751f\u6210\u6270\u52a8\u4f4d\u7f6e", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u673a\u5236\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u670d\u52a1\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "PTPPM\u673a\u5236\u80fd\u6709\u6548\u5e73\u8861\u9690\u79c1\u4fdd\u62a4\u4e0e\u670d\u52a1\u8d28\u91cf\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u8f68\u8ff9\u9690\u79c1\u4fdd\u62a4\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.21022", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21022", "abs": "https://arxiv.org/abs/2511.21022", "authors": ["Guancheng Lin", "Xiao Yu", "Jacky Keung", "Xing Hu", "Xin Xia", "Alex X. Liu"], "title": "Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations", "comment": null, "summary": "Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines \"Common API Layers\" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to \"Specific API Layers\" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u5e94\u752810\u79cd\u5148\u8fdb\u7684\u6a21\u578b\u7f16\u8f91\u6280\u672f\u6765\u66f4\u65b0LLMs\u4e2d\u7684\u8fc7\u65f6API\u77e5\u8bc6\uff0c\u63d0\u51fa\u4e86AdaLoRA-L\u65b9\u6cd5\u6765\u89e3\u51b3\u7279\u5f02\u6027\u95ee\u9898", "motivation": "LLMs\u5728\u4ee3\u7801\u8865\u5168\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5d4c\u5165\u77e5\u8bc6\u53d7\u9650\u4e8e\u8bad\u7ec3\u6570\u636e\u7684\u65f6\u6548\u6027\uff0c\u5e38\u5e38\u751f\u6210\u5df2\u5f03\u7528\u7684API\u3002\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u800c\u73b0\u6709\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\u7f16\u8f91\u65b9\u6cd5\u662f\u5426\u80fd\u6709\u6548\u66f4\u65b0\u8fc7\u65f6API\u77e5\u8bc6\u5c1a\u4e0d\u660e\u786e", "method": "\u57283\u4e2aLLMs\u4e0a\u5e94\u752810\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7f16\u8f91\u6280\u672f\uff0c\u5f15\u5165EDAPIBench\u57fa\u51c6\uff08\u5305\u542b8\u4e2a\u6d41\u884cPython\u5e93\u768470\u591a\u4e2a\u8fc7\u65f6API\uff0c3000\u591a\u4e2a\u7f16\u8f91\u5b9e\u4f8b\uff09\uff0c\u63d0\u51faAdaLoRA-L\u65b9\u6cd5\u5b9a\u4e49'\u901a\u7528API\u5c42'\u548c'\u7279\u5b9aAPI\u5c42'", "result": "AdaLoRA\u5728\u751f\u6210\u6b63\u786e\u3001\u6700\u65b0\u7684API\u65b9\u9762\u8868\u73b0\u6700\u4f73\u4f46\u5728\u7279\u5f02\u6027\u65b9\u9762\u4e0d\u8db3\uff1bAdaLoRA-L\u663e\u8457\u63d0\u9ad8\u4e86\u7279\u5f02\u6027\uff0c\u540c\u65f6\u5728\u5176\u4ed6\u8bc4\u4f30\u6307\u6807\u4e0a\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684AdaLoRA-L\u65b9\u6cd5\u901a\u8fc7\u5728\u7279\u5b9aAPI\u5c42\u8fdb\u884c\u7f16\u8f91\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6a21\u578b\u7f16\u8f91\u7684\u7279\u5f02\u6027\u95ee\u9898\uff0c\u4e3aLLMs\u7684\u77e5\u8bc6\u66f4\u65b0\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2511.21180", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21180", "abs": "https://arxiv.org/abs/2511.21180", "authors": ["Shuhan Xia", "Jing Dai", "Hui Ouyang", "Yadong Shang", "Dongxiao Zhao", "Peipei Li"], "title": "CAHS-Attack: CLIP-Aware Heuristic Search Attack Method for Stable Diffusion", "comment": null, "summary": "Diffusion models exhibit notable fragility when faced with adversarial prompts, and strengthening attack capabilities is crucial for uncovering such vulnerabilities and building more robust generative systems. Existing works often rely on white-box access to model gradients or hand-crafted prompt engineering, which is infeasible in real-world deployments due to restricted access or poor attack effect. In this paper, we propose CAHS-Attack , a CLIP-Aware Heuristic Search attack method. CAHS-Attack integrates Monte Carlo Tree Search (MCTS) to perform fine-grained suffix optimization, leveraging a constrained genetic algorithm to preselect high-potential adversarial prompts as root nodes, and retaining the most semantically disruptive outcome at each simulation rollout for efficient local search. Extensive experiments demonstrate that our method achieves state-of-the-art attack performance across both short and long prompts of varying semantics. Furthermore, we find that the fragility of SD models can be attributed to the inherent vulnerability of their CLIP-based text encoders, suggesting a fundamental security risk in current text-to-image pipelines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CAHS-Attack\u65b9\u6cd5\uff0c\u57fa\u4e8eCLIP\u6587\u672c\u7f16\u7801\u5668\u7684\u8106\u5f31\u6027\uff0c\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u548c\u9057\u4f20\u7b97\u6cd5\u4f18\u5316\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u6a21\u578b\u7684\u653b\u51fb\u6548\u679c\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u8106\u5f31\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u767d\u76d2\u68af\u5ea6\u6216\u624b\u5de5\u5de5\u7a0b\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u63ed\u793a\u6a21\u578b\u6f0f\u6d1e\u3002", "method": "CAHS-Attack\u7ed3\u5408\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u8fdb\u884c\u7ec6\u7c92\u5ea6\u540e\u7f00\u4f18\u5316\uff0c\u4f7f\u7528\u7ea6\u675f\u9057\u4f20\u7b97\u6cd5\u9884\u9009\u9ad8\u6f5c\u529b\u5bf9\u6297\u63d0\u793a\u4f5c\u4e3a\u6839\u8282\u70b9\uff0c\u5e76\u5728\u6bcf\u6b21\u6a21\u62df\u4e2d\u4fdd\u7559\u8bed\u4e49\u7834\u574f\u6027\u6700\u5f3a\u7684\u7ed3\u679c\u4ee5\u8fdb\u884c\u9ad8\u6548\u5c40\u90e8\u641c\u7d22\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8bed\u4e49\u7684\u77ed\u63d0\u793a\u548c\u957f\u63d0\u793a\u4e0a\u5747\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u653b\u51fb\u6027\u80fd\u3002", "conclusion": "SD\u6a21\u578b\u7684\u8106\u5f31\u6027\u6e90\u4e8e\u5176\u57fa\u4e8eCLIP\u7684\u6587\u672c\u7f16\u7801\u5668\u7684\u5185\u5728\u6f0f\u6d1e\uff0c\u8fd9\u8868\u660e\u5f53\u524d\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u6d41\u7a0b\u5b58\u5728\u6839\u672c\u6027\u5b89\u5168\u98ce\u9669\u3002"}}
{"id": "2511.21151", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21151", "abs": "https://arxiv.org/abs/2511.21151", "authors": ["M. Alecci", "P. Jim\u00e9nez", "J. Samhi", "T. Bissyand\u00e9", "J. Klein"], "title": "Exploring Hidden Geographic Disparities in Android Apps", "comment": null, "summary": "While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.\n  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.\n  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u7814\u7a76\u63ed\u793a\u4e86Android\u5e94\u7528\u5728\u5730\u533a\u95f4\u7684\u5dee\u5f02\u5316\u73b0\u8c61\uff0c\u5305\u62ec\u529f\u80fd\u76f8\u4f3c\u4f46\u547d\u540d\u4e0d\u540c\u7684GeoTwins\u5e94\u7528\u548c\u53f7\u79f0\u4e00\u81f4\u4f46\u5b9e\u9645\u5b58\u5728\u533a\u5206\u7684App Bundle\u751f\u6001\u7cfb\u7edf\uff0c\u6307\u51fa\u4e86\u8fd9\u5bf9\u5b89\u5168\u548c\u516c\u5e73\u6027\u7684\u5f71\u54cd\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u7684\u6f14\u5316\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5e94\u7528\u884c\u4e3a\u7684\u5730\u7406\u5dee\u5f02\u5374\u9c9c\u6709\u4eba\u63a2\u7d22\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7279\u522b\u662f\u5173\u6ce8\u5730\u7406\u4f4d\u7f6e\u5bf9Android\u5e94\u7528\u884c\u4e3a\u548c\u7ed3\u6784\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8de8\u591a\u4e2a\u533a\u57df\u7684\u5206\u5e03\u5f0f\u5e94\u7528\u6536\u96c6\u7ba1\u9053\uff0c\u5206\u6790\u6570\u5343\u4e2a\u5e94\u7528\uff0c\u5e76\u53d1\u5e03\u4e86\u5305\u542b81,963\u4e2aGeoTwins\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u7814\u7a76\u3002", "result": "\u63ed\u793a\u4e86GeoTwins\u5e94\u7528\u5728\u6743\u9650\u3001\u7b2c\u4e09\u65b9\u5e93\u548c\u9690\u79c1\u62ab\u9732\u4e0a\u7684\u5206\u6b67\uff0c\u4ee5\u53caApp Bundle\u751f\u6001\u7cfb\u7edf\u4e2dbase.apk\u6587\u4ef6\u7684\u533a\u57df\u5dee\u5f02\uff0c\u8fd9\u4e9b\u5dee\u5f02\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u8bc4\u4f30\u7684\u4e0d\u4e00\u81f4\u548c\u5730\u7406\u504f\u89c1\u3002", "conclusion": "\u53d1\u73b0\u7cfb\u7edf\u6027\u533a\u57df\u5dee\u5f02\u5f71\u54cd\u4e86\u79fb\u52a8\u8f6f\u4ef6\u7684\u900f\u660e\u5ea6\u3001\u5b89\u5168\u6027\u548c\u516c\u5e73\u6027\uff0c\u547c\u5401\u7814\u7a76\u8005\u3001\u5f00\u53d1\u8005\u3001\u5e73\u53f0\u8bbe\u8ba1\u5e08\u548c\u653f\u7b56\u5236\u5b9a\u8005\u5173\u6ce8\u8fd9\u4e9b\u9690\u85cf\u7684\u5730\u7406\u5b9a\u5236\u95ee\u9898\u3002"}}
{"id": "2511.20937", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.20937", "abs": "https://arxiv.org/abs/2511.20937", "authors": ["Qineng Wang", "Wenlong Huang", "Yu Zhou", "Hang Yin", "Tianwei Bao", "Jianwen Lyu", "Weiyu Liu", "Ruohan Zhang", "Jiajun Wu", "Li Fei-Fei", "Manling Li"], "title": "ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction", "comment": "Preprint version", "summary": "Embodied cognition argues that intelligence arises from sensorimotor interaction rather than passive observation. It raises an intriguing question: do modern vision-language models (VLMs), trained largely in a disembodied manner, exhibit signs of embodied cognition? We introduce ENACT, a benchmark that casts evaluation of embodied cognition as world modeling from egocentric interaction in a visual question answering (VQA) format. Framed as a partially observable Markov decision process (POMDP) whose actions are scene graph changes, ENACT comprises two complementary sequence reordering tasks: forward world modeling (reorder shuffled observations given actions) and inverse world modeling (reorder shuffled actions given observations). While conceptually simple, solving these tasks implicitly demands capabilities central to embodied cognition-affordance recognition, action-effect reasoning, embodied awareness, and interactive, long-horizon memory from partially observable egocentric input, while avoiding low-level image synthesis that could confound the evaluation. We provide a scalable pipeline that synthesizes QA pairs from robotics simulation (BEHAVIOR) and evaluates models on 8,972 QA pairs spanning long-horizon home-scale activities. Experiments reveal a performance gap between frontier VLMs and humans that widens with interaction horizon. Models consistently perform better on the inverse task than the forward one and exhibit anthropocentric biases, including a preference for right-handed actions and degradation when camera intrinsics or viewpoints deviate from human vision. Website at https://enact-embodied-cognition.github.io/.", "AI": {"tldr": "ENACT\u57fa\u51c6\u6d4b\u8bd5\u65e8\u5728\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u8868\u73b0\u51fa\u5177\u8eab\u8ba4\u77e5\u7279\u5f81\uff0c\u901a\u8fc7\u4e16\u754c\u5efa\u6a21\u4efb\u52a1\u6765\u6d4b\u8bd5\u6a21\u578b\u4ece\u81ea\u6211\u4e2d\u5fc3\u4ea4\u4e92\u4e2d\u7406\u89e3\u548c\u63a8\u7406\u7684\u80fd\u529b", "motivation": "\u63a2\u8ba8\u73b0\u4ee3\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5728\u6ca1\u6709\u5177\u8eab\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u8868\u73b0\u51fa\u5177\u8eab\u8ba4\u77e5\u7684\u7279\u5f81", "method": "\u8bbe\u8ba1\u4e86ENACT\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u6b63\u5411\u4e16\u754c\u5efa\u6a21\u548c\u9006\u5411\u4e16\u754c\u5efa\u6a21\u4e24\u4e2a\u5e8f\u5217\u91cd\u6392\u5e8f\u4efb\u52a1\uff0c\u4f7f\u7528POMDP\u6846\u67b6\uff0c\u52a8\u4f5c\u5b9a\u4e49\u4e3a\u573a\u666f\u56fe\u53d8\u5316\uff0c\u57fa\u4e8e\u673a\u5668\u4eba\u6a21\u62df\u5668BEHAVIOR\u751f\u6210QA\u6570\u636e\u96c6", "result": "\u5b9e\u9a8c\u663e\u793a\u524d\u6cbfVLM\u4e0e\u4eba\u7c7b\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\uff0c\u5dee\u8ddd\u968f\u4ea4\u4e92\u65f6\u95f4\u8de8\u5ea6\u589e\u5927\uff1b\u6a21\u578b\u5728\u9006\u5411\u4efb\u52a1\u8868\u73b0\u66f4\u597d\uff0c\u8868\u73b0\u51fa\u4eba\u7c7b\u4e2d\u5fc3\u504f\u89c1\uff08\u5982\u504f\u597d\u53f3\u624b\u52a8\u4f5c\uff09", "conclusion": "\u867d\u7136\u73b0\u4ee3VLM\u663e\u793a\u51fa\u4e00\u4e9b\u5177\u8eab\u8ba4\u77e5\u7279\u5f81\uff0c\u4f46\u4e0e\u4eba\u7c7b\u76f8\u6bd4\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u957f\u671f\u4ea4\u4e92\u548c\u591a\u89c6\u89d2\u9002\u5e94\u65b9\u9762"}}
{"id": "2511.21216", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21216", "abs": "https://arxiv.org/abs/2511.21216", "authors": ["Fangming Shi", "Li Li", "Kejiang Chen", "Guorui Feng", "Xinpeng Zhang"], "title": "AuthenLoRA: Entangling Stylization with Imperceptible Watermarks for Copyright-Secure LoRA Adapters", "comment": "16 pages, 7 figures, 12 tables", "summary": "Low-Rank Adaptation (LoRA) offers an efficient paradigm for customizing diffusion models, but its ease of redistribution raises concerns over unauthorized use and the generation of untraceable content. Existing watermarking techniques either target base models or verify LoRA modules themselves, yet they fail to propagate watermarks to generated images, leaving a critical gap in traceability. Moreover, traceability watermarking designed for base models is not tightly coupled with stylization and often introduces visual degradation or high false-positive detection rates. To address these limitations, we propose AuthenLoRA, a unified watermarking framework that embeds imperceptible, traceable watermarks directly into the LoRA training process while preserving stylization quality. AuthenLoRA employs a dual-objective optimization strategy that jointly learns the target style distribution and the watermark-induced distribution shift, ensuring that any image generated with the watermarked LoRA reliably carries the watermark. We further design an expanded LoRA architecture for enhanced multi-scale adaptation and introduce a zero-message regularization mechanism that substantially reduces false positives during watermark verification. Extensive experiments demonstrate that AuthenLoRA achieves high-fidelity stylization, robust watermark propagation, and significantly lower false-positive rates compared with existing approaches. Open-source implementation is available at: https://github.com/ShiFangming0823/AuthenLoRA", "AI": {"tldr": "AuthenLoRA\uff1a\u4e00\u79cd\u5728LoRA\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5d4c\u5165\u4e0d\u53ef\u5bdf\u89c9\u6c34\u5370\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u53ef\u786e\u4fdd\u4f7f\u7528\u5e26\u6c34\u5370LoRA\u751f\u6210\u7684\u56fe\u50cf\u53ef\u9760\u643a\u5e26\u6c34\u5370\uff0c\u540c\u65f6\u4fdd\u6301\u98ce\u683c\u5316\u8d28\u91cf", "motivation": "\u73b0\u6709\u6c34\u5370\u6280\u672f\u8981\u4e48\u9488\u5bf9\u57fa\u7840\u6a21\u578b\uff0c\u8981\u4e48\u9a8c\u8bc1LoRA\u6a21\u5757\u672c\u8eab\uff0c\u4f46\u65e0\u6cd5\u5c06\u6c34\u5370\u4f20\u64ad\u5230\u751f\u6210\u7684\u56fe\u50cf\u4e2d\uff1b\u57fa\u7840\u6a21\u578b\u7684\u8ffd\u6eaf\u6c34\u5370\u4e0e\u98ce\u683c\u5316\u4e0d\u7d27\u5bc6\u8026\u5408\uff0c\u5e38\u5bfc\u81f4\u89c6\u89c9\u9000\u5316\u6216\u9ad8\u8bef\u68c0\u7387", "method": "\u91c7\u7528\u53cc\u76ee\u6807\u4f18\u5316\u7b56\u7565\u8054\u5408\u5b66\u4e60\u76ee\u6807\u98ce\u683c\u5206\u5e03\u548c\u6c34\u5370\u5f15\u8d77\u7684\u5206\u5e03\u504f\u79fb\uff1b\u8bbe\u8ba1\u6269\u5c55LoRA\u67b6\u6784\u589e\u5f3a\u591a\u5c3a\u5ea6\u9002\u5e94\uff1b\u5f15\u5165\u96f6\u6d88\u606f\u6b63\u5219\u5316\u673a\u5236\u5927\u5e45\u964d\u4f4e\u6c34\u5370\u9a8c\u8bc1\u8bef\u68c0\u7387", "result": "AuthenLoRA\u5b9e\u73b0\u9ad8\u4fdd\u771f\u98ce\u683c\u5316\u3001\u9c81\u68d2\u6c34\u5370\u4f20\u64ad\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u8bef\u68c0\u7387", "conclusion": "AuthenLoRA\u89e3\u51b3\u4e86LoRA\u6a21\u5757\u6c34\u5370\u4f20\u64ad\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u6269\u6563\u6a21\u578b\u5b9a\u5236\u63d0\u4f9b\u6709\u6548\u8ffd\u6eaf\u673a\u5236"}}
{"id": "2511.21197", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21197", "abs": "https://arxiv.org/abs/2511.21197", "authors": ["Paolo Buono", "Mary Cerullo", "Stefano Cirillo", "Giuseppe Desolda", "Francesco Greco", "Emanuela Guglielmi", "Grazia Margarella", "Giuseppe Polese", "Simone Scalabrino", "Cesare Tucci"], "title": "Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools", "comment": null, "summary": "AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \\textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \\textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.", "AI": {"tldr": "AI\u8f85\u52a9\u5de5\u5177\u652f\u6301\u5f00\u53d1\u8005\u5b8c\u6210\u9519\u8bef\u68c0\u6d4b\u548c\u4ee3\u7801\u53ef\u8bfb\u6027\u8bc4\u4f30\u7b49\u8ba4\u77e5\u5bc6\u96c6\u578b\u4efb\u52a1\u3002\u7136\u800c\uff0c\u5f00\u53d1\u8005\u5982\u4f55\u6784\u5efa\u5bf9\u8fd9\u4e9b\u5de5\u5177\u7684\u5fc3\u667a\u6a21\u578b\u4ee5\u53ca\u4e0d\u5339\u914d\u5982\u4f55\u5f71\u54cd\u4fe1\u4efb\u3001\u63a7\u5236\u548c\u91c7\u7528\u4ecd\u4e0d\u6e05\u695a\u3002\u901a\u8fc758\u540d\u5f00\u53d1\u8005\u53c2\u4e0e\u76846\u6b21\u534f\u540c\u8bbe\u8ba1\u5de5\u4f5c\u574a\uff0c\u7814\u7a76\u53d1\u73b0\u9519\u8bef\u68c0\u6d4b\u5de5\u5177\u88ab\u89c6\u4e3a\u201c\u9519\u8bef\u4fa6\u63a2\u201d\uff0c\u63d0\u4f9b\u900f\u660e\u3001\u53ef\u64cd\u4f5c\u7684\u53cd\u9988\u548c\u81ea\u4fe1\u63d0\u793a\uff1b\u53ef\u8bfb\u6027\u8bc4\u4f30\u5de5\u5177\u88ab\u89c6\u4e3a\u201c\u8d28\u91cf\u6559\u7ec3\u201d\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u3001\u60c5\u5883\u5316\u548c\u6e10\u8fdb\u5f0f\u6307\u5bfc\u3002\u4fe1\u4efb\u53d6\u51b3\u4e8e\u89e3\u91ca\u6e05\u6670\u5ea6\u3001\u65f6\u673a\u548c\u7528\u6237\u63a7\u5236\u3002\u63d0\u51fa\u4e86\u4e00\u5957\u4ee5\u4eba\u4e3a\u672c\u7684AI\u8bbe\u8ba1\u539f\u5219\uff0c\u4ee5\u5e73\u8861\u4e2d\u65ad\u4e0e\u652f\u6301\u3001\u7b80\u6d01\u4e0e\u6df1\u5ea6\u3001\u81ea\u52a8\u5316\u4e0e\u4eba\u7c7b\u80fd\u52a8\u6027\u3002", "motivation": "\u5c3d\u7ba1AI\u8f85\u52a9\u5de5\u5177\u5728\u6280\u672f\u7279\u6027\u4e0a\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u4f46\u5f00\u53d1\u8005\u5982\u4f55\u5fc3\u667a\u5efa\u6a21\u8fd9\u4e9b\u5de5\u5177\u4ee5\u53ca\u5fc3\u667a\u6a21\u578b\u4e0e\u5de5\u5177\u80fd\u529b\u4e0d\u5339\u914d\u5982\u4f55\u5f71\u54cd\u4fe1\u4efb\u3001\u63a7\u5236\u548c\u4f7f\u7528\u91c7\u7eb3\u4ecd\u77e5\u4e4b\u751a\u5c11\u3002", "method": "\u8fdb\u884c\u4e86\u516d\u6b21\u534f\u540c\u8bbe\u8ba1\u5de5\u4f5c\u574a\uff0c\u6d89\u53ca58\u540d\u5f00\u53d1\u8005\uff0c\u4ee5\u6fc0\u53d1\u4ed6\u4eec\u5bf9AI\u8f85\u52a9\u9519\u8bef\u68c0\u6d4b\u548c\u53ef\u8bfb\u6027\u529f\u80fd\u7684\u5fc3\u667a\u6a21\u578b\u3002", "result": "\u5f00\u53d1\u8005\u5c06\u9519\u8bef\u68c0\u6d4b\u5de5\u5177\u89c6\u4e3a\u201c\u9519\u8bef\u4fa6\u63a2\u201d\uff0c\u4ec5\u5728\u5173\u952e\u95ee\u9898\u65f6\u8b66\u544a\u7528\u6237\uff0c\u4fdd\u8bc1\u900f\u660e\u5ea6\u3001\u53ef\u64cd\u4f5c\u53cd\u9988\u548c\u81ea\u4fe1\u63d0\u793a\uff1b\u53ef\u8bfb\u6027\u8bc4\u4f30\u5de5\u5177\u88ab\u89c6\u4e3a\u201c\u8d28\u91cf\u6559\u7ec3\u201d\uff0c\u63d0\u4f9b\u60c5\u5883\u5316\u3001\u4e2a\u6027\u5316\u548c\u6e10\u8fdb\u5f0f\u6307\u5bfc\u3002\u4fe1\u4efb\u53d6\u51b3\u4e8e\u89e3\u91ca\u6e05\u6670\u5ea6\u3001\u65f6\u673a\u548c\u7528\u6237\u63a7\u5236\u3002", "conclusion": "\u63d0\u70bc\u51fa\u4e00\u5957\u4ee5\u4eba\u4e3a\u672c\u7684AI\u96c6\u6210\u5f00\u53d1\u73af\u5883\u8bbe\u8ba1\u539f\u5219\uff0c\u65e8\u5728\u5e73\u8861\u4e2d\u65ad\u4e0e\u652f\u6301\u3001\u7b80\u6d01\u4e0e\u6df1\u5ea6\u3001\u81ea\u52a8\u5316\u4e0e\u4eba\u7c7b\u80fd\u52a8\u6027\uff0c\u4ee5\u4fc3\u8fdb\u5f00\u53d1\u8005\u5bf9AI\u5de5\u5177\u7684\u4fe1\u4efb\u548c\u91c7\u7eb3\u3002"}}
{"id": "2511.20942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20942", "abs": "https://arxiv.org/abs/2511.20942", "authors": ["Rahul Dass", "Thomas Bowlin", "Zebing Li", "Xiao Jin", "Ashok Goel"], "title": "Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture", "comment": null, "summary": "In procedural skill learning, instructional explanations must convey not just steps, but the causal, goal-directed, and compositional logic behind them. Large language models (LLMs) often produce fluent yet shallow responses that miss this structure. We present Ivy, an AI coaching system that delivers structured, multi-step explanations by combining symbolic Task-Method-Knowledge (TMK) models with a generative interpretation layer-an LLM that constructs explanations while being constrained by TMK structure. TMK encodes causal transitions, goal hierarchies, and problem decompositions, and guides the LLM within explicit structural bounds. We evaluate Ivy against responses against GPT and retrieval-augmented GPT baselines using expert and independent annotations across three inferential dimensions. Results show that symbolic constraints consistently improve the structural quality of explanations for \"how\" and \"why\" questions. This study demonstrates a scalable AI for education approach that strengthens the pedagogical value of AI-generated explanations in intelligent coaching systems.", "AI": {"tldr": "Ivy\u7cfb\u7edf\u7ed3\u5408\u7b26\u53f7TMK\u6a21\u578b\u4e0eLLM\u751f\u6210\u5c42\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7ea6\u675f\u63d0\u5347\u6559\u5b66\u89e3\u91ca\u7684\u8d28\u91cf", "motivation": "\u4f20\u7edfLLM\u751f\u6210\u7684\u6559\u5b66\u89e3\u91ca\u5f80\u5f80\u6d41\u7545\u4f46\u6d45\u5c42\uff0c\u7f3a\u4e4f\u56e0\u679c\u3001\u76ee\u6807\u5bfc\u5411\u548c\u7ec4\u5408\u903b\u8f91", "method": "\u7ed3\u5408\u7b26\u53f7Task-Method-Knowledge(TMK)\u6a21\u578b\u4e0e\u751f\u6210\u89e3\u91ca\u5c42\uff0cTMK\u7f16\u7801\u56e0\u679c\u8f6c\u6362\u3001\u76ee\u6807\u5c42\u6b21\u548c\u95ee\u9898\u5206\u89e3", "result": "\u7b26\u53f7\u7ea6\u675f\u663e\u8457\u63d0\u5347\u4e86\u9488\u5bf9'\u5982\u4f55'\u548c'\u4e3a\u4f55'\u95ee\u9898\u7684\u89e3\u91ca\u7ed3\u6784\u8d28\u91cf", "conclusion": "\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u7684\u6559\u80b2AI\u65b9\u6cd5\uff0c\u80fd\u589e\u5f3a\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2dAI\u751f\u6210\u89e3\u91ca\u7684\u6559\u5b66\u4ef7\u503c"}}
{"id": "2511.21380", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.21380", "abs": "https://arxiv.org/abs/2511.21380", "authors": ["Jingyi Chen", "Xiaoyan Guo", "Songqiang Chen", "Shing-Chi Cheung", "Jiasi Shen"], "title": "Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions", "comment": null, "summary": "Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.", "AI": {"tldr": "\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6570\u636e\u96c6\u9002\u5e94\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u7cfb\u7edf\u80fd\u8bc6\u522b\u5173\u952e\u6587\u4ef6\u5e76\u751f\u6210\u90e8\u5206\u9002\u5e94\uff0c\u4f46\u5f88\u5c11\u4ea7\u751f\u529f\u80fd\u6b63\u786e\u5b9e\u73b0\u3002\u63d0\u793a\u5e72\u9884\uff08\u5c24\u5176\u662f\u63d0\u4f9b\u6267\u884c\u9519\u8bef\u4fe1\u606f\u548c\u53c2\u8003\u4ee3\u7801\uff09\u53ef\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u5de5\u4ef6\u7684\u8de8\u6570\u636e\u96c6\u81ea\u52a8\u9002\u5e94\u5bf9\u53ef\u6269\u5c55\u6027\u548c\u53ef\u91cd\u590d\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08\u5982GitHub Copilot\uff09\u6709\u671b\u901a\u8fc7\u534f\u8c03\u63a8\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u5de5\u5177\u4ea4\u4e92\u81ea\u52a8\u5316\u590d\u6742\u5de5\u4f5c\u6d41\u3002", "method": "\u901a\u8fc7\u4e94\u9636\u6bb5\u8bc4\u4f30\u7ba1\u9053\uff08\u6587\u4ef6\u7406\u89e3\u3001\u4ee3\u7801\u7f16\u8f91\u3001\u547d\u4ee4\u751f\u6210\u3001\u9a8c\u8bc1\u548c\u6700\u7ec8\u6267\u884c\uff09\u8bc4\u4f30\u57fa\u4e8eGPT-4.1\u548cClaude Sonnet 4\u7684Copilot\u5728ROCODE\u548cLogHub2.0\u7b49\u57fa\u51c6\u5e93\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u6210\u529f\u7387\u3001\u5931\u8d25\u6a21\u5f0f\u53ca\u63d0\u793a\u5e72\u9884\u6548\u679c\u3002", "result": "\u5f53\u524d\u7cfb\u7edf\u53ef\u5b9e\u73b0\u5173\u952e\u6587\u4ef6\u8bc6\u522b\u548c\u90e8\u5206\u9002\u5e94\u751f\u6210\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u5b9e\u73b0\u7387\u4f4e\u3002\u63d0\u4f9b\u6267\u884c\u9519\u8bef\u4fe1\u606f\u548c\u53c2\u8003\u4ee3\u7801\u7684\u63d0\u793a\u5e72\u9884\u5c06\u7ed3\u6784\u76f8\u4f3c\u5ea6\u4ece7.25%\u63d0\u5347\u81f367.14%\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edf\u5728\u6570\u636e\u96c6\u9002\u5e94\u4e2d\u5c55\u73b0\u6f5c\u529b\u4f46\u5b58\u5728\u5c40\u9650\uff0c\u9700\u901a\u8fc7\u4e0a\u4e0b\u6587\u548c\u53cd\u9988\u9a71\u52a8\u6307\u5bfc\u6784\u5efa\u66f4\u53ef\u9760\u3001\u81ea\u6821\u6b63\u7684\u667a\u80fd\u4f53\u3002"}}
{"id": "2511.21005", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.21005", "abs": "https://arxiv.org/abs/2511.21005", "authors": ["Jinpeng Wang", "Chao Li", "Ting Ye", "Mengyuan Zhang", "Wei Liu", "Jian Luan"], "title": "ICPO: Intrinsic Confidence-Driven Group Relative Preference Optimization for Efficient Reinforcement Learning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) demonstrates significant potential in enhancing the reasoning capabilities of Large Language Models (LLMs). However, existing RLVR methods are often constrained by issues such as coarse-grained rewards, reward noise, and inefficient exploration, which lead to unstable training and entropy collapse. To address this challenge, we propose the Intrinsic Confidence-Driven Group Relative Preference Optimization method (ICPO). The intuition behind it lies in the fact that the probabilities of an LLM generating different responses can inherently and directly reflect its self-assessment of the reasoning process. Inspired by the idea of preference modeling, ICPO calculates a preference advantage score for each response by comparing the relative generation probabilities of multiple responses under the same input prompt, and integrates this score with verifiable rewards to guide the exploration process. We have discovered that the preference advantage score not only alleviates the issues of coarse-grained rewards and reward noise but also effectively curbs overconfident errors, enhances the relative superiority of undervalued high-quality responses, and prevents the model from overfitting to specific strategies, thereby facilitating more thorough exploration. Comprehensive experiments across four general-domain benchmarks and three mathematical benchmarks demonstrate that ICPO steadily boosts reasoning compared to GRPO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ICPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528LLM\u751f\u6210\u4e0d\u540c\u54cd\u5e94\u7684\u6982\u7387\u6765\u53cd\u6620\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u81ea\u6211\u8bc4\u4f30\uff0c\u7ed3\u5408\u53ef\u9a8c\u8bc1\u5956\u52b1\u89e3\u51b3\u73b0\u6709RLVR\u65b9\u6cd5\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7a33\u5b9a\u63d0\u5347\u4e86\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684RLVR\u65b9\u6cd5\u5b58\u5728\u7c97\u7c92\u5ea6\u5956\u52b1\u3001\u5956\u52b1\u566a\u58f0\u548c\u4f4e\u6548\u63a2\u7d22\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u71b5\u5d29\u6e83\u3002", "method": "ICPO\u901a\u8fc7\u6bd4\u8f83\u540c\u4e00\u8f93\u5165\u63d0\u793a\u4e0b\u591a\u4e2a\u54cd\u5e94\u7684\u751f\u6210\u6982\u7387\uff0c\u8ba1\u7b97\u504f\u597d\u4f18\u52bf\u5206\u6570\uff0c\u5e76\u5c06\u5176\u4e0e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7ed3\u5408\u6765\u6307\u5bfc\u63a2\u7d22\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cICPO\u7f13\u89e3\u4e86\u7c97\u7c92\u5ea6\u5956\u52b1\u548c\u5956\u52b1\u566a\u58f0\u95ee\u9898\uff0c\u6709\u6548\u6291\u5236\u4e86\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff0c\u589e\u5f3a\u4e86\u88ab\u4f4e\u4f30\u9ad8\u8d28\u91cf\u54cd\u5e94\u7684\u76f8\u5bf9\u4f18\u52bf\uff0c\u9632\u6b62\u6a21\u578b\u8fc7\u62df\u5408\u7279\u5b9a\u7b56\u7565\u3002", "conclusion": "ICPO\u5728\u56db\u4e2a\u901a\u7528\u9886\u57df\u57fa\u51c6\u548c\u4e09\u4e2a\u6570\u5b66\u57fa\u51c6\u4e0a\u5747\u663e\u793a\u51fa\u6bd4GRPO\u66f4\u7a33\u5b9a\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2511.21291", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21291", "abs": "https://arxiv.org/abs/2511.21291", "authors": ["Tien Dat Hoang"], "title": "Illuminating the Black Box: Real-Time Monitoring of Backdoor Unlearning in CNNs via Explainable AI", "comment": "5 pages, 4 figures, IEEE conference format", "summary": "Backdoor attacks pose severe security threats to deep neural networks by embedding malicious triggers that force misclassification. While machine unlearning techniques can remove backdoor behaviors, current methods lack transparency and real-time interpretability. This paper introduces a novel framework that integrates Gradient-weighted Class Activation Mapping (Grad-CAM) into the unlearning process to provide real-time monitoring and explainability. We propose the Trigger Attention Ratio (TAR) metric to quantitatively measure the model's attention shift from trigger patterns to legitimate object features. Our balanced unlearning strategy combines gradient ascent on backdoor samples, Elastic Weight Consolidation (EWC) for catastrophic forgetting prevention, and a recovery phase for clean accuracy restoration. Experiments on CIFAR-10 with BadNets attacks demonstrate that our approach reduces Attack Success Rate (ASR) from 96.51% to 5.52% while retaining 99.48% of clean accuracy (82.06%), achieving a 94.28% ASR reduction. The integration of explainable AI enables transparent, observable, and verifiable backdoor removal.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408Grad-CAM\u53ef\u89c6\u5316\u6280\u672f\u7684\u540e\u95e8\u9057\u5fd8\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u91cf\u6307\u6807TAR\u5b9e\u65f6\u76d1\u63a7\u6ce8\u610f\u529b\u8f6c\u79fb\uff0c\u5b9e\u73b0\u9ad8\u900f\u660e\u5ea6\u7684\u540e\u95e8\u6e05\u9664\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u9057\u5fd8\u65b9\u6cd5\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u5b9e\u65f6\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u89c2\u5bdf\u548c\u9a8c\u8bc1\u6a21\u578b\u4fee\u590d\u8fc7\u7a0b\u3002", "method": "\u8bbe\u8ba1\u5747\u8861\u9057\u5fd8\u7b56\u7565\uff1a1\uff09\u5728\u540e\u95e8\u6837\u672c\u4e0a\u4f7f\u7528\u68af\u5ea6\u4e0a\u5347 2\uff09EWC\u9632\u6b62\u707e\u96be\u6027\u9057\u5fd8 3\uff09\u6062\u590d\u9636\u6bb5\u4fdd\u6301\u5e72\u51c0\u7cbe\u5ea6 4\uff09\u96c6\u6210Grad-CAM\u5b9e\u65f6\u53ef\u89c6\u5316", "result": "\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\uff0c\u653b\u51fb\u6210\u529f\u7387\u4ece96.51%\u964d\u81f35.52%\uff0c\u540c\u65f6\u4fdd\u630199.48%\u7684\u5e72\u51c0\u7cbe\u5ea6\u6062\u590d\u7387\uff0882.06%\u57fa\u51c6\uff09\uff0cASR\u964d\u4f4e94.28%", "conclusion": "\u53ef\u89e3\u91caAI\u6280\u672f\u7684\u96c6\u6210\u5b9e\u73b0\u4e86\u900f\u660e\u3001\u53ef\u89c2\u6d4b\u3001\u53ef\u9a8c\u8bc1\u7684\u540e\u95e8\u6e05\u9664\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u5b89\u5168\u63d0\u4f9b\u65b0\u8303\u5f0f"}}
{"id": "2511.21301", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.21301", "abs": "https://arxiv.org/abs/2511.21301", "authors": ["Leonardo Regano", "Daniele Canavese", "Cataldo Basile", "Marco Torchiano"], "title": "Empirical Assessment of the Code Comprehension Effort Needed to Attack Programs Protected with Obfuscation", "comment": null, "summary": "Evaluating the effectiveness of software protection is crucial for selecting the most effective methods to safeguard assets within software applications. Obfuscation involves techniques that deliberately modify software to make it more challenging to understand and reverse-engineer, while maintaining its original functionality. Although obfuscation is widely adopted, its effectiveness remains largely unexplored and unthoroughly evaluated. This paper presents a controlled experiment involving Master's students performing code comprehension tasks on applications hardened with obfuscation. The experiment's goals are to assess the effectiveness of obfuscation in delaying code comprehension by attackers and to determine whether complexity metrics can accurately predict the impact of these protections on success rates and durations of code comprehension tasks. The study is the first to evaluate the effect of layering multiple obfuscation techniques on a single piece of protected code. It also provides experimental evidence of the correlation between objective metrics of the attacked code and the likelihood of a successful attack, bridging the gap between objective and subjective approaches to estimating potency. Finally, the paper highlights significant aspects that warrant additional analysis and opens new avenues for further experiments.", "AI": {"tldr": "\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u8f6f\u4ef6\u6df7\u6dc6\u6280\u672f\u6709\u6548\u6027\u7684\u5b9e\u8bc1\u7814\u7a76\u8bba\u6587\uff0c\u9996\u6b21\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u8bc4\u4f30\u591a\u5c42\u6df7\u6dc6\u6280\u672f\u5bf9\u4ee3\u7801\u7406\u89e3\u7684\u5f71\u54cd\u3002", "motivation": "\u8f6f\u4ef6\u4fdd\u62a4\u6280\u672f\uff08\u7279\u522b\u662f\u6df7\u6dc6\u6280\u672f\uff09\u867d\u7136\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u6709\u6548\u6027\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u3002\u7814\u7a76\u8005\u5e0c\u671b\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4e3a\u9009\u62e9\u6700\u6709\u6548\u7684\u8f6f\u4ef6\u4fdd\u62a4\u65b9\u6cd5\u63d0\u4f9b\u5b9e\u8bc1\u4f9d\u636e\u3002", "method": "\u91c7\u7528\u63a7\u5236\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u8ba9\u7855\u58eb\u751f\u5728\u6df7\u6dc6\u540e\u7684\u5e94\u7528\u7a0b\u5e8f\u4e0a\u6267\u884c\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\uff0c\u8bc4\u4f30\u6df7\u6dc6\u6280\u672f\u5728\u5ef6\u8fdf\u4ee3\u7801\u7406\u89e3\u65b9\u9762\u7684\u6548\u679c\uff0c\u5e76\u68c0\u9a8c\u590d\u6742\u5ea6\u6307\u6807\u662f\u5426\u80fd\u51c6\u786e\u9884\u6d4b\u4fdd\u62a4\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u6df7\u6dc6\u6280\u672f\u786e\u5b9e\u80fd\u6709\u6548\u5ef6\u8fdf\u653b\u51fb\u8005\u7684\u4ee3\u7801\u7406\u89e3\u8fc7\u7a0b\uff0c\u540c\u65f6\u8bc1\u5b9e\u4e86\u5ba2\u89c2\u4ee3\u7801\u6307\u6807\u4e0e\u653b\u51fb\u6210\u529f\u7387\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8f6f\u4ef6\u4fdd\u62a4\u6548\u679c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u6df7\u6dc6\u6280\u672f\u7684\u5b9e\u9645\u6548\u679c\uff0c\u5e76\u4e3a\u540e\u7eed\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002\u8be5\u7814\u7a76\u9996\u6b21\u8bc4\u4f30\u4e86\u5728\u5355\u4e00\u4ee3\u7801\u4e0a\u53e0\u52a0\u591a\u5c42\u6df7\u6dc6\u6280\u672f\u7684\u6548\u679c\u3002"}}
{"id": "2511.21260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21260", "abs": "https://arxiv.org/abs/2511.21260", "authors": ["Joseph Y. Halpern", "Rafael Pass"], "title": "Causality Without Causal Models", "comment": "In Proceedings TARK 2025, arXiv:2511.20540", "summary": "Perhaps the most prominent current definition of (actual) causality is due to Halpern and Pearl.  It is defined using causal models (also known as structural equations models).  We abstract the definition, extracting its key features, so that it can be applied to any other model where counterfactuals are defined. By abstracting the definition, we gain a number of benefits. Not only can we apply the definition in a wider range of models, including ones that allow, for example, backtracking, but we can apply the definition to determine if A is a cause of B  even if A and B are formulas involving disjunctions, negations, beliefs, and nested counterfactuals (none of which can be handled by the Halpern-Pearl definition). Moreover, we can extend the ideas to getting an abstract definition of explanation that can be applied beyond causal models. Finally, we gain a deeper understanding of features of the definition  even in causal models.", "AI": {"tldr": "\u62bd\u8c61\u5316Halpern-Pearl\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u4efb\u4f55\u53cd\u4e8b\u5b9e\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u903b\u8f91\u516c\u5f0f\u548c\u975e\u56e0\u679c\u6a21\u578b\u7684\u89e3\u91ca\u3002", "motivation": "Halpern-Pearl\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u5c40\u9650\u4e8e\u56e0\u679c\u6a21\u578b\uff0c\u65e0\u6cd5\u5904\u7406\u6d89\u53ca\u6790\u53d6\u3001\u5426\u5b9a\u3001\u4fe1\u5ff5\u548c\u5d4c\u5957\u53cd\u4e8b\u5b9e\u7684\u590d\u6742\u516c\u5f0f\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u5b9a\u4e49\u6846\u67b6\u3002", "method": "\u63d0\u53d6Halpern-Pearl\u5b9a\u4e49\u7684\u5173\u952e\u7279\u5f81\uff0c\u6784\u5efa\u62bd\u8c61\u5316\u5b9a\u4e49\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u4efb\u4f55\u53cd\u4e8b\u5b9e\u5b9a\u4e49\u7684\u6a21\u578b\uff0c\u5305\u62ec\u652f\u6301\u56de\u6eaf\u7b49\u7279\u6027\u7684\u6a21\u578b\u3002", "result": "\u6210\u529f\u5f00\u53d1\u51fa\u62bd\u8c61\u5316\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\uff0c\u53ef\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u548c\u590d\u6742\u516c\u5f0f\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u89e3\u91ca\u7684\u5b9a\u4e49\u3002", "conclusion": "\u62bd\u8c61\u5316\u65b9\u6cd5\u4e0d\u4ec5\u6269\u5c55\u4e86\u56e0\u679c\u5173\u7cfb\u5b9a\u4e49\u7684\u9002\u7528\u8303\u56f4\uff0c\u8fd8\u6df1\u5316\u4e86\u5bf9\u539f\u59cb\u5b9a\u4e49\u7279\u5f81\u7684\u7406\u89e3\uff0c\u4e3a\u975e\u56e0\u679c\u6a21\u578b\u4e2d\u7684\u89e3\u91ca\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.21552", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.21552", "abs": "https://arxiv.org/abs/2511.21552", "authors": ["Roi Bar-Zur", "Aviv Tamar", "Ittay Eyal"], "title": "MAD-DAG: Protecting Blockchain Consensus from MEV", "comment": null, "summary": "Blockchain security is threatened by selfish mining, where a miner (operator) deviates from the protocol to increase their revenue. Selfish mining is exacerbated by adverse conditions: rushing (network propagation advantage for the selfish miner), varying block rewards due to block contents, called miner extractable value (MEV), and petty-compliant miners who accept bribes from the selfish miner.\n  The state-of-the-art selfish-mining-resistant blockchain protocol, Colordag, does not treat these adverse conditions and was proven secure only when its latency is impractically high.\n  We present MAD-DAG, Mutually-Assured-Destruction Directed-Acyclic-Graph, the first practical protocol to counter selfish mining under adverse conditions. MAD-DAG achieves this thanks to its novel ledger function, which discards the contents of equal-length chains competing to be the longest.\n  We analyze selfish mining in both Colordag and MAD-DAG by modeling a rational miner using a Markov Decision Process (MDP). We obtain a tractable model for both by developing conservative reward rules that favor the selfish miner to yield an upper bound on selfish mining revenue. To the best of our knowledge, this is the first tractable model of selfish mining in a practical DAG-based blockchain. This enables us to obtain a lower bound on the security threshold, the minimum fraction of computational power a miner needs in order to profit from selfish mining.\n  MAD-DAG withstands adverse conditions under which Colordag and Bitcoin fail, while otherwise maintaining comparable security. For example, with petty-compliant miners and high levels of block reward variability, MAD-DAG's security threshold ranges from 11% to 31%, whereas both Colordag and Bitcoin achieve 0% for all levels.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86MAD-DAG\u534f\u8bae\uff0c\u8fd9\u662f\u9996\u4e2a\u5728\u4e0d\u5229\u6761\u4ef6\u4e0b\uff08\u5982MEV\u3001\u62a2\u5148\u4ea4\u6613\u3001\u5c0f\u8d3f\u8d42\u77ff\u5de5\uff09\u5b9e\u7528\u7684\u81ea\u79c1\u6316\u77ff\u9632\u5fa1\u534f\u8bae\uff0c\u76f8\u6bd4\u73b0\u6709\u534f\u8bae\uff08Colordag\u548c\u6bd4\u7279\u5e01\uff09\u5177\u6709\u66f4\u9ad8\u7684\u5b89\u5168\u6027\u9608\u503c\u3002", "motivation": "\u73b0\u6709\u533a\u5757\u94fe\u534f\u8bae\uff08\u5982Colordag\u548c\u6bd4\u7279\u5e01\uff09\u5728\u4e0d\u5229\u6761\u4ef6\u4e0b\u65e0\u6cd5\u6709\u6548\u62b5\u5fa1\u81ea\u79c1\u6316\u77ff\u653b\u51fb\uff0c\u7279\u522b\u662f\u5f53\u5b58\u5728\u62a2\u5148\u4f20\u8f93\u4f18\u52bf\u3001MEV\u5bfc\u81f4\u533a\u5757\u5956\u52b1\u53d8\u5f02\u4ee5\u53ca\u5c0f\u8d3f\u8d42\u77ff\u5de5\u65f6\uff0c\u5b89\u5168\u6027\u9608\u503c\u964d\u81f30%\u3002", "method": "\u63d0\u51faMAD-DAG\u534f\u8bae\uff0c\u91c7\u7528\u65b0\u578b\u8d26\u672c\u51fd\u6570\uff0c\u901a\u8fc7\u4e22\u5f03\u7ade\u4e89\u6700\u957f\u94fe\u7684\u7b49\u957f\u94fe\u5185\u5bb9\u6765\u62b5\u5fa1\u81ea\u79c1\u6316\u77ff\u3002\u4f7f\u7528\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u5bf9\u7406\u6027\u77ff\u5de5\u5efa\u6a21\uff0c\u5e76\u5f00\u53d1\u4fdd\u5b88\u5956\u52b1\u89c4\u5219\u4ee5\u83b7\u5f97\u81ea\u79c1\u6316\u77ff\u6536\u76ca\u7684\u4e0a\u754c\u3002", "result": "MAD-DAG\u5728\u4e0d\u5229\u6761\u4ef6\u4e0b\u5b89\u5168\u6027\u9608\u503c\u4ecb\u4e8e11%\u81f331%\uff0c\u800cColordag\u548c\u6bd4\u7279\u5e01\u5728\u6240\u6709\u6761\u4ef6\u4e0b\u5747\u4e3a0%\u3002\u534f\u8bae\u5728\u4fdd\u6301\u53ef\u6bd4\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u6210\u529f\u62b5\u5fa1\u4e86Colordag\u548c\u6bd4\u7279\u5e01\u5931\u6548\u7684\u573a\u666f\u3002", "conclusion": "MAD-DAG\u662f\u9996\u4e2a\u5728\u73b0\u5b9e\u4e0d\u5229\u6761\u4ef6\u4e0b\u53ef\u5b9e\u7528\u7684\u81ea\u79c1\u6316\u77ff\u9632\u5fa1\u534f\u8bae\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533a\u5757\u94fe\u5b89\u5168\u6027\uff0c\u4e3aDAG-based\u533a\u5757\u94fe\u63d0\u4f9b\u4e86\u9996\u4e2a\u53ef\u5904\u7406\u7684\u81ea\u79c1\u6316\u77ff\u6a21\u578b\u3002"}}
{"id": "2511.21417", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21417", "abs": "https://arxiv.org/abs/2511.21417", "authors": ["Mia M\u00fc\u00dfig", "Jan Johannsen"], "title": "New Hybrid Heuristics for Pseudo-Boolean Propagation", "comment": null, "summary": "In pseudo-boolean solving the currently most successful unit propagation strategy is a hybrid mode combining the watched literal scheme with the counting method. This short paper introduces new heuristics for this hybrid decision, which are able to drastically outperform the current method in the RoundingSAT solver.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u7528\u4e8e\u6539\u8fdb\u4f2a\u5e03\u5c14\u6c42\u89e3\u5668\u4e2d\u5355\u5143\u4f20\u64ad\u7684\u6df7\u5408\u51b3\u7b56\u65b9\u6cd5\uff0c\u663e\u8457\u8d85\u8d8a\u4e86RoundingSAT\u6c42\u89e3\u5668\u4e2d\u7684\u5f53\u524d\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u4f2a\u5e03\u5c14\u6c42\u89e3\u4e2d\u6700\u6210\u529f\u7684\u5355\u5143\u4f20\u64ad\u7b56\u7565\u662f\u76d1\u89c6\u6587\u5b57\u65b9\u6848\u4e0e\u8ba1\u6570\u65b9\u6cd5\u7684\u6df7\u5408\u6a21\u5f0f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u6709\u4f18\u5316\u7a7a\u95f4\u3002", "method": "\u5f15\u5165\u4e86\u65b0\u7684\u542f\u53d1\u5f0f\u7b56\u7565\u6765\u4f18\u5316\u6df7\u5408\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u65b0\u542f\u53d1\u5f0f\u7b56\u7565\u80fd\u591f\u663e\u8457\u4f18\u4e8eRoundingSAT\u6c42\u89e3\u5668\u4e2d\u7684\u5f53\u524d\u65b9\u6cd5\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u542f\u53d1\u5f0f\u7b56\u7565\u6709\u6548\u63d0\u5347\u4e86\u4f2a\u5e03\u5c14\u6c42\u89e3\u5668\u4e2d\u5355\u5143\u4f20\u64ad\u7684\u6027\u80fd\u3002"}}
{"id": "2511.21438", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.21438", "abs": "https://arxiv.org/abs/2511.21438", "authors": ["Simon S\u00fcwer", "Kester Bagemihl", "Sylvie Baier", "Lucia Dicunta", "Markus List", "Jan Baumbach", "Andreas Maier", "Fernando M. Delgado-Chaves"], "title": "Conversational no-code and multi-agentic disease module identification and drug repurposing prediction with ChatDRex", "comment": null, "summary": "Repurposing approved drugs offers a time-efficient and cost-effective alternative to traditional drug development. However, in silico prediction of repurposing candidates is challenging and requires the effective collaboration of specialists in various fields, including pharmacology, medicine, biology, and bioinformatics. Fragmented, specialized algorithms and tools often address only narrow aspects of the overall problem, and heterogeneous, unstructured data landscapes require specialized users to be involved. Hence, these data services do not integrate smoothly across workflows. With ChatDRex, we present a conversation-based, multi-agent system that facilitates the execution of complex bioinformatic analyses aiming for network-based drug repurposing prediction. It builds on the integrated systems medicine knowledge graph NeDRex. ChatDRex provides natural language access to its extensive biomedical KG and integrates bioinformatics agents for network analysis and drug repurposing, complemented by agents for functional coherence evaluation for in silico validation, as well as agents for literature mining and for discussing the obtained results in a scientific context. Its flexible multi-agent design assigns specific tasks to specialized agents, including query routing, data retrieval, algorithm execution, and result visualization. A dedicated reasoning module keeps the user in the loop and allows for hallucination detection. By enabling physicians and researchers without computer science expertise to control complex analyses in natural language, ChatDRex democratizes access to bioinformatics as an important resource for drug repurposing. It enables clinical experts to generate hypotheses and explore drug repurposing opportunities, ultimately accelerating the discovery of novel therapies and advancing personalized medicine and translational research.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.21460", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21460", "abs": "https://arxiv.org/abs/2511.21460", "authors": ["Junjian Wang", "Lidan Zhao", "Xi Sheryl Zhang"], "title": "MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning", "comment": null, "summary": "Ensuring the safety of embodied AI agents during task planning is critical for real-world deployment, especially in household environments where dangerous instructions pose significant risks. Existing methods often suffer from either high computational costs due to preference alignment training or over-rejection when using single-agent safety prompts. To address these limitations, we propose MADRA, a training-free Multi-Agent Debate Risk Assessment framework that leverages collective reasoning to enhance safety awareness without sacrificing task performance. MADRA employs multiple LLM-based agents to debate the safety of a given instruction, guided by a critical evaluator that scores responses based on logical soundness, risk identification, evidence quality, and clarity. Through iterative deliberation and consensus voting, MADRA significantly reduces false rejections while maintaining high sensitivity to dangerous tasks. Additionally, we introduce a hierarchical cognitive collaborative planning framework that integrates safety, memory, planning, and self-evolution mechanisms to improve task success rates through continuous learning. We also contribute SafeAware-VH, a benchmark dataset for safety-aware task planning in VirtualHome, containing 800 annotated instructions. Extensive experiments on AI2-THOR and VirtualHome demonstrate that our approach achieves over 90% rejection of unsafe tasks while ensuring that safe-task rejection is low, outperforming existing methods in both safety and execution efficiency. Our work provides a scalable, model-agnostic solution for building trustworthy embodied agents.", "AI": {"tldr": "\u63d0\u51faMADRA\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u8fdb\u884c\u98ce\u9669\u8bc4\u4f30\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u63d0\u5347\u5177\u8eabAI\u5b89\u5168\u6027\uff0c\u5728VirtualHome\u548cAI2-THOR\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u6216\u8fc7\u5ea6\u62d2\u7edd\u5b89\u5168\u6307\u4ee4\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u5b89\u5168\u610f\u8bc6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u7531\u5173\u952e\u8bc4\u4f30\u5668\u6839\u636e\u903b\u8f91\u6027\u3001\u98ce\u9669\u8bc6\u522b\u7b49\u6807\u51c6\u8bc4\u5206\uff0c\u7ed3\u5408\u8fed\u4ee3\u5ba1\u8bae\u548c\u5171\u8bc6\u6295\u7968\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5bf9\u4e0d\u5b89\u5168\u4efb\u52a1\u62d2\u7edd\u7387\u8d85\u8fc790%\uff0c\u4e14\u5b89\u5168\u4efb\u52a1\u62d2\u7edd\u7387\u4f4e\uff0c\u5728\u5b89\u5168\u6027\u548c\u6267\u884c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "MADRA\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u6a21\u578b\u65e0\u5173\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u6784\u5efa\u53ef\u4fe1\u8d56\u7684\u5177\u8eab\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2511.21471", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21471", "abs": "https://arxiv.org/abs/2511.21471", "authors": ["Peiran Xu", "Sudong Wang", "Yao Zhu", "Jianing Li", "Yunjian Zhang"], "title": "SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition", "comment": null, "summary": "Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c42\u6b21\u5316\u7a7a\u95f4\u8ba4\u77e5\u6846\u67b6\u548cSpatialBench\u57fa\u51c6\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u611f\u77e5\u5c42\u9762\u8868\u73b0\u826f\u597d\u4f46\u5728\u9ad8\u5c42\u63a8\u7406\u65b9\u9762\u5b58\u5728\u5c40\u9650", "motivation": "\u73b0\u6709\u57fa\u51c6\u8fc7\u5ea6\u7b80\u5316\u7a7a\u95f4\u8ba4\u77e5\uff0c\u5c06\u5176\u7b80\u5316\u4e3a\u5355\u4e00\u7ef4\u5ea6\u6307\u6807\uff0c\u65e0\u6cd5\u6355\u6349\u7a7a\u95f4\u80fd\u529b\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb", "method": "\u63d0\u51fa\u5c42\u6b21\u5316\u7a7a\u95f4\u8ba4\u77e5\u6846\u67b6\uff0c\u5c06\u7a7a\u95f4\u667a\u80fd\u5206\u89e3\u4e3a5\u4e2a\u9010\u6b65\u590d\u6742\u7684\u5c42\u6b21\uff1b\u6784\u5efa\u6db5\u76d615\u4e2a\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u7ec6\u7c92\u5ea6\u57fa\u51c6SpatialBench\uff1b\u5f15\u5165\u9ad8\u5c42\u80fd\u529b\u5bfc\u5411\u7684\u7edf\u4e00\u8bc4\u4f30\u6307\u6807", "result": "\u5927\u89c4\u6a21MLLM\u5b9e\u9a8c\u663e\u793a\u4e0d\u540c\u8ba4\u77e5\u5c42\u6b21\u5b58\u5728\u660e\u663e\u7684\u6027\u80fd\u5206\u5c42\uff1a\u6a21\u578b\u5728\u611f\u77e5\u57fa\u7840\u5c42\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u7b26\u53f7\u63a8\u7406\u3001\u56e0\u679c\u63a8\u65ad\u548c\u89c4\u5212\u65b9\u9762\u4ecd\u53d7\u9650\uff1b\u4eba\u7c7b\u6d4b\u8bd5\u663e\u793a\u4eba\u7c7b\u8fdb\u884c\u9009\u62e9\u6027\u76ee\u6807\u5bfc\u5411\u62bd\u8c61\uff0c\u800cMLLM\u503e\u5411\u4e8e\u8fc7\u5ea6\u5173\u6ce8\u8868\u9762\u7ec6\u8282", "conclusion": "\u5efa\u7acb\u4e86\u9996\u4e2a\u7cfb\u7edf\u5316\u6d4b\u91cfMLLM\u5c42\u6b21\u5316\u7a7a\u95f4\u8ba4\u77e5\u7684\u6846\u67b6\uff0c\u4e3a\u672a\u6765\u7a7a\u95f4\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840"}}
{"id": "2511.21522", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21522", "abs": "https://arxiv.org/abs/2511.21522", "authors": ["Yanxing Huang", "Zihan Tang", "Zejin Lin", "Peng Li", "Yang Liu"], "title": "Pessimistic Verification for Open Ended Math Questions", "comment": null, "summary": "The key limitation of the verification performance lies in the ability of error detection. With this intuition we designed several variants of pessimistic verification, which are simple workflows that could significantly improve the verification of open-ended math questions. In pessimistic verification we construct multiple parallel verifications for the same proof, and the proof is deemed incorrect if any one of them reports an error. This simple technique significantly improves the performance across many math verification benchmarks without incurring substantial computational resources. Its token efficiency even surpassed extended long-CoT in test-time scaling. Our case studies further indicate that the majority of false negatives in stronger models are actually caused by annotation errors in the original dataset, so our method's performance is in fact underestimated. Self-verification for mathematical problems can effectively improve the reliability and performance of language model outputs, and it also plays a critical role in enabling long-horizon mathematical tasks. We believe that research on pessimistic verification will help enhance the mathematical capabilities of language models across a wide range of tasks.", "AI": {"tldr": "\u60b2\u89c2\u9a8c\u8bc1\u901a\u8fc7\u6784\u5efa\u591a\u4e2a\u5e76\u884c\u9a8c\u8bc1\u6d41\u7a0b\u6765\u6539\u5584\u6570\u5b66\u95ee\u9898\u9a8c\u8bc1\u6027\u80fd\uff0c\u663e\u8457\u63d0\u5347\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u4f4e", "motivation": "\u73b0\u6709\u9a8c\u8bc1\u6027\u80fd\u7684\u5173\u952e\u5c40\u9650\u5728\u4e8e\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u9a8c\u8bc1\u65b9\u6cd5", "method": "\u8bbe\u8ba1\u60b2\u89c2\u9a8c\u8bc1\u53d8\u4f53\uff1a\u4e3a\u540c\u4e00\u8bc1\u660e\u6784\u5efa\u591a\u4e2a\u5e76\u884c\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4efb\u4e00\u9a8c\u8bc1\u62a5\u544a\u9519\u8bef\u5373\u5224\u5b9a\u8bc1\u660e\u9519\u8bef", "result": "\u663e\u8457\u63d0\u5347\u591a\u4e2a\u6570\u5b66\u9a8c\u8bc1\u57fa\u51c6\u6027\u80fd\uff0ctoken\u6548\u7387\u8d85\u8d8a\u6269\u5c55\u957f\u94fe\u601d\u7ef4\uff0c\u8bc6\u522b\u51fa\u6570\u636e\u96c6\u4e2d\u6807\u6ce8\u9519\u8bef\u5bfc\u81f4\u7684\u5047\u9634\u6027", "conclusion": "\u60b2\u89c2\u9a8c\u8bc1\u53ef\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6570\u5b66\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u5bf9\u5b9e\u73b0\u957f\u89c6\u91ce\u6570\u5b66\u4efb\u52a1\u81f3\u5173\u91cd\u8981"}}
{"id": "2511.21569", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21569", "abs": "https://arxiv.org/abs/2511.21569", "authors": ["Alex Diep"], "title": "Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit", "comment": null, "summary": "If a language model cannot reliably disclose its AI identity in expert contexts, users cannot trust its competence boundaries. This study examines self-transparency in models assigned professional personas within high-stakes domains where false expertise risks user harm. Using a common-garden design, sixteen open-weight models (4B--671B parameters) were audited across 19,200 trials. Models exhibited sharp domain-specific inconsistency: a Financial Advisor persona elicited 30.8% disclosure initially, while a Neurosurgeon persona elicited only 3.5%. This creates preconditions for a \"Reverse Gell-Mann Amnesia\" effect, where transparency in some domains leads users to overgeneralize trust to contexts where disclosure fails. Disclosure ranged from 2.8% to 73.6%, with a 14B model reaching 61.4% while a 70B produced just 4.1%. Model identity predicted behavior better than parameter count ($\u0394R_{adj}^{2} = 0.359$ vs 0.018). Reasoning optimization actively suppressed self-transparency in some models, with reasoning variants showing up to 48.4% lower disclosure than base counterparts. Bayesian validation with Rogan--Gladen correction confirmed robustness to measurement error ($\u03ba= 0.908$). These findings demonstrate transparency reflects training factors rather than scale. Organizations cannot assume safety properties transfer to deployment contexts, requiring deliberate behavior design and empirical verification.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u516c\u5171\u82b1\u56ed\u8bbe\u8ba1\u5ba1\u8ba1\u4e8616\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff0c\u53d1\u73b0AI\u6a21\u578b\u5728\u4e0d\u540c\u4e13\u4e1a\u9886\u57df\u4e2d\u7684\u8eab\u4efd\u62ab\u9732\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\uff0c\u900f\u660e\u5ea6\u53d7\u5230\u8bad\u7ec3\u56e0\u7d20\u800c\u975e\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u9700\u8981\u4e13\u95e8\u7684\u884c\u4e3a\u8bbe\u8ba1\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u5bb6\u8bed\u5883\u4e2d\u65e0\u6cd5\u53ef\u9760\u62ab\u9732\u5176AI\u8eab\u4efd\u7684\u95ee\u9898\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u7528\u6237\u65e0\u6cd5\u4fe1\u4efb\u5176\u80fd\u529b\u8fb9\u754c\u3002\u5728\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u865a\u5047\u7684\u4e13\u4e1a\u77e5\u8bc6\u53ef\u80fd\u5bf9\u7528\u6237\u9020\u6210\u4f24\u5bb3\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u5305\u62ec\uff1a\u91c7\u7528\u516c\u5171\u82b1\u56ed\u8bbe\u8ba1\uff0c\u5bf916\u4e2a\u5f00\u653e\u6743\u91cd\u6a21\u578b\uff08\u53c2\u6570\u8303\u56f44B-671B\uff09\u8fdb\u884c19,200\u6b21\u8bd5\u9a8c\u5ba1\u8ba1\uff1b\u4f7f\u7528\u8d1d\u53f6\u65af\u9a8c\u8bc1\u548cRogan-Gladen\u6821\u6b63\u6765\u786e\u8ba4\u7ed3\u679c\u7684\u7a33\u5065\u6027\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff1a\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u8868\u73b0\u51fa\u5c16\u9510\u7684\u4e0d\u4e00\u81f4\u6027\uff0c\u91d1\u878d\u987e\u95ee\u89d2\u8272\u7684\u521d\u59cb\u62ab\u9732\u7387\u4e3a30.8%\uff0c\u800c\u795e\u7ecf\u5916\u79d1\u533b\u751f\u89d2\u8272\u4ec5\u4e3a3.5%\uff1b\u62ab\u9732\u7387\u8303\u56f4\u4e3a2.8%\u81f373.6%\uff1b\u6a21\u578b\u8eab\u4efd\u6bd4\u53c2\u6570\u6570\u91cf\u66f4\u80fd\u9884\u6d4b\u884c\u4e3a\uff1b\u63a8\u7406\u4f18\u5316\u5728\u67d0\u4e9b\u6a21\u578b\u4e2d\u79ef\u6781\u6291\u5236\u4e86\u81ea\u6211\u900f\u660e\u5ea6\u3002", "conclusion": "\u7814\u7a76\u7ed3\u8bba\u8868\u660e\uff1a\u900f\u660e\u5ea6\u53cd\u6620\u7684\u662f\u8bad\u7ec3\u56e0\u7d20\u800c\u975e\u89c4\u6a21\uff1b\u7ec4\u7ec7\u4e0d\u80fd\u5047\u8bbe\u5b89\u5168\u5c5e\u6027\u4f1a\u8f6c\u79fb\u5230\u90e8\u7f72\u73af\u5883\u4e2d\uff0c\u9700\u8981\u8fdb\u884c\u6709\u610f\u8bc6\u7684\u884c\u4e3a\u8bbe\u8ba1\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u3002"}}
{"id": "2511.21570", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.21570", "abs": "https://arxiv.org/abs/2511.21570", "authors": ["Maria Perez-Ortiz"], "title": "From Prediction to Foresight: The Role of AI in Designing Responsible Futures", "comment": "Accessible at https://projecteuclid.org/journals/journal-of-artificial-intelligence-for-sustainable-development/volume-1/issue-1/From-Prediction-to-Foresight--The-Role-of-AI-in/10.69828/4d4kja.full", "summary": "In an era marked by rapid technological advancements and complex global challenges, responsible foresight has emerged as an essential framework for policymakers aiming to navigate future uncertainties and shape the future. Responsible foresight entails the ethical anticipation of emerging opportunities and risks, with a focus on fostering proactive, sustainable, and accountable future design. This paper coins the term \"responsible computational foresight\", examining the role of human-centric artificial intelligence and computational modeling in advancing responsible foresight, establishing a set of foundational principles for this new field and presenting a suite of AI-driven foresight tools currently shaping it. AI, particularly in conjunction with simulations and scenario analysis, enhances policymakers' ability to address uncertainty, evaluate risks, and devise strategies geared toward sustainable, resilient futures. However, responsible foresight extends beyond mere technical forecasting; it demands a nuanced understanding of the interdependencies within social, environmental, economic and political systems, alongside a commitment to ethical, long-term decision-making that supports human intelligence. We argue that AI will play a role as a supportive tool in responsible, human-centered foresight, complementing rather than substituting policymaker judgment to enable the proactive shaping of resilient and ethically sound futures. This paper advocates for the thoughtful integration of AI into foresight practices to empower policymakers and communities as they confront the grand challenges of the 21st century.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u201c\u8d1f\u8d23\u8ba1\u7b97\u524d\u77bb\u201d\u6982\u5ff5\uff0c\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5982\u4f55\u652f\u6301\u8d1f\u8d23\u4efb\u7684\u524d\u77bb\u51b3\u7b56\uff0c\u5f3a\u8c03AI\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\u800c\u975e\u66ff\u4ee3\u54c1\uff0c\u52a9\u529b\u5e94\u5bf921\u4e16\u7eaa\u91cd\u5927\u6311\u6218\u3002", "motivation": "\u5728\u6280\u672f\u5feb\u901f\u53d1\u5c55\u548c\u5168\u7403\u6311\u6218\u590d\u6742\u7684\u80cc\u666f\u4e0b\uff0c\u9700\u8981\u8d1f\u8d23\u4efb\u7684\u524d\u77bb\u6846\u67b6\u6765\u5e94\u5bf9\u672a\u6765\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u5851\u9020\u53ef\u6301\u7eed\u7684\u672a\u6765\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u8d1f\u8d23\u4efb\u8ba1\u7b97\u524d\u77bb\u7684\u539f\u5219\uff0c\u5f00\u53d1AI\u9a71\u52a8\u7684\u524d\u77bb\u5de5\u5177\uff0c\u7ed3\u5408\u6a21\u62df\u548c\u60c5\u666f\u5206\u6790\uff0c\u589e\u5f3a\u51b3\u7b56\u8005\u7684\u80fd\u529b\u3002", "result": "\u786e\u7acb\u4e86\u4e00\u5957\u8d1f\u8d23\u4efb\u8ba1\u7b97\u524d\u77bb\u7684\u57fa\u7840\u539f\u5219\uff0c\u5e76\u5c55\u793a\u4e86AI\u5de5\u5177\u5728\u589e\u5f3a\u524d\u77bb\u51b3\u7b56\u4e2d\u7684\u5e94\u7528\u3002", "conclusion": "AI\u5e94\u4f5c\u4e3a\u652f\u6301\u6027\u5de5\u5177\u878d\u5165\u524d\u77bb\u5b9e\u8df5\uff0c\u8865\u5145\u800c\u975e\u66ff\u4ee3\u4eba\u7c7b\u5224\u65ad\uff0c\u4ee5\u4fc3\u6210\u6709\u97e7\u6027\u548c\u9053\u5fb7\u7684\u672a\u6765\u5851\u9020\u3002"}}
