{"id": "2512.05907", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.05907", "abs": "https://arxiv.org/abs/2512.05907", "authors": ["Abrar Hossain Mufakir Qamar Ansari Haziq Jeelani Monia Digra Fayeq Jeelani Syed"], "title": "From Text to Returns: Using Large Language Models for Mutual Fund Portfolio Optimization and Risk-Adjusted Allocation", "comment": null, "summary": "Generative AI (GenAI) has enormous potential for improving two critical areas in investing, namely portfolio optimization (choosing the best combination of assets) and risk management (protecting those investments). Our study works at this intersection, using Large Language Models (LLMs) to upgrade how financial decisions are traditionally made. This research specifically tested how well advanced LLMs like Microsoft Phi 2, Mistral 7B, and Zypher 7B can create practical, risk-aware strategies for investing mutual funds in different sectors of the economy. Our method is sophisticated: it combines a Retrieval-Augmented Generation (RAG) pipeline, which enables the LLM to check external, real-time data with standard financial optimization methods. The model's advice is context-aware because we feed it large economic signals, like changes in the global economy. The Zypher 7B model was the clear winner. It consistently produced strategies that maximized investment returns while delivering better risk-adjusted results than the other models. Its ability to process complex relationships and contextual information makes it a highly powerful tool for financial allocation. In conclusion, our findings show that GenAI substantially improves performance over basic allocation methods. By connecting GenAI to real-world financial applications, this work lays the groundwork for creating smarter, more efficient, and more adaptable solutions for asset management professionals.", "AI": {"tldr": "\u5229\u7528\u751f\u6210\u5f0fAI\uff08Large Language Models\uff09\u6539\u8fdb\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u548c\u98ce\u9669\u7ba1\u7406\uff0c\u5728\u91d1\u878d\u51b3\u7b56\u4e2d\u5e94\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\u7ed3\u5408\u5b9e\u65f6\u7ecf\u6d4e\u6570\u636e\uff0cZypher 7B\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u751f\u6210\u5f0fAI\u5728\u6295\u8d44\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u4f18\u5316\u8d44\u4ea7\u7ec4\u5408\u548c\u7ba1\u7406\u98ce\u9669\u65b9\u9762\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u7528\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u4f20\u7edf\u91d1\u878d\u51b3\u7b56\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7ba1\u9053\uff0c\u4f7fLLM\u80fd\u591f\u7ed3\u5408\u5916\u90e8\u5b9e\u65f6\u6570\u636e\u4e0e\u6807\u51c6\u91d1\u878d\u4f18\u5316\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u4e86Microsoft Phi 2\u3001Mistral 7B\u548cZypher 7B\u7b49\u6a21\u578b\u5728\u4e0d\u540c\u7ecf\u6d4e\u90e8\u95e8\u7684\u4e92\u60e0\u57fa\u91d1\u6295\u8d44\u4e2d\u5236\u5b9a\u98ce\u9669\u611f\u77e5\u7b56\u7565\u3002", "result": "Zypher 7B\u6a21\u578b\u8868\u73b0\u6700\u4f18\uff0c\u80fd\u6301\u7eed\u751f\u6210\u6700\u5927\u5316\u6295\u8d44\u56de\u62a5\u4e14\u98ce\u9669\u8c03\u6574\u540e\u7ed3\u679c\u66f4\u597d\u7684\u7b56\u7565\uff0c\u5176\u5904\u7406\u590d\u6742\u5173\u7cfb\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u80fd\u529b\u7a81\u51fa\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u663e\u8457\u4f18\u4e8e\u57fa\u672c\u8d44\u4ea7\u5206\u914d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06AI\u4e0e\u73b0\u5b9e\u91d1\u878d\u5e94\u7528\u7ed3\u5408\uff0c\u4e3a\u8d44\u4ea7\u7ba1\u7406\u4e13\u4e1a\u4eba\u58eb\u5f00\u53d1\u66f4\u667a\u80fd\u3001\u9ad8\u6548\u548c\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.05159", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.05159", "abs": "https://arxiv.org/abs/2512.05159", "authors": ["Zhiyi Wang", "Xiwei Wu", "Yi Fang", "Chengtao Li", "Hongyi Zhong", "Lihan Xie", "Qinxiang Cao", "Zhenjiang Hu"], "title": "Stellis: A Strategy Language for Purifying Separation Logic Entailments", "comment": null, "summary": "Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.", "AI": {"tldr": "\u63d0\u51faStellis\u7b56\u7565\u8bed\u8a00\u89e3\u51b3\u5206\u79bb\u903b\u8f91\u8574\u6db5\u81ea\u52a8\u8bc1\u660e\u95ee\u9898\uff0c\u901a\u8fc7\u7eaf\u5316\u64cd\u4f5c\u5c06\u8574\u7ea6\u7b80\u4e3a\u7eaf\u8574\u6db5\uff0c\u7cfb\u7edf\u5728229\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u6210\u529f\u7eaf\u531695.6%\u7684\u8574\u6db5\u3002", "motivation": "\u57fa\u4e8e\u89c4\u5219\u7684\u5206\u79bb\u903b\u8f91\u81ea\u52a8\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u65e0\u6cd5\u63cf\u8ff0\u6d89\u53ca\u5185\u5b58\u5e03\u5c40\u5bf9\u9f50\u548c\u6d88\u9664\u7684\u5177\u4f53\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1Stellis\u7b56\u7565\u8bed\u8a00\uff0c\u5305\u542b\u5339\u914d\u673a\u5236\u548c\u52a8\u4f5c\u63cf\u8ff0\uff1b\u63d0\u51fa\u7b97\u6cd5\u751f\u6210\u7b56\u7565\u53ef\u9760\u6027\u6761\u4ef6\uff1b\u57fa\u4e8e\u673a\u68b0\u5316\u5f52\u7ea6\u53ef\u9760\u6027\u5b9a\u7406\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5728\u6807\u51c6\u94fe\u8868\u6570\u636e\u7ed3\u6784\u548c\u5fae\u5185\u6838\u5185\u5b58\u6a21\u5757\u7684229\u4e2a\u8574\u6db5\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u75285\u4e2a\u5e93\u768498\u6761\u7b56\u7565\u5b9e\u73b095.6%\u7684\u7eaf\u5316\u6210\u529f\u7387\u3002", "conclusion": "Stellis\u5728\u4fdd\u6301\u7075\u6d3b\u4fbf\u6377\u7684\u540c\u65f6\u5177\u5907\u9ad8\u6548\u6027\uff0c\u4e3a\u5206\u79bb\u903b\u8f91\u81ea\u52a8\u5316\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.05321", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.05321", "abs": "https://arxiv.org/abs/2512.05321", "authors": ["Darren Malvern Chin", "Bilal Isfaq", "Simon Yusuf Enoch"], "title": "A Practical Honeypot-Based Threat Intelligence Framework for Cyber Defence in the Cloud", "comment": "6 pages", "summary": "In cloud environments, conventional firewalls rely on predefined rules and manual configurations, limiting their ability to respond effectively to evolving or zero-day threats. As organizations increasingly adopt platforms such as Microsoft Azure, this static defense model exposes cloud assets to zero-day exploits, botnets, and advanced persistent threats. In this paper, we introduce an automated defense framework that leverages medium- to high-interaction honeypot telemetry to dynamically update firewall rules in real time. The framework integrates deception sensors (Cowrie), Azure-native automation tools (Monitor, Sentinel, Logic Apps), and MITRE ATT&CK-aligned detection within a closed-loop feedback mechanism. We developed a testbed to automatically observe adversary tactics, classify them using the MITRE ATT&CK framework, and mitigate network-level threats automatically with minimal human intervention.\n  To assess the framework's effectiveness, we defined and applied a set of attack- and defense-oriented security metrics. Building on existing adaptive defense strategies, our solution extends automated capabilities into cloud-native environments. The experimental results show an average Mean Time to Block of 0.86 seconds - significantly faster than benchmark systems - while accurately classifying over 12,000 SSH attempts across multiple MITRE ATT&CK tactics. These findings demonstrate that integrating deception telemetry with Azure-native automation reduces attacker dwell time, enhances SOC visibility, and provides a scalable, actionable defense model for modern cloud infrastructures.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u9632\u5fa1\u6846\u67b6\uff0c\u5b83\u6574\u5408\u4e86\u871c\u7f50\u9065\u6d4b\u548cAzure\u539f\u751f\u5de5\u5177\u6765\u52a8\u6001\u66f4\u65b0\u4e91\u9632\u706b\u5899\u89c4\u5219\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u653b\u51fb\u505c\u7559\u65f6\u95f4\u5e76\u63d0\u9ad8\u4e86\u5b89\u5168\u8fd0\u7ef4\u7684\u53ef\u89c1\u6027\u3002", "motivation": "\u4f20\u7edf\u9759\u6001\u9632\u706b\u5899\u5728\u4e91\u73af\u5883\u4e0b\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u96f6\u65e5\u5a01\u80c1\u548c\u9ad8\u7ea7\u6301\u7eed\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5728\u4f01\u4e1a\u5e7f\u6cdb\u91c7\u7528Azure\u7b49\u4e91\u5e73\u53f0\u540e\uff0c\u8fd9\u79cd\u9632\u5fa1\u6a21\u5f0f\u7684\u5c40\u9650\u6027\u66f4\u52a0\u7a81\u51fa\u3002", "method": "\u901a\u8fc7\u4e2d\u7b49\u81f3\u9ad8\u4ea4\u4e92\u871c\u7f50\uff08\u5982Cowrie\uff09\u6536\u96c6\u653b\u51fb\u9065\u6d4b\uff0c\u5229\u7528MITRE ATT&CK\u6846\u67b6\u5bf9\u653b\u51fb\u6280\u6218\u672f\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7Azure Monitor\u3001Sentinel\u548cLogic Apps\u5b9e\u73b0\u95ed\u73af\u81ea\u52a8\u5316\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u7684\u5e73\u5747\u963b\u65ad\u65f6\u95f4\u4e3a0.86\u79d2\uff0c\u8fdc\u5feb\u4e8e\u57fa\u51c6\u7cfb\u7edf\uff0c\u5e76\u6210\u529f\u5206\u7c7b\u4e86\u8d85\u8fc712,000\u6b21SSH\u653b\u51fb\u5c1d\u8bd5\uff0c\u8986\u76d6\u591a\u4e2aMITRE ATT&CK\u6218\u672f\u3002", "conclusion": "\u5c06\u871c\u7f50\u9065\u6d4b\u4e0e\u4e91\u539f\u751f\u81ea\u52a8\u5316\u76f8\u7ed3\u5408\uff0c\u80fd\u591f\u4e3a\u73b0\u4ee3\u4e91\u57fa\u7840\u8bbe\u65bd\u63d0\u4f9b\u53ef\u6269\u5c55\u3001\u9ad8\u6548\u7684\u52a8\u6001\u9632\u5fa1\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2512.05176", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.05176", "abs": "https://arxiv.org/abs/2512.05176", "authors": ["Brittany Johnson", "Erin Reddick", "Angela D. R. Smith"], "title": "Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge", "comment": "Under review", "summary": "Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as \"general purpose\" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of \"culturally-informed\" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5f00\u53d1CIVIQ\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u4e0e\u7f8e\u56fd\u4e0d\u540c\u793e\u533a\u6587\u5316\u4ef7\u503c\u89c2\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u4ee5\u5f25\u8865\u73b0\u6709\u56fd\u5bb6\u5c42\u9762\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u901a\u7528LLMs\u4e3b\u8981\u4e0e\u897f\u65b9\u767d\u4eba\u6587\u5316\u5bf9\u9f50\uff0c\u5ffd\u89c6\u4e86\u7f8e\u56fd\u591a\u6837\u7684\u6587\u5316\u7fa4\u4f53\u3002\u56fd\u5bb6\u5c42\u9762\u7684\u5bf9\u9f50\u57fa\u51c6\u65e0\u6cd5\u5145\u5206\u4ee3\u8868\u591a\u5143\u6587\u5316\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u590d\u5236\u97e9\u56fdKorNAT\u57fa\u51c6\u7684\u5f00\u53d1\u8fc7\u7a0b\uff0c\u5f00\u53d1CIVIQ\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u793e\u533a\u5c42\u9762\u7684\u793e\u4f1a\u4ef7\u503c\u89c2\u548c\u5e38\u8bc6\u5bf9\u9f50\u3002", "result": "\u63d0\u51fa\u4e86CIVIQ\u57fa\u51c6\u6846\u67b6\uff0c\u4e3a\u5b9e\u8df5\u4e2dAI\u6280\u672f\u7684\u6587\u5316\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002", "conclusion": "\u793e\u533a\u5c42\u9762\u7684\u6587\u5316\u5bf9\u9f50\u57fa\u51c6\u5bf9\u4e8e\u5b9e\u73b0\u66f4\u5177\u5305\u5bb9\u6027\u7684AI\u6280\u672f\u81f3\u5173\u91cd\u8981\uff0cCIVIQ\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u5173\u952e\u57fa\u7840\u3002"}}
{"id": "2512.05156", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.LG", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.05156", "abs": "https://arxiv.org/abs/2512.05156", "authors": ["Igor Halperin"], "title": "Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations", "comment": "23 pages, 6 figures", "summary": "Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\\bf Q}$ and ${\\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u548c\u70ed\u529b\u5b66\u7684\u65e0\u76d1\u7763\u6307\u6807SF\u548cSEP\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4efb\u52a1\u5fe0\u5b9e\u5ea6\uff0c\u901a\u8fc7\u5efa\u6a21\u95ee\u7b54\u4e3b\u9898\u8f6c\u6362\u7684\u6982\u7387\u5206\u5e03\u6765\u8861\u91cf\u751f\u6210\u5185\u5bb9\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u7ed9\u5b9a\u4efb\u52a1\u7684\u5fe0\u5b9e\u5ea6\u662f\u4e00\u4e2a\u590d\u6742\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u65b0\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u6307\u6807\u3002", "method": "\u5c06LLM\u89c6\u4e3a\u4e8c\u5206\u4fe1\u606f\u5f15\u64ce\uff0c\u9690\u85cf\u5c42\u4f5c\u4e3a\u9ea6\u514b\u65af\u97e6\u5996\u63a7\u5236\u4fe1\u606f\u8f6c\u6362\u3002\u901a\u8fc7QCA\u4e09\u5143\u7ec4\u7684\u6982\u7387\u5206\u5e03\u5efa\u6a21\uff0c\u7528KL\u6563\u5ea6\u8ba1\u7b97\u8bed\u4e49\u5fe0\u5b9e\u5ea6\u6307\u6807SF\uff0c\u5e76\u901a\u8fc7\u51f8\u4f18\u5316\u540c\u65f6\u63a8\u65ad\u8f6c\u6362\u77e9\u9635\u3002", "result": "\u5f00\u53d1\u4e86SF\u548cSEP\u4e24\u4e2a\u6307\u6807\uff0cSF\u901a\u8fc7KL\u6563\u5ea6\u91cf\u5316\u5fe0\u5b9e\u5ea6\uff080-1\u5206\uff09\uff0cSEP\u57fa\u4e8e\u70ed\u529b\u5b66\u71b5\u4ea7\u8bc4\u4f30\u751f\u6210\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8bc1\u660e\u9ad8\u5fe0\u5b9e\u5ea6\u901a\u5e38\u5bf9\u5e94\u4f4e\u71b5\u4ea7\u3002", "conclusion": "SF\u548cSEP\u6307\u6807\u53ef\u5355\u72ec\u6216\u8054\u5408\u7528\u4e8eLLM\u8bc4\u4f30\u548c\u5e7b\u89c9\u63a7\u5236\uff0c\u5728SEC\u6587\u4ef6\u6458\u8981\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u6709\u6548\u6027\u3002"}}
{"id": "2512.05239", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05239", "abs": "https://arxiv.org/abs/2512.05239", "authors": ["Ruofan Gao", "Amjed Tahir", "Peng Liang", "Teo Susnjak", "Foutse Khomh"], "title": "A Survey of Bugs in AI-Generated Code", "comment": null, "summary": "Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.05167", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05167", "abs": "https://arxiv.org/abs/2512.05167", "authors": ["Fang Li"], "title": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education", "comment": "Accepted by the 39th annual Consortium for Computing Sciences in Colleges (CCSC:SE)", "summary": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.", "AI": {"tldr": "\u4e00\u7bc7\u4ecb\u7ecd\u5c06\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u7ed3\u5408\u7684\u6559\u5b66\u65b9\u6cd5\u7684\u8bba\u6587\uff0c\u901a\u8fc7\u4e00\u4e2a\u5206\u4e3a\u4e24\u90e8\u5206\u7684\u8bfe\u7a0b\u8bbe\u8ba1\uff0c\u5e2e\u52a9\u5b66\u751f\u5168\u9762\u7406\u89e3AI\u53d1\u5c55\u5e76\u638c\u63e1\u5b9e\u7528\u6280\u80fd\u3002", "motivation": "\u4e3a\u4e86\u7cfb\u7edf\u5730\u5f25\u5408\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6280\u672f\u4e0e\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u8bbe\u8ba1\u4e00\u79cd\u521b\u65b0\u7684\u6559\u5b66\u65b9\u6cd5\uff0c\u4f7f\u5b66\u751f\u80fd\u591f\u5168\u9762\u7406\u89e3\u4eba\u5de5\u667a\u80fd\u7684\u6f14\u53d8\u8fc7\u7a0b\uff0c\u5e76\u638c\u63e1\u4f20\u7edf\u548c\u524d\u6cbf\u6280\u672f\u7684\u5b9e\u7528\u6280\u80fd\u3002", "method": "\u8bfe\u7a0b\u5206\u4e3a\u4e24\u4e2a\u8fde\u7eed\u4e14\u4e92\u8865\u7684\u90e8\u5206\uff1a\u57fa\u7840\u673a\u5668\u5b66\u4e60\u6982\u5ff5\u548c\u73b0\u4ee3LLM\u5e94\u7528\u3002\u8be6\u7ec6\u63cf\u8ff0\u4e86\u8bfe\u7a0b\u67b6\u6784\u3001\u5b9e\u65bd\u7b56\u7565\u3001\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u4e3a\u671f\u4e24\u4e2a\u4e03\u5468\u5b66\u671f\u7684\u6691\u671f\u8bfe\u7a0b\u8fdb\u884c\u5b9e\u65bd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u79cd\u7efc\u5408\u65b9\u6cd5\u589e\u5f3a\u4e86\u5b66\u751f\u5bf9AI\u9886\u57df\u7684\u7406\u89e3\uff0c\u5e76\u66f4\u597d\u5730\u4e3a\u4ed6\u4eec\u5e94\u5bf9\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u6f14\u53d8\u9886\u57df\u7684\u884c\u4e1a\u9700\u6c42\u505a\u597d\u4e86\u51c6\u5907\u3002", "conclusion": "\u8fd9\u79cd\u5c06\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u73b0\u4ee3LLM\u76f8\u7ed3\u5408\u7684\u6559\u5b66\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5b66\u751f\u5bf9AI\u5168\u666f\u7684\u7406\u89e3\uff0c\u5e76\u589e\u5f3a\u4e86\u4ed6\u4eec\u5e94\u5bf9\u884c\u4e1a\u9700\u6c42\u7684\u80fd\u529b\uff0c\u4e3aAI\u6559\u80b2\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002"}}
{"id": "2512.05459", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.05459", "abs": "https://arxiv.org/abs/2512.05459", "authors": ["Zheng Liu", "Chen Gong", "Terry Yue Zhuo", "Kecen Li", "Weichen Yu", "Matt Fredrikson", "Tianhao Wang"], "title": "PrivCode: When Code Generation Meets Differential Privacy", "comment": "Accepted at NDSS 2026; code available at https://github.com/Liuzzyg/PrivCode", "summary": "Large language models (LLMs) have presented outstanding performance in code generation and completion. However, fine-tuning these models on private datasets can raise privacy and proprietary concerns, such as the leakage of sensitive personal information. Differentially private (DP) code generation provides theoretical guarantees for protecting sensitive code by generating synthetic datasets that preserve statistical properties while reducing privacy leakage concerns. However, DP code generation faces significant challenges due to the strict syntactic dependencies and the privacy-utility trade-off.\n  We propose PrivCode, the first DP synthesizer specifically designed for code datasets. It incorporates a two-stage framework to improve both privacy and utility. In the first stage, termed \"privacy-sanitizing\", PrivCode generates DP-compliant synthetic code by training models using DP-SGD while introducing syntactic information to preserve code structure. The second stage, termed \"utility-boosting\", fine-tunes a larger pre-trained LLM on the synthetic privacy-free code to mitigate the utility loss caused by DP, enhancing the utility of the generated code. Extensive experiments on four LLMs show that PrivCode generates higher-utility code across various testing tasks under four benchmarks. The experiments also confirm its ability to protect sensitive data under varying privacy budgets. We provide the replication package at the anonymous link.", "AI": {"tldr": "PrivCode\u662f\u9996\u4e2a\u4e13\u4e3a\u4ee3\u7801\u6570\u636e\u96c6\u8bbe\u8ba1\u7684\u5dee\u5206\u9690\u79c1\u5408\u6210\u5668\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u6846\u67b6\uff08\u9690\u79c1\u6d88\u6bd2+\u6548\u7528\u63d0\u5347\uff09\u5728\u4fdd\u62a4\u654f\u611f\u6570\u636e\u7684\u540c\u65f6\u751f\u6210\u9ad8\u8d28\u91cf\u4ee3\u7801", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4f7f\u7528\u79c1\u6709\u6570\u636e\u5fae\u8c03\u4f1a\u5f15\u53d1\u9690\u79c1\u6cc4\u9732\u62c5\u5fe7", "method": "\u7b2c\u4e00\u9636\u6bb5\u7528DP-SGD\u8bad\u7ec3\u6a21\u578b\u751f\u6210\u5dee\u5206\u9690\u79c1\u5408\u6210\u4ee3\u7801\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5728\u5408\u6210\u4ee3\u7801\u4e0a\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u6548\u7528", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPrivCode\u5728\u56db\u79cdLLMs\u4e0a\u5747\u80fd\u751f\u6210\u66f4\u9ad8\u5b9e\u7528\u6027\u7684\u4ee3\u7801", "conclusion": "PrivCode\u6709\u6548\u5e73\u8861\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u4ee3\u7801\u5b9e\u7528\u6027\uff0c\u4e3aDP\u4ee3\u7801\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.05242", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05242", "abs": "https://arxiv.org/abs/2512.05242", "authors": ["Uwe M. Borghoff", "Mark Minas", "Jannis Schopp"], "title": "Learning to Code with Context: A Study-Based Approach", "comment": "36 pages, 7 figures, 5 tables", "summary": "The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u5927\u5b66\u7f16\u7a0b\u9879\u76ee\u4e2d\u6574\u5408\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7528\u6237\u7814\u7a76\u5206\u6790\u5b66\u751f\u5728\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u5982\u4f55\u4f7f\u7528AI\u5de5\u5177\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eRAG\u7684\u672c\u5730\u90e8\u7f72LLM\u52a9\u624b\u6765\u63d0\u4f9b\u9879\u76ee\u4e0a\u4e0b\u6587\u652f\u6301", "motivation": "\u751f\u6210\u5f0fAI\u5de5\u5177\u7684\u5feb\u901f\u51fa\u73b0\u6b63\u5728\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\u65b9\u5f0f\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u9700\u8981\u9002\u5e94\u8fd9\u4e00\u53d8\u5316\uff0c\u786e\u4fdd\u5b66\u751f\u4e0d\u4ec5\u80fd\u5b66\u4e60\u4f20\u7edf\u5f00\u53d1\u65b9\u6cd5\uff0c\u8fd8\u80fd\u6709\u610f\u4e49\u4e14\u8d1f\u8d23\u4efb\u5730\u4f7f\u7528\u65b0\u6280\u672f", "method": "\u5728\u5927\u5b66\u7f16\u7a0b\u9879\u76ee\u4e2d\u8fdb\u884c\u7684\u7528\u6237\u7814\u7a76\uff0c\u5b66\u751f\u534f\u4f5c\u5f00\u53d1\u7535\u8111\u6e38\u620f\uff0c\u7814\u7a76\u5206\u6790\u53c2\u4e0e\u8005\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e0d\u540c\u9636\u6bb5\u5982\u4f55\u4f7f\u7528\u751f\u6210\u5f0fAI\u5de5\u5177\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u672c\u5730\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u52a9\u624b", "result": "\u7814\u7a76\u786e\u5b9a\u4e86AI\u5de5\u5177\u6700\u6709\u6548\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u5206\u6790\u4e86\u5b66\u751f\u9047\u5230\u7684\u6311\u6218\uff0c\u5e76\u901a\u8fc7RAG\u7cfb\u7edf\u5b9e\u73b0\u5bf9\u6a21\u578b\u884c\u4e3a\u3001\u53c2\u6570\u654f\u611f\u6027\u548c\u5e38\u89c1\u6545\u969c\u6a21\u5f0f\u7684\u5b9a\u6027\u5206\u6790", "conclusion": "\u7814\u7a76\u7ed3\u679c\u52a0\u6df1\u4e86\u5bf9\u6559\u80b2\u8f6f\u4ef6\u9879\u76ee\u4e2d\u60c5\u5883\u611f\u77e5AI\u652f\u6301\u7684\u7406\u89e3\uff0c\u4e3a\u672a\u6765\u5c06\u57fa\u4e8eAI\u7684\u8f85\u52a9\u5de5\u5177\u6574\u5408\u5230\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u63d0\u4f9b\u4e86\u53c2\u8003"}}
{"id": "2512.05212", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05212", "abs": "https://arxiv.org/abs/2512.05212", "authors": ["Georgios Mappouras", "Charalambos Rossides"], "title": "On the Computability of Artificial General Intelligence", "comment": null, "summary": "In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.", "AI": {"tldr": "\u8bba\u6587\u8bc1\u660e\u4efb\u4f55\u7b97\u6cd5\u90fd\u65e0\u6cd5\u771f\u6b63\u521b\u65b0\uff0c\u65e0\u6cd5\u4ea7\u751f\u521d\u59cb\u7b97\u6cd5\u4e2d\u4e0d\u5b58\u5728\u7684\u529f\u80fd\u80fd\u529b", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u662f\u5426\u80fd\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u7684\u667a\u80fd\uff08AGI\uff09\uff0c\u7279\u522b\u662f\u521b\u65b0\u80fd\u529b", "method": "\u501f\u7528\u524d\u4ebaAGI\u5b9a\u4e49\uff0c\u8bc1\u660e\u7b97\u6cd5\u7684\u529f\u80fd\u6027\u4e0a\u9650\u5b9a\u7406", "result": "\u6b63\u5f0f\u8bc1\u660e\u6ca1\u6709\u7b97\u6cd5\u80fd\u5c55\u793a\u521d\u59cb\u7b97\u6cd5\u672c\u8eab\u4e0d\u5b58\u5728\u7684\u529f\u80fd\u80fd\u529b", "conclusion": "AI\u53ea\u80fd\u5c55\u793a\u73b0\u6709\u529f\u80fd\u80fd\u529b\u7684\u7ec4\u5408\u6392\u5217\uff0c\u65e0\u6cd5\u771f\u6b63\u521b\u65b0\uff1b\u8fd9\u5bf9AI\u53d1\u5c55\u548c\u4eba\u7c7b\u667a\u80fd\u8d77\u6e90\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2512.05485", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.05485", "abs": "https://arxiv.org/abs/2512.05485", "authors": ["Xiuyuan Chen", "Jian Zhao", "Yuxiang He", "Yuan Xun", "Xinwei Liu", "Yanshu Li", "Huilin Zhou", "Wei Cai", "Ziyan Shi", "Yuchen Yuan", "Tianle Zhang", "Chi Zhang", "Xuelong Li"], "title": "TeleAI-Safety: A comprehensive LLM jailbreaking benchmark towards attacks, defenses, and evaluations", "comment": null, "summary": "While the deployment of large language models (LLMs) in high-value industries continues to expand, the systematic assessment of their safety against jailbreak and prompt-based attacks remains insufficient. Existing safety evaluation benchmarks and frameworks are often limited by an imbalanced integration of core components (attack, defense, and evaluation methods) and an isolation between flexible evaluation frameworks and standardized benchmarking capabilities. These limitations hinder reliable cross-study comparisons and create unnecessary overhead for comprehensive risk assessment. To address these gaps, we present TeleAI-Safety, a modular and reproducible framework coupled with a systematic benchmark for rigorous LLM safety evaluation. Our framework integrates a broad collection of 19 attack methods (including one self-developed method), 29 defense methods, and 19 evaluation methods (including one self-developed method). With a curated attack corpus of 342 samples spanning 12 distinct risk categories, the TeleAI-Safety benchmark conducts extensive evaluations across 14 target models. The results reveal systematic vulnerabilities and model-specific failure cases, highlighting critical trade-offs between safety and utility, and identifying potential defense patterns for future optimization. In practical scenarios, TeleAI-Safety can be flexibly adjusted with customized attack, defense, and evaluation combinations to meet specific demands. We release our complete code and evaluation results to facilitate reproducible research and establish unified safety baselines.", "AI": {"tldr": "TeleAI-Safety\u662f\u4e00\u4e2a\u6a21\u5757\u5316\u3001\u53ef\u590d\u73b0\u7684\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u548c\u6846\u67b6\u5b58\u5728\u6838\u5fc3\u7ec4\u4ef6\uff08\u653b\u51fb\u3001\u9632\u5fa1\u548c\u8bc4\u4f30\u65b9\u6cd5\uff09\u96c6\u6210\u4e0d\u5e73\u8861\u4ee5\u53ca\u7075\u6d3b\u8bc4\u4f30\u6846\u67b6\u4e0e\u6807\u51c6\u5316\u57fa\u51c6\u80fd\u529b\u4e4b\u95f4\u9694\u79bb\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u53ef\u9760\u7684\u8de8\u7814\u7a76\u6bd4\u8f83\u548c\u5168\u9762\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "method": "\u6846\u67b6\u96c6\u6210\u4e8619\u79cd\u653b\u51fb\u65b9\u6cd5\uff08\u5305\u62ec\u4e00\u79cd\u81ea\u7814\u65b9\u6cd5\uff09\u300129\u79cd\u9632\u5fa1\u65b9\u6cd5\u548c19\u79cd\u8bc4\u4f30\u65b9\u6cd5\uff08\u5305\u62ec\u4e00\u79cd\u81ea\u7814\u65b9\u6cd5\uff09\uff0c\u4f7f\u7528\u5305\u542b12\u4e2a\u4e0d\u540c\u98ce\u9669\u7c7b\u522b\u7684342\u4e2a\u6837\u672c\u7684\u653b\u51fb\u8bed\u6599\u5e93\uff0c\u5bf914\u4e2a\u76ee\u6807\u6a21\u578b\u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u63ed\u793a\u4e86\u7cfb\u7edf\u7684\u6f0f\u6d1e\u548c\u6a21\u578b\u7279\u5b9a\u7684\u5931\u8d25\u6848\u4f8b\uff0c\u51f8\u663e\u4e86\u5b89\u5168\u6027\u548c\u6548\u7528\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u5e76\u8bc6\u522b\u4e86\u672a\u6765\u4f18\u5316\u7684\u6f5c\u5728\u9632\u5fa1\u6a21\u5f0f\u3002", "conclusion": "TeleAI-Safety\u53ef\u7075\u6d3b\u8c03\u6574\u4ee5\u9002\u5e94\u7279\u5b9a\u9700\u6c42\uff0c\u901a\u8fc7\u53d1\u5e03\u5b8c\u6574\u4ee3\u7801\u548c\u8bc4\u4f30\u7ed3\u679c\u4fc3\u8fdb\u53ef\u590d\u73b0\u7814\u7a76\u5e76\u5efa\u7acb\u7edf\u4e00\u7684\u5b89\u5168\u57fa\u7ebf\u3002"}}
{"id": "2512.05309", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05309", "abs": "https://arxiv.org/abs/2512.05309", "authors": ["Adam Alami", "Nathan Cassee", "Thiago Rocha Silva", "Elda Paja", "Neil A. Ernst"], "title": "Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions", "comment": "Submitted to TOSEM", "summary": "Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86LLM\u8f85\u52a9\u4ee3\u7801\u8bc4\u5ba1\u4e0e\u4eba\u5de5\u540c\u884c\u8bc4\u5ba1\u7684\u4e0d\u540c\uff0c\u53d1\u73b0LLM\u8bc4\u5ba1\u964d\u4f4e\u4e86\u60c5\u611f\u6210\u672c\u548c\u81ea\u6211\u8c03\u8282\u9700\u6c42\uff0c\u5c06\u53c2\u4e0e\u91cd\u70b9\u4ece\u60c5\u611f\u7ba1\u7406\u8f6c\u5411\u8ba4\u77e5\u8d1f\u8377\u7ba1\u7406\uff0c\u63d0\u51faAI\u5e94\u4f5c\u4e3a\u652f\u6301\u6027\u4f19\u4f34\u6765\u51cf\u8f7b\u8d1f\u62c5\u540c\u65f6\u4fdd\u7559\u4eba\u7c7b\u8d23\u4efb\u3002", "motivation": "\u7406\u89e3\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728LLM\u8f85\u52a9\u4ee3\u7801\u8bc4\u5ba1\u4e0e\u4eba\u5de5\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u53c2\u4e0e\u5dee\u5f02\uff0c\u7279\u522b\u662f\u60c5\u611f\u81ea\u6211\u8c03\u8282\u548c\u884c\u4e3a\u53c2\u4e0e\u7684\u5173\u7cfb\u3002", "method": "\u5bf920\u540d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8fdb\u884c\u4e24\u9636\u6bb5\u5b9a\u6027\u7814\u7a76\uff1a\u7b2c\u4e00\u9636\u6bb5\u8fdb\u884c\u540c\u884c\u8bc4\u5ba1\u5e76\u8bbf\u8c08\u60c5\u611f\u53cd\u5e94\u548c\u53c2\u4e0e\u51b3\u7b56\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u7b26\u5408\u5de5\u7a0b\u5e08\u504f\u597d\u7684\u63d0\u793a\uff0c\u63a2\u7a76\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u53cd\u5e94\u3002", "result": "\u8bc6\u522b\u4e86\u5de5\u7a0b\u5e08\u5e94\u5bf9\u8d1f\u9762\u53cd\u9988\u7684\u81ea\u6211\u8c03\u8282\u7b56\u7565\uff08\u91cd\u6784\u3001\u5bf9\u8bdd\u8c03\u8282\u3001\u56de\u907f\u3001\u9632\u5fa1\u6027\uff09\uff0c\u53d1\u73b0LLM\u8f85\u52a9\u8bc4\u5ba1\u964d\u4f4e\u4e86\u60c5\u611f\u6210\u672c\uff0c\u5f53\u53cd\u9988\u7b26\u5408\u8ba4\u77e5\u671f\u671b\u65f6\u51cf\u5c11\u5904\u7406\u52aa\u529b\u5e76\u63d0\u9ad8\u91c7\u7eb3\u503e\u5411\u3002", "conclusion": "AI\u6700\u9002\u5408\u4f5c\u4e3a\u652f\u6301\u6027\u4f19\u4f34\uff0c\u51cf\u5c11\u8ba4\u77e5\u548c\u60c5\u611f\u8d1f\u8377\uff0c\u540c\u65f6\u4fdd\u7559\u4eba\u7c7b\u8d23\u4efb\u548c\u540c\u884c\u8bc4\u5ba1\u7b49\u793e\u4f1a\u6280\u672f\u6d3b\u52a8\u7684\u793e\u4f1a\u610f\u4e49\u3002"}}
{"id": "2512.05257", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05257", "abs": "https://arxiv.org/abs/2512.05257", "authors": ["Bychkov Oleksii", "Bychkova Sophia", "Lytvynchuk Khrystyna"], "title": "Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence", "comment": "9 pages", "summary": "This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.", "AI": {"tldr": "\u672c\u6587\u8bba\u8bc1\u53ef\u80fd\u6027\u7406\u8bba\u4e3aDempster-Shafer\u7406\u8bba\u6096\u8bba\u63d0\u4f9b\u4e86\u6839\u672c\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u57fa\u4e8e\u53ef\u80fd\u6027\u548c\u5fc5\u8981\u6027\u6d4b\u5ea6\u7684\u516c\u7406\u5316\u65b9\u6cd5\u6784\u5efa\u4e86\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u7684\u4e25\u8c28\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3DST\u6096\u8bba\u5371\u673a\uff0c\u8bc1\u660e\u53ef\u80fd\u6027\u7406\u8bba\u4e0d\u4ec5\u662f\u4e00\u79cd\u66ff\u4ee3\u65b9\u6848\uff0c\u800c\u662f\u80fd\u591f\u4ece\u6839\u672c\u4e0a\u89e3\u51b3DST\u7684\u903b\u8f91\u9677\u9631\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6bd4\u8f83\u5206\u6790\u65b9\u6cd5\uff0c\u5bf9\u6bd4\u6982\u7387\u8bba\u3001\u8bc1\u636e\u7406\u8bba\u548c\u53ef\u80fd\u6027\u7406\u8bba\u4e09\u79cd\u8303\u5f0f\uff0c\u5e76\u4ee5\u7ecf\u5178\u533b\u7597\u8bca\u65ad\u56f0\u5883\u4e3a\u4f8b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u8868\u660e\u53ef\u80fd\u6027\u7406\u8bba\u80fd\u591f\u6b63\u786e\u5904\u7406\u77db\u76fe\u6570\u636e\uff0c\u907f\u514dDST\u7684\u903b\u8f91\u9677\u9631\uff0c\u4f7f\u5f62\u5f0f\u63a8\u7406\u66f4\u63a5\u8fd1\u81ea\u7136\u667a\u80fd\u903b\u8f91\u3002", "conclusion": "\u53ef\u80fd\u6027\u7406\u8bba\u4e3a\u89e3\u51b3DST\u6096\u8bba\u63d0\u4f9b\u4e86\u6839\u672c\u6027\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5efa\u7acb\u4e86\u903b\u8f91\u4e00\u81f4\u4e14\u6570\u5b66\u4e25\u8c28\u7684\u4e0d\u786e\u5b9a\u6027\u5904\u7406\u57fa\u7840\u3002"}}
{"id": "2512.05518", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05518", "abs": "https://arxiv.org/abs/2512.05518", "authors": ["Jason Vega", "Gagandeep Singh"], "title": "Matching Ranks Over Probability Yields Truly Deep Safety Alignment", "comment": null, "summary": "A frustratingly easy technique known as the prefilling attack has been shown to effectively circumvent the safety alignment of frontier LLMs by simply prefilling the assistant response with an affirmative prefix before decoding. In response, recent work proposed a supervised fine-tuning (SFT) defense using data augmentation to achieve a \\enquote{deep} safety alignment, allowing the model to generate natural language refusals immediately following harmful prefills. Unfortunately, we show in this work that the \"deep\" safety alignment produced by such an approach is in fact not very deep. A generalization of the prefilling attack, which we refer to as the Rank-Assisted Prefilling (RAP) attack, can effectively extract harmful content from models fine-tuned with the data augmentation defense by selecting low-probability \"harmful\" tokens from the top 20 predicted next tokens at each step (thus ignoring high-probability \"refusal\" tokens). We argue that this vulnerability is enabled due to the \"gaming\" of the SFT objective when the target distribution entropies are low, where low fine-tuning loss is achieved by shifting large probability mass to a small number of refusal tokens while neglecting the high ranks of harmful tokens. We then propose a new perspective on achieving deep safety alignment by matching the token ranks of the target distribution, rather than their probabilities. This perspective yields a surprisingly simple fix to the data augmentation defense based on regularizing the attention placed on harmful prefill tokens, an approach we call PRefill attEntion STOpping (PRESTO). Adding PRESTO yields up to a 4.7x improvement in the mean StrongREJECT score under RAP attacks across three popular open-source LLMs, with low impact to model utility.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRAP\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u80fd\u591f\u7ed5\u8fc7\u73b0\u6709\u7684\u6df1\u5ea6\u5b89\u5168\u5bf9\u9f50\u9632\u5fa1\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9632\u5fa1\u65b9\u6cd5PRESTO\u6765\u89e3\u51b3\u8be5\u6f0f\u6d1e\u3002", "motivation": "\u73b0\u6709\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u5b9e\u73b0\u7684\u6df1\u5ea6\u5b89\u5168\u5bf9\u9f50\u9632\u5fa1\u5b9e\u9645\u4e0a\u5e76\u4e0d\u591f\u6df1\u5ea6\uff0c\u5bb9\u6613\u53d7\u5230\u63a8\u5e7f\u7684\u9884\u586b\u5145\u653b\u51fb\u7684\u7ed5\u8fc7\u3002", "method": "\u63d0\u51fa\u4e86Rank-Assisted Prefilling (RAP)\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u524d20\u4e2a\u9884\u6d4b\u4ee4\u724c\u4e2d\u7684\u4f4e\u6982\u7387\u6709\u5bb3\u4ee4\u724c\u6765\u7ed5\u8fc7\u9632\u5fa1\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u57fa\u4e8e\u4ee4\u724c\u6392\u540d\u5339\u914d\u7684PRESTO\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "PRESTO\u9632\u5fa1\u5728RAP\u653b\u51fb\u4e0b\u5c06\u5e73\u5747StrongREJECT\u5f97\u5206\u63d0\u9ad8\u4e864.7\u500d\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u5b9e\u7528\u6027\u5f71\u54cd\u8f83\u5c0f\u3002", "conclusion": "\u57fa\u4e8e\u4ee4\u724c\u6392\u540d\u5339\u914d\u7684\u5b89\u5168\u5bf9\u9f50\u6bd4\u57fa\u4e8e\u6982\u7387\u5206\u5e03\u7684\u66f4\u6709\u6548\uff0cPRESTO\u65b9\u6cd5\u4e3a\u89e3\u51b3\u9884\u586b\u5145\u653b\u51fb\u63d0\u4f9b\u4e86\u7b80\u5355\u800c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.05356", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05356", "abs": "https://arxiv.org/abs/2512.05356", "authors": ["Jason Weston", "Jakob Foerster"], "title": "AI & Human Co-Improvement for Safer Co-Superintelligence", "comment": null, "summary": "Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5e94\u4ee5'\u5171\u540c\u8fdb\u6b65'\uff08\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u5b9e\u73b0\u5171\u540c\u8d85\u667a\u80fd\uff09\u4f5c\u4e3aAI\u53d1\u5c55\u7684\u4f18\u5148\u76ee\u6807\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42AI\u7684\u81ea\u6211\u6539\u8fdb\u3002", "motivation": "\u5f53\u524dAI\u9886\u57df\u8fc7\u5ea6\u5173\u6ce8\u81ea\u6211\u6539\u8fdb\u76ee\u6807\u5b58\u5728\u5371\u9669\u4e14\u96be\u4ee5\u5b9e\u73b0\uff0c\u9700\u8981\u66f4\u5b89\u5168\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u5f3a\u8c03\u4eba\u7c7b\u7814\u7a76\u5458\u4e0eAI\u7cfb\u7edf\u7684\u534f\u4f5c\u7814\u7a76\u5faa\u73af\uff0c\u4ece\u6784\u601d\u5230\u5b9e\u9a8c\u5171\u540c\u63a8\u8fdbAI\u7814\u7a76\u3002", "result": "\u63d0\u51fa\u5171\u540c\u8fdb\u6b65\u6846\u67b6\u80fd\u52a0\u901fAI\u7814\u7a76\u53d1\u5c55\uff0c\u5e76\u901a\u8fc7\u4eba\u673a\u5171\u751f\u5b9e\u73b0\u66f4\u5b89\u5168\u7684\u8d85\u667a\u80fd\u3002", "conclusion": "\u4ee5\u4eba\u7c7b\u7814\u7a76\u6539\u8fdb\u4e3a\u6838\u5fc3\u7684\u5408\u4f5c\u6a21\u5f0f\u662f\u5b9e\u73b0\u8d85\u667a\u80fd\u66f4\u5feb\u901f\u3001\u66f4\u5b89\u5168\u7684\u8def\u5f84\u3002"}}
{"id": "2512.05350", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.05350", "abs": "https://arxiv.org/abs/2512.05350", "authors": ["Munazza Zaib", "Wei Wang", "Dulaji Hidellaarachchi", "Isma Farah Siddiqui"], "title": "Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering", "comment": null, "summary": "Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u7814\u7a76\u5e76\u63d0\u51fa\u6df7\u5408\u65b9\u6cd5\u8bba\u6846\u67b6\u3002", "motivation": "\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u5c1a\u672a\u7cfb\u7edf\u5173\u6ce8\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u7fa4\u4f53\uff0c\u5979\u4eec\u9762\u4e34\u7740\u6027\u522b\u504f\u89c1\u548c\u795e\u7ecf\u5dee\u5f02\u4ea4\u53c9\u7684\u72ec\u7279\u969c\u788d\uff0c\u5bfc\u81f4\u804c\u4e1a\u538b\u529b\u548c\u9ad8\u6d41\u5931\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u5408InclusiveMag\u5305\u5bb9\u6027\u6846\u67b6\u548cGenderWalkthrough\u6d41\u7a0b\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u5206\u4e3a\u6587\u732e\u56de\u987e\u3001\u4eba\u7269\u89d2\u8272\u4e0e\u5206\u6790\u65b9\u6cd5\u5f00\u53d1\u3001\u534f\u4f5c\u5de5\u4f5c\u574a\u5e94\u7528\u4e09\u9636\u6bb5\u3002", "result": "\u6587\u732e\u7efc\u8ff0\u5f52\u7eb3\u51fa\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u9762\u4e34\u7684\u8ba4\u77e5\u3001\u793e\u4ea4\u3001\u7ec4\u7ec7\u3001\u7ed3\u6784\u548c\u804c\u4e1a\u53d1\u5c55\u4e94\u7c7b\u6311\u6218\uff0c\u63ed\u793a\u4e86\u8bef\u8bca/\u5ef6\u8fdf\u8bca\u65ad\u548c\u4f2a\u88c5\u884c\u4e3a\u52a0\u5267\u6392\u65a5\u7684\u95ee\u9898\u3002", "conclusion": "\u7814\u7a76\u4e3a\u540e\u7eed\u5f00\u53d1\u548c\u5e94\u7528\u5305\u5bb9\u6027\u5206\u6790\u65b9\u6cd5\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u65e8\u5728\u652f\u6301\u9488\u5bf9\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u7684 actionable changes\u3002"}}
{"id": "2512.05745", "categories": ["cs.CR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.05745", "abs": "https://arxiv.org/abs/2512.05745", "authors": ["Weikai Lu", "Ziqian Zeng", "Kehua Zhang", "Haoran Li", "Huiping Zhuang", "Ruidong Wang", "Cen Chen", "Hao Peng"], "title": "ARGUS: Defending Against Multimodal Indirect Prompt Injection via Steering Instruction-Following Behavior", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are increasingly vulnerable to multimodal Indirect Prompt Injection (IPI) attacks, which embed malicious instructions in images, videos, or audio to hijack model behavior. Existing defenses, designed primarily for text-only LLMs, are unsuitable for countering these multimodal threats, as they are easily bypassed, modality-dependent, or generalize poorly. Inspired by activation steering researches, we hypothesize that a robust, general defense independent of modality can be achieved by steering the model's behavior in the representation space. Through extensive experiments, we discover that the instruction-following behavior of MLLMs is encoded in a subspace. Steering along directions within this subspace can enforce adherence to user instructions, forming the basis of a defense. However, we also found that a naive defense direction could be coupled with a utility-degrading direction, and excessive intervention strength harms model performance. To address this, we propose ARGUS, which searches for an optimal defense direction within the safety subspace that decouples from the utility degradation direction, further combining adaptive strength steering to achieve a better safety-utility trade-off. ARGUS also introduces lightweight injection detection stage to activate the defense on-demand, and a post-filtering stage to verify defense success. Experimental results show that ARGUS can achieve robust defense against multimodal IPI while maximally preserving the MLLM's utility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faARGUS\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u6fc0\u6d3b\u5f15\u5bfc\u6765\u62b5\u5fa1\u591a\u6a21\u6001\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u5b89\u5168\u4e0e\u6548\u7528\u7684\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u9632\u5fa1\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u7eaf\u6587\u672cLLM\u8bbe\u8ba1\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u591a\u6a21\u6001IPI\u653b\u51fb\uff0c\u5b58\u5728\u6613\u88ab\u7ed5\u8fc7\u3001\u6a21\u6001\u4f9d\u8d56\u6216\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\u3002", "method": "\u53d1\u73b0MLLMs\u7684\u6307\u4ee4\u8ddf\u968f\u884c\u4e3a\u7f16\u7801\u5728\u4e00\u4e2a\u5b50\u7a7a\u95f4\u4e2d\uff0c\u63d0\u51faARGUS\u65b9\u6cd5\uff1a\u5728\u5b89\u5168\u5b50\u7a7a\u95f4\u4e2d\u5bfb\u627e\u4e0e\u6548\u7528\u9000\u5316\u65b9\u5411\u89e3\u8026\u7684\u6700\u4f18\u9632\u5fa1\u65b9\u5411\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u5f3a\u5ea6\u5f15\u5bfc\u3001\u8f7b\u91cf\u7ea7\u6ce8\u5165\u68c0\u6d4b\u548c\u540e\u671f\u8fc7\u6ee4\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eARGUS\u80fd\u591f\u5b9e\u73b0\u5bf9\u591a\u6a21\u6001IPI\u7684\u9c81\u68d2\u9632\u5fa1\uff0c\u540c\u65f6\u6700\u5927\u7a0b\u5ea6\u4fdd\u7559MLLM\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u901a\u8fc7\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u5b9a\u5411\u5f15\u5bfc\u53ef\u4ee5\u6784\u5efa\u72ec\u7acb\u4e8e\u6a21\u6001\u7684\u901a\u7528\u9632\u5fa1\u673a\u5236\uff0cARGUS\u6846\u67b6\u5728\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2512.05371", "categories": ["cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.05371", "abs": "https://arxiv.org/abs/2512.05371", "authors": ["Changwen Xing", "SamZaak Wong", "Xinlai Wan", "Yanfeng Lu", "Mengli Zhang", "Zebin Ma", "Lei Qi", "Zhengxiong Li", "Nan Guan", "Zhe Jiang", "Xi Wang", "Jun Yang"], "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications", "comment": "Accepted by the AAAl26 Conference Main Track", "summary": "While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).", "AI": {"tldr": "ChipMind\u662f\u4e00\u4e2a\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u63a8\u7406\u7684\u6846\u67b6\uff0c\u4e13\u95e8\u5904\u7406\u5197\u957f\u7684\u96c6\u6210\u7535\u8def\u89c4\u8303\u6587\u6863\uff0c\u89e3\u51b3\u4e86\u5f53\u524dLLMs\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u4e0b\u7684IC\u8bbe\u8ba1\u81ea\u52a8\u5316\u96be\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u82af\u7247\u5f00\u53d1\u81ea\u52a8\u5316\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5b9e\u9645\u5e94\u7528\u53d7\u5230\u4e0a\u4e0b\u6587\u7a97\u53e3\u957f\u5ea6\u7684\u9650\u5236\u3002\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u6269\u5c55\u65b9\u6cd5\u96be\u4ee5\u5bf9\u590d\u6742\u5197\u957f\u7684\u7535\u8def\u89c4\u8303\u8fdb\u884c\u6709\u6548\u7684\u8bed\u4e49\u5efa\u6a21\u548c\u591a\u8df3\u63a8\u7406\u3002", "method": "ChipMind\u9996\u5148\u901a\u8fc7\u7535\u8def\u8bed\u4e49\u611f\u77e5\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u5c06\u7535\u8def\u89c4\u8303\u8f6c\u5316\u4e3a\u9886\u57df\u77e5\u8bc6\u56fe\u8c31ChipKG\uff0c\u7136\u540e\u91c7\u7528ChipKG\u589e\u5f3a\u63a8\u7406\u673a\u5236\uff0c\u7ed3\u5408\u4fe1\u606f\u8bba\u81ea\u9002\u5e94\u68c0\u7d22\u52a8\u6001\u8ffd\u8e2a\u903b\u8f91\u4f9d\u8d56\uff0c\u4ee5\u53ca\u610f\u56fe\u611f\u77e5\u8bed\u4e49\u8fc7\u6ee4\u53bb\u9664\u65e0\u5173\u566a\u58f0\u3002", "result": "\u5728\u5de5\u4e1a\u7ea7\u89c4\u8303\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cChipMind\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u63d0\u534734.59%\uff0c\u6700\u9ad8\u63d0\u5347\u8fbe72.73%\u3002", "conclusion": "\u8be5\u6846\u67b6\u586b\u8865\u4e86LLM\u8f85\u52a9\u786c\u4ef6\u8bbe\u8ba1\u4ece\u5b66\u672f\u7814\u7a76\u5230\u5de5\u4e1a\u90e8\u7f72\u4e4b\u95f4\u7684\u5173\u952e\u7a7a\u767d\u3002"}}
{"id": "2512.05375", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05375", "abs": "https://arxiv.org/abs/2512.05375", "authors": ["Sunil Khemka", "Arunava Majumdar"], "title": "Legacy Modernization with AI -- Mainframe modernization", "comment": "Accepted for publication at International Conference on Innovations and Trends in Advanced Engineering Technologies (ICIAET 2025) held on 25th and 26th November 2025", "summary": "Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u4f20\u7edf\u5927\u578b\u673a\u7cfb\u7edf\u73b0\u4ee3\u5316\u8f6c\u578b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u4ee3\u7801\u91cd\u6784\u3001\u667a\u80fd\u6570\u636e\u8fc1\u79fb\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49\u6280\u672f\uff0c\u5e2e\u52a9\u4f01\u4e1a\u8fc7\u6e21\u5230\u5fae\u670d\u52a1\u3001\u5bb9\u5668\u5316\u548c\u6df7\u5408\u4e91\u5e73\u53f0\u3002", "motivation": "\u4f20\u7edf\u5927\u578b\u673a\u7cfb\u7edf\u867d\u7136\u53ef\u9760\uff0c\u4f46\u9762\u4e34\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u6280\u672f\u4eba\u624d\u77ed\u7f3a\u4ee5\u53ca\u4e0e\u4e91\u7cfb\u7edf\u6574\u5408\u56f0\u96be\u7b49\u6311\u6218\uff0c\u9700\u8981\u5bfb\u627e\u6709\u6548\u7684\u73b0\u4ee3\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528AI\u9a71\u52a8\u7684\u73b0\u4ee3\u5316\u7b56\u7565\uff0c\u5305\u62ec\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5206\u6790\u9057\u7559\u4ee3\u7801\u5e93\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u548c\u90e8\u7f72\u3001\u667a\u80fd\u5de5\u5177\u8fdb\u884c\u6570\u636e\u8fc1\u79fb\u7b49\u65b9\u6cd5\u3002", "result": "AI\u8f85\u52a9\u7684\u73b0\u4ee3\u5316\u6539\u9020\u4e0d\u4ec5\u80fd\u4fdd\u7559\u6838\u5fc3\u4e1a\u52a1\u903b\u8f91\uff0c\u8fd8\u80fd\u5b9e\u73b0\u66f4\u5feb\u7684\u521b\u65b0\u3001\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u5e76\u589e\u5f3a\u7cfb\u7edf\u5f39\u6027\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u5728\u5927\u578b\u673a\u73b0\u4ee3\u5316\u4e2d\u7684\u5e94\u7528\u662f\u63a8\u52a8\u6570\u5b57\u5316\u8f6c\u578b\u548c\u4f01\u4e1a\u53ef\u6301\u7eed\u589e\u957f\u7684\u91cd\u8981\u50ac\u5316\u5242\u3002"}}
{"id": "2512.05439", "categories": ["cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.05439", "abs": "https://arxiv.org/abs/2512.05439", "authors": ["Tarun Suresh", "Nalin Wadhwa", "Debangshu Banerjee", "Gagandeep Singh"], "title": "BEAVER: An Efficient Deterministic LLM Verifier", "comment": null, "summary": "As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.", "AI": {"tldr": "BEAVER\u662f\u9996\u4e2a\u5b9e\u7528\u7684LLM\u7ea6\u675f\u6ee1\u8db3\u786e\u5b9a\u6027\u6982\u7387\u8fb9\u754c\u8ba1\u7b97\u6846\u67b6\uff0c\u80fd\u591f\u63d0\u4f9b\u53ef\u9760\u4fdd\u8bc1\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u662f\u5426\u7b26\u5408\u7ea6\u675f", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u7814\u7a76\u539f\u578b\u8f6c\u5411\u751f\u4ea7\u7cfb\u7edf\u65f6\uff0c\u9700\u8981\u53ef\u9760\u65b9\u6cd5\u6765\u9a8c\u8bc1\u6a21\u578b\u8f93\u51fa\u662f\u5426\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\uff0c\u800c\u57fa\u4e8e\u91c7\u6837\u7684\u4f30\u8ba1\u65e0\u6cd5\u63d0\u4f9b\u53ef\u9760\u4fdd\u8bc1", "method": "\u4f7f\u7528\u65b0\u9896\u7684token trie\u548cfrontier\u6570\u636e\u7ed3\u6784\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u751f\u6210\u7a7a\u95f4\uff0c\u5728\u4efb\u4f55\u8fed\u4ee3\u4e2d\u90fd\u4fdd\u6301\u53ef\u8bc1\u660e\u7684\u53ef\u9760\u8fb9\u754c", "result": "BEAVER\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u5b9e\u73b0\u4e866-8\u500d\u66f4\u7d27\u7684\u6982\u7387\u8fb9\u754c\uff0c\u8bc6\u522b\u51fa3-4\u500d\u66f4\u591a\u9ad8\u98ce\u9669\u5b9e\u4f8b", "conclusion": "BEAVER\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u677e\u6563\u8fb9\u754c\u6216\u7ecf\u9a8c\u8bc4\u4f30\u65e0\u6cd5\u5b9e\u73b0\u7684\u7cbe\u786e\u7279\u5f81\u63cf\u8ff0\u548c\u98ce\u9669\u8bc4\u4f30\u80fd\u529b"}}
{"id": "2512.05383", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05383", "abs": "https://arxiv.org/abs/2512.05383", "authors": ["Mara Downing", "Matthew Peng", "Jacob Granley", "Michael Beyeler", "Tevfik Bultan"], "title": "Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation", "comment": "20 pages, 4 figures, 2 tables", "summary": "Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u7684\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u795e\u7ecf\u523a\u6fc0\u7cfb\u7edf\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u7cfb\u7edf\u6027\u5730\u68c0\u6d4b\u8fdd\u53cd\u751f\u7269\u7269\u7406\u5b89\u5168\u9650\u5236\u7684\u523a\u6fc0\u6a21\u5f0f\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u795e\u7ecf\u5047\u4f53\u8bbe\u5907\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u9700\u8981\u89e3\u51b3\u6a21\u578b\u8f93\u51fa\u76f4\u63a5\u4f5c\u7528\u4e8e\u795e\u7ecf\u7ec4\u7ec7\u65f6\u5f15\u5165\u7684\u65b0\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5c06\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\u9002\u914d\u5230\u795e\u7ecf\u523a\u6fc0\u9886\u57df\uff0c\u901a\u8fc7\u6270\u52a8\u6a21\u578b\u8f93\u5165\u6765\u8ffd\u8e2a\u4ea7\u751f\u7684\u523a\u6fc0\u662f\u5426\u8fdd\u53cd\u7535\u8377\u5bc6\u5ea6\u3001\u77ac\u65f6\u7535\u6d41\u6216\u7535\u6781\u5171\u6fc0\u6d3b\u7b49\u751f\u7269\u7269\u7406\u9650\u5236\u3002", "result": "\u5e94\u7528\u4e8e\u89c6\u7f51\u819c\u548c\u76ae\u5c42\u6df1\u5ea6\u523a\u6fc0\u7f16\u7801\u5668\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u7cfb\u7edf\u6027\u5730\u53d1\u73b0\u8d85\u51fa\u5b89\u5168\u9650\u5236\u7684\u591a\u6837\u5316\u523a\u6fc0\u6a21\u5f0f\u3002", "conclusion": "\u4ee5\u8fdd\u89c4\u4e3a\u91cd\u70b9\u7684\u6a21\u7cca\u6d4b\u8bd5\u5c06\u5b89\u5168\u8bc4\u4f30\u91cd\u6784\u4e3a\u53ef\u91cd\u590d\u7684\u5b9e\u8bc1\u8fc7\u7a0b\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u795e\u7ecf\u63a5\u53e3\u7684\u8bc1\u636e\u57fa\u51c6\u6d4b\u8bd5\u3001\u76d1\u7ba1\u51c6\u5907\u548c\u4f26\u7406\u4fdd\u8bc1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.05449", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05449", "abs": "https://arxiv.org/abs/2512.05449", "authors": ["Robert Yang"], "title": "The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems", "comment": "4 pages + appendix. AAAI 2026 FAST Workshop (Oral)", "summary": "Large language models display a peculiar form of inconsistency: they \"know\" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of \"self-control\" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as \"scheming\" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86'akrasia'\uff08\u610f\u5fd7\u8584\u5f31\uff09\u4f5c\u4e3a\u5206\u6790AI\u7cfb\u7edf\u4e0d\u4e00\u81f4\u6027\u7684\u6846\u67b6\uff0c\u5e76\u5f00\u53d1\u4e86Akrasia Benchmark\u6765\u8861\u91cf\u6a21\u578b\u81ea\u6211\u63a7\u5236\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u77e5\u9053\u6b63\u786e\u7b54\u6848\u4f46\u65e0\u6cd5\u575a\u6301\u7684\u77db\u76fe\u884c\u4e3a\uff0c\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u54f2\u5b66\u4e2d\u7684\u610f\u5fd7\u8584\u5f31\u73b0\u8c61\u3002", "method": "\u5f15\u5165\u4e86Akrasia Benchmark\uff0c\u5305\u542b\u57fa\u7ebf\u3001\u540c\u4e49\u8bcd\u3001\u65f6\u95f4\u5ef6\u8fdf\u548c\u8bf1\u60d1\u56db\u79cd\u6d4b\u8bd5\u6761\u4ef6\u6765\u91cf\u5316\u6a21\u578b\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u8be5\u57fa\u51c6\u80fd\u4e3a\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u3001\u89e3\u7801\u7b56\u7565\u548c\u8bf1\u60d1\u7c7b\u578b\u63d0\u4f9b\u5b9a\u91cf\u6bd4\u8f83\uff0c\u63ed\u793a\u5fae\u89c2\u4e0d\u4e00\u81f4\u53ef\u80fd\u5bfc\u81f4\u7684\u5b8f\u89c2\u4e0d\u7a33\u5b9a\u3002", "conclusion": "\u901a\u8fc7\u5c06AI\u4e0d\u4e00\u81f4\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u610f\u5fd7\u8584\u5f31\uff0c\u8fd9\u9879\u5de5\u4f5c\u5728\u54f2\u5b66\u3001\u5fc3\u7406\u5b66\u548c\u667a\u80fd\u4f53AI\u79d1\u5b66\u4e4b\u95f4\u5efa\u7acb\u4e86\u5b9e\u8bc1\u6865\u6881\u3002"}}
{"id": "2512.05428", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05428", "abs": "https://arxiv.org/abs/2512.05428", "authors": ["Keeryn Johnson", "Cleyton Magalhaes", "Ronnie de Souza Santos"], "title": "Bita: A Conversational Assistant for Fairness Testing", "comment": null, "summary": "Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86Bita\u2014\u2014\u4e00\u4e2a\u57fa\u4e8e\u5bf9\u8bdd\u5f0fAI\u7684\u5b9e\u9a8c\u8f85\u52a9\u5de5\u5177\uff0c\u65e8\u5728\u5e2e\u52a9\u8f6f\u4ef6\u6d4b\u8bd5\u4eba\u5458\u68c0\u6d4bAI\u7cfb\u7edf\u4e2d\u7684\u504f\u5dee\uff0c\u6267\u884c\u516c\u5e73\u6027\u6d4b\u8bd5\uff0c\u5e76\u751f\u6210\u9762\u5411\u516c\u5e73\u6027\u7684\u63a2\u7d22\u6027\u6d4b\u8bd5\u5927\u7eb2\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u6d4b\u8bd5\u5de5\u5177\u4f7f\u7528\u95e8\u69db\u9ad8\uff0c\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u5bf9\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u652f\u6301\u6709\u9650\uff0c\u5bfc\u81f4AI\u7cfb\u7edf\u4e2d\u7684\u504f\u5dee\u53ef\u80fd\u672a\u88ab\u5145\u5206\u68c0\u6d4b\uff0c\u8fdb\u800c\u5f15\u53d1\u4e0d\u516c\u5e73\u548c\u6b67\u89c6\u6027\u7ed3\u679c\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u5c06\u54cd\u5e94\u5efa\u7acb\u5728\u7ecf\u8fc7\u7b5b\u9009\u7684\u516c\u5e73\u6027\u6587\u732e\u57fa\u7840\u4e0a\uff0c\u5f00\u53d1\u51fa\u540d\u4e3aBita\u7684\u5bf9\u8bdd\u52a9\u624b\u3002", "result": "\u5728\u5b9e\u9645AI\u7cfb\u7edf\u4e0a\u7684\u9a8c\u8bc1\u8868\u660e\uff0cBita\u80fd\u6709\u6548\u652f\u6301\u516c\u5e73\u6027\u6d4b\u8bd5\u4efb\u52a1\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u548c\u53ef\u590d\u73b0\u7684\u5b9e\u7528\u6027\u8bc1\u636e\u3002", "conclusion": "Bita\u4f5c\u4e3a\u4e00\u6b3e\u5b9e\u7528\u5de5\u5177\uff0c\u4f7f\u516c\u5e73\u6027\u6d4b\u8bd5\u53d8\u5f97\u6613\u4e8e\u64cd\u4f5c\u3001\u7cfb\u7edf\u5316\uff0c\u5e76\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u5de5\u4e1a\u5b9e\u8df5\u3002"}}
{"id": "2512.05530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05530", "abs": "https://arxiv.org/abs/2512.05530", "authors": ["Chuang Yu", "Jinmiao Zhao", "Mingxuan Zhao", "Yunpeng Liu", "Xiujun Shu", "Yuanhao Feng", "Bo Wang", "Xiangyu Yue"], "title": "MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models", "comment": null, "summary": "Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of \"Understand -> Rethink -> Correct\", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMIND\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7RAD\u8303\u5f0f\u3001P2CL\u7b56\u7565\u548cMCA\u4f18\u5316\u7b56\u7565\uff0c\u4f7f\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907'\u7406\u89e3-\u53cd\u601d-\u4fee\u6b63'\u7684\u7c7b\u4eba\u8ba4\u77e5\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u63a8\u7406\u8bed\u4e49\u5efa\u6a21\u3001\u903b\u8f91\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u6613\u53d7\u590d\u6742\u573a\u666f\u8bef\u5bfc\uff0c\u9700\u8981\u4ece\u88ab\u52a8\u6a21\u4eff\u63a8\u7406\u8f6c\u5411\u4e3b\u52a8\u5224\u522b\u63a8\u7406\u3002", "method": "\u91c7\u7528RAD\u8303\u5f0f\u81ea\u52a8\u751f\u6210\u591a\u6837\u63a8\u7406\u8def\u5f84\u6269\u5145\u6570\u636e\u96c6\uff1b\u8bbe\u8ba1P2CL\u4e24\u9636\u6bb5\u4fee\u6b63\u5b66\u4e60\u7b56\u7565\uff08\u591a\u63a8\u7406\u6b63\u5411\u5b66\u4e60+\u4e3b\u52a8\u903b\u8f91\u5224\u522b\u4fee\u6b63\uff09\uff1b\u63d0\u51faMCA\u4f18\u5316\u7b56\u7565\u89e3\u51b3\u591a\u63a8\u7406\u8bed\u4e49\u7a7a\u95f4\u8868\u793a\u7ea0\u7f20\u95ee\u9898\u3002", "result": "\u5728\u6db5\u76d6\u79d1\u5b66\u3001\u5e38\u8bc6\u548c\u6570\u5b66\u573a\u666f\u7684\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "MIND\u6846\u67b6\u4e3a\u63a8\u8fdb\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5411\u66f4\u9ad8\u8ba4\u77e5\u667a\u80fd\u6c34\u5e73\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2512.05576", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05576", "abs": "https://arxiv.org/abs/2512.05576", "authors": ["Ting-Ting Xie", "Yixin Zhang"], "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning", "comment": "2nd Place Solution to the CURE-Bench Competition @ NeurIPS 2025. Code available at https://github.com/June01/CureAgent", "summary": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2512.05594", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05594", "abs": "https://arxiv.org/abs/2512.05594", "authors": ["Roos M. Bakker", "Daan L. Di Scala", "Maaike H. T. de Boer", "Stephan A. Raaijmakers"], "title": "Ontology Learning with LLMs: A Benchmark Study on Axiom Identification", "comment": "Submitted to Semantic Web Journal, under review", "summary": "Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4f7f\u7528LLMs\u81ea\u52a8\u5316\u8bc6\u522b\u672c\u4f53\u8bba\u516c\u7406\u7684\u65b9\u6cd5\uff0c\u521b\u5efa\u4e86OntoAxiom\u57fa\u51c6\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u548c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u672c\u4f53\u8bba\u5f00\u53d1\u590d\u6742\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u968f\u7740NLP\u6280\u672f\u7279\u522b\u662fLLMs\u7684\u53d1\u5c55\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u81ea\u52a8\u5316\u8bc6\u522b\u672c\u4f53\u8bba\u516c\u7406\u3002", "method": "\u6784\u5efa\u5305\u542b9\u4e2a\u4e2d\u7b49\u89c4\u6a21\u672c\u4f53\u8bba\u7684OntoAxiom\u57fa\u51c6\uff0817,118\u4e09\u5143\u7ec4\uff0c2,771\u4e2a\u516c\u7406\uff09\uff0c\u6bd4\u8f8312\u4e2aLLMs\u5728\u4e09\u79cdfew-shot\u8bbe\u7f6e\u548c\u4e24\u79cd\u63d0\u793a\u7b56\u7565\uff08Direct vs Axiom-by-Axiom\uff09\u4e0b\u7684\u6027\u80fd\u3002", "result": "AbA\u63d0\u793a\u7b56\u7565\u83b7\u5f97\u66f4\u9ad8F1\u5206\u6570\uff0c\u6027\u80fd\u56e0\u516c\u7406\u7c7b\u578b\u548c\u9886\u57df\u800c\u5f02\uff0c\u5927\u6a21\u578b\u4f18\u4e8e\u5c0f\u6a21\u578b\u4f46\u5c0f\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u4ecd\u53ef\u7528\u3002", "conclusion": "LLMs\u76ee\u524d\u6027\u80fd\u4e0d\u8db3\u4ee5\u5b8c\u5168\u81ea\u52a8\u5316\u516c\u7406\u8bc6\u522b\uff0c\u4f46\u80fd\u4e3a\u672c\u4f53\u5de5\u7a0b\u5e08\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u5019\u9009\u516c\u7406\u652f\u6301\u672c\u4f53\u5f00\u53d1\u548c\u5b8c\u5584\u3002"}}
{"id": "2512.05498", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05498", "abs": "https://arxiv.org/abs/2512.05498", "authors": ["Xiao He", "Ru Chen", "Zeqing Zhang", "Yanling Wang", "Qiuyan Dong"], "title": "A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models", "comment": null, "summary": "Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.", "AI": {"tldr": "iEcoreGen\u7ed3\u5408EMF\u5efa\u6a21\u6846\u67b6\u548cLLM\uff0c\u901a\u8fc7\u5206\u89e3\u9700\u6c42\u751f\u6210\u89c4\u8303\u5e76\u521b\u5efa\u521d\u59cb\u4ee3\u7801\uff0c\u518d\u5229\u7528LLM\u8865\u5145\u672a\u5b9e\u73b0\u65b9\u6cd5\uff0c\u572820\u4e2a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u4f18\u4e8e\u7eafLLM\u57fa\u7ebf\u3002", "motivation": "\u6a21\u677f\u9a71\u52a8\u4ee3\u7801\u751f\u6210\u867d\u80fd\u4fdd\u8bc1\u6b63\u786e\u6027\u4f46\u7075\u6d3b\u6027\u4e0d\u8db3\uff0c\u800cLLM\u7075\u6d3b\u6027\u9ad8\u5374\u53ef\u80fd\u751f\u6210\u9519\u8bef\u4ee3\u7801\uff0c\u56e0\u6b64\u9700\u8981\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u3002", "method": "\u4f7f\u7528EMF\u7684Ecore\u6a21\u578b\u5b9a\u4e49\u7cfb\u7edf\u7ed3\u6784\uff0c\u5206\u89e3\u9700\u6c42\u751f\u6210\u64cd\u4f5c\u89c4\u8303\uff0c\u5148\u7528\u6a21\u677f\u751f\u6210\u521d\u59cbJava\u4ee3\u7801\uff0c\u518d\u5c06\u89c4\u8303\u5e8f\u5217\u5316\u4e3a\u6587\u6863\u5b57\u7b26\u4e32\uff0c\u6700\u540e\u8c03\u7528LLM\u5b8c\u6210\u672a\u5b9e\u73b0\u65b9\u6cd5\u3002", "result": "\u57285\u79cdLLM\u4e0a\u768420\u4e2a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u8bc4\u4f30\u663e\u793a\uff0ciEcoreGen\u5728pass@k\u6307\u6807\u4e0a\u4f18\u4e8e\u7eafLLM\u57fa\u7ebf\uff0c\u5728compilation@k\u6307\u6807\u4e0a\u8868\u73b0\u76f8\u5f53\u3002\u6d88\u878d\u7814\u7a76\u660e\u786e\u4e86\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u662f\u63d0\u9ad8\u8f6f\u4ef6\u81ea\u52a8\u5316\u6548\u7387\u7684\u6709\u524d\u666f\u65b9\u5411\u3002"}}
{"id": "2512.05619", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05619", "abs": "https://arxiv.org/abs/2512.05619", "authors": ["Menghua Jiang", "Haokai Gao", "Shuhao Chen", "Yin Chen"], "title": "Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting", "comment": "Accepted by ECAI 2025", "summary": "Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u533a\u522b\u5904\u7406PMS\u548cWPMS\u95ee\u9898\u7684\u65b0\u578b\u5b50\u53e5\u6743\u91cd\u65b9\u6848DeepDist\uff0c\u901a\u8fc7\u5dee\u5f02\u5316\u7684\u6743\u91cd\u66f4\u65b0\u7b56\u7565\u3001\u65b0\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u548c\u4f18\u5148\u6ee1\u8db3\u5355\u4f4d/\u786c\u5b50\u53e5\u7684decimation\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86SLS\u6c42\u89e3\u5668\u6027\u80fd\uff0c\u5728MaxSAT\u8bc4\u6d4b\u4e2d\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u6c42\u89e3\u5668\u3002", "motivation": "\u73b0\u6709\u7684(W)PMS\u968f\u673a\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u4e3b\u8981\u5173\u6ce8\u5b50\u53e5\u6743\u91cd\u65b9\u6848\u8bbe\u8ba1\uff0c\u4f46\u5f80\u5f80\u672a\u80fd\u5145\u5206\u533a\u5206PMS\u548cWPMS\u95ee\u9898\uff0c\u901a\u5e38\u91c7\u7528\u7edf\u4e00\u7684\u6743\u91cd\u66f4\u65b0\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u4e24\u7c7b\u95ee\u9898\u4e4b\u95f4\u7684\u5173\u952e\u7ed3\u6784\u5dee\u5f02\u3002", "method": "1)\u9996\u6b21\u6839\u636e\u4e0d\u540c\u6761\u4ef6\u5206\u522b\u66f4\u65b0PMS\u548cWPMS\u5b9e\u4f8b\u7684\u5b50\u53e5\u6743\u91cd\uff1b2)\u65b0\u7684\u521d\u59cb\u5316\u65b9\u6cd5\u66f4\u597d\u5730\u9002\u5e94\u4e24\u79cd\u5b9e\u4f8b\u7c7b\u578b\u7684\u72ec\u7279\u7279\u5f81\uff1b3)\u63d0\u51fa\u4f18\u5148\u6ee1\u8db3\u5355\u4f4d\u5b50\u53e5\u548c\u786c\u5b50\u53e5\u7684decimation\u65b9\u6cd5\u3002", "result": "\u5728\u6700\u8fd1MaxSAT\u8bc4\u6d4b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepDist\u4f18\u4e8e\u6700\u5148\u8fdb\u7684SLS\u6c42\u89e3\u5668\u3002\u4e0eTT-Open-WBO-Inc\u76f8\u7ed3\u5408\u7684\u6df7\u5408\u6c42\u89e3\u5668\u751a\u81f3\u8d85\u8d8a\u4e86MaxSAT Evaluation 2024\u7684\u83b7\u80dc\u8005SPB-MaxSAT-c-Band\u548cSPB-MaxSAT-c-FPS\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86PMS\u548cWPMS\u95ee\u9898\u7684\u5dee\u5f02\u5316\u5904\u7406\u9700\u6c42\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002\u65b0\u7684\u6743\u91cd\u65b9\u6848\u548c\u914d\u5957\u65b9\u6cd5\u4e3a(W)PMS\u6c42\u89e3\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2512.05507", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05507", "abs": "https://arxiv.org/abs/2512.05507", "authors": ["Masoud Sadrnezhaad", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Torvald M\u00e5rtensson", "Daniel Varro"], "title": "Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study", "comment": "This paper appears in the proceedings of the 26th International Conference on Product-Focused Software Process Improvement (PROFES 2025). For citations, please refer to the published version in the PROFES 2025 proceedings", "summary": "Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9\u516d\u5bb6\u516c\u53f8\u7684\u8de8\u4f01\u4e1a\u7814\u8ba8\uff0c\u63a2\u8ba8\u751f\u6210\u5f0fAI\u5728\u5927\u578b\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u4eff\u771f\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u4e0e\u6311\u6218\uff0c\u5e76\u63d0\u51fa\u4e86\u7814\u7a76\u8bae\u7a0b\u3002", "motivation": "\u5927\u578b\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u7684\u8d28\u91cf\u4fdd\u969c\u4f9d\u8d56\u590d\u6742\u4eff\u771f\u6d4b\u8bd5\u73af\u5883\uff0c\u9700\u8981\u5927\u91cf\u8d44\u6e90\u5f00\u53d1\u7ef4\u62a4\u6a21\u578b\u3002\u751f\u6210\u5f0fAI\u53ef\u751f\u6210\u53ef\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f46\u5728\u6b64\u7c7b\u7cfb\u7edf\u7684\u4eff\u771f\u6d4b\u8bd5\u4e2d\u5e94\u7528\u4ecd\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u8de8\u4f01\u4e1a\u7814\u8ba8\u4f1a\u6536\u96c6\u516d\u5bb6\u7ec4\u7ec7\u7684\u5b9e\u8df5\u8005\u89c2\u70b9\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u751f\u6210\u5f0fAI\u5177\u6709\u5de8\u5927\u6f5c\u529b\u4f46\u5b58\u5728\u672a\u89e3\u51b3\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e09\u5927\u7814\u7a76\u65b9\u5411\uff1aAI\u751f\u6210\u573a\u666f\u4e0e\u73af\u5883\u6a21\u578b\u3001CI/CD\u7ba1\u9053\u4e2d\u4eff\u771f\u5668\u4e0eAI\u7ed3\u5408\u3001\u751f\u6210\u5f0fAI\u7684\u53ef\u4fe1\u5ea6\u3002", "conclusion": "\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u8be6\u7ec6\u95ee\u9898\u63cf\u8ff0\u5f15\u5bfc\u672a\u6765\u5b66\u672f\u754c\u4e0e\u4ea7\u4e1a\u754c\u5408\u4f5c\uff0c\u63a8\u52a8\u751f\u6210\u5f0fAI\u5728\u4eff\u771f\u6d4b\u8bd5\u4e2d\u7684\u8d1f\u8d23\u4efb\u5e94\u7528\u3002"}}
{"id": "2512.05533", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05533", "abs": "https://arxiv.org/abs/2512.05533", "authors": ["Theocharis Tavantzis", "Stefano Lambiase", "Daniel Russo", "Robert Feldt"], "title": "From Challenge to Change: Design Principles for AI Transformations", "comment": "Submitted to JSS", "summary": "The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u884c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u4eba\u7c7b\u4e2d\u5fc3\u6846\u67b6\uff0c\u901a\u8fc7\u6df7\u5408\u65b9\u6cd5\u5efa\u7acb\u5e76\u5b8c\u5584\uff0c\u5305\u542b\u4e5d\u4e2a\u7ef4\u5ea6\uff0c\u4e3a\u65e9\u671fAI\u91c7\u7528\u63d0\u4f9b\u5b9e\u7528\u8def\u7ebf\u56fe\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u5173\u6ce8AI\u96c6\u6210\u7684\u6280\u672f\u95ee\u9898\uff0c\u800c\u5bf9\u56e2\u961f\u5982\u4f55\u9002\u5e94\u548c\u4fe1\u4efbAI\u7684\u884c\u4e3a\u56e0\u7d20\u5173\u6ce8\u6709\u9650\uff0c\u9700\u8981\u4eba\u7c7b\u4e2d\u5fc3\u7684\u6846\u67b6\u652f\u6301SE\u7ec4\u7ec7\u65e9\u671fAI\u91c7\u7528\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u7ec4\u7ec7\u53d8\u9769\u6a21\u578b\u548c\u8bbf\u8c08\u6570\u636e\u7684\u4e3b\u9898\u5206\u6790\uff0c\u5efa\u7acb\u5e76\u5b8c\u5584\u6846\u67b6\uff0c\u5e76\u8fdb\u884c\u8c03\u67e5\uff08N=105\uff09\u548c\u4e24\u4e2a\u4e13\u5bb6\u7814\u8ba8\u4f1a\uff08N=4\uff09\u6536\u96c6\u5b9e\u8df5\u8005\u53cd\u9988\u3002", "result": "\u8c03\u67e5\u663e\u793a\uff0c\u6280\u80fd\u63d0\u5347\uff0815.2%\uff09\u548cAI\u6218\u7565\u8bbe\u8ba1\uff0815.1%\uff09\u88ab\u89c6\u4e3a\u6700\u91cd\u8981\u7ef4\u5ea6\uff1b\u7ec4\u7ec7\u5f53\u524d\u4f18\u5148\u7a0b\u5e8f\u6027\u5143\u7d20\uff0c\u800c\u4eba\u7c7b\u4e2d\u5fc3\u9632\u62a4\u63aa\u65bd\u8f83\u4e0d\u53d1\u8fbe\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u8bc6\u522b\u5173\u952e\u884c\u4e3a\u7ef4\u5ea6\u548c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u6307\u5bfc\uff0c\u4e3a\u5e94\u5bf9\u65e9\u671fAI\u91c7\u7528\u7684\u793e\u4f1a\u6280\u672f\u590d\u6742\u6027\u63d0\u4f9b\u5b9e\u7528\u8def\u7ebf\u56fe\uff0c\u5e76\u7a81\u51faSE\u4e2d\u4eba\u7c7b\u4e2d\u5fc3AI\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2512.05551", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05551", "abs": "https://arxiv.org/abs/2512.05551", "authors": ["Jai Lal Lulla", "Raula Gaikovina Kula", "Christoph Treude"], "title": "Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub", "comment": "15 pages, 9 figures, 8 tables", "summary": "Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9GitHub\u7684CODEOWNERS\u529f\u80fd\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u5176\u572884.4\u4e07\u6b21\u62c9\u53d6\u8bf7\u6c42\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u53d1\u73b0CODEOWNERS\u80fd\u6539\u5584\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\u5e76\u91cd\u65b0\u5206\u914d\u5ba1\u67e5\u8d23\u4efb\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u589e\u52a0\uff0c\u4ee3\u7801\u6240\u6709\u6743\u673a\u5236\u5bf9\u4fdd\u8bc1\u8f6f\u4ef6\u8d28\u91cf\u8d8a\u53d1\u91cd\u8981\u3002GitHub\u7684CODEOWNERS\u529f\u80fd\u867d\u80fd\u81ea\u52a8\u6307\u5b9a\u4ee3\u7801\u5ba1\u67e5\u8005\uff0c\u4f46\u5176\u5b9e\u9645\u91c7\u7528\u60c5\u51b5\u548c\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5bf9844,000\u6b21\u62c9\u53d6\u8bf7\u6c42\u3001190\u4e07\u6761\u8bc4\u8bba\u548c200\u4e07\u6b21\u5ba1\u67e5\u7684\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u8ffd\u8e2a10,287\u540d\u4ee3\u7801\u6240\u6709\u8005\u7684\u5ba1\u67e5\u6d3b\u52a8\uff0c\u5e76\u4f7f\u7528\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1(RDD)\u5206\u6790CODEOWNERS\u91c7\u7528\u524d\u540e\u7684\u53d8\u5316\u3002", "result": "\u4ee3\u7801\u6240\u6709\u8005\u666e\u904d\u9075\u5b88CODEOWNERS\u89c4\u5219\uff0c\u5176\u534f\u4f5c\u884c\u4e3a\u4e0e\u4f20\u7edf\u6240\u6709\u6743\u6307\u6807\u76f8\u4f3c\uff0c\u4f46\u80fd\u5e26\u6765\u66f4\u987a\u7545\u3001\u66f4\u5feb\u6377\u7684PR\u5de5\u4f5c\u6d41\u7a0b\u3002\u91c7\u7528CODEOWNERS\u540e\uff0c\u5ba1\u67e5\u8d23\u4efb\u4ece\u6838\u5fc3\u5f00\u53d1\u8005\u5411\u66f4\u5e7f\u6cdb\u7fa4\u4f53\u8f6c\u79fb\u3002", "conclusion": "CODEOWNERS\u662f\u6539\u5584\u8f6f\u4ef6\u6cbb\u7406\u548c\u97e7\u6027\u7684\u6709\u524d\u666f\u4f46\u672a\u5145\u5206\u5229\u7528\u7684\u673a\u5236\uff0c\u53ef\u4f5c\u4e3a\u589e\u5f3a\u5f00\u6e90\u5f00\u53d1\u5b89\u5168\u6027\u3001\u8d23\u4efb\u6027\u548c\u5de5\u4f5c\u6d41\u6548\u7387\u7684\u66ff\u4ee3\u6240\u6709\u6743\u65b9\u6cd5\u3002"}}
{"id": "2512.05760", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05760", "abs": "https://arxiv.org/abs/2512.05760", "authors": ["Zeyuan Ma", "Wenqi Huang", "Guo-Huan Song", "Hongshu Guo", "Sijie Ma", "Zhiguang Cao", "Yue-Jiao Gong"], "title": "Evolutionary System 2 Reasoning: An Empirical Proof", "comment": null, "summary": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8fdb\u5316\u63a8\u7406\u4f18\u5316\uff08ERO\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u9009\u62e9\u7b56\u7565\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u5373\u4f7f\u8f83\u5f31\u6a21\u578b\u7ecf\u8fc7\u8fdb\u5316\u4e5f\u80fd\u83b7\u5f97\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u5728\u7279\u5b9a\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u4eba\u7c7b\u822c\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u3002\u7814\u7a76\u63a2\u7d22\u80fd\u5426\u901a\u8fc7\u8fdb\u5316\u65b9\u6cd5\u8ba9\u673a\u5668\u83b7\u5f97\u7c7b\u4f3c\u4eba\u7c7b\u7684\u7cfb\u7edf2\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faERO\u6846\u67b6\uff1a\u521d\u59cb\u5316\u591a\u4e2aLLMs\u4f5c\u4e3a\u79cd\u7fa4\uff0c\u91c7\u7528\u8fdb\u5316\u7b56\u7565\u4f18\u5316\u79cd\u7fa4\uff0c\u4ee5\u6700\u5927\u5316\u6700\u4f73\u4e2a\u4f53\u7684\u91cf\u5316\u63a8\u7406\u5206\u6570\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff1a1\uff09\u6700\u65b0LLM\uff08\u5982GPT-5\uff09\u7cfb\u7edf2\u63a8\u7406\u80fd\u529b\u6709\u9650\uff1b2\uff09\u5f31\u6a21\u578b\uff08Qwen-7B\uff09\u901a\u8fc7ERO\u8fdb\u5316\u540e\u80fd\u6d8c\u73b0\u5f3a\u5927\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u8fdb\u5316\u65b9\u6cd5\u53ef\u6709\u6548\u63d0\u5347LLMs\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u673a\u5668\u667a\u80fd\u53d1\u5c55\u63d0\u4f9b\u65b0\u8def\u5f84\u3002"}}
{"id": "2512.05765", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05765", "abs": "https://arxiv.org/abs/2512.05765", "authors": ["Edward Y. Chang"], "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics", "comment": "13 pages, 3 figures", "summary": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.", "AI": {"tldr": "\u8bba\u6587\u53cd\u9a73\u4e86LLMs\u662fAGI\u6b7b\u7ed3\u7684\u89c2\u70b9\uff0c\u63d0\u51fa\u74f6\u9888\u5728\u4e8e\u7f3a\u4e4fSystem-2\u534f\u8c03\u5c42\u800c\u975e\u6a21\u5f0f\u5339\u914d\u672c\u8eab\uff0c\u5e76\u7406\u8bba\u5316UCCT\u6846\u67b6\u4e0eMACI\u67b6\u6784\u6765\u5b9e\u73b0\u63a8\u7406\u3002", "motivation": "\u9488\u5bf9\u5b66\u754c\u6279\u8bc4LLMs\u4ec5\u662f\u6a21\u5f0f\u5339\u914d\u5668\u3001\u65e0\u6cd5\u5b9e\u73b0\u771f\u6b63\u63a8\u7406\u7684\u8bba\u70b9\uff0c\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u9519\u8bef\u8bc6\u522b\u4e86\u74f6\u9888\u2014\u2014\u95ee\u9898\u4e0d\u5728\u6a21\u5f0f\u5e93\uff08System-1\uff09\uff0c\u800c\u5728\u4e8e\u7f3a\u5c11\u534f\u8c03\u5c42\uff08System-2\uff09\u3002", "method": "\u63d0\u51faUCCT\u7406\u8bba\uff0c\u5c06\u63a8\u7406\u5efa\u6a21\u4e3a\u53d7\u6709\u6548\u652f\u6301\u5ea6\uff08\u03c1_d\uff09\u3001\u8868\u5f81\u5931\u914d\uff08d_r\uff09\u548c\u81ea\u9002\u5e94\u951a\u5b9a\u9884\u7b97\uff08\u03b3 log k\uff09\u63a7\u5236\u7684\u76f8\u53d8\uff1b\u5e76\u8bbe\u8ba1MACI\u67b6\u6784\uff0c\u5305\u542b\u8bf1\u9975\u673a\u5236\uff08\u884c\u4e3a\u8c03\u63a7\u8fa9\u8bba\uff09\u3001\u8fc7\u6ee4\uff08\u82cf\u683c\u62c9\u5e95\u5f0f\u5224\u65ad\uff09\u4e0e\u6301\u4e45\u5316\uff08\u4e8b\u52a1\u5185\u5b58\uff09\u3002", "result": "\u7406\u8bba\u8868\u660e\uff0c\u65e0\u951a\u5b9a\u751f\u6210\u4ec5\u662f\u6a21\u5f0f\u5e93\u7684\u6700\u5927\u4f3c\u7136\u68c0\u7d22\uff0c\u800c\u951a\u5b9a\u80fd\u5c06\u540e\u9a8c\u6982\u7387\u5bfc\u5411\u76ee\u6807\u7ea6\u675f\uff0c\u4ece\u800c\u6d8c\u73b0\u63a8\u7406\u884c\u4e3a\uff1bMACI\u5c06\u5e38\u89c1\u8d28\u7591\u8f6c\u5316\u4e3a\u53ef\u6d4b\u8bd5\u7684\u534f\u8c03\u5931\u6548\u6848\u4f8b\u3002", "conclusion": "AGI\u7684\u5b9e\u73b0\u8def\u5f84\u5e94\u901a\u8fc7\u589e\u5f3aLLMs\u7684\u534f\u8c03\u5c42\uff08\u800c\u975e\u7ed5\u8fc7\u5b83\u4eec\uff09\uff0c\u8bc1\u660eLLMs\u672c\u8eab\u662fAGI\u7684\u5fc5\u8981\u57fa\u7840\u800c\u975e\u969c\u788d\u3002"}}
{"id": "2512.05703", "categories": ["cs.SE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05703", "abs": "https://arxiv.org/abs/2512.05703", "authors": ["Zhuangbin Chen", "Juzheng Zheng", "Zibin Zheng"], "title": "Metronome: Differentiated Delay Scheduling for Serverless Functions", "comment": "Accepted to ICSE 2026", "summary": "Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Metronome\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u6027\u5ef6\u65f6\u8c03\u5ea6\u4f18\u5316\u65e0\u670d\u52a1\u5668\u51fd\u6570\u8c03\u5ea6\uff0c\u5229\u7528\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6267\u884c\u65f6\u95f4\uff0c\u663e\u8457\u964d\u4f4e\u5e73\u5747\u6267\u884c\u65f6\u95f4\u5e76\u4fdd\u8bc1SLA\u5408\u89c4\u3002", "motivation": "\u65e0\u670d\u52a1\u5668(FaaS)\u8ba1\u7b97\u56e0\u5176\u6613\u7ba1\u7406\u6027\u548c\u5f39\u6027\u800c\u5174\u8d77\uff0c\u4f46\u5176\u52a8\u6001\u548c\u4e8b\u4ef6\u9a71\u52a8\u7684\u7279\u6027\u4f7f\u5f97\u8c03\u5ea6\u4f18\u5316\u5177\u6709\u6311\u6218\u6027\u3002\u6570\u636e\u5c40\u90e8\u6027\u5728\u4f20\u7edf\u96c6\u7fa4\u8ba1\u7b97\u4e2d\u901a\u8fc7\u5ef6\u65f6\u8c03\u5ea6\u5df2\u88ab\u8bc1\u660e\u6709\u6548\uff0c\u4f46\u5728\u65e0\u670d\u52a1\u5668\u5e73\u53f0\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u7684\u73b0\u6709\u5ef6\u65f6\u8c03\u5ea6\u65b9\u6cd5\uff0c\u53d1\u73b0\u4e09\u4e2a\u5173\u952e\u89c2\u5bdf\uff1a\u51fd\u6570\u8f93\u5165\u7279\u6027\u5f71\u54cd\u8c03\u5ea6\u6548\u679c\u3001\u65e0\u670d\u52a1\u5668\u8ba1\u7b97\u5177\u6709\u66f4\u590d\u6742\u7684\u5c40\u90e8\u6027\u6a21\u5f0f\uff08\u6570\u636e\u548c\u57fa\u7840\u8bbe\u65bd\uff09\u3001\u5f02\u6784\u51fd\u6570\u6267\u884c\u65f6\u95f4\u4f7f\u57fa\u4e8e\u89c4\u5219\u7684\u5ef6\u65f6\u9608\u503c\u65e0\u6548\u3002\u57fa\u4e8e\u6b64\u63d0\u51faMetronome\u6846\u67b6\uff0c\u91c7\u7528\u968f\u673a\u68ee\u6797\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u4e0d\u540c\u8282\u70b9\u4e0a\u7684\u51fd\u6570\u6267\u884c\u65f6\u95f4\uff0c\u5b9e\u73b0\u5dee\u5f02\u5316\u7684\u5ef6\u65f6\u8c03\u5ea6\u3002", "result": "\u5728OpenLambda\u4e0a\u7684\u5b9e\u73b0\u8868\u660e\uff0cMetronome\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u51fd\u6570\u5e73\u5747\u6267\u884c\u65f6\u95f4\u51cf\u5c1164.88%-95.83%\uff0c\u5728\u9ad8\u5e76\u53d1\u4e0b\u4ecd\u4fdd\u6301\u6027\u80fd\u4f18\u52bf\u5e76\u786e\u4fddSLA\u5408\u89c4\u3002", "conclusion": "Metronome\u901a\u8fc7\u9884\u6d4b\u673a\u5236\u548c\u5dee\u5f02\u5316\u5ef6\u65f6\u8c03\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u670d\u52a1\u5668\u51fd\u6570\u8c03\u5ea6\u4e2d\u7684\u5c40\u90e8\u6027\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u65e0\u670d\u52a1\u5668\u5e73\u53f0\u7684\u9ad8\u6548\u8c03\u5ea6\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.05824", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.05824", "abs": "https://arxiv.org/abs/2512.05824", "authors": ["Hafsa Akebli", "Adam Shephard", "Vincenzo Della Mea", "Nasir Rajpoot"], "title": "Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma", "comment": "4 pages, 2 figures", "summary": "Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u591a\u6a21\u6001\u80bf\u7624\u667a\u80fd\u4f53\uff08MOA\uff09\uff0c\u5b83\u7ed3\u5408\u4e86\u57fa\u4e8eTITAN\u57fa\u7840\u6a21\u578b\u7684\u75c5\u7406\u5b66\u5de5\u5177\u548c\u5916\u90e8\u751f\u7269\u533b\u5b66\u8d44\u6e90\uff0c\u7528\u4e8e\u9884\u6d4b\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624\u7684IDH1\u7a81\u53d8\u3002\u5728TCGA-LGG\u961f\u5217\u7684488\u540d\u60a3\u8005\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cMOA\u878d\u5408\u75c5\u7406\u5b66\u7279\u5f81\u540e\u53d6\u5f97\u6700\u9ad8\u6027\u80fd\uff08F1\u5f97\u52060.912\uff09\u3002", "motivation": "\u4f4e\u7ea7\u522b\u80f6\u8d28\u7624\u4e2dIDH1\u7a81\u53d8\u53ef\u5b9a\u4e49\u4e34\u5e8a\u4e0d\u540c\u7684\u4e9a\u7ec4\uff0c\u5177\u6709\u7279\u5b9a\u7684\u9884\u540e\u548c\u6cbb\u7597\u610f\u4e49\uff0c\u4f46\u9700\u8981\u66f4\u51c6\u786e\u7684\u9884\u6d4b\u65b9\u6cd5\u3002", "method": "MOA\u6574\u5408\u4e86\u4e00\u4e2a\u57fa\u4e8eTITAN\u57fa\u7840\u6a21\u578b\u7684\u75c5\u7406\u5b66\u5de5\u5177\u7528\u4e8eIDH1\u7a81\u53d8\u9884\u6d4b\uff0c\u5e76\u7ed3\u5408PubMed\u3001Google\u641c\u7d22\u548cOncoKB\u7b49\u5916\u90e8\u8d44\u6e90\u8fdb\u884c\u4e34\u5e8a\u548c\u57fa\u56e0\u7ec4\u6570\u636e\u7684\u63a8\u7406\u3002", "result": "\u5728TCGA-LGG\u961f\u5217\u4e2d\u8bc4\u4f30\uff1a\u4e0d\u542b\u75c5\u7406\u5b66\u5de5\u5177\u7684MOA\u4f18\u4e8e\u4e34\u5e8a\u57fa\u7ebf\uff08F1\u5f97\u52060.826 vs 0.798\uff09\uff1b\u878d\u5408\u75c5\u7406\u5b66\u7279\u5f81\u7684MOA\u8fbe\u5230\u6700\u9ad8\u6027\u80fd\uff08F1\u5f97\u52060.912\uff09\uff0c\u8d85\u8fc7\u75c5\u7406\u5b66\u57fa\u7ebf\uff080.894\uff09\u548c\u878d\u5408\u75c5\u7406\u5b66-\u4e34\u5e8a\u57fa\u7ebf\uff080.897\uff09\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u667a\u80fd\u4f53\u901a\u8fc7\u5916\u90e8\u751f\u7269\u533b\u5b66\u8d44\u6e90\u6355\u83b7\u4e86\u4e92\u8865\u7684\u7a81\u53d8\u76f8\u5173\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7684IDH1\u7a81\u53d8\u9884\u6d4b\u3002"}}
{"id": "2512.05716", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05716", "abs": "https://arxiv.org/abs/2512.05716", "authors": ["Zhiling Deng", "Juepeng Wang", "Zhuangbin Chen"], "title": "MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems", "comment": null, "summary": "Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.", "AI": {"tldr": "MicroRacer\u662f\u4e00\u4e2a\u975e\u4fb5\u5165\u5f0f\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u5728\u5fae\u670d\u52a1\u67b6\u6784\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u68c0\u6d4b\u5e76\u53d1\u9519\u8bef", "motivation": "\u73b0\u4ee3\u4e91\u7aef\u5e94\u7528\u91c7\u7528\u5fae\u670d\u52a1\u67b6\u6784\uff0c\u7528\u6237\u8bf7\u6c42\u7ecf\u8fc7\u591a\u4e2a\u670d\u52a1\u548c\u673a\u5668\uff0c\u5b58\u5728\u590d\u6742\u7684\u4ea4\u4e92\u5173\u7cfb\uff0c\u4f7f\u5f97\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u5e76\u53d1\u9519\u8bef\u5f71\u54cd\u3002\u73b0\u6709\u7684\u5e76\u53d1\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4fb5\u5165\u6027\u4e14\u65e0\u6cd5\u5904\u7406\u5fae\u670d\u52a1\u67b6\u6784\u590d\u6742\u6027", "method": "\u901a\u8fc7\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u6ce8\u5165\u5e7f\u6cdb\u4f7f\u7528\u7684\u5e93\u6765\u6536\u96c6\u8be6\u7ec6\u7684\u8ffd\u8e2a\u6570\u636e\uff0c\u800c\u4e0d\u9700\u8981\u4fee\u6539\u5e94\u7528\u4ee3\u7801\u3002\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u5206\u6790\u670d\u52a1\u7cfb\u7edf\u4e2d\u5e38\u89c1\u64cd\u4f5c\u7684\u53d1\u751f\u987a\u5e8f\u5173\u7cfb\u548c\u8d44\u6e90\u8bbf\u95ee\u6a21\u5f0f\uff0c\u8bc6\u522b\u53ef\u7591\u5e76\u53d1\u64cd\u4f5c\uff0c\u5e76\u91c7\u7528\u4e09\u9636\u6bb5\u9a8c\u8bc1\u8fc7\u7a0b\u6765\u6d4b\u8bd5\u548c\u786e\u8ba4\u5e76\u53d1\u9519\u8bef", "result": "\u5728\u5f00\u6e90\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86MicroRacer\u7684\u6709\u6548\u6027\u548c\u6548\u7387\uff0c\u80fd\u591f\u51c6\u786e\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5e76\u53d1\u95ee\u9898", "conclusion": "MicroRacer\u4e3a\u975e\u4fb5\u5165\u5f0f\u5e76\u53d1\u9519\u8bef\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u590d\u6742\u7684\u5fae\u670d\u52a1\u67b6\u6784\u73af\u5883"}}
{"id": "2512.05887", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.05887", "abs": "https://arxiv.org/abs/2512.05887", "authors": ["Sairam Vaidya", "Marcel B\u00f6hme", "Loris D'Antoni"], "title": "Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models", "comment": null, "summary": "Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.", "AI": {"tldr": "\u63d0\u51fa\u4e86Germinator\u5de5\u5177\uff0c\u4f7f\u7528\u8bed\u6cd5\u5f15\u5bfc\u548c\u8986\u76d6\u5bfc\u5411\u7684\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u81ea\u52a8\u4e3aMLIR\u7b49\u53ef\u6269\u5c55\u7f16\u8bd1\u5668\u6846\u67b6\u751f\u6210\u6d4b\u8bd5\u79cd\u5b50\uff0c\u57286\u4e2a\u9879\u76ee\u4e2d\u63d0\u5347\u4e8610-120%\u7684\u4ee3\u7801\u8986\u76d6\u7387\uff0c\u5e76\u53d1\u73b0\u4e8688\u4e2a\u65b0bug\u3002", "motivation": "\u53ef\u6269\u5c55\u7f16\u8bd1\u5668\u6846\u67b6\u867d\u7136\u652f\u6301\u5feb\u901f\u521b\u5efa\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u65b9\u8a00\uff0c\u4f46\u6d4b\u8bd5\u57fa\u7840\u8bbe\u65bd\u96be\u4ee5\u7ef4\u62a4\uff1b\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u5b9e\u73b0\u65b9\u8a00\u65e0\u5173\uff08\u901a\u7528\u6027\uff09\u548c\u65b9\u8a00\u6709\u6548\uff08\u9488\u5bf9\u6027\uff09\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u3002", "method": "\u7ed3\u5408\u8bed\u6cd5\u5f15\u5bfc\u548c\u8986\u76d6\u5bfc\u5411\u7684\u6a21\u7cca\u6d4b\u8bd5\uff1a\u81ea\u52a8\u4ece\u65b9\u8a00\u89c4\u8303\u63d0\u53d6\u8bed\u6cd5\u7ed3\u6784\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u79cd\u5b50\u8f93\u5165\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u6216\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u57286\u4e2aMLIR\u9879\u76ee\u768491\u79cd\u65b9\u8a00\u4e0a\u9a8c\u8bc1\uff1a\u79cd\u5b50\u8f93\u5165\u6bd4\u8bed\u6cd5\u57fa\u7ebf\u63d0\u534710-120%\u884c\u8986\u76d6\u7387\uff1b\u53d1\u73b088\u4e2a\u672a\u77e5bug\uff0840\u4e2a\u5df2\u786e\u8ba4\uff09\uff0c\u5176\u4e2d23\u4e2a\u6765\u81ea\u6b64\u524d\u65e0\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u5668\u7684\u65b9\u8a00\u3002", "conclusion": "Germinator\u5b9e\u73b0\u4e86\u65b9\u8a00\u65e0\u5173\u4e14\u6709\u6548\u7684\u6d4b\u8bd5\u751f\u6210\uff0c\u80fd\u89c4\u6a21\u5316\u53ef\u63a7\u5730\u6d4b\u8bd5\u4f4e\u8d44\u6e90\u65b9\u8a00\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8bd1\u5668\u6846\u67b6\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.05925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05925", "abs": "https://arxiv.org/abs/2512.05925", "authors": ["Federico Bianchi", "Yongchan Kwon", "Zachary Izzo", "Linjun Zhang", "James Zou"], "title": "To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis", "comment": null, "summary": "How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8eGPT-5\u7684\u8bba\u6587\u68c0\u67e5\u5668\uff0c\u53d1\u73b0AI\u9876\u4f1a\u8bba\u6587\u4e2d\u5b58\u5728\u663e\u8457\u4e14\u65e5\u76ca\u589e\u591a\u7684\u5ba2\u89c2\u9519\u8bef\uff08\u5982\u516c\u5f0f\u3001\u56fe\u8868\u9519\u8bef\uff09\uff0c\u9519\u8bef\u6570\u91cf\u57282018-2025\u5e74\u95f4\u4e0a\u5347\u4e8655.3%\uff0cAI\u68c0\u67e5\u5668\u8bc6\u522b\u7cbe\u786e\u5ea6\u8fbe83.2%\uff0c\u4e14\u80fd\u81ea\u52a8\u4fee\u6b6375.8%\u7684\u9519\u8bef\u3002", "motivation": "\u540c\u884c\u8bc4\u5ba1\u538b\u529b\u589e\u5927\u5bfc\u81f4\u8bba\u6587\u9519\u8bef\u96be\u4ee5\u68c0\u6d4b\uff0c\u9519\u8bef\u5728\u6587\u732e\u4e2d\u4f20\u64ad\u4f1a\u8bef\u5bfc\u540e\u7eed\u7814\u7a76\u5e76\u5f71\u54cd\u53ef\u590d\u73b0\u6027\u3002", "method": "\u4f7f\u7528GPT-5\u6784\u5efa\u8bba\u6587\u6b63\u786e\u6027\u68c0\u67e5\u5668\uff0c\u9488\u5bf9\u9876\u4f1a\u8bba\u6587\u4e2d\u7684\u5ba2\u89c2\u9519\u8bef\uff08\u516c\u5f0f\u3001\u8ba1\u7b97\u3001\u56fe\u8868\u7b49\u53ef\u9a8c\u8bc1\u9519\u8bef\uff09\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u5e76\u4eba\u5de5\u9a8c\u8bc1AI\u8bc6\u522b\u7ed3\u679c\u3002", "result": "NeurIPS\u8bba\u6587\u9519\u8bef\u4ece2021\u5e74\u76843.8\u4e2a/\u7bc7\u589e\u81f32025\u5e74\u76845.9\u4e2a\uff1bAI\u68c0\u67e5\u5668\u8bc6\u522b\u9519\u8bef\u7684\u7cbe\u786e\u5ea6\u4e3a83.2%\uff08\u4eba\u5de5\u9a8c\u8bc1316\u6761\u9519\u8bef\u4e2d263\u6761\u5c5e\u5b9e\uff09\uff0c\u53ef\u81ea\u52a8\u4fee\u6b6375.8%\u7684\u9519\u8bef\u3002", "conclusion": "\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u6709\u6548\u68c0\u6d4b\u548c\u4fee\u6b63\u8bba\u6587\u4e2d\u7684\u5ba2\u89c2\u9519\u8bef\uff0c\u6709\u52a9\u4e8e\u592f\u5b9e\u5b66\u672f\u77e5\u8bc6\u57fa\u7840\uff0c\u51cf\u5c11\u6587\u732e\u6df7\u4e71\u3002"}}
{"id": "2512.05946", "categories": ["cs.AI", "cs.ET", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05946", "abs": "https://arxiv.org/abs/2512.05946", "authors": ["Truong Thanh Hung Nguyen", "Truong Thinh Nguyen", "Hung Cao"], "title": "Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem", "comment": "Quantum Software Engineering Practices at The 41st ACM/SIGAPP Symposium On Applied Computing (SAC 2026)", "summary": "Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53d8\u5206\u91cf\u5b50\u7535\u8def\u4e0eRainbow DQN\u7684\u65b0\u7b97\u6cd5VQR-DQN\uff0c\u7528\u4e8e\u89e3\u51b3NP\u96be\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u8d44\u6e90\u5206\u914d\u95ee\u9898\u56e0\u5176\u7ec4\u5408\u590d\u6742\u6027\u800cNP\u96be\u3002\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u51fd\u6570\u903c\u8fd1\u5668\u7684\u8868\u793a\u80fd\u529b\u3002", "method": "\u5c06\u91cf\u5b50\u53e0\u52a0\u548c\u7ea0\u7f20\u7279\u6027\u878d\u5165Rainbow DQN\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u73af\u62d3\u6251\u7684\u53d8\u5206\u91cf\u5b50\u7535\u8def\uff0c\u5e76\u5c06\u4eba\u529b\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVQR-DQN\u76f8\u6bd4\u968f\u673a\u57fa\u7ebf\u51cf\u5c11\u4e8626.8%\u7684\u6807\u51c6\u5316\u5b8c\u5de5\u65f6\u95f4\uff0c\u6bd4Double DQN\u548c\u7ecf\u5178Rainbow DQN\u63d0\u53474.9-13.4%\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7535\u8def\u8868\u8fbe\u80fd\u529b\u3001\u7ea0\u7f20\u4e0e\u7b56\u7565\u8d28\u91cf\u7684\u7406\u8bba\u8054\u7cfb\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u589e\u5f3aDRL\u5728\u5927\u89c4\u6a21\u8d44\u6e90\u5206\u914d\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.05943", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05943", "abs": "https://arxiv.org/abs/2512.05943", "authors": ["Shima Imani", "Seungwhan Moon", "Lambert Mathias", "Lu Zhang", "Babak Damavandi"], "title": "TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models", "comment": null, "summary": "Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u540d\u4e3aTRACE\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u900f\u660e\u5316\u548c\u4e00\u81f4\u6027\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\uff0c\u4ee5\u8bca\u65ad\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u6570\u5b66\u548c\u79d1\u5b66\u95ee\u9898\u4e0a\u7684\u63a8\u7406\u9519\u8bef\u3002", "motivation": "\u6807\u51c6\u6700\u7ec8\u7b54\u6848\u8bc4\u4f30\u5f80\u5f80\u63a9\u76d6\u63a8\u7406\u9519\u8bef\uff0c\u5bfc\u81f4\u65e0\u58f0\u6545\u969c\u6301\u7eed\u5b58\u5728\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u7ed3\u679c\uff0c\u800c\u5ffd\u89c6\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u3002", "method": "\u6838\u5fc3\u662f\u5229\u7528\u8f85\u52a9\u63a8\u7406\u96c6(ARS)\uff0c\u5373\u7d27\u51d1\u7684\u5b50\u95ee-\u7b54\u5bf9\uff0c\u5206\u89e3\u590d\u6742\u95ee\u9898\uff0c\u901a\u8fc7\u57fa\u4e8e\u4e00\u81f4\u6027\u7684\u6307\u6807\u8bc4\u4f30\u4e2d\u95f4\u6b65\u9aa4\uff0c\u63ed\u793a\u6807\u51c6\u8bc4\u4f30\u5ffd\u7565\u7684\u6545\u969c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cARS\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u76f8\u5173\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u5e76\u80fd\u7cbe\u786e\u5b9a\u4f4d\u63a8\u7406\u5931\u8d25\u7684\u5177\u4f53\u6b65\u9aa4\uff0c\u4e3a\u6a21\u578b\u6539\u8fdb\u63d0\u4f9b\u53ef\u884c\u7684\u4fe1\u53f7\u3002", "conclusion": "TRACE\u5b9a\u4e49\u4e86\u7f6e\u4fe1\u533a\u57df\uff0c\u533a\u5206\u53ef\u9760\u4e0e\u4e0d\u53ef\u9760\u7684\u63a8\u7406\u8def\u5f84\uff0c\u652f\u6301\u6709\u6548\u7684\u8fc7\u6ee4\u3001\u8c03\u8bd5\u548c\u6a21\u578b\u7cbe\u70bc\uff0c\u65e8\u5728\u63d0\u5347\u6a21\u578b\u7684\u53ef\u9760\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2512.05954", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05954", "abs": "https://arxiv.org/abs/2512.05954", "authors": ["Shima Imani", "Seungwhan Moon", "Adel Ahmadyan", "Lu Zhang", "Kirmani Ahmed", "Babak Damavandi"], "title": "SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code", "comment": null, "summary": "We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems", "AI": {"tldr": "SymPyBench\u662f\u4e00\u4e2a\u5305\u542b15,045\u4e2a\u5927\u5b66\u7269\u7406\u95ee\u9898\u7684\u5927\u89c4\u6a21\u5408\u6210\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u652f\u6301\u65e0\u9650\u53c2\u6570\u914d\u7f6e\uff0c\u5305\u542b\u4e09\u79cd\u9898\u578b\u548c\u4e09\u79cd\u65b0\u9896\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u6d4b\u8bd5\u8bed\u8a00\u6a21\u578b\u7684\u79d1\u5b66\u63a8\u7406\u80fd\u529b", "motivation": "\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u79d1\u5b66\u63a8\u7406\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9700\u8981\u52a8\u6001\u3001\u53ef\u53c2\u6570\u5316\u7684\u95ee\u9898\u96c6\u6765\u6d4b\u8bd5\u6a21\u578b\u5728\u4e0d\u540c\u53d8\u4f53\u4e0b\u7684\u8868\u73b0", "method": "\u521b\u5efa\u5b8c\u5168\u53c2\u6570\u5316\u7684\u95ee\u9898\u5e93\uff0c\u6bcf\u4e2a\u95ee\u9898\u9644\u5e26\u7ed3\u6784\u5316\u63a8\u7406\u6b65\u9aa4\u548c\u53ef\u6267\u884cPython\u4ee3\u7801\uff0c\u5f15\u5165Consistency Score\u3001Failure Rate\u548cConfusion Rate\u7b49\u65b0\u8bc4\u4f30\u6307\u6807", "result": "\u5728\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u63ed\u793a\u4e86\u79d1\u5b66\u63a8\u7406\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\uff0c\u6a21\u578b\u5728\u4e0d\u540c\u95ee\u9898\u7c7b\u578b\u548c\u53c2\u6570\u53d8\u4f53\u4e2d\u8868\u73b0\u51fa\u53ef\u53d8\u6027", "conclusion": "SymPyBench\u4e3a\u5f00\u53d1\u66f4\u9c81\u68d2\u3001\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5c55\u793a\u4e86\u4ee3\u7801\u9a71\u52a8\u57fa\u51c6\u5728\u8bc4\u4f30\u79d1\u5b66\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u4ef7\u503c"}}
