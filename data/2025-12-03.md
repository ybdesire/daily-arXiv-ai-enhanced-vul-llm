<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 14]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.SE](#cs.SE) [Total: 6]
- [cs.CE](#cs.CE) [Total: 3]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Superpixel Attack: Enhancing Black-box Adversarial Attack with Image-driven Division Areas](https://arxiv.org/abs/2512.02062)
*Issa Oe,Keiichiro Yamamura,Hiroki Ishikura,Ryo Hamahira,Katsuki Fujisawa*

Main category: cs.CR

TL;DR: 本文提出了基于超像素的黑盒对抗攻击方法Superpixel Attack，通过超像素划分和多样化搜索策略，相比现有方法平均攻击成功率提升了2.10%。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在安全关键任务中易受微小扰动影响，现有黑盒攻击方法使用的矩形区域划分简单，需要更精细的扰动优化方法。

Method: 采用超像素取代传统矩形区域划分，结合新提出的多样化搜索策略，在保持颜色方差和紧凑性平衡的基础上优化扰动。

Result: 在对抗鲁棒性较强的模型上，Superpixel Attack平均攻击成功率达到2.10%的提升，代码已开源。

Conclusion: 超像素划分结合多样化搜索能有效提升黑盒对抗攻击性能，为防御策略开发提供更强大的测试基准。

Abstract: Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is avilable at https://github.com/oe1307/SuperpixelAttack.git.

</details>


### [2] [Large Language Model based Smart Contract Auditing with LLMBugScanner](https://arxiv.org/abs/2512.02069)
*Yining Yuan,Yifei Wang,Yichang Xu,Zachary Yahn,Sihao Hu,Ling Liu*

Main category: cs.CR

TL;DR: LLMBugScanner是一个基于大型语言模型的智能合约漏洞检测框架，通过微调和集成学习提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有的智能合约审计方法面临挑战：不同的预训练模型推理能力各异，单个模型无法在所有漏洞类型或合约结构上表现一致，即使在微调后仍有局限。

Method: 结合领域知识适应和集成推理。领域知识适应通过参数高效微调在互补数据集上训练模型，捕捉一般代码语义和指令引导的漏洞推理；集成推理利用多个模型的互补优势，采用基于共识的冲突解决策略。

Result: 在多个人工智能模型上的广泛实验表明，LLMBugScanner相比预训练和微调的单个模型，实现了持续的准确率提升和更强的泛化能力。

Conclusion: LLMBugScanner为智能合约审计提供了一个有原则、成本效益高且可扩展的框架。

Abstract: This paper presents LLMBugScanner, a large language model (LLM) based framework for smart contract vulnerability detection using fine-tuning and ensemble learning. Smart contract auditing presents several challenges for LLMs: different pretrained models exhibit varying reasoning abilities, and no single model performs consistently well across all vulnerability types or contract structures. These limitations persist even after fine-tuning individual LLMs.
  To address these challenges, LLMBugScanner combines domain knowledge adaptation with ensemble reasoning to improve robustness and generalization. Through domain knowledge adaptation, we fine-tune LLMs on complementary datasets to capture both general code semantics and instruction-guided vulnerability reasoning, using parameter-efficient tuning to reduce computational cost. Through ensemble reasoning, we leverage the complementary strengths of multiple LLMs and apply a consensus-based conflict resolution strategy to produce more reliable vulnerability assessments.
  We conduct extensive experiments across multiple popular LLMs and compare LLMBugScanner with both pretrained and fine-tuned individual models. Results show that LLMBugScanner achieves consistent accuracy improvements and stronger generalization, demonstrating that it provides a principled, cost-effective, and extensible framework for smart contract auditing.

</details>


### [3] [Deterministic Random Bit Generators Based on Ascon for Embedded Systems](https://arxiv.org/abs/2512.02082)
*Abel C. H. Chen*

Main category: cs.CR

TL;DR: 本研究提出了三种基于Ascon轻量级密码标准的DRBG构造方案，在嵌入式系统中展现出更高的计算效率和更低的内存使用率


<details>
  <summary>Details</summary>
Motivation: 在资源受限的嵌入式系统中，随机数生成器的性能和安全性至关重要，而NIST新制定的Ascon标准适合此类环境使用

Method: 提出三种基于Ascon的DRBG构造：哈希型DRBG、HMAC型DRBG和计数器型DRBG，并在树莓派平台上进行实验验证

Result: 实验结果表明，相比现有DRBG实现，所提方法计算效率更高、内存使用更低

Conclusion: 基于Ascon的DRBG方案适合在嵌入式系统中部署，为资源受限环境提供了高性能的安全随机数生成方案

Abstract: As the Deterministic Random Bit Generator (DRBG) serves as a fundamental component in random number generation and cryptographic applications, its performance and security are particularly critical in resource-constrained embedded systems, where memory capacity and computational efficiency are limited. Establishing a high-performance and secure DRBG is therefore an important issue for embedded system design. Furthermore, the National Institute of Standards and Technology (NIST) established the Ascon lightweight cryptographic standard in August 2025, which is suitable for use in resource-limited embedded environments. Therefore, this study revises the DRBG standard and proposes three Ascon-driven constructions: the Ascon-Driven Hash-Based DRBG, the Ascon-Driven keyed-Hash Message Authentication Code (HMAC) DRBG, and the Ascon-Driven Counter-mode (CTR) DRBG. In the experiments, these methods are implemented on a Raspberry Pi platform. The experimental results demonstrate that the proposed approaches achieve higher computational efficiency and lower memory usage compared with existing DRBG implementations, making them suitable for deployment in embedded systems.

</details>


### [4] [A survey about Hidden Subgroup Problem from a mathematical and cryptographic perspective](https://arxiv.org/abs/2512.02087)
*Simone Dutto,Pietro Mercuri,Nadir Murru,Lorenzo Romano*

Main category: cs.CR

TL;DR: 关于隐子群问题的综述，讨论其在公钥密码安全中的重要性和在不同群结构中的量子解法


<details>
  <summary>Details</summary>
Motivation: 研究隐子群问题的量子解法对评估密码系统的安全性至关重要，为理解量子计算对密码学的影响提供理论基础

Method: 采用文献综述方法，首先回顾阿贝尔群案例及其在经典问题中的应用，然后分析非阿贝尔群的最新研究进展

Result: 总结了阿贝尔群的量子高效解法，揭示非阿贝尔群尚无通用高效量子解法的现状，分析了特定群结构的连接问题

Conclusion: 隐子群问题是连接量子计算与传统密码安全的核心桥梁，需进一步发展数学工具来应对非阿贝尔群挑战

Abstract: We provide a survey on the Hidden Subgroup Problem (HSP), which plays an important role in studying the security of public-key cryptosystems. We first review the abelian case, where Kitaev's algorithm yields an efficient quantum solution to the HSP, recalling how classical problems (such as order finding, integer factorization, and discrete logarithm) can be formulated as abelian HSP instances. We then examine the current state of the art for non-abelian HSP, where no general efficient quantum solution is known, focusing on some relevant groups including dihedral group (connected to the shortest vector problem), symmetric groups (connected to the graph isomorphism problem), and semidirect product constructions (connected, in a special case, to the code equivalence problem). We also describe the main techniques for addressing the HSP in non-abelian cases, namely Fourier sampling and the black-box approach. Throughout the paper, we highlight the mathematical notions required and exploited in this context, providing a cryptography-oriented perspective.

</details>


### [5] [Factor(T,U): Factored Cognition Strengthens Monitoring of Untrusted AI](https://arxiv.org/abs/2512.02157)
*Aaron Sandoval,Cody Rushing*

Main category: cs.CR

TL;DR: 本文探讨了AI控制领域，提出了基于分解认知（factored cognition）的控制协议，将一个复杂的任务交由可信模型分解为子任务，再由不可信模型单独解决，从而提高安全性。在APPS编码环境中测试，该方法将安全性能从41%提升至63%，但在APPS中用处有限，适用于更复杂的任务。


<details>
  <summary>Details</summary>
Motivation: 当前AI控制协议依赖弱监视器检测不安全行为，但在监视器难以理解的复杂任务上常常失效，因此需要更有效的安全控制方法。

Method: 开发基于分解认知的控制协议：可信模型分解任务，不可信模型独立解决每个子任务，结果重新组装。在APPS编码环境中实施，并用对抗性GPT-4.1 Nano进行红队测试。

Result: 分解认知的加入使安全性能从41%提升至63%，监视器性能提高是主要原因，而分解认知并未增加有能力LLM植入后门的难度。

Conclusion: 尽管在APPS中实用性低，但分解认知协议在更复杂的任务中具有提升AI控制安全性的潜力。

Abstract: The field of AI Control seeks to develop robust control protocols, deployment safeguards for untrusted AI which may be intentionally subversive. However, existing protocols that rely on weaker monitors to detect unsafe behavior often fail on complex tasks beyond the monitor's comprehension. We develop control protocols based on factored cognition, in which a trusted model decomposes a task, an untrusted model solves each resultant child task in isolation, and the results are reassembled into a full solution. These protocols may improve safety by several means, such as by simplifying the context for monitors, or by obscuring vulnerabilities in the environment. We implement our protocols in the APPS coding setting and red team them against backdoor attempts from an adversarial GPT-4.1 Nano. We find that: (i) Adding factored cognition to a trusted monitoring protocol can boost safety from 41% to 63%; (ii) Safety improves because monitor performance improves; (iii) Factored cognition makes it no harder for capable LLMs to write backdoors in APPS. While our protocols show low usefulness in APPS, they hold promise for more complex tasks.

</details>


### [6] [PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing](https://arxiv.org/abs/2512.02243)
*Md Abdul Ahad Minhaz,Zannatul Zahan Meem,Md. Shohrab Hossain*

Main category: cs.CR

TL;DR: PhishSnap是一个基于感知哈希的钓鱼检测系统，通过截图比对实现即时本地检测，保护用户隐私。在10,000个URL数据集上达到0.79准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击利用人类信任窃取敏感信息，传统URL/HTML检测方法易受混淆和视觉欺骗影响。

Method: 开发浏览器扩展，捕获网页截图并计算视觉哈希值，与合法模板进行本地比对。使用2024年从PhishTank和Netcraft收集的10,000个URL数据集（训练/验证/测试比例70%/20%/10%）。

Result: 系统达到0.79准确率、0.76精确率和0.78召回率，证明视觉相似性检测有效。

Conclusion: 视觉相似性是一种可行的反钓鱼措施，本地推理确保隐私和低延迟，但数据集多样性受安全下架影响。

Abstract: Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \textbf{2024 dataset of 10,000 URLs} (70\%/20\%/10\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \textbf{0.79 accuracy}, \textbf{0.76 precision}, and \textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.

</details>


### [7] [CVE Breadcrumbs: Tracking Vulnerabilities Through Versioned Apache Libraries](https://arxiv.org/abs/2512.02259)
*Derek Garcia,Briana Lee,Ibrahim Matar,David Rickards,Andrew Zilnicki*

Main category: cs.CR

TL;DR: 该论文对Apache软件基金会生态系统中历史漏洞进行了分析，建立了包含24,285个库、1,285个CVE和157个CWE的数据集，研究漏洞的持续性、披露时间和修复实践。


<details>
  <summary>Details</summary>
Motivation: Apache生态系统是现代软件基础设施的重要组成部分，但广泛使用的组件（如Log4j、Tomcat）频繁成为高影响安全漏洞的目标（如Log4Shell事件），需要系统性分析漏洞模式以改善安全实践。

Method: 通过整理CVE和CWE的综合数据集，进行历史分析，考察漏洞重现趋势、披露时间线和修复实践，围绕四个研究问题展开。

Result: 研究发现Apache库中存在持续和重复的CWE，漏洞在解决前持续存在，披露与修复之间存在延迟，并提供了漏洞生命周期的详细时间线。

Conclusion: 研究提供了经验发现和面向开发者的建议，以改进安全编码实践、漏洞监控和修复策略，帮助提升Apache生态系统的安全性。

Abstract: The Apache Software Foundation (ASF) ecosystem underpins a vast portion of modern software infrastructure, powering widely used components such as Log4j, Tomcat, and Struts. However, the ubiquity of these libraries has made them prime targets for high-impact security vulnerabilities, as illustrated by incidents like Log4Shell. Despite their widespread adoption, Apache projects are not immune to recurring and severe security weaknesses. We conduct a historical analysis of the Apache ecosystem to follow the "breadcrumb trail of vulnerabilities" by compiling a comprehensive dataset of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). We examine trends in exploit recurrence, disclosure timelines, and remediation practices. Our analysis is guided by four key research questions: (1) What are the most persistent and repeated CWEs in Apache libraries? (2) How long do CVEs persist before being addressed? (3) What is the delay between CVE introduction and official disclosure? and (4) How long after disclosure are CVEs remediated? We present a detailed timeline of vulnerability lifecycle stages across Apache libraries and offer insights to improve secure coding practices, vulnerability monitoring, and remediation strategies. Our contributions include a curated dataset covering 24,285 Apache libraries, 1,285 CVEs, and 157 CWEs, along with empirical findings and developer-focused recommendations.

</details>


### [8] [COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers](https://arxiv.org/abs/2512.02318)
*Junyu Wang,Changjia Zhu,Yuanbo Zhou,Lingyao Li,Xu He,Junjie Xiong*

Main category: cs.CR

TL;DR: 本文研究多模态大语言模型如何削弱视觉验证码的安全保证，发现攻击者可以利用现成模型廉价自动化破解验证码。评估了7个主流MLLM在18种验证码任务上的表现，发现当前模型可可靠解决识别类和低交互类验证码，但精确定位和多步推理任务仍具挑战。


<details>
  <summary>Details</summary>
Motivation: 验证码作为区分人类和机器的重要安全机制，面临多模态大语言模型的威胁。研究旨在系统评估MLLMs对验证码安全性的实际影响。

Method: 评估7个商业和开源MLLM在18类真实验证码任务上的表现，指标包括单次准确率、有限重试成功率、端到端延迟和单次破解成本。分析提示工程和少样本演示对破解效果的影响。

Result: MLLM能以接近人类的成本和延迟可靠解决识别导向和低交互验证码任务；需要精确定位、多步空间推理或跨帧一致性的任务对当前模型仍困难。

Conclusion: 通过分析模型推理轨迹揭示成功/失败机制，为平台运营者提供验证码选择和强化的防御导向指南，讨论验证码在滥用缓解流程中的部署意义。

Abstract: This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation pipeline.Code Availability (https://anonymous.4open.science/r/Captcha-465E/).

</details>


### [9] [Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts](https://arxiv.org/abs/2512.02918)
*Wanxu Xia,Ziqiao Kong,Zhengwei Li,Yi Lu,Pan Li,Liqun Yang,Yang Liu,Xiapu Luo,Shaohua Li*

Main category: cs.CR

TL;DR: 本文提出了第一个针对Move智能合约的模糊测试框架Belobog，它能生成类型感知的有效交易来检测标准类型系统无法捕获的漏洞。


<details>
  <summary>Details</summary>
Motivation: Move语言虽然具有强大的类型系统来保证智能合约安全，但其类型系统无法检测所有漏洞，而现有模糊测试工具难以生成有效的Move交易来进行测试。

Method: Belogog首先基于Move类型系统构建类型图，然后基于类型图轨迹生成或变异交易，并设计了concolic执行器来处理复杂检查。

Result: 在109个真实Move合约项目上的测试显示，Belobog能检测100%的关键漏洞和79%的主要漏洞，并成功复现了Cetus和Nemo两个著名安全事件。

Conclusion: Belobog是第一个有效的Move智能合约模糊测试框架，能够显著提升Move生态系统的安全性。

Abstract: Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\% critical and 79\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.

</details>


### [10] [Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins](https://arxiv.org/abs/2512.02418)
*Yuexin Xiang,Yuchen Lei,SM Mahir Shazeed Rish,Yuanzhe Zhang,Qin Wang,Tsz Hon Yuen,Jiangshan Yu*

Main category: cs.CR

TL;DR: 本文构建了一个基于大语言模型的框架，将稳定币链上发行数据与链下披露声明对齐，以提高透明度和审计效率。


<details>
  <summary>Details</summary>
Motivation: 稳定币的透明度数据分散在可验证的链上轨迹和无结构的链下文本披露中，二者缺乏关联。

Method: 通过LLM进行文档解析和语义对齐，提取链下财务指标并映射到链上指标；整合多链发行记录和披露文件到模型上下文协议框架中。

Result: 量化了报告与实际流通量之间的差异，发现披露数据与可验证数据之间存在系统性差距。

Conclusion: LLM辅助分析增强了跨模态透明度，支持去中心化金融中的自动化数据驱动审计。

Abstract: Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).

</details>


### [11] [Equilibrium SAT based PQC: New aegis against quantum computing](https://arxiv.org/abs/2512.02598)
*Keum-Bae Cho*

Main category: cs.CR

TL;DR: 提出基于多重集合随机子集计数的新型公钥密码算法，具有快速、无需大数运算、易于扩展为量子抵抗密码系统等优势。


<details>
  <summary>Details</summary>
Motivation: 随着互联网和量子计算发展，传统公钥密码算法计算复杂度不断增加，需要更高效且量子安全的替代方案。

Method: 通过从多重集合中随机抽取子集并计算元素数量生成密文，并利用可满足性问题进行数学精炼。

Result: 算法速度显著快于现有公钥算法，无需大数运算可在任何设备运行，支持单公钥多私钥的量子抵抗扩展。

Conclusion: 该算法为量子计算时代提供了一种高效、轻量级且可扩展的公钥密码学新范式。

Abstract: Public-key cryptography algorithms have evolved towards increasing computational complexity to hide desired messages, which is accelerating with the development of the Internet and quantum computing. This paper introduces a novel public-key cryptography algorithm that generates ciphertexts by counting the number of elements in randomly extracted subsets from a multiset. After explaining the novel cryptographic concept, the process of mathematically refining it using satisfiability problems is described. The advantages of the proposed algorithm are: first, it is significantly faster than other public-key algorithms; second, it does not require big numbers, making it executable on any devices; and third, it can be easily extended into a public-key cryptosystem using a single public key and multiple private keys while maintaining quantum resistance.

</details>


### [12] [Semigroup action based on skew polynomial evaluation with applications to Cryptography](https://arxiv.org/abs/2512.02603)
*Daniel Camazón-Portela,Juan Antonio López-Ramos*

Main category: cs.CR

TL;DR: 论文引入了一种基于多项式赋值和左斜积函数概念的$\mathbb{F}_{q}\left[X; σ, δ\right]$环的作用，构建子集$\mathcal{T}(X)$以控制环的非交换性，并以此构建在Canetti-Krawczyk模型下安全的公钥交换协议。


<details>
  <summary>Details</summary>
Motivation: 探索斜多项式环的结构性质，利用其非交换特性来设计安全的密码学协议。

Method: 基于多项式赋值和左斜积函数定义环的作用，构造子集$\mathcal{T}(X)$来控制非交换性。

Result: 成功构建了一个在Canetti-Krawczyk安全模型下安全的公钥交换协议。

Conclusion: 该方法有效利用了斜多项式环的非交换性质，为密码学协议设计提供了新的思路。

Abstract: Through this work we introduce an action of the skew polynomial ring $\mathbb{F}_{q}\left[X; σ, δ\right]$ over $\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\mathcal{T}(X)\subset\mathbb{F}_{q}\left[X; σ, δ\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.

</details>


### [13] [CryptoQA: A Large-scale Question-answering Dataset for AI-assisted Cryptography](https://arxiv.org/abs/2512.02625)
*Mayar Elfares,Pascal Reisert,Tilman Dietz,Manpa Barman,Ahmed Zaki,Ralf Küsters,Andreas Bulling*

Main category: cs.CR

TL;DR: 提出了首个专门针对密码学的大规模问答数据集CryptoQA，包含200多万个QA对，并评估了15个主流大语言模型在密码学任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在通用NLP任务上表现出色，但在需要深度推理和数学分析的密码学任务上表现不佳，主要缺乏合适的评估和训练数据。

Method: 创建CryptoQA数据集，包含学术来源的200多万QA对和上下文元数据；评估15个SOTA LLM在事实准确性、数学推理、一致性等方面的表现。

Result: 发现LLM在密码学任务上存在显著性能缺陷，特别是在需要形式推理和精确数学知识的任务上；通过微调可提升性能。

Conclusion: 迫切需要专门针对密码学研发的LLM助手，CryptoQA可作为训练和评估密码学能力LLM的重要资源。

Abstract: Large language models (LLMs) excel at many general-purpose natural language processing tasks. However, their ability to perform deep reasoning and mathematical analysis, particularly for complex tasks as required in cryptography, remains poorly understood, largely due to the lack of suitable data for evaluation and training. To address this gap, we present CryptoQA, the first large-scale question-answering (QA) dataset specifically designed for cryptography. CryptoQA contains over two million QA pairs drawn from curated academic sources, along with contextual metadata that can be used to test the cryptographic capabilities of LLMs and to train new LLMs on cryptographic tasks. We benchmark 15 state-of-the-art LLMs on CryptoQA, evaluating their factual accuracy, mathematical reasoning, consistency, referencing, backward reasoning, and robustness to adversarial samples. In addition to quantitative metrics, we provide expert reviews that qualitatively assess model outputs and establish a gold-standard baseline. Our results reveal significant performance deficits of LLMs, particularly on tasks that require formal reasoning and precise mathematical knowledge. This shows the urgent need for LLM assistants tailored to cryptography research and development. We demonstrate that, by using CryptoQA, LLMs can be fine-tuned to exhibit better performance on cryptographic tasks.

</details>


### [14] [Decryption thorough polynomial ambiguity: noise-enhanced high-memory convolutional codes for post-quantum cryptography](https://arxiv.org/abs/2512.02822)
*Meir Ariel*

Main category: cs.CR

TL;DR: 提出一种基于有向图解密和噪声增强的高内存卷积码的后量子密码学新方法，安全裕度超过Classic McEliece方案2^200倍以上


<details>
  <summary>Details</summary>
Motivation: 需要开发能够抵抗量子计算攻击的密码学方案，同时提供更好的设计灵活性和可扩展性

Method: 使用随机化生成矩阵隐藏代数结构，在解密过程中故意注入强噪声来自多项式除法，通过有向图解码器阵列进行并行解密

Result: 合法接收者保持多项式时间解码，而攻击者面临指数级时间复杂性，支持任意明文长度和线性时间解密

Conclusion: 该方案是强大、可扩展且量子抵抗的公钥密码学的有前景候选方案

Abstract: We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [The 4/$δ$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee](https://arxiv.org/abs/2512.02080)
*PIerre Dantas,Lucas Cordeiro,Youcheng Sun,Waldir Junior*

Main category: cs.AI

TL;DR: 本论文提出了LLM验证器收敛定理，为LLM辅助的软件验证提供了首个具有可证明终止性和收敛性保证的形式化框架。


<details>
  <summary>Details</summary>
Motivation: 填补当前LLM验证方法缺乏理论基础的关键空白，解决验证过程不稳定、不可靠的问题。

Method: 将LLM与验证器的交互建模为离散时间马尔可夫链，引入错误减少概率(δ)作为关键参数。

Result: 证明了对于任何δ>0，程序都能几乎必然达到验证状态，期望迭代次数有界E[n]≤4/δ。通过超过90,000次实验验证了理论预测。

Conclusion: 建立了具有理论保证和实践验证的LLM辅助验证架构基础，为安全关键软件环境的部署提供了可预测的资源规划框架。

Abstract: The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($δ$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $δ> 0$, with an expected iteration count bounded by $\mathbb{E}[n] \leq 4/δ$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.

</details>


### [16] [From monoliths to modules: Decomposing transducers for efficient world modelling](https://arxiv.org/abs/2512.02193)
*Alexander Boyd,Franz Nowak,David Hyland,Manuel Baltieri,Fernando E. Rosas*

Main category: cs.AI

TL;DR: 本文提出了一种将复杂世界模型分解为可并行子组件的新框架，利用模块化交互实现高效建模。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景通常是模块化交互的，但现有世界模型计算需求高，需要更高效的建模方法。

Method: 开发了基于transducer的分解框架，将复杂模型分解为在独立输入输出空间运行的子transducer。

Result: 实现了可并行、可解释的模块化世界建模方案，支持分布式推理。

Conclusion: 为AI安全所需的结构透明性和实际推理所需的计算效率之间搭建了桥梁。

Abstract: World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.

</details>


### [17] [Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence](https://arxiv.org/abs/2512.02280)
*Noorbakhsh Amiri Golilarz,Sindhuja Penchala,Shahram Rahimi*

Main category: cs.AI

TL;DR: 论文指出当前AI系统在自我监控、元认知、自适应学习等方面存在七项核心缺陷，建议通过借鉴神经认知原理来发展具备认知自主性的AI架构。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在感知、语言和推理等领域取得快速进展，但现有系统在动态环境中缺乏自我监控、自我纠正和自主行为调节的能力，限制了其实现稳健泛化和终身适应性。

Method: 通过对比人工系统与生物认知，整合AI研究、认知科学和神经科学的见解，识别并分析了七项核心缺陷，并基于神经认知原理提出了前瞻性架构方案。

Result: 明确指出当前AI架构（包括深度学习和基于Transformer的系统）因结构性限制无法实现强大泛化、终身适应性和真实世界自主性，单纯扩大规模无法解决这些问题。

Conclusion: 倡导向认知基础的AI（认知自主性）进行范式转变，使其具备自我导向适应、动态表征管理和有意图的目标导向行为，同时配备改革性监督机制以确保可解释性、可治理性和与人类价值观的一致性。

Abstract: Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fun- damentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self- monitoring, lack of meta-cognitive awareness, fixed and non- adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust general- ization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.

</details>


### [18] [Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization](https://arxiv.org/abs/2512.02302)
*Varun Kumar Dasoju,Qingsu Cheng,Zeyun Yu*

Main category: cs.AI

TL;DR: 开发了一个基于量子启发的医学图像分割框架，仅用599张训练图像就在乳腺细胞分割中达到了95.5%的Dice分数，显著减少了标注需求。


<details>
  <summary>Details</summary>
Motivation: 医学图像标注需要大量专家时间和专业知识，特别是乳腺上皮细胞标注极为耗时，成为临床AI发展的瓶颈。

Method: 采用EfficientNet-B7/UNet++架构，通过多尺度Gabor滤波器实现量子启发边缘增强创建第四输入通道；设计了稳定多组件损失函数结合自适应Dice损失和边界感知项；引入基于复杂度的加权采样策略。

Result: 在验证集（129张图像）上达到Dice分数95.5%±0.3%和IoU 91.2%±0.4%；量子增强使边界准确率提升2.1%，加权采样提高小病灶检测3.8%。

Conclusion: 该框架通过突破性的少标注高性能，显著减少医学专家标注时间，解决了临床感知AI开发的关键瓶颈。

Abstract: Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.

</details>


### [19] [OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning](https://arxiv.org/abs/2512.02306)
*Boyu Zhu,Xiaofei Wen,Wenjie Jacky Mo,Tinghui Zhu,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: 提出的OmniGuard是首个全模态护栏框架，通过精心挑选的大型数据集和专家模型蒸馏，实现了跨文本、图像、视频和音频的统一安全防护。


<details>
  <summary>Details</summary>
Motivation: 现有的护栏研究主要针对单模态设置，采用二元分类方法，缺乏在多模态任务中的鲁棒性。

Method: 构建包含21万多样本的全模态安全数据集，通过专家模型蒸馏生成结构化安全标签和安全评论，训练具有深思熟虑推理能力的OmniGuard模型。

Result: 在15个基准测试上的广泛实验表明，OmniGuard在多种多模态安全场景中表现出强大的有效性和泛化能力。

Conclusion: OmniGuard提供了一个统一框架，可在全模态中执行策略并降低风险，为构建更强大和稳健的全模态防护系统铺平了道路。

Abstract: Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.

</details>


### [20] [Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective](https://arxiv.org/abs/2512.02340)
*Qiyao Xue,Weichen Liu,Shiqi Wang,Haoming Wang,Yuyang Wu,Wei Gao*

Main category: cs.AI

TL;DR: ReMindView-Bench基准测试揭示了视觉语言模型在多视图空间推理中的系统弱点，特别是在跨视图对齐和视角转换方面。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多视图环境下难以保持几何连贯性和跨视图一致性的空间推理能力，缺乏能够将多视图推理与单视图感知和时间因素隔离的细粒度基准测试。

Method: 提出ReMindView-Bench基准，通过系统变化视点空间模式和查询类型来评估VLMs构建、对齐和维护空间心理模型的能力。采用显式分阶段分析（LLM-as-a-judge和自一致性提示）和隐式分析（线性探测和熵动力学）方法。

Result: 评估15个现有VLM发现它们在多视图空间推理中存在一致的跨视图对齐和视角转换失败。VLMs在帧内感知表现良好，但在跨视图信息整合时性能急剧下降。隐式分析显示任务相关信息逐渐丢失，正确和错误推理轨迹之间存在不确定性分离。

Conclusion: 该研究为VLM空间推理提供了认知基础的诊断，揭示了多视图空间心理模型在推理过程中的形成、退化和不稳定机制。ReMindView-Bench基准可作为评估和改进VLM空间推理能力的有效工具。

Abstract: Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.

</details>


### [21] [PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing](https://arxiv.org/abs/2512.02589)
*Junyi Hou,Andre Lin Huikai,Nuo Chen,Yiwei Gong,Bingsheng He*

Main category: cs.AI

TL;DR: 提出了PaperDebugger，一款内嵌于LaTeX编辑器（如Overleaf）的多智能体、插件式学术写作助手，解决了现有工具无法与编辑器深度交互的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI写作助手与编辑器分离，无法支持基于文档状态、结构和修订历史的上下文感知操作，限制了在LaTeX编辑器内的智能辅助能力。

Method: 设计基于Chrome扩展、Kubernetes原生编排层和Model Context Protocol（MCP）工具链的系统，实现可靠的编辑器双向同步、细粒度版本控制、安全状态管理、多智能体调度和外部工具集成。

Result: 开发出功能完整的演示系统，支持本地化编辑、结构化评审、并行智能体执行和基于差异的更新，用户界面侵入性最小；早期用户数据分析显示积极的使用参与度。

Conclusion: PaperDebugger验证了在编辑器内部集成基于LLM的智能写作助手的可行性，为学术写作工作流提供了更深度、上下文感知的AI支持。

Abstract: Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.

</details>


### [22] [Synthetic Error Injection Fails to Elicit Self-Correction In Language Models](https://arxiv.org/abs/2512.02389)
*David X. Wu,Shreyas Kapur,Anant Sahai,Stuart Russell*

Main category: cs.AI

TL;DR: 监督学习加错误注入的方法无法有效激发语言模型的自我修正能力，需要采用强化学习方案


<details>
  <summary>Details</summary>
Motivation: 强化学习方法虽然能激发大语言模型的推理和自我修正能力但计算成本高昂，作者尝试从自动驾驶和机器人技术中汲取灵感，探索通过监督学习加人工错误注入的方法来替代RL

Method: 在推理链中插入人工设计错误后进行掩码处理，然后监督模型识别并修正这些错误

Result: 该方法即使在简单任务和多模型上都未能显著提升性能，模型即使发现了错误也常常重复原有错误

Conclusion: 合成错误与在线错误的分布差异显著削弱了微调后的错误修正能力，实验结果解释了为什么在线强化学习对激发自我修正能力具有独特优势

Abstract: Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.

</details>


### [23] [Guided Self-Evolving LLMs with Minimal Human Supervision](https://arxiv.org/abs/2512.02472)
*Wenhao Yu,Zhenwen Liang,Chengsong Huang,Kishan Panaganti,Tianqing Fang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: R-Few框架通过指导性自我博弈实现AI稳定自进化，在数学和推理任务上取得显著提升


<details>
  <summary>Details</summary>
Motivation: 解决AI自进化过程中出现的概念漂移、多样性崩溃和错误进化等问题，实现稳定可控的自进化

Method: 提出R-Few框架：基于Challenger-Solver的指导性自我博弈，通过上下文接地和混合训练融入轻量级人工监督

Result: Qwen3-8B-Base在数学任务上比R-Zero提升3.0分，性能与使用20倍人类数据的General-Reasoner相当

Conclusion: R-FFew证明了指导性自进化方法的有效性，能够稳定模型协同进化过程，减少概念漂移

Abstract: AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.

</details>


### [24] [COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes](https://arxiv.org/abs/2512.02499)
*Yongkai Liu,Helena Feng,Bin Jiang,Yixin Wang,Max Wintermark,David S. Liebeskind,Michael Moseley,Maarten Lansberg,Gregory Albers,Jeremy Heit,Greg Zaharchuk*

Main category: cs.AI

TL;DR: COPE是一个基于思维链推理的轻量级LLM框架，用于从非结构化临床笔记预测急性缺血性卒中90天功能结局，性能媲美GPT-4且优于传统模型


<details>
  <summary>Details</summary>
Motivation: 临床笔记包含丰富信息但非结构化特点限制了传统预测模型的使用，需要开发能利用这些数据的智能预测工具

Method: 使用两阶段LLaMA-3-8B模型：首先生成临床推理，然后输出mRS评分预测，并与GPT-4、ClinicalBERT等模型对比

Result: COPE的MAE为1.01，±1准确率74.4%，精确准确率32.8%，性能与GPT-4.1相当，优于其他基线模型

Conclusion: COPE为从非结构化临床文本进行结局预测提供了准确、实用、轻量且可解释的开源解决方案

Abstract: Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.

</details>


### [25] [Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration](https://arxiv.org/abs/2512.02530)
*Yuxiang He,Jian Zhao,Yuchen Yuan,Tianle Zhang,Wei Cai,Haojie Cheng,Ziyan Shi,Ming Zhu,Haichuan Tang,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: Aetheria：基于多智能体辩论与协作的多模态可解释内容安全框架


<details>
  <summary>Details</summary>
Motivation: 数字内容爆炸式增长给内容安全带来挑战，当前基于单一模型或固定流程的审核系统在识别隐含风险和提供可解释判定过程方面存在局限

Method: 提出基于多智能体辩论协作的五核心智能体架构，通过动态相互说服的辩论机制，结合RAG知识检索进行多模态内容深度分析与裁决

Result: 在AIR-Bench基准上验证，Aetheria不仅能生成详细可追溯的审计报告，在整体内容安全准确性（特别是隐含风险识别）上显著优于基线方法

Conclusion: 该框架建立了透明可解释的范式，显著推进了可信AI内容审核领域的发展

Abstract: The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.

</details>


### [26] [Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction](https://arxiv.org/abs/2512.02610)
*Yubo Hou,Mohamed Ragab,Min Wu,Chee-Keong Kwoh,Xiaoli Li,Zhenghua Chen*

Main category: cs.AI

TL;DR: 提出TACDA方法解决机械剩余寿命预测中的领域差异问题，通过目标域重建和退化阶段聚类配对策略提升跨领域预测性能。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的机械剩余寿命预测方法通常假设训练和测试数据来自同一分布，但实际工业环境中存在领域差异问题。现有对抗领域适应方法忽视了目标域特定信息和退化阶段的一致性特征。

Method: 提出TACDA方法：1）在对抗适应过程中引入目标域重建策略，保留目标域特定信息的同时学习领域不变特征；2）开发聚类配对策略，实现相似退化阶段的一致对齐。

Result: 大量实验表明TACDA方法在两种不同评估指标上均显著优于现有最先进方法。

Conclusion: TACDA通过结合目标域重建和退化阶段对齐策略，有效解决了跨领域RUL预测中的领域差异问题，取得了优异的性能表现。

Abstract: Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.

</details>


### [27] [Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks](https://arxiv.org/abs/2512.02677)
*Zhiyuan He*

Main category: cs.AI

TL;DR: 本文发现标准Transformer架构在处理深度递归推理问题时存在局限性，并提出了一种新的循环定位替换流水线方法来改善深度泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在许多任务上表现出色，但在处理需要解决嵌套层次结构的递归推理问题时面临挑战，特别是深度泛化问题（处理比训练时更深的嵌套层次）。

Method: 开发了一种循环定位替换流水线，包含两个专门模型：定位器识别可解决的子表达式，替换器评估这些组件同时保持整体结构。在布尔代数、递归算术和命题逻辑三个领域进行了评估。

Result: 该方法有效缓解了在分布外递归深度上测试时的性能衰减问题，表明能够改善模型对深度递归问题的处理能力。

Conclusion: 标准Transformer架构难以维持类似栈的行为来跟踪多级嵌套依赖，而提出的循环定位替换方法为解决深度泛化挑战提供了有效途径。

Abstract: Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.

</details>


### [28] [Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding](https://arxiv.org/abs/2512.02699)
*Hyeongseop Rha,Jeong Hun Yeo,Junil Won,Se Jin Park,Yong Man Ro*

Main category: cs.AI

TL;DR: MIGR框架通过模态重要性引导推理，改善多模态情感理解的可靠性，减少推理漂移问题


<details>
  <summary>Details</summary>
Motivation: 现有方法存在推理漂移问题：模型逐渐依赖自身生成的文本而非多模态证据，且解释过度受视觉推理路径影响

Method: 引入模态重要性机制识别情感主导模态，采用两阶段框架（模态对齐监督微调+模态感知奖励优化）重组推理序列

Result: 在DFEW基准测试中将正确预测但情感不一致解释的比例从18.10%降至7.37%

Conclusion: 从情感主导模态开始推理能显著提升多模态情感理解的可信度

Abstract: In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.

</details>


### [29] [Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs](https://arxiv.org/abs/2512.02713)
*Theodoros Aivalis,Iraklis A. Klampanos,Antonis Troumpoukis,Joemon M. Jose*

Main category: cs.AI

TL;DR: 提出了一种基于知识图谱的生成模型输出溯源框架，利用多模态大语言模型从图像中提取结构化三元组，通过比较生成图像和训练图像的图谱来分析版权和透明度问题。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的强大，对透明度、问责制和版权侵权的担忧加剧。需要理解特定训练数据如何影响模型输出。

Method: 利用多模态大语言模型从图像中提取与领域本体对齐的结构化三元组，构建知识图谱。通过比较生成图像和训练图像的图谱来溯源。

Result: 通过局部模型的去学习实验和大规模模型的风格特定实验验证了方法的有效性。

Conclusion: 该框架支持开发促进人类协作、创造力和激发好奇心的AI系统。

Abstract: As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.

</details>


### [30] [Menta: A Small Language Model for On-Device Mental Health Prediction](https://arxiv.org/abs/2512.02716)
*Tianyi Zhang,Xiangyuan Xue,Lingyan Ruan,Shiya Fu,Feng Xia,Simon D'Alfonso,Vassilis Kostakos,Hong Jia*

Main category: cs.AI

TL;DR: 研究者开发了名为Menta的小型语言模型，针对社交媒体数据进行多任务心理健康预测，在保持模型轻量化的同时，性能优于未微调的SLM基线，并在特定任务中媲美更大的LLM，支持实时设备部署。


<details>
  <summary>Details</summary>
Motivation: 心理健康问题影响广泛，但早期检测受限；大型语言模型（LLM）在心理健康应用中虽有潜力，但计算资源需求高，难以实际部署；小型语言模型（SLM）作为轻量替代方案，但在基于社交媒体的心理健康预测方面研究不足。

Method: 提出Menta模型，首个针对社交媒体数据优化的多任务心理健康预测SLM；采用基于LoRA的框架、跨数据集策略和平衡精度导向的损失函数，联合训练六个分类任务。

Result: 与九个先进SLM基线相比，Menta在抑郁、压力和自杀倾向等任务上平均提升15.2%；在抑郁和压力分类任务上，性能优于130亿参数LLM，而模型大小仅为其约1/3；在iPhone 15 Pro Max上实现实时部署，仅需约3GB内存。

Conclusion: Menta展示了可扩展、保护隐私的心理健康监测潜力，为资源受限环境下的实际应用提供了可行方案；代码已开源。

Abstract: Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/

</details>


### [31] [StockMem: An Event-Reflection Memory Framework for Stock Forecasting](https://arxiv.org/abs/2512.02720)
*He Wang,Wenyilin Xiao,Songqiao Han,Hailiang Huang*

Main category: cs.AI

TL;DR: StockMem：一种双层内存框架，通过事件整合与纵向跟踪构建时态事件知识库，结合因果经验进行股价预测，优于现有方法并提供可解释推理。


<details>
  <summary>Details</summary>
Motivation: 股价预测受市场波动和实时事件影响，现有LLM在金融应用中受噪声新闻数据和缺乏明确答案限制，通用内存架构难以识别价格变动的关键驱动因素。

Method: 提出StockMem事件反思双层内存框架：将新闻结构化为事件，横向整合每日事件，纵向跟踪事件演变提取反映市场预期差异的增量信息，构建时态事件知识库和因果经验反思知识库。

Result: 实验表明StockMem优于现有内存架构，通过追踪影响价格的信息链提供优越的可解释推理，增强金融预测的决策透明度。

Conclusion: StockMem通过结构化事件分析和历史场景推理，有效解决股价预测中的噪声和解释性问题，为基于文本的金融预测提供新途径。

Abstract: Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.

</details>


### [32] [AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping](https://arxiv.org/abs/2512.02726)
*Md Abdul Kadir,Sai Suresh Macharla Vasu,Sidharth S. Nair,Daniel Sonntag*

Main category: cs.AI

TL;DR: 大型语言模型在审计中的异常检测方面优于基于规则的方法和传统机器学习方法，并提供更好的可解释性。


<details>
  <summary>Details</summary>
Motivation: 审计师依赖日记账测试检测税务相关分类账异常，但基于规则的方法会产生大量误报且难以检测微妙异常。

Method: 在合成和真实匿名分类账上对LLaMA和Gemma等最先进的大型语言模型进行基准测试，并与日记账测试和机器学习基线进行比较。

Result: 大型语言模型持续优于传统基于规则的日记账测试和经典机器学习基线，同时提供自然语言解释增强可解释性。

Conclusion: 结果突出了AI增强审计的潜力，人类审计师与基础模型合作可加强财务完整性。

Abstract: Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.

</details>


### [33] [Self-Improving AI Agents through Self-Play](https://arxiv.org/abs/2512.02731)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 本文提出了一个动力学系统的模态理论框架，将智能体建模为由计算资源参数化的流，并推导了保证自改进稳定性的方差不等式。


<details>
  <summary>Details</summary>
Motivation: 现有工作仅将AAI能力分数定义为智能体表示空间上的静态泛函，需要将其扩展为考虑动力学演化过程的框架。

Method: 引入递归的生成器-验证器-更新器(GVU)算子，证明其在参数流形上生成向量场，并将自改进系数定义为能力泛函沿该流的李导数。

Result: 推导出方差不等式这一谱条件，证明生成和验证的组合噪声足够小时可保证自改进稳定。该框架统一了LSP、自校正和合成数据引导等多种方法。

Conclusion: GVU算子为理解智能体自改进提供了统一的形式化框架，STaR、SPIN、Reflexion、GANs和AlphaZero等架构都是其特定拓扑实现。

Abstract: We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $ν_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $Θ$, and we identify the coefficient of self-improvement $κ$ as the Lie derivative of the capability functional along this flow.
  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $κ> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.
  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.

</details>


### [34] [A Framework for Causal Concept-based Model Explanations](https://arxiv.org/abs/2512.02735)
*Anna Rodum Bjøru,Jacob Lysnæs-Larsen,Oskar Jørgensen,Inga Strümke,Helge Langseth*

Main category: cs.AI

TL;DR: 这篇论文提出了一个基于因果概念的事后可解释人工智能(XAI)框架，强调解释需要同时具备可理解性和对模型的忠实性。


<details>
  <summary>Details</summary>
Motivation: 现有非解释性AI模型的黑箱特性使得解释难以同时满足可理解性和忠实性要求，需要一个统一的框架来解决这一问题。

Method: 通过计算概念干预的充分概率来生成局部和全局解释，并使用CelebA数据集上的分类器作为概念验证模型。

Result: 展示了示例解释，证明了框架通过清晰的概念词汇表实现可理解性，并通过强调框架假设来确保忠实性。

Conclusion: 该因果概念XAI框架成功平衡了解释的可理解性和忠实性，但需要确保解释生成和解释解读的上下文一致性。

Abstract: This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.

</details>


### [35] [Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control](https://arxiv.org/abs/2512.02814)
*Yongrui Yu,Zhongzhen Huang,Linjie Mu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: Radiologist Copilot是一个具备工具编排能力的AI助手，通过自动化放射学报告生成和质量控制来辅助放射科医生


<details>
  <summary>Details</summary>
Motivation: 放射学报告撰写耗时且易出错，现有自动方法主要关注报告生成而忽略了质量控制这个关键环节

Method: 利用大语言模型作为推理核心，通过区域定位、定向区域分析、模板选择和自适应优化等编排工具模拟放射科医生的工作流程

Result: 实验结果表明Radiologist Copilot在放射学报告任务上显著优于现有的最先进方法

Conclusion: 该系统能够实现准确、完整和高效的放射学报告，提高临床工作效率

Abstract: Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.

</details>


### [36] [The future of AI in critical mineral exploration](https://arxiv.org/abs/2512.02879)
*Jef Caers*

Main category: cs.AI

TL;DR: 提出基于AI的矿产勘探科学方法，通过贝叶斯主义和证伪原则减少认知偏差，利用无监督学习和人在环AI优化数据采集


<details>
  <summary>Details</summary>
Motivation: 过去20年尽管投资增加但新矿产发现减少，需要更有效的勘探方法

Method: 基于贝叶斯主义和证伪原则的新科学方法，AI辅助生成竞争性地质假说并优化数据采集决策

Result: 开发了实用的勘探协议模板，通过不确定性量化指导数据采集顺序

Conclusion: AI驱动的科学方法有望降低勘探成本，提高发现效率

Abstract: The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [37] [Process-Centric Analysis of Agentic Software Systems](https://arxiv.org/abs/2512.02393)
*Shuyang Liu,Yang Chen,Rahul Krishna,Saurabh Sinha,Jatin Ganhotra,Reyhan Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出了Graphectory方法来分析和评估智能体软件系统的执行轨迹，超越传统的结果导向评估方法。


<details>
  <summary>Details</summary>
Motivation: 智能体系统具有随机性和适应性特征，传统的结果导向评估方法无法深入理解其推理、规划和行动过程。

Method: 通过图结构编码智能体系统的时空和语义关系，设计了过程中心的度量标准分析智能体工作流质量。

Result: 对4000个轨迹的分析表明：提示质量与LLM强度影响决策复杂性；问题难度和LLM影响解决策略；成功系统仍存在效率问题。

Conclusion: Graphectory提供了系统化分析智能体系统过程的框架，揭示了传统评估方法无法发现的效率和行为模式问题。

Abstract: Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.
  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.

</details>


### [38] [Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System](https://arxiv.org/abs/2512.02567)
*Martin Weiss,Jesko Hecking-Harbusch,Jochen Quante,Matthias Woehrle*

Main category: cs.SE

TL;DR: 论文探讨了自动化C-to-Rust代码翻译系统中，反馈循环、LLM选择和代码扰动对翻译质量的影响。研究发现，反馈循环能缩小不同LLM的性能差距，代码扰动多样性甚至能提升系统表现。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI在软件工程中应用广泛，但自动化方法需要更高可靠性才能用于工业实践。本文重点研究影响结果质量的三个关键因素：反馈循环、LLM选择和代码扰动。

Method: 基于生成-检查模式的C-to-Rust翻译系统，通过自动检查生成代码的可编译性和行为等价性，对不合格结果进行反馈循环修复。通过控制三个变量进行对比实验。

Result: 无反馈循环时LLM选择对翻译成功率影响显著；引入反馈循环后模型间差异减小。代码扰动提供的多样性还能提升系统性能和鲁棒性。

Conclusion: 反馈循环是提升自动化代码翻译系统可靠性的关键机制，能有效弥补不同LLM的性能差异，而行为保持的代码扰动可进一步增强系统稳定性。

Abstract: The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.
  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.
  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.

</details>


### [39] [Integrative Analysis of Risk Management Methodologies in Data Science Projects](https://arxiv.org/abs/2512.02728)
*Sabrina Delmondes da Costa Feitosa*

Main category: cs.SE

TL;DR: 本研究比较分析了数据科学项目中的主要风险管理方法，识别了传统方法的局限性和新兴框架的优势，提出了结合技术效率、组织对齐和伦理实践的混合框架方向。


<details>
  <summary>Details</summary>
Motivation: 数据科学项目失败率高，主要由于技术限制、组织局限和风险管理不足。现有方法对新兴风险（如伦理和社会技术风险）覆盖有限，需要系统性分析现有方法论以改进实践。

Method: 采用整合性文献综述方法，使用索引数据库和结构化协议进行文献筛选与内容分析。比较了ISO 31000、PMBOK风险管理、NIST RMF等标准，以及CRISP-DM和DS EthiCo RMF等数据科学特定框架。

Result: 研究发现传统风险管理方法对新兴风险覆盖不足，而现代模型（如DS EthiCo RMF）提供了能整合伦理监督、治理和持续监控的多维结构。

Conclusion: 研究为开发平衡技术效率、组织对齐和负责任数据实践的混合框架提供了理论支持，并指出了未来研究的方向和空白。

Abstract: Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.

</details>


### [40] ["Can you feel the vibes?": An exploration of novice programmer engagement with vibe coding](https://arxiv.org/abs/2512.02750)
*Kiev Gama,Filipe Calegario,Victoria Jackson,Alexander Nolte,Luiz Augusto Morais,Vinicius Garcia*

Main category: cs.SE

TL;DR: 本文探讨了新兴的"氛围编程"教育价值，通过在巴西大学组织31名参与者进行9小时黑客松，分析AI辅助编程对新手学习的影响。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和AI辅助编程兴起，"氛围编程"通过自然语言提示创建软件，有望 democratize 软件开发，但其教育意义尚未充分探索。

Method: 通过包含观察、离场调查和半结构化访谈的混合方法，研究9个跨学科团队在黑客松中的创意过程、工具使用、协作动态和学习成果。

Result: 氛围编程实现了快速原型设计和跨学科协作，参与者培养了提示工程技能；但也存在构思过早收敛、代码质量不均、对核心软件工程实践参与有限等问题。

Conclusion: 黑客松可作为低风险学习环境，但需要结合发散思维支架、AI输出批判性评估和对生产质量的实际期望。

Abstract: Emerging alongside generative AI and the broader trend of AI-assisted coding, the term "vibe coding" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.

</details>


### [41] [Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior](https://arxiv.org/abs/2512.02795)
*Marcus Kessel*

Main category: cs.SE

TL;DR: 论文提出了一种基于持续行为观察的代码行为分析基础设施——观察湖仓（Observation Lakehouses），通过动态执行数据捕获和SQL查询实现大规模行为分析。


<details>
  <summary>Details</summary>
Motivation: 当前代码生成大模型主要基于静态代码训练，容易学习到有缺陷的代码模式。由于语义属性难以静态判定，需要动态执行观察来获取真实功能行为。

Method: 构建基于Apache Parquet + Iceberg + DuckDB的观察湖仓，采用持续刺激-响应立方体（SRCs）结构，通过仅追加表存储执行观测数据，支持按需SQL查询生成行为视图。

Result: 在509个问题基准测试中，成功摄入860万行观测数据（<51MiB），在笔记本电脑上实现<100ms的SRM/SRC视图重构和聚类，证明无需分布式集群即可实现持续行为挖掘。

Conclusion: 观察湖仓使行为真实数据成为运行时数据的一等公民，为基于行为的模型评估和训练提供了基础设施路径。

Abstract: Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse

</details>


### [42] [Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits](https://arxiv.org/abs/2512.02898)
*Pedro Orvalho,Marta Kwiatkowska,Mikoláš Janota,Vasco Manquinho*

Main category: cs.SE

TL;DR: 一篇介绍CFaults工具用于C软件和布尔电路多重故障定位的研究论文


<details>
  <summary>Details</summary>
Motivation: 现有的基于公式的故障定位方法在处理多重故障时无法保证跨所有失败测试的诊断集一致性，且可能产生非最小子集的冗余诊断

Method: 开发CFaults工具，利用基于模型的诊断方法，将所有失败测试用例聚合到统一的MaxSAT公式中

Result: 实验表明CFaults在C软件故障定位上比BugAssist、SNIPER和HSD更快，在ISCAS85基准测试中虽稍慢但仍有竞争力，且只产生最小子集诊断

Conclusion: CFaults方法能保证观察一致性，简化故障定位流程，并在多个基准测试中表现出优越性能

Abstract: Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.
  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [43] [A unified framework for equation discovery and dynamic prediction of hysteretic systems](https://arxiv.org/abs/2512.02408)
*Siyuan Yang,Wei Liu,Zhilu Lai*

Main category: cs.CE

TL;DR: 本文提出了一个统一框架，结合内部变量学习和符号回归，直接从数据中发现迟滞系统的显式控制方程，无需预定义模型库。


<details>
  <summary>Details</summary>
Motivation: 现有迟滞模型（如Bouc-Wen模型）依赖理想化假设和参数校准，而现有的方程发现方法通常系统特定或依赖预定义库，限制了灵活性和捕捉隐藏机制的能力。

Method: 开发一个统一框架，集成内部变量学习和符号回归，自动提取内部迟滞变量，直接从数据中发现显式控制方程。

Result: 该框架能够自动发现迟滞系统的控制方程，并自然支持动态响应的预测。

Conclusion: 这项工作为迟滞动力学的方程发现和表征提供了系统视角和方法，为这类问题定义了一个统一框架。

Abstract: Hysteresis is a nonlinear phenomenon with memory effects, where a system's output depends on both its current state and past states. It is prevalent in various physical and mechanical systems, such as yielding structures under seismic excitation, ferromagnetic materials, and piezoelectric actuators. Analytical models like the Bouc-Wen model are often employed but rely on idealized assumptions and careful parameter calibration, limiting their applicability to diverse or mechanism-unknown behaviors. Existing equation discovery approaches for hysteresis are often system-specific or rely on predefined model libraries, which limit their flexibility and ability to capture the hidden mechanisms. To address these, this research develops a unified framework that integrates learning of internal variables (commonly used in modeling hysteresis) and symbolic regression to automatically extract internal hysteretic variable, and discover explicit governing equations directly from data without predefined libraries as required by methods such as sparse identification of nonlinear dynamics (SINDy). Solving the discovered equations naturally enables prediction of the dynamic responses of hysteretic systems. This work provides a systematic view and approach for both equation discovery and characterization of hysteretic dynamics, defining a unified framework for these types of problems.

</details>


### [44] [The Invisible Hand: Characterizing Generative AI Adoption and its Effects on An Online Freelancing Market](https://arxiv.org/abs/2512.02509)
*Yiming Zhu,Gareth Tyson,Pan Hui*

Main category: cs.CE

TL;DR: 研究新冠疫情后自由职业平台的变化，重点分析生成式AI技术特别是ChatGPT对自由职业市场需求和工作者参与度的影响


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI技术引发广泛讨论，但缺乏关于其在自由职业市场采用情况及其对工作需求和工作者参与影响的实证研究

Method: 基于Freelancer.com平台的大规模数据分析，包含180万个工作岗位发布和380万用户数据

Result: 识别了生成式AI采纳相关岗位的出现，确定了ChatGPT在自由职业市场的主导地位，分析了相关岗位的技能要求和任务类型

Conclusion: 研究为理解AI时代自由职业市场演变提供了洞察，展示了生成式AI对就业、技能和用户行为的全面影响

Abstract: Since the COVID-19 pandemic, freelancing platforms have experienced significant growth in both worker registrations and job postings. However, the rise of generative AI (GenAI) technologies has raised questions about how it affect the job posting in freelancer market. Despite growing discussions, there is limited empirical research on the GenAI adoption and its effect on job demand and worker engagement. We present a large-scale analysis of Freelancer.com, utilizing over 1.8 million job posts and 3.8 million users. We investigate the emergence of jobs with the adoption of GenAI and identify leading position of ChatGPT in the freelancing market. With a focus on ChatGPT related jobs, we inspect their specific skill requirements, and the tasks that workers are asked to perform. Our findings provide insights into the evolving landscape of freelancing in the age of AI, offering a comprehensive profile of GenAI's effects on employment, skills, and user behaviors in freelancing market.

</details>


### [45] [Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation](https://arxiv.org/abs/2512.02710)
*Yuan Wang,Shujian Gao,Jiaxiang Liu,Songtao Jiang,Haoxiang Xia,Xiaotian Zhang,Zhaolu Kang,Yemin Wang,Zuozhu Liu*

Main category: cs.CE

TL;DR: 提出HiMed-RL分层医学奖励学习框架，通过标记级流畅性、概念级事实对齐和语义级诊断一致性三层次奖励机制，显著提升了医学报告生成的临床质量


<details>
  <summary>Details</summary>
Motivation: 解决现有医学报告生成方法虽然能生成流畅文本但存在临床幻觉问题，导致医学错误无法实际部署的挑战

Method: 分层医学奖励学习框架包含三个层次：token级确保语言流畅性，concept级对齐医学术语与专家知识，semantic级使用专用LLM验证器评估诊断一致性

Result: HiMed-3B模型在域内和域外基准测试中均达到最先进性能，特别是在域外测试中比次优基线提升12.1%

Conclusion: 该框架为生成既提高流畅性又保证临床细粒度质量的报告提供了稳健范例，解决了医学报告生成中的可信度问题

Abstract: Automatic medical report generation can greatly reduce the workload of doctors, but it is often unreliable for real-world deployment. Current methods can write formally fluent sentences but may be factually flawed, introducing serious medical errors known as clinical hallucinations, which make them untrustworthy for diagnosis. To bridge this gap, we introduce HiMed-RL, a Hierarchical Medical Reward Learning Framework designed to explicitly prioritize clinical quality. HiMed-RL moves beyond simple text matching by deconstructing reward learning into three synergistic levels: it first ensures linguistic fluency at the token-level, then enforces factual grounding at the concept-level by aligning key medical terms with expert knowledge, and finally assesses high-level diagnostic consistency at the semantic-level using a specialized LLM verifier. This hierarchical reward is implemented via a Human-inspired Dynamic Reward Adjustment, a strategy which first teaches the model to learn basic facts before progressing to more complex diagnostic reasoning. Experimentally, HiMed-3B achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks, particularly on the latter, with an improvement of 12.1% over the second-best baseline. Our work provides a robust paradigm for generating reports that not only improve fluency but clinical fine-grained quality.

</details>
