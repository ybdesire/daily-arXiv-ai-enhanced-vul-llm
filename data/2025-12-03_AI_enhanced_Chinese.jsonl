{"id": "2512.02408", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.02408", "abs": "https://arxiv.org/abs/2512.02408", "authors": ["Siyuan Yang", "Wei Liu", "Zhilu Lai"], "title": "A unified framework for equation discovery and dynamic prediction of hysteretic systems", "comment": null, "summary": "Hysteresis is a nonlinear phenomenon with memory effects, where a system's output depends on both its current state and past states. It is prevalent in various physical and mechanical systems, such as yielding structures under seismic excitation, ferromagnetic materials, and piezoelectric actuators. Analytical models like the Bouc-Wen model are often employed but rely on idealized assumptions and careful parameter calibration, limiting their applicability to diverse or mechanism-unknown behaviors. Existing equation discovery approaches for hysteresis are often system-specific or rely on predefined model libraries, which limit their flexibility and ability to capture the hidden mechanisms. To address these, this research develops a unified framework that integrates learning of internal variables (commonly used in modeling hysteresis) and symbolic regression to automatically extract internal hysteretic variable, and discover explicit governing equations directly from data without predefined libraries as required by methods such as sparse identification of nonlinear dynamics (SINDy). Solving the discovered equations naturally enables prediction of the dynamic responses of hysteretic systems. This work provides a systematic view and approach for both equation discovery and characterization of hysteretic dynamics, defining a unified framework for these types of problems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u5185\u90e8\u53d8\u91cf\u5b66\u4e60\u548c\u7b26\u53f7\u56de\u5f52\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u8fdf\u6ede\u7cfb\u7edf\u7684\u663e\u5f0f\u63a7\u5236\u65b9\u7a0b\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u6a21\u578b\u5e93\u3002", "motivation": "\u73b0\u6709\u8fdf\u6ede\u6a21\u578b\uff08\u5982Bouc-Wen\u6a21\u578b\uff09\u4f9d\u8d56\u7406\u60f3\u5316\u5047\u8bbe\u548c\u53c2\u6570\u6821\u51c6\uff0c\u800c\u73b0\u6709\u7684\u65b9\u7a0b\u53d1\u73b0\u65b9\u6cd5\u901a\u5e38\u7cfb\u7edf\u7279\u5b9a\u6216\u4f9d\u8d56\u9884\u5b9a\u4e49\u5e93\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u548c\u6355\u6349\u9690\u85cf\u673a\u5236\u7684\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u96c6\u6210\u5185\u90e8\u53d8\u91cf\u5b66\u4e60\u548c\u7b26\u53f7\u56de\u5f52\uff0c\u81ea\u52a8\u63d0\u53d6\u5185\u90e8\u8fdf\u6ede\u53d8\u91cf\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u53d1\u73b0\u663e\u5f0f\u63a7\u5236\u65b9\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u8fdf\u6ede\u7cfb\u7edf\u7684\u63a7\u5236\u65b9\u7a0b\uff0c\u5e76\u81ea\u7136\u652f\u6301\u52a8\u6001\u54cd\u5e94\u7684\u9884\u6d4b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8fdf\u6ede\u52a8\u529b\u5b66\u7684\u65b9\u7a0b\u53d1\u73b0\u548c\u8868\u5f81\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89c6\u89d2\u548c\u65b9\u6cd5\uff0c\u4e3a\u8fd9\u7c7b\u95ee\u9898\u5b9a\u4e49\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u3002"}}
{"id": "2512.02509", "categories": ["cs.CE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.02509", "abs": "https://arxiv.org/abs/2512.02509", "authors": ["Yiming Zhu", "Gareth Tyson", "Pan Hui"], "title": "The Invisible Hand: Characterizing Generative AI Adoption and its Effects on An Online Freelancing Market", "comment": "Work in progress", "summary": "Since the COVID-19 pandemic, freelancing platforms have experienced significant growth in both worker registrations and job postings. However, the rise of generative AI (GenAI) technologies has raised questions about how it affect the job posting in freelancer market. Despite growing discussions, there is limited empirical research on the GenAI adoption and its effect on job demand and worker engagement. We present a large-scale analysis of Freelancer.com, utilizing over 1.8 million job posts and 3.8 million users. We investigate the emergence of jobs with the adoption of GenAI and identify leading position of ChatGPT in the freelancing market. With a focus on ChatGPT related jobs, we inspect their specific skill requirements, and the tasks that workers are asked to perform. Our findings provide insights into the evolving landscape of freelancing in the age of AI, offering a comprehensive profile of GenAI's effects on employment, skills, and user behaviors in freelancing market.", "AI": {"tldr": "\u7814\u7a76\u65b0\u51a0\u75ab\u60c5\u540e\u81ea\u7531\u804c\u4e1a\u5e73\u53f0\u7684\u53d8\u5316\uff0c\u91cd\u70b9\u5206\u6790\u751f\u6210\u5f0fAI\u6280\u672f\u7279\u522b\u662fChatGPT\u5bf9\u81ea\u7531\u804c\u4e1a\u5e02\u573a\u9700\u6c42\u548c\u5de5\u4f5c\u8005\u53c2\u4e0e\u5ea6\u7684\u5f71\u54cd", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u6280\u672f\u5f15\u53d1\u5e7f\u6cdb\u8ba8\u8bba\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5176\u5728\u81ea\u7531\u804c\u4e1a\u5e02\u573a\u91c7\u7528\u60c5\u51b5\u53ca\u5176\u5bf9\u5de5\u4f5c\u9700\u6c42\u548c\u5de5\u4f5c\u8005\u53c2\u4e0e\u5f71\u54cd\u7684\u5b9e\u8bc1\u7814\u7a76", "method": "\u57fa\u4e8eFreelancer.com\u5e73\u53f0\u7684\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\uff0c\u5305\u542b180\u4e07\u4e2a\u5de5\u4f5c\u5c97\u4f4d\u53d1\u5e03\u548c380\u4e07\u7528\u6237\u6570\u636e", "result": "\u8bc6\u522b\u4e86\u751f\u6210\u5f0fAI\u91c7\u7eb3\u76f8\u5173\u5c97\u4f4d\u7684\u51fa\u73b0\uff0c\u786e\u5b9a\u4e86ChatGPT\u5728\u81ea\u7531\u804c\u4e1a\u5e02\u573a\u7684\u4e3b\u5bfc\u5730\u4f4d\uff0c\u5206\u6790\u4e86\u76f8\u5173\u5c97\u4f4d\u7684\u6280\u80fd\u8981\u6c42\u548c\u4efb\u52a1\u7c7b\u578b", "conclusion": "\u7814\u7a76\u4e3a\u7406\u89e3AI\u65f6\u4ee3\u81ea\u7531\u804c\u4e1a\u5e02\u573a\u6f14\u53d8\u63d0\u4f9b\u4e86\u6d1e\u5bdf\uff0c\u5c55\u793a\u4e86\u751f\u6210\u5f0fAI\u5bf9\u5c31\u4e1a\u3001\u6280\u80fd\u548c\u7528\u6237\u884c\u4e3a\u7684\u5168\u9762\u5f71\u54cd"}}
{"id": "2512.02710", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.02710", "abs": "https://arxiv.org/abs/2512.02710", "authors": ["Yuan Wang", "Shujian Gao", "Jiaxiang Liu", "Songtao Jiang", "Haoxiang Xia", "Xiaotian Zhang", "Zhaolu Kang", "Yemin Wang", "Zuozhu Liu"], "title": "Beyond N-grams: A Hierarchical Reward Learning Framework for Clinically-Aware Medical Report Generation", "comment": "10 pages, 4 figures", "summary": "Automatic medical report generation can greatly reduce the workload of doctors, but it is often unreliable for real-world deployment. Current methods can write formally fluent sentences but may be factually flawed, introducing serious medical errors known as clinical hallucinations, which make them untrustworthy for diagnosis. To bridge this gap, we introduce HiMed-RL, a Hierarchical Medical Reward Learning Framework designed to explicitly prioritize clinical quality. HiMed-RL moves beyond simple text matching by deconstructing reward learning into three synergistic levels: it first ensures linguistic fluency at the token-level, then enforces factual grounding at the concept-level by aligning key medical terms with expert knowledge, and finally assesses high-level diagnostic consistency at the semantic-level using a specialized LLM verifier. This hierarchical reward is implemented via a Human-inspired Dynamic Reward Adjustment, a strategy which first teaches the model to learn basic facts before progressing to more complex diagnostic reasoning. Experimentally, HiMed-3B achieves state-of-the-art performance on both in-domain and out-of-domain benchmarks, particularly on the latter, with an improvement of 12.1% over the second-best baseline. Our work provides a robust paradigm for generating reports that not only improve fluency but clinical fine-grained quality.", "AI": {"tldr": "\u63d0\u51faHiMed-RL\u5206\u5c42\u533b\u5b66\u5956\u52b1\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6807\u8bb0\u7ea7\u6d41\u7545\u6027\u3001\u6982\u5ff5\u7ea7\u4e8b\u5b9e\u5bf9\u9f50\u548c\u8bed\u4e49\u7ea7\u8bca\u65ad\u4e00\u81f4\u6027\u4e09\u5c42\u6b21\u5956\u52b1\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u62a5\u544a\u751f\u6210\u7684\u4e34\u5e8a\u8d28\u91cf", "motivation": "\u89e3\u51b3\u73b0\u6709\u533b\u5b66\u62a5\u544a\u751f\u6210\u65b9\u6cd5\u867d\u7136\u80fd\u751f\u6210\u6d41\u7545\u6587\u672c\u4f46\u5b58\u5728\u4e34\u5e8a\u5e7b\u89c9\u95ee\u9898\uff0c\u5bfc\u81f4\u533b\u5b66\u9519\u8bef\u65e0\u6cd5\u5b9e\u9645\u90e8\u7f72\u7684\u6311\u6218", "method": "\u5206\u5c42\u533b\u5b66\u5956\u52b1\u5b66\u4e60\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u5c42\u6b21\uff1atoken\u7ea7\u786e\u4fdd\u8bed\u8a00\u6d41\u7545\u6027\uff0cconcept\u7ea7\u5bf9\u9f50\u533b\u5b66\u672f\u8bed\u4e0e\u4e13\u5bb6\u77e5\u8bc6\uff0csemantic\u7ea7\u4f7f\u7528\u4e13\u7528LLM\u9a8c\u8bc1\u5668\u8bc4\u4f30\u8bca\u65ad\u4e00\u81f4\u6027", "result": "HiMed-3B\u6a21\u578b\u5728\u57df\u5185\u548c\u57df\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u57df\u5916\u6d4b\u8bd5\u4e2d\u6bd4\u6b21\u4f18\u57fa\u7ebf\u63d0\u534712.1%", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u751f\u6210\u65e2\u63d0\u9ad8\u6d41\u7545\u6027\u53c8\u4fdd\u8bc1\u4e34\u5e8a\u7ec6\u7c92\u5ea6\u8d28\u91cf\u7684\u62a5\u544a\u63d0\u4f9b\u4e86\u7a33\u5065\u8303\u4f8b\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u62a5\u544a\u751f\u6210\u4e2d\u7684\u53ef\u4fe1\u5ea6\u95ee\u9898"}}
{"id": "2512.02080", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02080", "abs": "https://arxiv.org/abs/2512.02080", "authors": ["PIerre Dantas", "Lucas Cordeiro", "Youcheng Sun", "Waldir Junior"], "title": "The 4/$\u03b4$ Bound: Designing Predictable LLM-Verifier Systems for Formal Method Guarantee", "comment": "32 pages, 9 figures", "summary": "The idea of using Formal Verification tools with large language models (LLMs) has enabled scaling software verification beyond manual workflows. However, current methods remain unreliable. Without a solid theoretical footing, the refinement process can wander; sometimes it settles, sometimes it loops back, and sometimes it breaks away from any stable trajectory. This work bridges this critical gap by developing an LLM-Verifier Convergence Theorem, providing the first formal framework with provable guarantees for termination and convergence. We model the interaction between the LLM and the verifier as a discrete-time Markov Chain, with state transitions determined by a key parameter: the error-reduction probability ($\u03b4$). The procedure reaching the Verified state almost surely demonstrates that the program terminates for any $\u03b4> 0$, with an expected iteration count bounded by $\\mathbb{E}[n] \\leq 4/\u03b4$. We then stress-tested this prediction in an extensive empirical campaign comprising more than 90,000 trials. The empirical results match the theory with striking consistency. Every single run reached verification, and the convergence factor clustered tightly around $C_f\\approx$ 1.0. Consequently, the bound mirrors the system's actual behavior. The evidence is sufficiently robust to support dividing the workflow into three distinct operating zones: marginal, practical, and high-performance. Consequently, we establish the design thresholds with absolute confidence. Together, the theoretical guarantee and the experimental evidence provide a clearer architectural foundation for LLM-assisted verification. Heuristic tuning no longer has to be carried out by the system. Engineers gain a framework that supports predictable resource planning and performance budgeting, precisely what is needed before deploying these pipelines into safety-critical software environments.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86LLM\u9a8c\u8bc1\u5668\u6536\u655b\u5b9a\u7406\uff0c\u4e3aLLM\u8f85\u52a9\u7684\u8f6f\u4ef6\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u9996\u4e2a\u5177\u6709\u53ef\u8bc1\u660e\u7ec8\u6b62\u6027\u548c\u6536\u655b\u6027\u4fdd\u8bc1\u7684\u5f62\u5f0f\u5316\u6846\u67b6\u3002", "motivation": "\u586b\u8865\u5f53\u524dLLM\u9a8c\u8bc1\u65b9\u6cd5\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u7684\u5173\u952e\u7a7a\u767d\uff0c\u89e3\u51b3\u9a8c\u8bc1\u8fc7\u7a0b\u4e0d\u7a33\u5b9a\u3001\u4e0d\u53ef\u9760\u7684\u95ee\u9898\u3002", "method": "\u5c06LLM\u4e0e\u9a8c\u8bc1\u5668\u7684\u4ea4\u4e92\u5efa\u6a21\u4e3a\u79bb\u6563\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u5f15\u5165\u9519\u8bef\u51cf\u5c11\u6982\u7387(\u03b4)\u4f5c\u4e3a\u5173\u952e\u53c2\u6570\u3002", "result": "\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u03b4>0\uff0c\u7a0b\u5e8f\u90fd\u80fd\u51e0\u4e4e\u5fc5\u7136\u8fbe\u5230\u9a8c\u8bc1\u72b6\u6001\uff0c\u671f\u671b\u8fed\u4ee3\u6b21\u6570\u6709\u754cE[n]\u22644/\u03b4\u3002\u901a\u8fc7\u8d85\u8fc790,000\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u9884\u6d4b\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u9a8c\u8bc1\u7684LLM\u8f85\u52a9\u9a8c\u8bc1\u67b6\u6784\u57fa\u7840\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u8f6f\u4ef6\u73af\u5883\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u9884\u6d4b\u7684\u8d44\u6e90\u89c4\u5212\u6846\u67b6\u3002"}}
{"id": "2512.02062", "categories": ["cs.CR", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02062", "abs": "https://arxiv.org/abs/2512.02062", "authors": ["Issa Oe", "Keiichiro Yamamura", "Hiroki Ishikura", "Ryo Hamahira", "Katsuki Fujisawa"], "title": "Superpixel Attack: Enhancing Black-box Adversarial Attack with Image-driven Division Areas", "comment": null, "summary": "Deep learning models are used in safety-critical tasks such as automated driving and face recognition. However, small perturbations in the model input can significantly change the predictions. Adversarial attacks are used to identify small perturbations that can lead to misclassifications. More powerful black-box adversarial attacks are required to develop more effective defenses. A promising approach to black-box adversarial attacks is to repeat the process of extracting a specific image area and changing the perturbations added to it. Existing attacks adopt simple rectangles as the areas where perturbations are changed in a single iteration. We propose applying superpixels instead, which achieve a good balance between color variance and compactness. We also propose a new search method, versatile search, and a novel attack method, Superpixel Attack, which applies superpixels and performs versatile search. Superpixel Attack improves attack success rates by an average of 2.10% compared with existing attacks. Most models used in this study are robust against adversarial attacks, and this improvement is significant for black-box adversarial attacks. The code is avilable at https://github.com/oe1307/SuperpixelAttack.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u8d85\u50cf\u7d20\u7684\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5Superpixel Attack\uff0c\u901a\u8fc7\u8d85\u50cf\u7d20\u5212\u5206\u548c\u591a\u6837\u5316\u641c\u7d22\u7b56\u7565\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u63d0\u5347\u4e862.10%\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u4efb\u52a1\u4e2d\u6613\u53d7\u5fae\u5c0f\u6270\u52a8\u5f71\u54cd\uff0c\u73b0\u6709\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u4f7f\u7528\u7684\u77e9\u5f62\u533a\u57df\u5212\u5206\u7b80\u5355\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u6270\u52a8\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8d85\u50cf\u7d20\u53d6\u4ee3\u4f20\u7edf\u77e9\u5f62\u533a\u57df\u5212\u5206\uff0c\u7ed3\u5408\u65b0\u63d0\u51fa\u7684\u591a\u6837\u5316\u641c\u7d22\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u989c\u8272\u65b9\u5dee\u548c\u7d27\u51d1\u6027\u5e73\u8861\u7684\u57fa\u7840\u4e0a\u4f18\u5316\u6270\u52a8\u3002", "result": "\u5728\u5bf9\u6297\u9c81\u68d2\u6027\u8f83\u5f3a\u7684\u6a21\u578b\u4e0a\uff0cSuperpixel Attack\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387\u8fbe\u52302.10%\u7684\u63d0\u5347\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "\u8d85\u50cf\u7d20\u5212\u5206\u7ed3\u5408\u591a\u6837\u5316\u641c\u7d22\u80fd\u6709\u6548\u63d0\u5347\u9ed1\u76d2\u5bf9\u6297\u653b\u51fb\u6027\u80fd\uff0c\u4e3a\u9632\u5fa1\u7b56\u7565\u5f00\u53d1\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u6d4b\u8bd5\u57fa\u51c6\u3002"}}
{"id": "2512.02069", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02069", "abs": "https://arxiv.org/abs/2512.02069", "authors": ["Yining Yuan", "Yifei Wang", "Yichang Xu", "Zachary Yahn", "Sihao Hu", "Ling Liu"], "title": "Large Language Model based Smart Contract Auditing with LLMBugScanner", "comment": null, "summary": "This paper presents LLMBugScanner, a large language model (LLM) based framework for smart contract vulnerability detection using fine-tuning and ensemble learning. Smart contract auditing presents several challenges for LLMs: different pretrained models exhibit varying reasoning abilities, and no single model performs consistently well across all vulnerability types or contract structures. These limitations persist even after fine-tuning individual LLMs.\n  To address these challenges, LLMBugScanner combines domain knowledge adaptation with ensemble reasoning to improve robustness and generalization. Through domain knowledge adaptation, we fine-tune LLMs on complementary datasets to capture both general code semantics and instruction-guided vulnerability reasoning, using parameter-efficient tuning to reduce computational cost. Through ensemble reasoning, we leverage the complementary strengths of multiple LLMs and apply a consensus-based conflict resolution strategy to produce more reliable vulnerability assessments.\n  We conduct extensive experiments across multiple popular LLMs and compare LLMBugScanner with both pretrained and fine-tuned individual models. Results show that LLMBugScanner achieves consistent accuracy improvements and stronger generalization, demonstrating that it provides a principled, cost-effective, and extensible framework for smart contract auditing.", "AI": {"tldr": "LLMBugScanner\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03\u548c\u96c6\u6210\u5b66\u4e60\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u667a\u80fd\u5408\u7ea6\u5ba1\u8ba1\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff1a\u4e0d\u540c\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u63a8\u7406\u80fd\u529b\u5404\u5f02\uff0c\u5355\u4e2a\u6a21\u578b\u65e0\u6cd5\u5728\u6240\u6709\u6f0f\u6d1e\u7c7b\u578b\u6216\u5408\u7ea6\u7ed3\u6784\u4e0a\u8868\u73b0\u4e00\u81f4\uff0c\u5373\u4f7f\u5728\u5fae\u8c03\u540e\u4ecd\u6709\u5c40\u9650\u3002", "method": "\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u9002\u5e94\u548c\u96c6\u6210\u63a8\u7406\u3002\u9886\u57df\u77e5\u8bc6\u9002\u5e94\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5728\u4e92\u8865\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6a21\u578b\uff0c\u6355\u6349\u4e00\u822c\u4ee3\u7801\u8bed\u4e49\u548c\u6307\u4ee4\u5f15\u5bfc\u7684\u6f0f\u6d1e\u63a8\u7406\uff1b\u96c6\u6210\u63a8\u7406\u5229\u7528\u591a\u4e2a\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u91c7\u7528\u57fa\u4e8e\u5171\u8bc6\u7684\u51b2\u7a81\u89e3\u51b3\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLLMBugScanner\u76f8\u6bd4\u9884\u8bad\u7ec3\u548c\u5fae\u8c03\u7684\u5355\u4e2a\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6301\u7eed\u7684\u51c6\u786e\u7387\u63d0\u5347\u548c\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "LLMBugScanner\u4e3a\u667a\u80fd\u5408\u7ea6\u5ba1\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u3001\u6210\u672c\u6548\u76ca\u9ad8\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002"}}
{"id": "2512.02393", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02393", "abs": "https://arxiv.org/abs/2512.02393", "authors": ["Shuyang Liu", "Yang Chen", "Rahul Krishna", "Saurabh Sinha", "Jatin Ganhotra", "Reyhan Jabbarvand"], "title": "Process-Centric Analysis of Agentic Software Systems", "comment": null, "summary": "Agentic systems are modern software systems: they consist of orchestrated modules, expose interfaces, and are deployed in software pipelines. Unlike conventional programs, their execution (i.e., trajectories) is inherently stochastic and adaptive to the problem they are solving. Evaluation of such systems is often outcome-centric, judging their performance based on success or failure at the final step. This narrow focus overlooks detailed insights about such systems, failing to explain how agents reason, plan, act, or change their strategies over time. Inspired by the structured representation of conventional software systems as graphs, we introduce Graphectory to systematically encode the temporal and semantic relations in such software systems. Graphectory facilitates the design of process-centric metrics and analyses to assess the quality of agentic workflows independent of final success.\n  Using Graphectory, we analyze 4000 trajectories of two dominant agentic programming workflows, namely SWE-agent and OpenHands, with a combination of four backbone Large Language Models (LLMs), attempting to resolve SWE-bench Verified issues. Our fully automated analyses reveal that: (1) agents using richer prompts or stronger LLMs exhibit more complex Graphectory, reflecting deeper exploration, broader context gathering, and more thorough validation before patch submission; (2) agents' problem-solving strategies vary with both problem difficulty and the underlying LLM -- for resolved issues, the strategies often follow coherent localization-patching-validation steps, while unresolved ones exhibit chaotic, repetitive, or backtracking behaviors; (3) even when successful, agentic programming systems often display inefficient processes, leading to unnecessarily prolonged trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Graphectory\u65b9\u6cd5\u6765\u5206\u6790\u548c\u8bc4\u4f30\u667a\u80fd\u4f53\u8f6f\u4ef6\u7cfb\u7edf\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u8d85\u8d8a\u4f20\u7edf\u7684\u7ed3\u679c\u5bfc\u5411\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u4f53\u7cfb\u7edf\u5177\u6709\u968f\u673a\u6027\u548c\u9002\u5e94\u6027\u7279\u5f81\uff0c\u4f20\u7edf\u7684\u7ed3\u679c\u5bfc\u5411\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6df1\u5165\u7406\u89e3\u5176\u63a8\u7406\u3001\u89c4\u5212\u548c\u884c\u52a8\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u56fe\u7ed3\u6784\u7f16\u7801\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u65f6\u7a7a\u548c\u8bed\u4e49\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e86\u8fc7\u7a0b\u4e2d\u5fc3\u7684\u5ea6\u91cf\u6807\u51c6\u5206\u6790\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u8d28\u91cf\u3002", "result": "\u5bf94000\u4e2a\u8f68\u8ff9\u7684\u5206\u6790\u8868\u660e\uff1a\u63d0\u793a\u8d28\u91cf\u4e0eLLM\u5f3a\u5ea6\u5f71\u54cd\u51b3\u7b56\u590d\u6742\u6027\uff1b\u95ee\u9898\u96be\u5ea6\u548cLLM\u5f71\u54cd\u89e3\u51b3\u7b56\u7565\uff1b\u6210\u529f\u7cfb\u7edf\u4ecd\u5b58\u5728\u6548\u7387\u95ee\u9898\u3002", "conclusion": "Graphectory\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u5206\u6790\u667a\u80fd\u4f53\u7cfb\u7edf\u8fc7\u7a0b\u7684\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u53d1\u73b0\u7684\u6548\u7387\u548c\u884c\u4e3a\u6a21\u5f0f\u95ee\u9898\u3002"}}
{"id": "2512.02193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02193", "abs": "https://arxiv.org/abs/2512.02193", "authors": ["Alexander Boyd", "Franz Nowak", "David Hyland", "Manuel Baltieri", "Fernando E. Rosas"], "title": "From monoliths to modules: Decomposing transducers for efficient world modelling", "comment": null, "summary": "World models have been recently proposed as sandbox environments in which AI agents can be trained and evaluated before deployment. Although realistic world models often have high computational demands, efficient modelling is usually possible by exploiting the fact that real-world scenarios tend to involve subcomponents that interact in a modular manner. In this paper, we explore this idea by developing a framework for decomposing complex world models represented by transducers, a class of models generalising POMDPs. Whereas the composition of transducers is well understood, our results clarify how to invert this process, deriving sub-transducers operating on distinct input-output subspaces, enabling parallelizable and interpretable alternatives to monolithic world modelling that can support distributed inference. Overall, these results lay a groundwork for bridging the structural transparency demanded by AI safety and the computational efficiency required for real-world inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u590d\u6742\u4e16\u754c\u6a21\u578b\u5206\u89e3\u4e3a\u53ef\u5e76\u884c\u5b50\u7ec4\u4ef6\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u6a21\u5757\u5316\u4ea4\u4e92\u5b9e\u73b0\u9ad8\u6548\u5efa\u6a21\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u901a\u5e38\u662f\u6a21\u5757\u5316\u4ea4\u4e92\u7684\uff0c\u4f46\u73b0\u6709\u4e16\u754c\u6a21\u578b\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8etransducer\u7684\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u590d\u6742\u6a21\u578b\u5206\u89e3\u4e3a\u5728\u72ec\u7acb\u8f93\u5165\u8f93\u51fa\u7a7a\u95f4\u8fd0\u884c\u7684\u5b50transducer\u3002", "result": "\u5b9e\u73b0\u4e86\u53ef\u5e76\u884c\u3001\u53ef\u89e3\u91ca\u7684\u6a21\u5757\u5316\u4e16\u754c\u5efa\u6a21\u65b9\u6848\uff0c\u652f\u6301\u5206\u5e03\u5f0f\u63a8\u7406\u3002", "conclusion": "\u4e3aAI\u5b89\u5168\u6240\u9700\u7684\u7ed3\u6784\u900f\u660e\u6027\u548c\u5b9e\u9645\u63a8\u7406\u6240\u9700\u7684\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u642d\u5efa\u4e86\u6865\u6881\u3002"}}
{"id": "2512.02082", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02082", "abs": "https://arxiv.org/abs/2512.02082", "authors": ["Abel C. H. Chen"], "title": "Deterministic Random Bit Generators Based on Ascon for Embedded Systems", "comment": "in Chinese language", "summary": "As the Deterministic Random Bit Generator (DRBG) serves as a fundamental component in random number generation and cryptographic applications, its performance and security are particularly critical in resource-constrained embedded systems, where memory capacity and computational efficiency are limited. Establishing a high-performance and secure DRBG is therefore an important issue for embedded system design. Furthermore, the National Institute of Standards and Technology (NIST) established the Ascon lightweight cryptographic standard in August 2025, which is suitable for use in resource-limited embedded environments. Therefore, this study revises the DRBG standard and proposes three Ascon-driven constructions: the Ascon-Driven Hash-Based DRBG, the Ascon-Driven keyed-Hash Message Authentication Code (HMAC) DRBG, and the Ascon-Driven Counter-mode (CTR) DRBG. In the experiments, these methods are implemented on a Raspberry Pi platform. The experimental results demonstrate that the proposed approaches achieve higher computational efficiency and lower memory usage compared with existing DRBG implementations, making them suitable for deployment in embedded systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e09\u79cd\u57fa\u4e8eAscon\u8f7b\u91cf\u7ea7\u5bc6\u7801\u6807\u51c6\u7684DRBG\u6784\u9020\u65b9\u6848\uff0c\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u548c\u66f4\u4f4e\u7684\u5185\u5b58\u4f7f\u7528\u7387", "motivation": "\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u968f\u673a\u6570\u751f\u6210\u5668\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u800cNIST\u65b0\u5236\u5b9a\u7684Ascon\u6807\u51c6\u9002\u5408\u6b64\u7c7b\u73af\u5883\u4f7f\u7528", "method": "\u63d0\u51fa\u4e09\u79cd\u57fa\u4e8eAscon\u7684DRBG\u6784\u9020\uff1a\u54c8\u5e0c\u578bDRBG\u3001HMAC\u578bDRBG\u548c\u8ba1\u6570\u5668\u578bDRBG\uff0c\u5e76\u5728\u6811\u8393\u6d3e\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709DRBG\u5b9e\u73b0\uff0c\u6240\u63d0\u65b9\u6cd5\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3001\u5185\u5b58\u4f7f\u7528\u66f4\u4f4e", "conclusion": "\u57fa\u4e8eAscon\u7684DRBG\u65b9\u6848\u9002\u5408\u5728\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u7684\u5b89\u5168\u968f\u673a\u6570\u751f\u6210\u65b9\u6848"}}
{"id": "2512.02567", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02567", "abs": "https://arxiv.org/abs/2512.02567", "authors": ["Martin Weiss", "Jesko Hecking-Harbusch", "Jochen Quante", "Matthias Woehrle"], "title": "Feedback Loops and Code Perturbations in LLM-based Software Engineering: A Case Study on a C-to-Rust Translation System", "comment": "10 pages, 9 figures", "summary": "The advent of strong generative AI has a considerable impact on various software engineering tasks such as code repair, test generation, or language translation. While tools like GitHub Copilot are already in widespread use in interactive settings, automated approaches require a higher level of reliability before being usable in industrial practice. In this paper, we focus on three aspects that directly influence the quality of the results: a) the effect of automated feedback loops, b) the choice of Large Language Model (LLM), and c) the influence of behavior-preserving code changes.\n  We study the effect of these three variables on an automated C-to-Rust translation system. Code translation from C to Rust is an attractive use case in industry due to Rust's safety guarantees. The translation system is based on a generate-and-check pattern, in which Rust code generated by the LLM is automatically checked for compilability and behavioral equivalence with the original C code. For negative checking results, the LLM is re-prompted in a feedback loop to repair its output. These checks also allow us to evaluate and compare the respective success rates of the translation system when varying the three variables.\n  Our results show that without feedback loops LLM selection has a large effect on translation success. However, when the translation system uses feedback loops the differences across models diminish. We observe this for the average performance of the system as well as its robustness under code perturbations. Finally, we also identify that diversity provided by code perturbations can even result in improved system performance.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u81ea\u52a8\u5316C-to-Rust\u4ee3\u7801\u7ffb\u8bd1\u7cfb\u7edf\u4e2d\uff0c\u53cd\u9988\u5faa\u73af\u3001LLM\u9009\u62e9\u548c\u4ee3\u7801\u6270\u52a8\u5bf9\u7ffb\u8bd1\u8d28\u91cf\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u53cd\u9988\u5faa\u73af\u80fd\u7f29\u5c0f\u4e0d\u540cLLM\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u4ee3\u7801\u6270\u52a8\u591a\u6837\u6027\u751a\u81f3\u80fd\u63d0\u5347\u7cfb\u7edf\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u81ea\u52a8\u5316\u65b9\u6cd5\u9700\u8981\u66f4\u9ad8\u53ef\u9760\u6027\u624d\u80fd\u7528\u4e8e\u5de5\u4e1a\u5b9e\u8df5\u3002\u672c\u6587\u91cd\u70b9\u7814\u7a76\u5f71\u54cd\u7ed3\u679c\u8d28\u91cf\u7684\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\uff1a\u53cd\u9988\u5faa\u73af\u3001LLM\u9009\u62e9\u548c\u4ee3\u7801\u6270\u52a8\u3002", "method": "\u57fa\u4e8e\u751f\u6210-\u68c0\u67e5\u6a21\u5f0f\u7684C-to-Rust\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u68c0\u67e5\u751f\u6210\u4ee3\u7801\u7684\u53ef\u7f16\u8bd1\u6027\u548c\u884c\u4e3a\u7b49\u4ef7\u6027\uff0c\u5bf9\u4e0d\u5408\u683c\u7ed3\u679c\u8fdb\u884c\u53cd\u9988\u5faa\u73af\u4fee\u590d\u3002\u901a\u8fc7\u63a7\u5236\u4e09\u4e2a\u53d8\u91cf\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u65e0\u53cd\u9988\u5faa\u73af\u65f6LLM\u9009\u62e9\u5bf9\u7ffb\u8bd1\u6210\u529f\u7387\u5f71\u54cd\u663e\u8457\uff1b\u5f15\u5165\u53cd\u9988\u5faa\u73af\u540e\u6a21\u578b\u95f4\u5dee\u5f02\u51cf\u5c0f\u3002\u4ee3\u7801\u6270\u52a8\u63d0\u4f9b\u7684\u591a\u6837\u6027\u8fd8\u80fd\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u53cd\u9988\u5faa\u73af\u662f\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u7ffb\u8bd1\u7cfb\u7edf\u53ef\u9760\u6027\u7684\u5173\u952e\u673a\u5236\uff0c\u80fd\u6709\u6548\u5f25\u8865\u4e0d\u540cLLM\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u800c\u884c\u4e3a\u4fdd\u6301\u7684\u4ee3\u7801\u6270\u52a8\u53ef\u8fdb\u4e00\u6b65\u589e\u5f3a\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.02087", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02087", "abs": "https://arxiv.org/abs/2512.02087", "authors": ["Simone Dutto", "Pietro Mercuri", "Nadir Murru", "Lorenzo Romano"], "title": "A survey about Hidden Subgroup Problem from a mathematical and cryptographic perspective", "comment": null, "summary": "We provide a survey on the Hidden Subgroup Problem (HSP), which plays an important role in studying the security of public-key cryptosystems. We first review the abelian case, where Kitaev's algorithm yields an efficient quantum solution to the HSP, recalling how classical problems (such as order finding, integer factorization, and discrete logarithm) can be formulated as abelian HSP instances. We then examine the current state of the art for non-abelian HSP, where no general efficient quantum solution is known, focusing on some relevant groups including dihedral group (connected to the shortest vector problem), symmetric groups (connected to the graph isomorphism problem), and semidirect product constructions (connected, in a special case, to the code equivalence problem). We also describe the main techniques for addressing the HSP in non-abelian cases, namely Fourier sampling and the black-box approach. Throughout the paper, we highlight the mathematical notions required and exploited in this context, providing a cryptography-oriented perspective.", "AI": {"tldr": "\u5173\u4e8e\u9690\u5b50\u7fa4\u95ee\u9898\u7684\u7efc\u8ff0\uff0c\u8ba8\u8bba\u5176\u5728\u516c\u94a5\u5bc6\u7801\u5b89\u5168\u4e2d\u7684\u91cd\u8981\u6027\u548c\u5728\u4e0d\u540c\u7fa4\u7ed3\u6784\u4e2d\u7684\u91cf\u5b50\u89e3\u6cd5", "motivation": "\u7814\u7a76\u9690\u5b50\u7fa4\u95ee\u9898\u7684\u91cf\u5b50\u89e3\u6cd5\u5bf9\u8bc4\u4f30\u5bc6\u7801\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u7406\u89e3\u91cf\u5b50\u8ba1\u7b97\u5bf9\u5bc6\u7801\u5b66\u7684\u5f71\u54cd\u63d0\u4f9b\u7406\u8bba\u57fa\u7840", "method": "\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u9996\u5148\u56de\u987e\u963f\u8d1d\u5c14\u7fa4\u6848\u4f8b\u53ca\u5176\u5728\u7ecf\u5178\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u7136\u540e\u5206\u6790\u975e\u963f\u8d1d\u5c14\u7fa4\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55", "result": "\u603b\u7ed3\u4e86\u963f\u8d1d\u5c14\u7fa4\u7684\u91cf\u5b50\u9ad8\u6548\u89e3\u6cd5\uff0c\u63ed\u793a\u975e\u963f\u8d1d\u5c14\u7fa4\u5c1a\u65e0\u901a\u7528\u9ad8\u6548\u91cf\u5b50\u89e3\u6cd5\u7684\u73b0\u72b6\uff0c\u5206\u6790\u4e86\u7279\u5b9a\u7fa4\u7ed3\u6784\u7684\u8fde\u63a5\u95ee\u9898", "conclusion": "\u9690\u5b50\u7fa4\u95ee\u9898\u662f\u8fde\u63a5\u91cf\u5b50\u8ba1\u7b97\u4e0e\u4f20\u7edf\u5bc6\u7801\u5b89\u5168\u7684\u6838\u5fc3\u6865\u6881\uff0c\u9700\u8fdb\u4e00\u6b65\u53d1\u5c55\u6570\u5b66\u5de5\u5177\u6765\u5e94\u5bf9\u975e\u963f\u8d1d\u5c14\u7fa4\u6311\u6218"}}
{"id": "2512.02157", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.02157", "abs": "https://arxiv.org/abs/2512.02157", "authors": ["Aaron Sandoval", "Cody Rushing"], "title": "Factor(T,U): Factored Cognition Strengthens Monitoring of Untrusted AI", "comment": "7 pages body; 19 pages total; 8 figures", "summary": "The field of AI Control seeks to develop robust control protocols, deployment safeguards for untrusted AI which may be intentionally subversive. However, existing protocols that rely on weaker monitors to detect unsafe behavior often fail on complex tasks beyond the monitor's comprehension. We develop control protocols based on factored cognition, in which a trusted model decomposes a task, an untrusted model solves each resultant child task in isolation, and the results are reassembled into a full solution. These protocols may improve safety by several means, such as by simplifying the context for monitors, or by obscuring vulnerabilities in the environment. We implement our protocols in the APPS coding setting and red team them against backdoor attempts from an adversarial GPT-4.1 Nano. We find that: (i) Adding factored cognition to a trusted monitoring protocol can boost safety from 41% to 63%; (ii) Safety improves because monitor performance improves; (iii) Factored cognition makes it no harder for capable LLMs to write backdoors in APPS. While our protocols show low usefulness in APPS, they hold promise for more complex tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u63a7\u5236\u9886\u57df\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u89e3\u8ba4\u77e5\uff08factored cognition\uff09\u7684\u63a7\u5236\u534f\u8bae\uff0c\u5c06\u4e00\u4e2a\u590d\u6742\u7684\u4efb\u52a1\u4ea4\u7531\u53ef\u4fe1\u6a21\u578b\u5206\u89e3\u4e3a\u5b50\u4efb\u52a1\uff0c\u518d\u7531\u4e0d\u53ef\u4fe1\u6a21\u578b\u5355\u72ec\u89e3\u51b3\uff0c\u4ece\u800c\u63d0\u9ad8\u5b89\u5168\u6027\u3002\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\u6d4b\u8bd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u5b89\u5168\u6027\u80fd\u4ece41%\u63d0\u5347\u81f363%\uff0c\u4f46\u5728APPS\u4e2d\u7528\u5904\u6709\u9650\uff0c\u9002\u7528\u4e8e\u66f4\u590d\u6742\u7684\u4efb\u52a1\u3002", "motivation": "\u5f53\u524dAI\u63a7\u5236\u534f\u8bae\u4f9d\u8d56\u5f31\u76d1\u89c6\u5668\u68c0\u6d4b\u4e0d\u5b89\u5168\u884c\u4e3a\uff0c\u4f46\u5728\u76d1\u89c6\u5668\u96be\u4ee5\u7406\u89e3\u7684\u590d\u6742\u4efb\u52a1\u4e0a\u5e38\u5e38\u5931\u6548\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6709\u6548\u7684\u5b89\u5168\u63a7\u5236\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5206\u89e3\u8ba4\u77e5\u7684\u63a7\u5236\u534f\u8bae\uff1a\u53ef\u4fe1\u6a21\u578b\u5206\u89e3\u4efb\u52a1\uff0c\u4e0d\u53ef\u4fe1\u6a21\u578b\u72ec\u7acb\u89e3\u51b3\u6bcf\u4e2a\u5b50\u4efb\u52a1\uff0c\u7ed3\u679c\u91cd\u65b0\u7ec4\u88c5\u3002\u5728APPS\u7f16\u7801\u73af\u5883\u4e2d\u5b9e\u65bd\uff0c\u5e76\u7528\u5bf9\u6297\u6027GPT-4.1 Nano\u8fdb\u884c\u7ea2\u961f\u6d4b\u8bd5\u3002", "result": "\u5206\u89e3\u8ba4\u77e5\u7684\u52a0\u5165\u4f7f\u5b89\u5168\u6027\u80fd\u4ece41%\u63d0\u5347\u81f363%\uff0c\u76d1\u89c6\u5668\u6027\u80fd\u63d0\u9ad8\u662f\u4e3b\u8981\u539f\u56e0\uff0c\u800c\u5206\u89e3\u8ba4\u77e5\u5e76\u672a\u589e\u52a0\u6709\u80fd\u529bLLM\u690d\u5165\u540e\u95e8\u7684\u96be\u5ea6\u3002", "conclusion": "\u5c3d\u7ba1\u5728APPS\u4e2d\u5b9e\u7528\u6027\u4f4e\uff0c\u4f46\u5206\u89e3\u8ba4\u77e5\u534f\u8bae\u5728\u66f4\u590d\u6742\u7684\u4efb\u52a1\u4e2d\u5177\u6709\u63d0\u5347AI\u63a7\u5236\u5b89\u5168\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.02728", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02728", "abs": "https://arxiv.org/abs/2512.02728", "authors": ["Sabrina Delmondes da Costa Feitosa"], "title": "Integrative Analysis of Risk Management Methodologies in Data Science Projects", "comment": "13 p\u00e1ginas, in Portuguese language", "summary": "Data science initiatives frequently exhibit high failure rates, driven by technical constraints, organizational limitations and insufficient risk management practices. Challenges such as low data maturity, lack of governance, misalignment between technical and business teams, and the absence of structured mechanisms to address ethical and sociotechnical risks have been widely identified in the literature. In this context, the purpose of this study is to conduct a comparative analysis of the main risk management methodologies applied to data science projects, aiming to identify, classify, and synthesize their similarities, differences and existing gaps. An integrative literature review was performed using indexed databases and a structured protocol for selection and content analysis. The study examines widely adopted risk management standards ISO 31000, PMBOK Risk Management and NIST RMF, as well as frameworks specific to data science workflows, such as CRISP DM and the recently proposed DS EthiCo RMF, which incorporates ethical and sociotechnical dimensions into the project life cycle. The findings reveal that traditional approaches provide limited coverage of emerging risks, whereas contemporary models propose multidimensional structures capable of integrating ethical oversight, governance and continuous monitoring. As a contribution, this work offers theoretical support for the development of hybrid frameworks that balance technical efficiency, organizational alignment and responsible data practices, while highlighting research gaps that can guide future investigations.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u5206\u6790\u4e86\u6570\u636e\u79d1\u5b66\u9879\u76ee\u4e2d\u7684\u4e3b\u8981\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\uff0c\u8bc6\u522b\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u548c\u65b0\u5174\u6846\u67b6\u7684\u4f18\u52bf\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u6280\u672f\u6548\u7387\u3001\u7ec4\u7ec7\u5bf9\u9f50\u548c\u4f26\u7406\u5b9e\u8df5\u7684\u6df7\u5408\u6846\u67b6\u65b9\u5411\u3002", "motivation": "\u6570\u636e\u79d1\u5b66\u9879\u76ee\u5931\u8d25\u7387\u9ad8\uff0c\u4e3b\u8981\u7531\u4e8e\u6280\u672f\u9650\u5236\u3001\u7ec4\u7ec7\u5c40\u9650\u548c\u98ce\u9669\u7ba1\u7406\u4e0d\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u65b0\u5174\u98ce\u9669\uff08\u5982\u4f26\u7406\u548c\u793e\u4f1a\u6280\u672f\u98ce\u9669\uff09\u8986\u76d6\u6709\u9650\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u8bba\u4ee5\u6539\u8fdb\u5b9e\u8df5\u3002", "method": "\u91c7\u7528\u6574\u5408\u6027\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u4f7f\u7528\u7d22\u5f15\u6570\u636e\u5e93\u548c\u7ed3\u6784\u5316\u534f\u8bae\u8fdb\u884c\u6587\u732e\u7b5b\u9009\u4e0e\u5185\u5bb9\u5206\u6790\u3002\u6bd4\u8f83\u4e86ISO 31000\u3001PMBOK\u98ce\u9669\u7ba1\u7406\u3001NIST RMF\u7b49\u6807\u51c6\uff0c\u4ee5\u53caCRISP-DM\u548cDS EthiCo RMF\u7b49\u6570\u636e\u79d1\u5b66\u7279\u5b9a\u6846\u67b6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4f20\u7edf\u98ce\u9669\u7ba1\u7406\u65b9\u6cd5\u5bf9\u65b0\u5174\u98ce\u9669\u8986\u76d6\u4e0d\u8db3\uff0c\u800c\u73b0\u4ee3\u6a21\u578b\uff08\u5982DS EthiCo RMF\uff09\u63d0\u4f9b\u4e86\u80fd\u6574\u5408\u4f26\u7406\u76d1\u7763\u3001\u6cbb\u7406\u548c\u6301\u7eed\u76d1\u63a7\u7684\u591a\u7ef4\u7ed3\u6784\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5f00\u53d1\u5e73\u8861\u6280\u672f\u6548\u7387\u3001\u7ec4\u7ec7\u5bf9\u9f50\u548c\u8d1f\u8d23\u4efb\u6570\u636e\u5b9e\u8df5\u7684\u6df7\u5408\u6846\u67b6\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\u548c\u7a7a\u767d\u3002"}}
{"id": "2512.02243", "categories": ["cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02243", "abs": "https://arxiv.org/abs/2512.02243", "authors": ["Md Abdul Ahad Minhaz", "Zannatul Zahan Meem", "Md. Shohrab Hossain"], "title": "PhishSnap: Image-Based Phishing Detection Using Perceptual Hashing", "comment": "IEE Standard Formatting, 3 pages, 3 figures", "summary": "Phishing remains one of the most prevalent online threats, exploiting human trust to harvest sensitive credentials. Existing URL- and HTML-based detection systems struggle against obfuscation and visual deception. This paper presents \\textbf{PhishSnap}, a privacy-preserving, on-device phishing detection system leveraging perceptual hashing (pHash). Implemented as a browser extension, PhishSnap captures webpage screenshots, computes visual hashes, and compares them against legitimate templates to identify visually similar phishing attempts. A \\textbf{2024 dataset of 10,000 URLs} (70\\%/20\\%/10\\% train/validation/test) was collected from PhishTank and Netcraft. Due to security takedowns, a subset of phishing pages was unavailable, reducing dataset diversity. The system achieved \\textbf{0.79 accuracy}, \\textbf{0.76 precision}, and \\textbf{0.78 recall}, showing that visual similarity remains a viable anti-phishing measure. The entire inference process occurs locally, ensuring user privacy and minimal latency.", "AI": {"tldr": "PhishSnap\u662f\u4e00\u4e2a\u57fa\u4e8e\u611f\u77e5\u54c8\u5e0c\u7684\u9493\u9c7c\u68c0\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u622a\u56fe\u6bd4\u5bf9\u5b9e\u73b0\u5373\u65f6\u672c\u5730\u68c0\u6d4b\uff0c\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002\u572810,000\u4e2aURL\u6570\u636e\u96c6\u4e0a\u8fbe\u52300.79\u51c6\u786e\u7387\u3002", "motivation": "\u9493\u9c7c\u653b\u51fb\u5229\u7528\u4eba\u7c7b\u4fe1\u4efb\u7a83\u53d6\u654f\u611f\u4fe1\u606f\uff0c\u4f20\u7edfURL/HTML\u68c0\u6d4b\u65b9\u6cd5\u6613\u53d7\u6df7\u6dc6\u548c\u89c6\u89c9\u6b3a\u9a97\u5f71\u54cd\u3002", "method": "\u5f00\u53d1\u6d4f\u89c8\u5668\u6269\u5c55\uff0c\u6355\u83b7\u7f51\u9875\u622a\u56fe\u5e76\u8ba1\u7b97\u89c6\u89c9\u54c8\u5e0c\u503c\uff0c\u4e0e\u5408\u6cd5\u6a21\u677f\u8fdb\u884c\u672c\u5730\u6bd4\u5bf9\u3002\u4f7f\u75282024\u5e74\u4ecePhishTank\u548cNetcraft\u6536\u96c6\u768410,000\u4e2aURL\u6570\u636e\u96c6\uff08\u8bad\u7ec3/\u9a8c\u8bc1/\u6d4b\u8bd5\u6bd4\u4f8b70%/20%/10%\uff09\u3002", "result": "\u7cfb\u7edf\u8fbe\u52300.79\u51c6\u786e\u7387\u30010.76\u7cbe\u786e\u7387\u548c0.78\u53ec\u56de\u7387\uff0c\u8bc1\u660e\u89c6\u89c9\u76f8\u4f3c\u6027\u68c0\u6d4b\u6709\u6548\u3002", "conclusion": "\u89c6\u89c9\u76f8\u4f3c\u6027\u662f\u4e00\u79cd\u53ef\u884c\u7684\u53cd\u9493\u9c7c\u63aa\u65bd\uff0c\u672c\u5730\u63a8\u7406\u786e\u4fdd\u9690\u79c1\u548c\u4f4e\u5ef6\u8fdf\uff0c\u4f46\u6570\u636e\u96c6\u591a\u6837\u6027\u53d7\u5b89\u5168\u4e0b\u67b6\u5f71\u54cd\u3002"}}
{"id": "2512.02750", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.02750", "abs": "https://arxiv.org/abs/2512.02750", "authors": ["Kiev Gama", "Filipe Calegario", "Victoria Jackson", "Alexander Nolte", "Luiz Augusto Morais", "Vinicius Garcia"], "title": "\"Can you feel the vibes?\": An exploration of novice programmer engagement with vibe coding", "comment": "International Conference on Software Engineering, Education Track (SEET) 2026", "summary": "Emerging alongside generative AI and the broader trend of AI-assisted coding, the term \"vibe coding\" refers to creating software via natural language prompts rather than direct code authorship. This approach promises to democratize software development, but its educational implications remain underexplored. This paper reports on a one-day educational hackathon investigating how novice programmers and mixed-experience teams engage with vibe coding. We organized an inclusive event at a Brazilian public university with 31 undergraduate participants from computing and non-computing disciplines, divided into nine teams. Through observations, an exit survey, and semi-structured interviews, we examined creative processes, tool usage patterns, collaboration dynamics, and learning outcomes. Findings reveal that vibe coding enabled rapid prototyping and cross-disciplinary collaboration, with participants developing prompt engineering skills and delivering functional demonstrations within time constraints. However, we observed premature convergence in ideation, uneven code quality requiring rework, and limited engagement with core software engineering practices. Teams adopted sophisticated workflows combining multiple AI tools in pipeline configurations, with human judgment remaining essential for critical refinement. The short format (9 hours) proved effective for confidence-building among newcomers while accommodating participants with limited availability. We conclude that vibe coding hackathons can serve as valuable low-stakes learning environments when coupled with explicit scaffolds for divergent thinking, critical evaluation of AI outputs, and realistic expectations about production quality.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u65b0\u5174\u7684\"\u6c1b\u56f4\u7f16\u7a0b\"\u6559\u80b2\u4ef7\u503c\uff0c\u901a\u8fc7\u5728\u5df4\u897f\u5927\u5b66\u7ec4\u7ec731\u540d\u53c2\u4e0e\u8005\u8fdb\u884c9\u5c0f\u65f6\u9ed1\u5ba2\u677e\uff0c\u5206\u6790AI\u8f85\u52a9\u7f16\u7a0b\u5bf9\u65b0\u624b\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u548cAI\u8f85\u52a9\u7f16\u7a0b\u5174\u8d77\uff0c\"\u6c1b\u56f4\u7f16\u7a0b\"\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u521b\u5efa\u8f6f\u4ef6\uff0c\u6709\u671b democratize \u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u5176\u6559\u80b2\u610f\u4e49\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5305\u542b\u89c2\u5bdf\u3001\u79bb\u573a\u8c03\u67e5\u548c\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7814\u7a769\u4e2a\u8de8\u5b66\u79d1\u56e2\u961f\u5728\u9ed1\u5ba2\u677e\u4e2d\u7684\u521b\u610f\u8fc7\u7a0b\u3001\u5de5\u5177\u4f7f\u7528\u3001\u534f\u4f5c\u52a8\u6001\u548c\u5b66\u4e60\u6210\u679c\u3002", "result": "\u6c1b\u56f4\u7f16\u7a0b\u5b9e\u73b0\u4e86\u5feb\u901f\u539f\u578b\u8bbe\u8ba1\u548c\u8de8\u5b66\u79d1\u534f\u4f5c\uff0c\u53c2\u4e0e\u8005\u57f9\u517b\u4e86\u63d0\u793a\u5de5\u7a0b\u6280\u80fd\uff1b\u4f46\u4e5f\u5b58\u5728\u6784\u601d\u8fc7\u65e9\u6536\u655b\u3001\u4ee3\u7801\u8d28\u91cf\u4e0d\u5747\u3001\u5bf9\u6838\u5fc3\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u53c2\u4e0e\u6709\u9650\u7b49\u95ee\u9898\u3002", "conclusion": "\u9ed1\u5ba2\u677e\u53ef\u4f5c\u4e3a\u4f4e\u98ce\u9669\u5b66\u4e60\u73af\u5883\uff0c\u4f46\u9700\u8981\u7ed3\u5408\u53d1\u6563\u601d\u7ef4\u652f\u67b6\u3001AI\u8f93\u51fa\u6279\u5224\u6027\u8bc4\u4f30\u548c\u5bf9\u751f\u4ea7\u8d28\u91cf\u7684\u5b9e\u9645\u671f\u671b\u3002"}}
{"id": "2512.02280", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02280", "abs": "https://arxiv.org/abs/2512.02280", "authors": ["Noorbakhsh Amiri Golilarz", "Sindhuja Penchala", "Shahram Rahimi"], "title": "Bridging the Gap: Toward Cognitive Autonomy in Artificial Intelligence", "comment": null, "summary": "Artificial intelligence has advanced rapidly across perception, language, reasoning, and multimodal domains. Yet despite these achievements, modern AI systems remain fun- damentally limited in their ability to self-monitor, self-correct, and regulate their behavior autonomously in dynamic contexts. This paper identifies and analyzes seven core deficiencies that constrain contemporary AI models: the absence of intrinsic self- monitoring, lack of meta-cognitive awareness, fixed and non- adaptive learning mechanisms, inability to restructure goals, lack of representational maintenance, insufficient embodied feedback, and the absence of intrinsic agency. Alongside identifying these limitations, we also outline a forward-looking perspective on how AI may evolve beyond them through architectures that mirror neurocognitive principles. We argue that these structural limitations prevent current architectures, including deep learning and transformer-based systems, from achieving robust general- ization, lifelong adaptability, and real-world autonomy. Drawing on a comparative analysis of artificial systems and biological cognition [7], and integrating insights from AI research, cognitive science, and neuroscience, we outline how these capabilities are absent in current models and why scaling alone cannot resolve them. We conclude by advocating for a paradigmatic shift toward cognitively grounded AI (cognitive autonomy) capable of self-directed adaptation, dynamic representation management, and intentional, goal-oriented behavior, paired with reformative oversight mechanisms [8] that ensure autonomous systems remain interpretable, governable, and aligned with human values.", "AI": {"tldr": "\u8bba\u6587\u6307\u51fa\u5f53\u524dAI\u7cfb\u7edf\u5728\u81ea\u6211\u76d1\u63a7\u3001\u5143\u8ba4\u77e5\u3001\u81ea\u9002\u5e94\u5b66\u4e60\u7b49\u65b9\u9762\u5b58\u5728\u4e03\u9879\u6838\u5fc3\u7f3a\u9677\uff0c\u5efa\u8bae\u901a\u8fc7\u501f\u9274\u795e\u7ecf\u8ba4\u77e5\u539f\u7406\u6765\u53d1\u5c55\u5177\u5907\u8ba4\u77e5\u81ea\u4e3b\u6027\u7684AI\u67b6\u6784\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u611f\u77e5\u3001\u8bed\u8a00\u548c\u63a8\u7406\u7b49\u9886\u57df\u53d6\u5f97\u5feb\u901f\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7f3a\u4e4f\u81ea\u6211\u76d1\u63a7\u3001\u81ea\u6211\u7ea0\u6b63\u548c\u81ea\u4e3b\u884c\u4e3a\u8c03\u8282\u7684\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u73b0\u7a33\u5065\u6cdb\u5316\u548c\u7ec8\u8eab\u9002\u5e94\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u4eba\u5de5\u7cfb\u7edf\u4e0e\u751f\u7269\u8ba4\u77e5\uff0c\u6574\u5408AI\u7814\u7a76\u3001\u8ba4\u77e5\u79d1\u5b66\u548c\u795e\u7ecf\u79d1\u5b66\u7684\u89c1\u89e3\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u4e86\u4e03\u9879\u6838\u5fc3\u7f3a\u9677\uff0c\u5e76\u57fa\u4e8e\u795e\u7ecf\u8ba4\u77e5\u539f\u7406\u63d0\u51fa\u4e86\u524d\u77bb\u6027\u67b6\u6784\u65b9\u6848\u3002", "result": "\u660e\u786e\u6307\u51fa\u5f53\u524dAI\u67b6\u6784\uff08\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\u548c\u57fa\u4e8eTransformer\u7684\u7cfb\u7edf\uff09\u56e0\u7ed3\u6784\u6027\u9650\u5236\u65e0\u6cd5\u5b9e\u73b0\u5f3a\u5927\u6cdb\u5316\u3001\u7ec8\u8eab\u9002\u5e94\u6027\u548c\u771f\u5b9e\u4e16\u754c\u81ea\u4e3b\u6027\uff0c\u5355\u7eaf\u6269\u5927\u89c4\u6a21\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u5021\u5bfc\u5411\u8ba4\u77e5\u57fa\u7840\u7684AI\uff08\u8ba4\u77e5\u81ea\u4e3b\u6027\uff09\u8fdb\u884c\u8303\u5f0f\u8f6c\u53d8\uff0c\u4f7f\u5176\u5177\u5907\u81ea\u6211\u5bfc\u5411\u9002\u5e94\u3001\u52a8\u6001\u8868\u5f81\u7ba1\u7406\u548c\u6709\u610f\u56fe\u7684\u76ee\u6807\u5bfc\u5411\u884c\u4e3a\uff0c\u540c\u65f6\u914d\u5907\u6539\u9769\u6027\u76d1\u7763\u673a\u5236\u4ee5\u786e\u4fdd\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6cbb\u7406\u6027\u548c\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.02259", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02259", "abs": "https://arxiv.org/abs/2512.02259", "authors": ["Derek Garcia", "Briana Lee", "Ibrahim Matar", "David Rickards", "Andrew Zilnicki"], "title": "CVE Breadcrumbs: Tracking Vulnerabilities Through Versioned Apache Libraries", "comment": null, "summary": "The Apache Software Foundation (ASF) ecosystem underpins a vast portion of modern software infrastructure, powering widely used components such as Log4j, Tomcat, and Struts. However, the ubiquity of these libraries has made them prime targets for high-impact security vulnerabilities, as illustrated by incidents like Log4Shell. Despite their widespread adoption, Apache projects are not immune to recurring and severe security weaknesses. We conduct a historical analysis of the Apache ecosystem to follow the \"breadcrumb trail of vulnerabilities\" by compiling a comprehensive dataset of Common Vulnerabilities and Exposures (CVEs) and Common Weakness Enumerations (CWEs). We examine trends in exploit recurrence, disclosure timelines, and remediation practices. Our analysis is guided by four key research questions: (1) What are the most persistent and repeated CWEs in Apache libraries? (2) How long do CVEs persist before being addressed? (3) What is the delay between CVE introduction and official disclosure? and (4) How long after disclosure are CVEs remediated? We present a detailed timeline of vulnerability lifecycle stages across Apache libraries and offer insights to improve secure coding practices, vulnerability monitoring, and remediation strategies. Our contributions include a curated dataset covering 24,285 Apache libraries, 1,285 CVEs, and 157 CWEs, along with empirical findings and developer-focused recommendations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9Apache\u8f6f\u4ef6\u57fa\u91d1\u4f1a\u751f\u6001\u7cfb\u7edf\u4e2d\u5386\u53f2\u6f0f\u6d1e\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u5305\u542b24,285\u4e2a\u5e93\u30011,285\u4e2aCVE\u548c157\u4e2aCWE\u7684\u6570\u636e\u96c6\uff0c\u7814\u7a76\u6f0f\u6d1e\u7684\u6301\u7eed\u6027\u3001\u62ab\u9732\u65f6\u95f4\u548c\u4fee\u590d\u5b9e\u8df5\u3002", "motivation": "Apache\u751f\u6001\u7cfb\u7edf\u662f\u73b0\u4ee3\u8f6f\u4ef6\u57fa\u7840\u8bbe\u65bd\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u4f46\u5e7f\u6cdb\u4f7f\u7528\u7684\u7ec4\u4ef6\uff08\u5982Log4j\u3001Tomcat\uff09\u9891\u7e41\u6210\u4e3a\u9ad8\u5f71\u54cd\u5b89\u5168\u6f0f\u6d1e\u7684\u76ee\u6807\uff08\u5982Log4Shell\u4e8b\u4ef6\uff09\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u5206\u6790\u6f0f\u6d1e\u6a21\u5f0f\u4ee5\u6539\u5584\u5b89\u5168\u5b9e\u8df5\u3002", "method": "\u901a\u8fc7\u6574\u7406CVE\u548cCWE\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u5386\u53f2\u5206\u6790\uff0c\u8003\u5bdf\u6f0f\u6d1e\u91cd\u73b0\u8d8b\u52bf\u3001\u62ab\u9732\u65f6\u95f4\u7ebf\u548c\u4fee\u590d\u5b9e\u8df5\uff0c\u56f4\u7ed5\u56db\u4e2a\u7814\u7a76\u95ee\u9898\u5c55\u5f00\u3002", "result": "\u7814\u7a76\u53d1\u73b0Apache\u5e93\u4e2d\u5b58\u5728\u6301\u7eed\u548c\u91cd\u590d\u7684CWE\uff0c\u6f0f\u6d1e\u5728\u89e3\u51b3\u524d\u6301\u7eed\u5b58\u5728\uff0c\u62ab\u9732\u4e0e\u4fee\u590d\u4e4b\u95f4\u5b58\u5728\u5ef6\u8fdf\uff0c\u5e76\u63d0\u4f9b\u4e86\u6f0f\u6d1e\u751f\u547d\u5468\u671f\u7684\u8be6\u7ec6\u65f6\u95f4\u7ebf\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u53d1\u73b0\u548c\u9762\u5411\u5f00\u53d1\u8005\u7684\u5efa\u8bae\uff0c\u4ee5\u6539\u8fdb\u5b89\u5168\u7f16\u7801\u5b9e\u8df5\u3001\u6f0f\u6d1e\u76d1\u63a7\u548c\u4fee\u590d\u7b56\u7565\uff0c\u5e2e\u52a9\u63d0\u5347Apache\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2512.02795", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02795", "abs": "https://arxiv.org/abs/2512.02795", "authors": ["Marcus Kessel"], "title": "Towards Observation Lakehouses: Living, Interactive Archives of Software Behavior", "comment": null, "summary": "Code-generating LLMs are trained largely on static artifacts (source, comments, specifications) and rarely on materializations of run-time behavior. As a result, they readily internalize buggy or mislabeled code. Since non-trivial semantic properties are undecidable in general, the only practical way to obtain ground-truth functionality is by dynamic observation of executions. In prior work, we addressed representation with Sequence Sheets, Stimulus-Response Matrices (SRMs), and Stimulus-Response Cubes (SRCs) to capture and compare behavior across tests, implementations, and contexts. These structures make observation data analyzable offline and reusable, but they do not by themselves provide persistence, evolution, or interactive analytics at scale. In this paper, therefore, we introduce observation lakehouses that operationalize continual SRCs: a tall, append-only observations table storing every actuation (stimulus, response, context) and SQL queries that materialize SRC slices on demand. Built on Apache Parquet + Iceberg + DuckDB, the lakehouse ingests data from controlled pipelines (LASSO) and CI pipelines (e.g., unit test executions), enabling n-version assessment, behavioral clustering, and consensus oracles without re-execution. On a 509-problem benchmark, we ingest $\\approx$8.6M observation rows ($<$51MiB) and reconstruct SRM/SRC views and clusters in $<$100ms on a laptop, demonstrating that continual behavior mining is practical without a distributed cluster of machines. This makes behavioral ground truth first-class alongside other run-time data and provides an infrastructure path toward behavior-aware evaluation and training. The Observation Lakehouse, together with the accompanying dataset, is publicly available as an open-source project on GitHub: https://github.com/SoftwareObservatorium/observation-lakehouse", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6301\u7eed\u884c\u4e3a\u89c2\u5bdf\u7684\u4ee3\u7801\u884c\u4e3a\u5206\u6790\u57fa\u7840\u8bbe\u65bd\u2014\u2014\u89c2\u5bdf\u6e56\u4ed3\uff08Observation Lakehouses\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u6267\u884c\u6570\u636e\u6355\u83b7\u548cSQL\u67e5\u8be2\u5b9e\u73b0\u5927\u89c4\u6a21\u884c\u4e3a\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u751f\u6210\u5927\u6a21\u578b\u4e3b\u8981\u57fa\u4e8e\u9759\u6001\u4ee3\u7801\u8bad\u7ec3\uff0c\u5bb9\u6613\u5b66\u4e60\u5230\u6709\u7f3a\u9677\u7684\u4ee3\u7801\u6a21\u5f0f\u3002\u7531\u4e8e\u8bed\u4e49\u5c5e\u6027\u96be\u4ee5\u9759\u6001\u5224\u5b9a\uff0c\u9700\u8981\u52a8\u6001\u6267\u884c\u89c2\u5bdf\u6765\u83b7\u53d6\u771f\u5b9e\u529f\u80fd\u884c\u4e3a\u3002", "method": "\u6784\u5efa\u57fa\u4e8eApache Parquet + Iceberg + DuckDB\u7684\u89c2\u5bdf\u6e56\u4ed3\uff0c\u91c7\u7528\u6301\u7eed\u523a\u6fc0-\u54cd\u5e94\u7acb\u65b9\u4f53\uff08SRCs\uff09\u7ed3\u6784\uff0c\u901a\u8fc7\u4ec5\u8ffd\u52a0\u8868\u5b58\u50a8\u6267\u884c\u89c2\u6d4b\u6570\u636e\uff0c\u652f\u6301\u6309\u9700SQL\u67e5\u8be2\u751f\u6210\u884c\u4e3a\u89c6\u56fe\u3002", "result": "\u5728509\u4e2a\u95ee\u9898\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6210\u529f\u6444\u5165860\u4e07\u884c\u89c2\u6d4b\u6570\u636e\uff08<51MiB\uff09\uff0c\u5728\u7b14\u8bb0\u672c\u7535\u8111\u4e0a\u5b9e\u73b0<100ms\u7684SRM/SRC\u89c6\u56fe\u91cd\u6784\u548c\u805a\u7c7b\uff0c\u8bc1\u660e\u65e0\u9700\u5206\u5e03\u5f0f\u96c6\u7fa4\u5373\u53ef\u5b9e\u73b0\u6301\u7eed\u884c\u4e3a\u6316\u6398\u3002", "conclusion": "\u89c2\u5bdf\u6e56\u4ed3\u4f7f\u884c\u4e3a\u771f\u5b9e\u6570\u636e\u6210\u4e3a\u8fd0\u884c\u65f6\u6570\u636e\u7684\u4e00\u7b49\u516c\u6c11\uff0c\u4e3a\u57fa\u4e8e\u884c\u4e3a\u7684\u6a21\u578b\u8bc4\u4f30\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u57fa\u7840\u8bbe\u65bd\u8def\u5f84\u3002"}}
{"id": "2512.02898", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.SC"], "pdf": "https://arxiv.org/pdf/2512.02898", "abs": "https://arxiv.org/abs/2512.02898", "authors": ["Pedro Orvalho", "Marta Kwiatkowska", "Mikol\u00e1\u0161 Janota", "Vasco Manquinho"], "title": "Model-Based Diagnosis with Multiple Observations: A Unified Approach for C Software and Boolean Circuits", "comment": "50 pages, 9 figures, 6 tables, 5 listings", "summary": "Debugging is one of the most time-consuming and expensive tasks in software development and circuit design. Several formula-based fault localisation (FBFL) methods have been proposed, but they fail to guarantee a set of diagnoses across all failing tests or may produce redundant diagnoses that are not subset-minimal, particularly for programs/circuits with multiple faults.\n  This paper introduces CFaults, a novel fault localisation tool for C software and Boolean circuits with multiple faults. CFaults leverages Model-Based Diagnosis (MBD) with multiple observations and aggregates all failing test cases into a unified Maximum Satisfiability (MaxSAT) formula. Consequently, our method guarantees consistency across observations and simplifies the fault localisation procedure. Experimental results on three benchmark sets, two of C programs, TCAS and C-Pack-IPAs, and one of Boolean circuits, ISCAS85, show that CFaults is faster at localising faults in C software than other FBFL approaches such as BugAssist, SNIPER, and HSD. On the ISCAS85 benchmark, CFaults is generally slower than HSD; however, it localises faults in only 6% fewer circuits, demonstrating that it remains competitive in this domain. Furthermore, CFaults produces only subset-minimal diagnoses of faulty statements, whereas the other approaches tend to enumerate redundant diagnoses (e.g., BugAssist and SNIPER).", "AI": {"tldr": "\u4e00\u7bc7\u4ecb\u7ecdCFaults\u5de5\u5177\u7528\u4e8eC\u8f6f\u4ef6\u548c\u5e03\u5c14\u7535\u8def\u591a\u91cd\u6545\u969c\u5b9a\u4f4d\u7684\u7814\u7a76\u8bba\u6587", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u516c\u5f0f\u7684\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\u5728\u5904\u7406\u591a\u91cd\u6545\u969c\u65f6\u65e0\u6cd5\u4fdd\u8bc1\u8de8\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7684\u8bca\u65ad\u96c6\u4e00\u81f4\u6027\uff0c\u4e14\u53ef\u80fd\u4ea7\u751f\u975e\u6700\u5c0f\u5b50\u96c6\u7684\u5197\u4f59\u8bca\u65ad", "method": "\u5f00\u53d1CFaults\u5de5\u5177\uff0c\u5229\u7528\u57fa\u4e8e\u6a21\u578b\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u5c06\u6240\u6709\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u805a\u5408\u5230\u7edf\u4e00\u7684MaxSAT\u516c\u5f0f\u4e2d", "result": "\u5b9e\u9a8c\u8868\u660eCFaults\u5728C\u8f6f\u4ef6\u6545\u969c\u5b9a\u4f4d\u4e0a\u6bd4BugAssist\u3001SNIPER\u548cHSD\u66f4\u5feb\uff0c\u5728ISCAS85\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u867d\u7a0d\u6162\u4f46\u4ecd\u6709\u7ade\u4e89\u529b\uff0c\u4e14\u53ea\u4ea7\u751f\u6700\u5c0f\u5b50\u96c6\u8bca\u65ad", "conclusion": "CFaults\u65b9\u6cd5\u80fd\u4fdd\u8bc1\u89c2\u5bdf\u4e00\u81f4\u6027\uff0c\u7b80\u5316\u6545\u969c\u5b9a\u4f4d\u6d41\u7a0b\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2512.02302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02302", "abs": "https://arxiv.org/abs/2512.02302", "authors": ["Varun Kumar Dasoju", "Qingsu Cheng", "Zeyun Yu"], "title": "Breast Cell Segmentation Under Extreme Data Constraints: Quantum Enhancement Meets Adaptive Loss Stabilization", "comment": "9 pages, 3 figures, 2 tables", "summary": "Annotating medical images demands significant time and expertise, often requiring pathologists to invest hundreds of hours in labeling mammary epithelial nuclei datasets. We address this critical challenge by achieving 95.5% Dice score using just 599 training images for breast cell segmentation, where just 4% of pixels represent breast tissue and 60% of images contain no breast regions. Our framework uses quantum-inspired edge enhancement via multi-scale Gabor filters creating a fourth input channel, enhancing boundary detection where inter-annotator variations reach +/- 3 pixels. We present a stabilized multi-component loss function that integrates adaptive Dice loss with boundary-aware terms and automatic positive weighting to effectively address severe class imbalance, where mammary epithelial cell regions comprise only 0.1%-20% of the total image area. Additionally, a complexity-based weighted sampling strategy is introduced to prioritize the challenging mammary epithelial cell regions. The model employs an EfficientNet-B7/UNet++ architecture with a 4-to-3 channel projection, enabling the use of pretrained weights despite limited medical imaging data. Finally, robust validation is achieved through exponential moving averaging and statistical outlier detection, ensuring reliable performance estimates on a small validation set (129 images). Our framework achieves a Dice score of 95.5% +/- 0.3% and an IoU of 91.2% +/- 0.4%. Notably, quantum-based enhancement contributes to a 2.1% improvement in boundary accuracy, while weighted sampling increases small lesion detection by 3.8%. By achieving groundbreaking performance with limited annotations, our approach significantly reduces the medical expert time required for dataset creation, addressing a fundamental bottleneck in clinical perception AI development.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u91cf\u5b50\u542f\u53d1\u7684\u533b\u5b66\u56fe\u50cf\u5206\u5272\u6846\u67b6\uff0c\u4ec5\u7528599\u5f20\u8bad\u7ec3\u56fe\u50cf\u5c31\u5728\u4e73\u817a\u7ec6\u80de\u5206\u5272\u4e2d\u8fbe\u5230\u4e8695.5%\u7684Dice\u5206\u6570\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6807\u6ce8\u9700\u6c42\u3002", "motivation": "\u533b\u5b66\u56fe\u50cf\u6807\u6ce8\u9700\u8981\u5927\u91cf\u4e13\u5bb6\u65f6\u95f4\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u4e73\u817a\u4e0a\u76ae\u7ec6\u80de\u6807\u6ce8\u6781\u4e3a\u8017\u65f6\uff0c\u6210\u4e3a\u4e34\u5e8aAI\u53d1\u5c55\u7684\u74f6\u9888\u3002", "method": "\u91c7\u7528EfficientNet-B7/UNet++\u67b6\u6784\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6Gabor\u6ee4\u6ce2\u5668\u5b9e\u73b0\u91cf\u5b50\u542f\u53d1\u8fb9\u7f18\u589e\u5f3a\u521b\u5efa\u7b2c\u56db\u8f93\u5165\u901a\u9053\uff1b\u8bbe\u8ba1\u4e86\u7a33\u5b9a\u591a\u7ec4\u4ef6\u635f\u5931\u51fd\u6570\u7ed3\u5408\u81ea\u9002\u5e94Dice\u635f\u5931\u548c\u8fb9\u754c\u611f\u77e5\u9879\uff1b\u5f15\u5165\u57fa\u4e8e\u590d\u6742\u5ea6\u7684\u52a0\u6743\u91c7\u6837\u7b56\u7565\u3002", "result": "\u5728\u9a8c\u8bc1\u96c6\uff08129\u5f20\u56fe\u50cf\uff09\u4e0a\u8fbe\u5230Dice\u5206\u657095.5%\u00b10.3%\u548cIoU 91.2%\u00b10.4%\uff1b\u91cf\u5b50\u589e\u5f3a\u4f7f\u8fb9\u754c\u51c6\u786e\u7387\u63d0\u53472.1%\uff0c\u52a0\u6743\u91c7\u6837\u63d0\u9ad8\u5c0f\u75c5\u7076\u68c0\u6d4b3.8%\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u7a81\u7834\u6027\u7684\u5c11\u6807\u6ce8\u9ad8\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u533b\u5b66\u4e13\u5bb6\u6807\u6ce8\u65f6\u95f4\uff0c\u89e3\u51b3\u4e86\u4e34\u5e8a\u611f\u77e5AI\u5f00\u53d1\u7684\u5173\u952e\u74f6\u9888\u3002"}}
{"id": "2512.02306", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02306", "abs": "https://arxiv.org/abs/2512.02306", "authors": ["Boyu Zhu", "Xiaofei Wen", "Wenjie Jacky Mo", "Tinghui Zhu", "Yanan Xie", "Peng Qi", "Muhao Chen"], "title": "OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning", "comment": null, "summary": "Omni-modal Large Language Models (OLLMs) that process text, images, videos, and audio introduce new challenges for safety and value guardrails in human-AI interaction. Prior guardrail research largely targets unimodal settings and typically frames safeguarding as binary classification, which limits robustness across diverse modalities and tasks. To address this gap, we propose OmniGuard, the first family of omni-modal guardrails that performs safeguarding across all modalities with deliberate reasoning ability. To support the training of OMNIGUARD, we curate a large, comprehensive omni-modal safety dataset comprising over 210K diverse samples, with inputs that cover all modalities through both unimodal and cross-modal samples. Each sample is annotated with structured safety labels and carefully curated safety critiques from expert models through targeted distillation. Extensive experiments on 15 benchmarks show that OmniGuard achieves strong effectiveness and generalization across a wide range of multimodal safety scenarios. Importantly, OmniGuard provides a unified framework that enforces policies and mitigates risks in omni-modalities, paving the way toward building more robust and capable omnimodal safeguarding systems.", "AI": {"tldr": "\u63d0\u51fa\u7684OmniGuard\u662f\u9996\u4e2a\u5168\u6a21\u6001\u62a4\u680f\u6846\u67b6\uff0c\u901a\u8fc7\u7cbe\u5fc3\u6311\u9009\u7684\u5927\u578b\u6570\u636e\u96c6\u548c\u4e13\u5bb6\u6a21\u578b\u84b8\u998f\uff0c\u5b9e\u73b0\u4e86\u8de8\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\u7684\u7edf\u4e00\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u73b0\u6709\u7684\u62a4\u680f\u7814\u7a76\u4e3b\u8981\u9488\u5bf9\u5355\u6a21\u6001\u8bbe\u7f6e\uff0c\u91c7\u7528\u4e8c\u5143\u5206\u7c7b\u65b9\u6cd5\uff0c\u7f3a\u4e4f\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b21\u4e07\u591a\u6837\u672c\u7684\u5168\u6a21\u6001\u5b89\u5168\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u4e13\u5bb6\u6a21\u578b\u84b8\u998f\u751f\u6210\u7ed3\u6784\u5316\u5b89\u5168\u6807\u7b7e\u548c\u5b89\u5168\u8bc4\u8bba\uff0c\u8bad\u7ec3\u5177\u6709\u6df1\u601d\u719f\u8651\u63a8\u7406\u80fd\u529b\u7684OmniGuard\u6a21\u578b\u3002", "result": "\u572815\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOmniGuard\u5728\u591a\u79cd\u591a\u6a21\u6001\u5b89\u5168\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "OmniGuard\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u53ef\u5728\u5168\u6a21\u6001\u4e2d\u6267\u884c\u7b56\u7565\u5e76\u964d\u4f4e\u98ce\u9669\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u548c\u7a33\u5065\u7684\u5168\u6a21\u6001\u9632\u62a4\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2512.02318", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02318", "abs": "https://arxiv.org/abs/2512.02318", "authors": ["Junyu Wang", "Changjia Zhu", "Yuanbo Zhou", "Lingyao Li", "Xu He", "Junjie Xiong"], "title": "COGNITION: From Evaluation to Defense against Multimodal LLM CAPTCHA Solvers", "comment": null, "summary": "This paper studies how multimodal large language models (MLLMs) undermine the security guarantees of visual CAPTCHA. We identify the attack surface where an adversary can cheaply automate CAPTCHA solving using off-the-shelf models. We evaluate 7 leading commercial and open-source MLLMs across 18 real-world CAPTCHA task types, measuring single-shot accuracy, success under limited retries, end-to-end latency, and per-solve cost. We further analyze the impact of task-specific prompt engineering and few-shot demonstrations on solver effectiveness. We reveal that MLLMs can reliably solve recognition-oriented and low-interaction CAPTCHA tasks at human-like cost and latency, whereas tasks requiring fine-grained localization, multi-step spatial reasoning, or cross-frame consistency remain significantly harder for current models. By examining the reasoning traces of such MLLMs, we investigate the underlying mechanisms of why models succeed/fail on specific CAPTCHA puzzles and use these insights to derive defense-oriented guidelines for selecting and strengthening CAPTCHA tasks. We conclude by discussing implications for platform operators deploying CAPTCHA as part of their abuse-mitigation pipeline.Code Availability (https://anonymous.4open.science/r/Captcha-465E/).", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u524a\u5f31\u89c6\u89c9\u9a8c\u8bc1\u7801\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u53d1\u73b0\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u73b0\u6210\u6a21\u578b\u5ec9\u4ef7\u81ea\u52a8\u5316\u7834\u89e3\u9a8c\u8bc1\u7801\u3002\u8bc4\u4f30\u4e867\u4e2a\u4e3b\u6d41MLLM\u572818\u79cd\u9a8c\u8bc1\u7801\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u53ef\u53ef\u9760\u89e3\u51b3\u8bc6\u522b\u7c7b\u548c\u4f4e\u4ea4\u4e92\u7c7b\u9a8c\u8bc1\u7801\uff0c\u4f46\u7cbe\u786e\u5b9a\u4f4d\u548c\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4ecd\u5177\u6311\u6218\u3002", "motivation": "\u9a8c\u8bc1\u7801\u4f5c\u4e3a\u533a\u5206\u4eba\u7c7b\u548c\u673a\u5668\u7684\u91cd\u8981\u5b89\u5168\u673a\u5236\uff0c\u9762\u4e34\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5a01\u80c1\u3002\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30MLLMs\u5bf9\u9a8c\u8bc1\u7801\u5b89\u5168\u6027\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u8bc4\u4f307\u4e2a\u5546\u4e1a\u548c\u5f00\u6e90MLLM\u572818\u7c7b\u771f\u5b9e\u9a8c\u8bc1\u7801\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u6307\u6807\u5305\u62ec\u5355\u6b21\u51c6\u786e\u7387\u3001\u6709\u9650\u91cd\u8bd5\u6210\u529f\u7387\u3001\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u5355\u6b21\u7834\u89e3\u6210\u672c\u3002\u5206\u6790\u63d0\u793a\u5de5\u7a0b\u548c\u5c11\u6837\u672c\u6f14\u793a\u5bf9\u7834\u89e3\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "MLLM\u80fd\u4ee5\u63a5\u8fd1\u4eba\u7c7b\u7684\u6210\u672c\u548c\u5ef6\u8fdf\u53ef\u9760\u89e3\u51b3\u8bc6\u522b\u5bfc\u5411\u548c\u4f4e\u4ea4\u4e92\u9a8c\u8bc1\u7801\u4efb\u52a1\uff1b\u9700\u8981\u7cbe\u786e\u5b9a\u4f4d\u3001\u591a\u6b65\u7a7a\u95f4\u63a8\u7406\u6216\u8de8\u5e27\u4e00\u81f4\u6027\u7684\u4efb\u52a1\u5bf9\u5f53\u524d\u6a21\u578b\u4ecd\u56f0\u96be\u3002", "conclusion": "\u901a\u8fc7\u5206\u6790\u6a21\u578b\u63a8\u7406\u8f68\u8ff9\u63ed\u793a\u6210\u529f/\u5931\u8d25\u673a\u5236\uff0c\u4e3a\u5e73\u53f0\u8fd0\u8425\u8005\u63d0\u4f9b\u9a8c\u8bc1\u7801\u9009\u62e9\u548c\u5f3a\u5316\u7684\u9632\u5fa1\u5bfc\u5411\u6307\u5357\uff0c\u8ba8\u8bba\u9a8c\u8bc1\u7801\u5728\u6ee5\u7528\u7f13\u89e3\u6d41\u7a0b\u4e2d\u7684\u90e8\u7f72\u610f\u4e49\u3002"}}
{"id": "2512.02340", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.02340", "abs": "https://arxiv.org/abs/2512.02340", "authors": ["Qiyao Xue", "Weichen Liu", "Shiqi Wang", "Haoming Wang", "Yuyang Wu", "Wei Gao"], "title": "Reasoning Path and Latent State Analysis for Multi-view Visual Spatial Reasoning: A Cognitive Science Perspective", "comment": "23 pages, 37 figures", "summary": "Spatial reasoning is a core aspect of human intelligence that allows perception, inference and planning in 3D environments. However, current vision-language models (VLMs) struggle to maintain geometric coherence and cross-view consistency for spatial reasoning in multi-view settings. We attribute this gap to the lack of fine-grained benchmarks that isolate multi-view reasoning from single-view perception and temporal factors. To address this, we present ReMindView-Bench, a cognitively grounded benchmark for evaluating how VLMs construct, align and maintain spatial mental models across complementary viewpoints. ReMindView-Bench systematically varies viewpoint spatial pattern and query type to probe key factors of spatial cognition. Evaluations of 15 current VLMs reveals consistent failures in cross-view alignment and perspective-taking in multi-view spatial reasoning, motivating deeper analysis on the reasoning process. Explicit phase-wise analysis using LLM-as-a-judge and self-consistency prompting shows that VLMs perform well on in-frame perception but degrade sharply when integrating information across views. Implicit analysis, including linear probing and entropy dynamics, further show progressive loss of task-relevant information and uncertainty separation between correct and incorrect trajectories. These results provide a cognitively grounded diagnosis of VLM spatial reasoning and reveal how multi-view spatial mental models are formed, degraded and destabilized across reasoning phases. The ReMindView-Bench benchmark is available at https://huggingface.co/datasets/Xue0823/ReMindView-Bench, and the source codes of benchmark construction and VLM reasoning analysis are available at https://github.com/pittisl/ReMindView-Bench.", "AI": {"tldr": "ReMindView-Bench\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u89c6\u56fe\u7a7a\u95f4\u63a8\u7406\u4e2d\u7684\u7cfb\u7edf\u5f31\u70b9\uff0c\u7279\u522b\u662f\u5728\u8de8\u89c6\u56fe\u5bf9\u9f50\u548c\u89c6\u89d2\u8f6c\u6362\u65b9\u9762\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u89c6\u56fe\u73af\u5883\u4e0b\u96be\u4ee5\u4fdd\u6301\u51e0\u4f55\u8fde\u8d2f\u6027\u548c\u8de8\u89c6\u56fe\u4e00\u81f4\u6027\u7684\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u7f3a\u4e4f\u80fd\u591f\u5c06\u591a\u89c6\u56fe\u63a8\u7406\u4e0e\u5355\u89c6\u56fe\u611f\u77e5\u548c\u65f6\u95f4\u56e0\u7d20\u9694\u79bb\u7684\u7ec6\u7c92\u5ea6\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u63d0\u51faReMindView-Bench\u57fa\u51c6\uff0c\u901a\u8fc7\u7cfb\u7edf\u53d8\u5316\u89c6\u70b9\u7a7a\u95f4\u6a21\u5f0f\u548c\u67e5\u8be2\u7c7b\u578b\u6765\u8bc4\u4f30VLMs\u6784\u5efa\u3001\u5bf9\u9f50\u548c\u7ef4\u62a4\u7a7a\u95f4\u5fc3\u7406\u6a21\u578b\u7684\u80fd\u529b\u3002\u91c7\u7528\u663e\u5f0f\u5206\u9636\u6bb5\u5206\u6790\uff08LLM-as-a-judge\u548c\u81ea\u4e00\u81f4\u6027\u63d0\u793a\uff09\u548c\u9690\u5f0f\u5206\u6790\uff08\u7ebf\u6027\u63a2\u6d4b\u548c\u71b5\u52a8\u529b\u5b66\uff09\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f3015\u4e2a\u73b0\u6709VLM\u53d1\u73b0\u5b83\u4eec\u5728\u591a\u89c6\u56fe\u7a7a\u95f4\u63a8\u7406\u4e2d\u5b58\u5728\u4e00\u81f4\u7684\u8de8\u89c6\u56fe\u5bf9\u9f50\u548c\u89c6\u89d2\u8f6c\u6362\u5931\u8d25\u3002VLMs\u5728\u5e27\u5185\u611f\u77e5\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8de8\u89c6\u56fe\u4fe1\u606f\u6574\u5408\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\u3002\u9690\u5f0f\u5206\u6790\u663e\u793a\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u9010\u6e10\u4e22\u5931\uff0c\u6b63\u786e\u548c\u9519\u8bef\u63a8\u7406\u8f68\u8ff9\u4e4b\u95f4\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u5206\u79bb\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aVLM\u7a7a\u95f4\u63a8\u7406\u63d0\u4f9b\u4e86\u8ba4\u77e5\u57fa\u7840\u7684\u8bca\u65ad\uff0c\u63ed\u793a\u4e86\u591a\u89c6\u56fe\u7a7a\u95f4\u5fc3\u7406\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5f62\u6210\u3001\u9000\u5316\u548c\u4e0d\u7a33\u5b9a\u673a\u5236\u3002ReMindView-Bench\u57fa\u51c6\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdbVLM\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.02589", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02589", "abs": "https://arxiv.org/abs/2512.02589", "authors": ["Junyi Hou", "Andre Lin Huikai", "Nuo Chen", "Yiwei Gong", "Bingsheng He"], "title": "PaperDebugger: A Plugin-Based Multi-Agent System for In-Editor Academic Writing, Review, and Editing", "comment": null, "summary": "Large language models are increasingly embedded into academic writing workflows, yet existing assistants remain external to the editor, preventing deep interaction with document state, structure, and revision history. This separation makes it impossible to support agentic, context-aware operations directly within LaTeX editors such as Overleaf. We present PaperDebugger, an in-editor, multi-agent, and plugin-based academic writing assistant that brings LLM-driven reasoning directly into the writing environment. Enabling such in-editor interaction is technically non-trivial: it requires reliable bidirectional synchronization with the editor, fine-grained version control and patching, secure state management, multi-agent scheduling, and extensible communication with external tools. PaperDebugger addresses these challenges through a Chrome-approved extension, a Kubernetes-native orchestration layer, and a Model Context Protocol (MCP) toolchain that integrates literature search, reference lookup, document scoring, and revision pipelines. Our demo showcases a fully integrated workflow, including localized edits, structured reviews, parallel agent execution, and diff-based updates, encapsulated within a minimal-intrusion user interface (UI). Early aggregated analytics demonstrate active user engagement and validate the practicality of an editor-native, agentic writing assistant. More details about this demo and video could be found at https://github.com/PaperDebugger/PaperDebugger.", "AI": {"tldr": "\u63d0\u51fa\u4e86PaperDebugger\uff0c\u4e00\u6b3e\u5185\u5d4c\u4e8eLaTeX\u7f16\u8f91\u5668\uff08\u5982Overleaf\uff09\u7684\u591a\u667a\u80fd\u4f53\u3001\u63d2\u4ef6\u5f0f\u5b66\u672f\u5199\u4f5c\u52a9\u624b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u65e0\u6cd5\u4e0e\u7f16\u8f91\u5668\u6df1\u5ea6\u4ea4\u4e92\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u5199\u4f5c\u52a9\u624b\u4e0e\u7f16\u8f91\u5668\u5206\u79bb\uff0c\u65e0\u6cd5\u652f\u6301\u57fa\u4e8e\u6587\u6863\u72b6\u6001\u3001\u7ed3\u6784\u548c\u4fee\u8ba2\u5386\u53f2\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u64cd\u4f5c\uff0c\u9650\u5236\u4e86\u5728LaTeX\u7f16\u8f91\u5668\u5185\u7684\u667a\u80fd\u8f85\u52a9\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8eChrome\u6269\u5c55\u3001Kubernetes\u539f\u751f\u7f16\u6392\u5c42\u548cModel Context Protocol\uff08MCP\uff09\u5de5\u5177\u94fe\u7684\u7cfb\u7edf\uff0c\u5b9e\u73b0\u53ef\u9760\u7684\u7f16\u8f91\u5668\u53cc\u5411\u540c\u6b65\u3001\u7ec6\u7c92\u5ea6\u7248\u672c\u63a7\u5236\u3001\u5b89\u5168\u72b6\u6001\u7ba1\u7406\u3001\u591a\u667a\u80fd\u4f53\u8c03\u5ea6\u548c\u5916\u90e8\u5de5\u5177\u96c6\u6210\u3002", "result": "\u5f00\u53d1\u51fa\u529f\u80fd\u5b8c\u6574\u7684\u6f14\u793a\u7cfb\u7edf\uff0c\u652f\u6301\u672c\u5730\u5316\u7f16\u8f91\u3001\u7ed3\u6784\u5316\u8bc4\u5ba1\u3001\u5e76\u884c\u667a\u80fd\u4f53\u6267\u884c\u548c\u57fa\u4e8e\u5dee\u5f02\u7684\u66f4\u65b0\uff0c\u7528\u6237\u754c\u9762\u4fb5\u5165\u6027\u6700\u5c0f\uff1b\u65e9\u671f\u7528\u6237\u6570\u636e\u5206\u6790\u663e\u793a\u79ef\u6781\u7684\u4f7f\u7528\u53c2\u4e0e\u5ea6\u3002", "conclusion": "PaperDebugger\u9a8c\u8bc1\u4e86\u5728\u7f16\u8f91\u5668\u5185\u90e8\u96c6\u6210\u57fa\u4e8eLLM\u7684\u667a\u80fd\u5199\u4f5c\u52a9\u624b\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5b66\u672f\u5199\u4f5c\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u66f4\u6df1\u5ea6\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684AI\u652f\u6301\u3002"}}
{"id": "2512.02389", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02389", "abs": "https://arxiv.org/abs/2512.02389", "authors": ["David X. Wu", "Shreyas Kapur", "Anant Sahai", "Stuart Russell"], "title": "Synthetic Error Injection Fails to Elicit Self-Correction In Language Models", "comment": "13 pages, 12 figures", "summary": "Reinforcement learning has become the dominant paradigm for eliciting reasoning and self-correction capabilities in large language models, but its computational expense motivates exploration of alternatives. Inspired by techniques from autonomous driving and robotics, we investigate whether supervised learning with synthetic error injection can induce self-correction abilities in language models. Our approach inserts artificial errors into reasoning chains, masks them, and supervises the model to recognize and correct these mistakes. Despite the intuitive appeal of this method, we find that it fails to significantly improve performance even on simple synthetic tasks across multiple models. Moreover, even when the model catches its own error, it often parrots the original mistake. We find that the distribution shift of synthetic errors to on-policy errors significantly degrades the error-correction capabilities of the fine-tuned model, even with good synthetic coverage of on-policy errors. Our results help explain why on-policy reinforcement learning methods have proven uniquely effective for eliciting self-correction.", "AI": {"tldr": "\u76d1\u7763\u5b66\u4e60\u52a0\u9519\u8bef\u6ce8\u5165\u7684\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6fc0\u53d1\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u6211\u4fee\u6b63\u80fd\u529b\uff0c\u9700\u8981\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u65b9\u6848", "motivation": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u80fd\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4f5c\u8005\u5c1d\u8bd5\u4ece\u81ea\u52a8\u9a7e\u9a76\u548c\u673a\u5668\u4eba\u6280\u672f\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u63a2\u7d22\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u52a0\u4eba\u5de5\u9519\u8bef\u6ce8\u5165\u7684\u65b9\u6cd5\u6765\u66ff\u4ee3RL", "method": "\u5728\u63a8\u7406\u94fe\u4e2d\u63d2\u5165\u4eba\u5de5\u8bbe\u8ba1\u9519\u8bef\u540e\u8fdb\u884c\u63a9\u7801\u5904\u7406\uff0c\u7136\u540e\u76d1\u7763\u6a21\u578b\u8bc6\u522b\u5e76\u4fee\u6b63\u8fd9\u4e9b\u9519\u8bef", "result": "\u8be5\u65b9\u6cd5\u5373\u4f7f\u5728\u7b80\u5355\u4efb\u52a1\u548c\u591a\u6a21\u578b\u4e0a\u90fd\u672a\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u6a21\u578b\u5373\u4f7f\u53d1\u73b0\u4e86\u9519\u8bef\u4e5f\u5e38\u5e38\u91cd\u590d\u539f\u6709\u9519\u8bef", "conclusion": "\u5408\u6210\u9519\u8bef\u4e0e\u5728\u7ebf\u9519\u8bef\u7684\u5206\u5e03\u5dee\u5f02\u663e\u8457\u524a\u5f31\u4e86\u5fae\u8c03\u540e\u7684\u9519\u8bef\u4fee\u6b63\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5bf9\u6fc0\u53d1\u81ea\u6211\u4fee\u6b63\u80fd\u529b\u5177\u6709\u72ec\u7279\u4f18\u52bf"}}
{"id": "2512.02918", "categories": ["cs.CR", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.02918", "abs": "https://arxiv.org/abs/2512.02918", "authors": ["Wanxu Xia", "Ziqiao Kong", "Zhengwei Li", "Yi Lu", "Pan Li", "Liqun Yang", "Yang Liu", "Xiapu Luo", "Shaohua Li"], "title": "Belobog: Move Language Fuzzing Framework For Real-World Smart Contracts", "comment": "Slight revision and under review", "summary": "Move is a research-oriented programming language design for secure and verifiable smart contract development and has been widely used in managing billions of digital assets in blockchains, such as Sui and Aptos. Move features a strong static type system and explicit resource semantics to enforce safety properties such as the prevention of data races, invalid asset transfers, and entry vulnerabilities. However, smart contracts written in Move may still contain certain vulnerabilities that are beyond the reach of its type system. It is thus essential to validate Move smart contracts. Unfortunately, due to its strong type system, existing smart contract fuzzers are ineffective in producing syntactically or semantically valid transactions to test Move smart contracts. This paper introduces the first fuzzing framework, Belobog, for Move smart contracts. Belobog is type-aware and ensures that all generated and mutated transactions are well-typed. More specifically, for a target Move smart contract, Belobog first constructs a type graph based on Move's type system, and then generates or mutates a transaction based on the graph trace derived from the type graph. In order to overcome the complex checks in Move smart contracts, we further design and implement a concolic executor in Belobog. We evaluated Belobog on 109 real-world Move smart contract projects. The experimental results show that Belobog is able to detect 100\\% critical and 79\\% major vulnerabilities manually audited by human experts. We further selected two recent notorious incidents in Move smart contracts, i.e., Cetus and Nemo. Belobog successfully reproduced full exploits for both of them, without any prior knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u9488\u5bf9Move\u667a\u80fd\u5408\u7ea6\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6Belobog\uff0c\u5b83\u80fd\u751f\u6210\u7c7b\u578b\u611f\u77e5\u7684\u6709\u6548\u4ea4\u6613\u6765\u68c0\u6d4b\u6807\u51c6\u7c7b\u578b\u7cfb\u7edf\u65e0\u6cd5\u6355\u83b7\u7684\u6f0f\u6d1e\u3002", "motivation": "Move\u8bed\u8a00\u867d\u7136\u5177\u6709\u5f3a\u5927\u7684\u7c7b\u578b\u7cfb\u7edf\u6765\u4fdd\u8bc1\u667a\u80fd\u5408\u7ea6\u5b89\u5168\uff0c\u4f46\u5176\u7c7b\u578b\u7cfb\u7edf\u65e0\u6cd5\u68c0\u6d4b\u6240\u6709\u6f0f\u6d1e\uff0c\u800c\u73b0\u6709\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u96be\u4ee5\u751f\u6210\u6709\u6548\u7684Move\u4ea4\u6613\u6765\u8fdb\u884c\u6d4b\u8bd5\u3002", "method": "Belogog\u9996\u5148\u57fa\u4e8eMove\u7c7b\u578b\u7cfb\u7edf\u6784\u5efa\u7c7b\u578b\u56fe\uff0c\u7136\u540e\u57fa\u4e8e\u7c7b\u578b\u56fe\u8f68\u8ff9\u751f\u6210\u6216\u53d8\u5f02\u4ea4\u6613\uff0c\u5e76\u8bbe\u8ba1\u4e86concolic\u6267\u884c\u5668\u6765\u5904\u7406\u590d\u6742\u68c0\u67e5\u3002", "result": "\u5728109\u4e2a\u771f\u5b9eMove\u5408\u7ea6\u9879\u76ee\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0cBelobog\u80fd\u68c0\u6d4b100%\u7684\u5173\u952e\u6f0f\u6d1e\u548c79%\u7684\u4e3b\u8981\u6f0f\u6d1e\uff0c\u5e76\u6210\u529f\u590d\u73b0\u4e86Cetus\u548cNemo\u4e24\u4e2a\u8457\u540d\u5b89\u5168\u4e8b\u4ef6\u3002", "conclusion": "Belobog\u662f\u7b2c\u4e00\u4e2a\u6709\u6548\u7684Move\u667a\u80fd\u5408\u7ea6\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347Move\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2512.02418", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02418", "abs": "https://arxiv.org/abs/2512.02418", "authors": ["Yuexin Xiang", "Yuchen Lei", "SM Mahir Shazeed Rish", "Yuanzhe Zhang", "Qin Wang", "Tsz Hon Yuen", "Jiangshan Yu"], "title": "Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins", "comment": null, "summary": "Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6846\u67b6\uff0c\u5c06\u7a33\u5b9a\u5e01\u94fe\u4e0a\u53d1\u884c\u6570\u636e\u4e0e\u94fe\u4e0b\u62ab\u9732\u58f0\u660e\u5bf9\u9f50\uff0c\u4ee5\u63d0\u9ad8\u900f\u660e\u5ea6\u548c\u5ba1\u8ba1\u6548\u7387\u3002", "motivation": "\u7a33\u5b9a\u5e01\u7684\u900f\u660e\u5ea6\u6570\u636e\u5206\u6563\u5728\u53ef\u9a8c\u8bc1\u7684\u94fe\u4e0a\u8f68\u8ff9\u548c\u65e0\u7ed3\u6784\u7684\u94fe\u4e0b\u6587\u672c\u62ab\u9732\u4e2d\uff0c\u4e8c\u8005\u7f3a\u4e4f\u5173\u8054\u3002", "method": "\u901a\u8fc7LLM\u8fdb\u884c\u6587\u6863\u89e3\u6790\u548c\u8bed\u4e49\u5bf9\u9f50\uff0c\u63d0\u53d6\u94fe\u4e0b\u8d22\u52a1\u6307\u6807\u5e76\u6620\u5c04\u5230\u94fe\u4e0a\u6307\u6807\uff1b\u6574\u5408\u591a\u94fe\u53d1\u884c\u8bb0\u5f55\u548c\u62ab\u9732\u6587\u4ef6\u5230\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6846\u67b6\u4e2d\u3002", "result": "\u91cf\u5316\u4e86\u62a5\u544a\u4e0e\u5b9e\u9645\u6d41\u901a\u91cf\u4e4b\u95f4\u7684\u5dee\u5f02\uff0c\u53d1\u73b0\u62ab\u9732\u6570\u636e\u4e0e\u53ef\u9a8c\u8bc1\u6570\u636e\u4e4b\u95f4\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u8ddd\u3002", "conclusion": "LLM\u8f85\u52a9\u5206\u6790\u589e\u5f3a\u4e86\u8de8\u6a21\u6001\u900f\u660e\u5ea6\uff0c\u652f\u6301\u53bb\u4e2d\u5fc3\u5316\u91d1\u878d\u4e2d\u7684\u81ea\u52a8\u5316\u6570\u636e\u9a71\u52a8\u5ba1\u8ba1\u3002"}}
{"id": "2512.02472", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02472", "abs": "https://arxiv.org/abs/2512.02472", "authors": ["Wenhao Yu", "Zhenwen Liang", "Chengsong Huang", "Kishan Panaganti", "Tianqing Fang", "Haitao Mi", "Dong Yu"], "title": "Guided Self-Evolving LLMs with Minimal Human Supervision", "comment": null, "summary": "AI self-evolution has long been envisioned as a path toward superintelligence, where models autonomously acquire, refine, and internalize knowledge from their own learning experiences. Yet in practice, unguided self-evolving systems often plateau quickly or even degrade as training progresses. These failures arise from issues such as concept drift, diversity collapse, and mis-evolution, as models reinforce their own biases and converge toward low-entropy behaviors. To enable models to self-evolve in a stable and controllable manner while minimizing reliance on human supervision, we introduce R-Few, a guided Self-Play Challenger-Solver framework that incorporates lightweight human oversight through in-context grounding and mixed training. At each iteration, the Challenger samples a small set of human-labeled examples to guide synthetic question generation, while the Solver jointly trains on human and synthetic examples under an online, difficulty-based curriculum. Across math and general reasoning benchmarks, R-Few achieves consistent and iterative improvements. For example, Qwen3-8B-Base improves by +3.0 points over R-Zero on math tasks and achieves performance on par with General-Reasoner, despite the latter being trained on 20 times more human data. Ablation studies confirm the complementary contributions of grounded challenger training and curriculum-based solver training, and further analysis shows that R-Few mitigates drift, yielding more stable and controllable co-evolutionary dynamics.", "AI": {"tldr": "R-Few\u6846\u67b6\u901a\u8fc7\u6307\u5bfc\u6027\u81ea\u6211\u535a\u5f08\u5b9e\u73b0AI\u7a33\u5b9a\u81ea\u8fdb\u5316\uff0c\u5728\u6570\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347", "motivation": "\u89e3\u51b3AI\u81ea\u8fdb\u5316\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u6982\u5ff5\u6f02\u79fb\u3001\u591a\u6837\u6027\u5d29\u6e83\u548c\u9519\u8bef\u8fdb\u5316\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u7a33\u5b9a\u53ef\u63a7\u7684\u81ea\u8fdb\u5316", "method": "\u63d0\u51faR-Few\u6846\u67b6\uff1a\u57fa\u4e8eChallenger-Solver\u7684\u6307\u5bfc\u6027\u81ea\u6211\u535a\u5f08\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u63a5\u5730\u548c\u6df7\u5408\u8bad\u7ec3\u878d\u5165\u8f7b\u91cf\u7ea7\u4eba\u5de5\u76d1\u7763", "result": "Qwen3-8B-Base\u5728\u6570\u5b66\u4efb\u52a1\u4e0a\u6bd4R-Zero\u63d0\u53473.0\u5206\uff0c\u6027\u80fd\u4e0e\u4f7f\u752820\u500d\u4eba\u7c7b\u6570\u636e\u7684General-Reasoner\u76f8\u5f53", "conclusion": "R-FFew\u8bc1\u660e\u4e86\u6307\u5bfc\u6027\u81ea\u8fdb\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u7a33\u5b9a\u6a21\u578b\u534f\u540c\u8fdb\u5316\u8fc7\u7a0b\uff0c\u51cf\u5c11\u6982\u5ff5\u6f02\u79fb"}}
{"id": "2512.02499", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02499", "abs": "https://arxiv.org/abs/2512.02499", "authors": ["Yongkai Liu", "Helena Feng", "Bin Jiang", "Yixin Wang", "Max Wintermark", "David S. Liebeskind", "Michael Moseley", "Maarten Lansberg", "Gregory Albers", "Jeremy Heit", "Greg Zaharchuk"], "title": "COPE: Chain-Of-Thought Prediction Engine for Open-Source Large Language Model Based Stroke Outcome Prediction from Clinical Notes", "comment": null, "summary": "Predicting outcomes in acute ischemic stroke (AIS) guides clinical decision-making, patient counseling, and resource allocation. Clinical notes contain rich contextual information, but their unstructured nature limits their use in traditional predictive models. We developed and evaluated the Chain-of-Thought (CoT) Outcome Prediction Engine (COPE), a reasoning-enhanced large language model framework, for predicting 90-day functional outcomes after AIS from unstructured clinical notes. This study included 464 AIS patients with discharge summaries and 90-day modified Rankin Scale (mRS) scores. COPE uses a two-step CoT framework based on sequential open-source LLaMA-3-8B models: the first generates clinical reasoning, and the second outputs an mRS prediction. We compared COPE with GPT-4.1, ClinicalBERT, a structured variable-based machine learning model (Clinical ML), and a single-step LLM without CoT. Performance was evaluated using mean absolute error (MAE), accuracy within +/-1 mRS point, and exact accuracy. COPE achieved an MAE of 1.01 (95% CI 0.92-1.11), +/-1 accuracy of 74.4% (69.9, 78.8%), and exact accuracy of 32.8% (28.0, 37.6%), comparable to GPT-4.1 and superior to ClinicalBERT [MAE 1.24 (1.13-1.36)], Clinical ML [1.28 (1.18-1.39)], and the single-step LLM [1.20 (1.09-1.33)]. Subgroup analyses showed consistent performance across sex and age, with slightly higher error among older patients, those undergoing thrombectomy, and those with longer summaries. These findings demonstrate that COPE, a lightweight, interpretable, and privacy-preserving open-source framework, provides an accurate and practical solution for outcome prediction from unstructured clinical text.", "AI": {"tldr": "COPE\u662f\u4e00\u4e2a\u57fa\u4e8e\u601d\u7ef4\u94fe\u63a8\u7406\u7684\u8f7b\u91cf\u7ea7LLM\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u7b14\u8bb0\u9884\u6d4b\u6025\u6027\u7f3a\u8840\u6027\u5352\u4e2d90\u5929\u529f\u80fd\u7ed3\u5c40\uff0c\u6027\u80fd\u5ab2\u7f8eGPT-4\u4e14\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b", "motivation": "\u4e34\u5e8a\u7b14\u8bb0\u5305\u542b\u4e30\u5bcc\u4fe1\u606f\u4f46\u975e\u7ed3\u6784\u5316\u7279\u70b9\u9650\u5236\u4e86\u4f20\u7edf\u9884\u6d4b\u6a21\u578b\u7684\u4f7f\u7528\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u7684\u667a\u80fd\u9884\u6d4b\u5de5\u5177", "method": "\u4f7f\u7528\u4e24\u9636\u6bb5LLaMA-3-8B\u6a21\u578b\uff1a\u9996\u5148\u751f\u6210\u4e34\u5e8a\u63a8\u7406\uff0c\u7136\u540e\u8f93\u51famRS\u8bc4\u5206\u9884\u6d4b\uff0c\u5e76\u4e0eGPT-4\u3001ClinicalBERT\u7b49\u6a21\u578b\u5bf9\u6bd4", "result": "COPE\u7684MAE\u4e3a1.01\uff0c\u00b11\u51c6\u786e\u738774.4%\uff0c\u7cbe\u786e\u51c6\u786e\u738732.8%\uff0c\u6027\u80fd\u4e0eGPT-4.1\u76f8\u5f53\uff0c\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b", "conclusion": "COPE\u4e3a\u4ece\u975e\u7ed3\u6784\u5316\u4e34\u5e8a\u6587\u672c\u8fdb\u884c\u7ed3\u5c40\u9884\u6d4b\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u5b9e\u7528\u3001\u8f7b\u91cf\u4e14\u53ef\u89e3\u91ca\u7684\u5f00\u6e90\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.02598", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02598", "abs": "https://arxiv.org/abs/2512.02598", "authors": ["Keum-Bae Cho"], "title": "Equilibrium SAT based PQC: New aegis against quantum computing", "comment": "8 pages, 5 figures", "summary": "Public-key cryptography algorithms have evolved towards increasing computational complexity to hide desired messages, which is accelerating with the development of the Internet and quantum computing. This paper introduces a novel public-key cryptography algorithm that generates ciphertexts by counting the number of elements in randomly extracted subsets from a multiset. After explaining the novel cryptographic concept, the process of mathematically refining it using satisfiability problems is described. The advantages of the proposed algorithm are: first, it is significantly faster than other public-key algorithms; second, it does not require big numbers, making it executable on any devices; and third, it can be easily extended into a public-key cryptosystem using a single public key and multiple private keys while maintaining quantum resistance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u91cd\u96c6\u5408\u968f\u673a\u5b50\u96c6\u8ba1\u6570\u7684\u65b0\u578b\u516c\u94a5\u5bc6\u7801\u7b97\u6cd5\uff0c\u5177\u6709\u5feb\u901f\u3001\u65e0\u9700\u5927\u6570\u8fd0\u7b97\u3001\u6613\u4e8e\u6269\u5c55\u4e3a\u91cf\u5b50\u62b5\u6297\u5bc6\u7801\u7cfb\u7edf\u7b49\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u4e92\u8054\u7f51\u548c\u91cf\u5b50\u8ba1\u7b97\u53d1\u5c55\uff0c\u4f20\u7edf\u516c\u94a5\u5bc6\u7801\u7b97\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0d\u65ad\u589e\u52a0\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u4e14\u91cf\u5b50\u5b89\u5168\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u4ece\u591a\u91cd\u96c6\u5408\u4e2d\u968f\u673a\u62bd\u53d6\u5b50\u96c6\u5e76\u8ba1\u7b97\u5143\u7d20\u6570\u91cf\u751f\u6210\u5bc6\u6587\uff0c\u5e76\u5229\u7528\u53ef\u6ee1\u8db3\u6027\u95ee\u9898\u8fdb\u884c\u6570\u5b66\u7cbe\u70bc\u3002", "result": "\u7b97\u6cd5\u901f\u5ea6\u663e\u8457\u5feb\u4e8e\u73b0\u6709\u516c\u94a5\u7b97\u6cd5\uff0c\u65e0\u9700\u5927\u6570\u8fd0\u7b97\u53ef\u5728\u4efb\u4f55\u8bbe\u5907\u8fd0\u884c\uff0c\u652f\u6301\u5355\u516c\u94a5\u591a\u79c1\u94a5\u7684\u91cf\u5b50\u62b5\u6297\u6269\u5c55\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u4e3a\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u4e14\u53ef\u6269\u5c55\u7684\u516c\u94a5\u5bc6\u7801\u5b66\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.02530", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02530", "abs": "https://arxiv.org/abs/2512.02530", "authors": ["Yuxiang He", "Jian Zhao", "Yuchen Yuan", "Tianle Zhang", "Wei Cai", "Haojie Cheng", "Ziyan Shi", "Ming Zhu", "Haichuan Tang", "Chi Zhang", "Xuelong Li"], "title": "Aetheria: A multimodal interpretable content safety framework based on multi-agent debate and collaboration", "comment": "https://github.com/Herrieson/Aetheria", "summary": "The exponential growth of digital content presents significant challenges for content safety. Current moderation systems, often based on single models or fixed pipelines, exhibit limitations in identifying implicit risks and providing interpretable judgment processes. To address these issues, we propose Aetheria, a multimodal interpretable content safety framework based on multi-agent debate and collaboration.Employing a collaborative architecture of five core agents, Aetheria conducts in-depth analysis and adjudication of multimodal content through a dynamic, mutually persuasive debate mechanism, which is grounded by RAG-based knowledge retrieval.Comprehensive experiments on our proposed benchmark (AIR-Bench) validate that Aetheria not only generates detailed and traceable audit reports but also demonstrates significant advantages over baselines in overall content safety accuracy, especially in the identification of implicit risks. This framework establishes a transparent and interpretable paradigm, significantly advancing the field of trustworthy AI content moderation.", "AI": {"tldr": "Aetheria\uff1a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4e0e\u534f\u4f5c\u7684\u591a\u6a21\u6001\u53ef\u89e3\u91ca\u5185\u5bb9\u5b89\u5168\u6846\u67b6", "motivation": "\u6570\u5b57\u5185\u5bb9\u7206\u70b8\u5f0f\u589e\u957f\u7ed9\u5185\u5bb9\u5b89\u5168\u5e26\u6765\u6311\u6218\uff0c\u5f53\u524d\u57fa\u4e8e\u5355\u4e00\u6a21\u578b\u6216\u56fa\u5b9a\u6d41\u7a0b\u7684\u5ba1\u6838\u7cfb\u7edf\u5728\u8bc6\u522b\u9690\u542b\u98ce\u9669\u548c\u63d0\u4f9b\u53ef\u89e3\u91ca\u5224\u5b9a\u8fc7\u7a0b\u65b9\u9762\u5b58\u5728\u5c40\u9650", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u534f\u4f5c\u7684\u4e94\u6838\u5fc3\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u76f8\u4e92\u8bf4\u670d\u7684\u8fa9\u8bba\u673a\u5236\uff0c\u7ed3\u5408RAG\u77e5\u8bc6\u68c0\u7d22\u8fdb\u884c\u591a\u6a21\u6001\u5185\u5bb9\u6df1\u5ea6\u5206\u6790\u4e0e\u88c1\u51b3", "result": "\u5728AIR-Bench\u57fa\u51c6\u4e0a\u9a8c\u8bc1\uff0cAetheria\u4e0d\u4ec5\u80fd\u751f\u6210\u8be6\u7ec6\u53ef\u8ffd\u6eaf\u7684\u5ba1\u8ba1\u62a5\u544a\uff0c\u5728\u6574\u4f53\u5185\u5bb9\u5b89\u5168\u51c6\u786e\u6027\uff08\u7279\u522b\u662f\u9690\u542b\u98ce\u9669\u8bc6\u522b\uff09\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u900f\u660e\u53ef\u89e3\u91ca\u7684\u8303\u5f0f\uff0c\u663e\u8457\u63a8\u8fdb\u4e86\u53ef\u4fe1AI\u5185\u5bb9\u5ba1\u6838\u9886\u57df\u7684\u53d1\u5c55"}}
{"id": "2512.02603", "categories": ["cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.02603", "abs": "https://arxiv.org/abs/2512.02603", "authors": ["Daniel Camaz\u00f3n-Portela", "Juan Antonio L\u00f3pez-Ramos"], "title": "Semigroup action based on skew polynomial evaluation with applications to Cryptography", "comment": "Submitted to the International Journal of Computer Mathematics: Computer Systems Theory in March 2025", "summary": "Through this work we introduce an action of the skew polynomial ring $\\mathbb{F}_{q}\\left[X; \u03c3, \u03b4\\right]$ over $\\mathbb{F}_{q}$ based on its polynomial valuation and the concept of left skew product of functions. This lead us to explore the construction of a certain subset $\\mathcal{T}(X)\\subset\\mathbb{F}_{q}\\left[X; \u03c3, \u03b4\\right]$ that allow us to control the non-commutativity of this ring, and exploit this fact in order to build a public key exchange protocol that is secure in Canetti and Krawczyk model.", "AI": {"tldr": "\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u9879\u5f0f\u8d4b\u503c\u548c\u5de6\u659c\u79ef\u51fd\u6570\u6982\u5ff5\u7684$\\mathbb{F}_{q}\\left[X; \u03c3, \u03b4\\right]$\u73af\u7684\u4f5c\u7528\uff0c\u6784\u5efa\u5b50\u96c6$\\mathcal{T}(X)$\u4ee5\u63a7\u5236\u73af\u7684\u975e\u4ea4\u6362\u6027\uff0c\u5e76\u4ee5\u6b64\u6784\u5efa\u5728Canetti-Krawczyk\u6a21\u578b\u4e0b\u5b89\u5168\u7684\u516c\u94a5\u4ea4\u6362\u534f\u8bae\u3002", "motivation": "\u63a2\u7d22\u659c\u591a\u9879\u5f0f\u73af\u7684\u7ed3\u6784\u6027\u8d28\uff0c\u5229\u7528\u5176\u975e\u4ea4\u6362\u7279\u6027\u6765\u8bbe\u8ba1\u5b89\u5168\u7684\u5bc6\u7801\u5b66\u534f\u8bae\u3002", "method": "\u57fa\u4e8e\u591a\u9879\u5f0f\u8d4b\u503c\u548c\u5de6\u659c\u79ef\u51fd\u6570\u5b9a\u4e49\u73af\u7684\u4f5c\u7528\uff0c\u6784\u9020\u5b50\u96c6$\\mathcal{T}(X)$\u6765\u63a7\u5236\u975e\u4ea4\u6362\u6027\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u5728Canetti-Krawczyk\u5b89\u5168\u6a21\u578b\u4e0b\u5b89\u5168\u7684\u516c\u94a5\u4ea4\u6362\u534f\u8bae\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5229\u7528\u4e86\u659c\u591a\u9879\u5f0f\u73af\u7684\u975e\u4ea4\u6362\u6027\u8d28\uff0c\u4e3a\u5bc6\u7801\u5b66\u534f\u8bae\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.02625", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02625", "abs": "https://arxiv.org/abs/2512.02625", "authors": ["Mayar Elfares", "Pascal Reisert", "Tilman Dietz", "Manpa Barman", "Ahmed Zaki", "Ralf K\u00fcsters", "Andreas Bulling"], "title": "CryptoQA: A Large-scale Question-answering Dataset for AI-assisted Cryptography", "comment": null, "summary": "Large language models (LLMs) excel at many general-purpose natural language processing tasks. However, their ability to perform deep reasoning and mathematical analysis, particularly for complex tasks as required in cryptography, remains poorly understood, largely due to the lack of suitable data for evaluation and training. To address this gap, we present CryptoQA, the first large-scale question-answering (QA) dataset specifically designed for cryptography. CryptoQA contains over two million QA pairs drawn from curated academic sources, along with contextual metadata that can be used to test the cryptographic capabilities of LLMs and to train new LLMs on cryptographic tasks. We benchmark 15 state-of-the-art LLMs on CryptoQA, evaluating their factual accuracy, mathematical reasoning, consistency, referencing, backward reasoning, and robustness to adversarial samples. In addition to quantitative metrics, we provide expert reviews that qualitatively assess model outputs and establish a gold-standard baseline. Our results reveal significant performance deficits of LLMs, particularly on tasks that require formal reasoning and precise mathematical knowledge. This shows the urgent need for LLM assistants tailored to cryptography research and development. We demonstrate that, by using CryptoQA, LLMs can be fine-tuned to exhibit better performance on cryptographic tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9\u5bc6\u7801\u5b66\u7684\u5927\u89c4\u6a21\u95ee\u7b54\u6570\u636e\u96c6CryptoQA\uff0c\u5305\u542b200\u591a\u4e07\u4e2aQA\u5bf9\uff0c\u5e76\u8bc4\u4f30\u4e8615\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5bc6\u7801\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528NLP\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u6df1\u5ea6\u63a8\u7406\u548c\u6570\u5b66\u5206\u6790\u7684\u5bc6\u7801\u5b66\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u7f3a\u4e4f\u5408\u9002\u7684\u8bc4\u4f30\u548c\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u521b\u5efaCryptoQA\u6570\u636e\u96c6\uff0c\u5305\u542b\u5b66\u672f\u6765\u6e90\u7684200\u591a\u4e07QA\u5bf9\u548c\u4e0a\u4e0b\u6587\u5143\u6570\u636e\uff1b\u8bc4\u4f3015\u4e2aSOTA LLM\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6570\u5b66\u63a8\u7406\u3001\u4e00\u81f4\u6027\u7b49\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0LLM\u5728\u5bc6\u7801\u5b66\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u6027\u80fd\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5f62\u5f0f\u63a8\u7406\u548c\u7cbe\u786e\u6570\u5b66\u77e5\u8bc6\u7684\u4efb\u52a1\u4e0a\uff1b\u901a\u8fc7\u5fae\u8c03\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8feb\u5207\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u5bc6\u7801\u5b66\u7814\u53d1\u7684LLM\u52a9\u624b\uff0cCryptoQA\u53ef\u4f5c\u4e3a\u8bad\u7ec3\u548c\u8bc4\u4f30\u5bc6\u7801\u5b66\u80fd\u529bLLM\u7684\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2512.02610", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02610", "abs": "https://arxiv.org/abs/2512.02610", "authors": ["Yubo Hou", "Mohamed Ragab", "Min Wu", "Chee-Keong Kwoh", "Xiaoli Li", "Zhenghua Chen"], "title": "Target-specific Adaptation and Consistent Degradation Alignment for Cross-Domain Remaining Useful Life Prediction", "comment": null, "summary": "Accurate prediction of the Remaining Useful Life (RUL) in machinery can significantly diminish maintenance costs, enhance equipment up-time, and mitigate adverse outcomes. Data-driven RUL prediction techniques have demonstrated commendable performance. However, their efficacy often relies on the assumption that training and testing data are drawn from the same distribution or domain, which does not hold in real industrial settings. To mitigate this domain discrepancy issue, prior adversarial domain adaptation methods focused on deriving domain-invariant features. Nevertheless, they overlook target-specific information and inconsistency characteristics pertinent to the degradation stages, resulting in suboptimal performance. To tackle these issues, we propose a novel domain adaptation approach for cross-domain RUL prediction named TACDA. Specifically, we propose a target domain reconstruction strategy within the adversarial adaptation process, thereby retaining target-specific information while learning domain-invariant features. Furthermore, we develop a novel clustering and pairing strategy for consistent alignment between similar degradation stages. Through extensive experiments, our results demonstrate the remarkable performance of our proposed TACDA method, surpassing state-of-the-art approaches with regard to two different evaluation metrics. Our code is available at https://github.com/keyplay/TACDA.", "AI": {"tldr": "\u63d0\u51faTACDA\u65b9\u6cd5\u89e3\u51b3\u673a\u68b0\u5269\u4f59\u5bff\u547d\u9884\u6d4b\u4e2d\u7684\u9886\u57df\u5dee\u5f02\u95ee\u9898\uff0c\u901a\u8fc7\u76ee\u6807\u57df\u91cd\u5efa\u548c\u9000\u5316\u9636\u6bb5\u805a\u7c7b\u914d\u5bf9\u7b56\u7565\u63d0\u5347\u8de8\u9886\u57df\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u673a\u68b0\u5269\u4f59\u5bff\u547d\u9884\u6d4b\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u6765\u81ea\u540c\u4e00\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u5de5\u4e1a\u73af\u5883\u4e2d\u5b58\u5728\u9886\u57df\u5dee\u5f02\u95ee\u9898\u3002\u73b0\u6709\u5bf9\u6297\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u5ffd\u89c6\u4e86\u76ee\u6807\u57df\u7279\u5b9a\u4fe1\u606f\u548c\u9000\u5316\u9636\u6bb5\u7684\u4e00\u81f4\u6027\u7279\u5f81\u3002", "method": "\u63d0\u51faTACDA\u65b9\u6cd5\uff1a1\uff09\u5728\u5bf9\u6297\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5f15\u5165\u76ee\u6807\u57df\u91cd\u5efa\u7b56\u7565\uff0c\u4fdd\u7559\u76ee\u6807\u57df\u7279\u5b9a\u4fe1\u606f\u7684\u540c\u65f6\u5b66\u4e60\u9886\u57df\u4e0d\u53d8\u7279\u5f81\uff1b2\uff09\u5f00\u53d1\u805a\u7c7b\u914d\u5bf9\u7b56\u7565\uff0c\u5b9e\u73b0\u76f8\u4f3c\u9000\u5316\u9636\u6bb5\u7684\u4e00\u81f4\u5bf9\u9f50\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eTACDA\u65b9\u6cd5\u5728\u4e24\u79cd\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "TACDA\u901a\u8fc7\u7ed3\u5408\u76ee\u6807\u57df\u91cd\u5efa\u548c\u9000\u5316\u9636\u6bb5\u5bf9\u9f50\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u9886\u57dfRUL\u9884\u6d4b\u4e2d\u7684\u9886\u57df\u5dee\u5f02\u95ee\u9898\uff0c\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2512.02822", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2512.02822", "abs": "https://arxiv.org/abs/2512.02822", "authors": ["Meir Ariel"], "title": "Decryption thorough polynomial ambiguity: noise-enhanced high-memory convolutional codes for post-quantum cryptography", "comment": "23 pages, 3 figures", "summary": "We present a novel approach to post-quantum cryptography that employs directed-graph decryption of noise-enhanced high-memory convolutional codes. The proposed construction generates random-like generator matrices that effectively conceal algebraic structure and resist known structural attacks. Security is further reinforced by the deliberate injection of strong noise during decryption, arising from polynomial division: while legitimate recipients retain polynomial-time decoding, adversaries face exponential-time complexity. As a result, the scheme achieves cryptanalytic security margins surpassing those of Classic McEliece by factors exceeding 2^(200). Beyond its enhanced security, the method offers greater design flexibility, supporting arbitrary plaintext lengths with linear-time decryption and uniform per-bit computational cost, enabling seamless scalability to long messages. Practical deployment is facilitated by parallel arrays of directed-graph decoders, which identify the correct plaintext through polynomial ambiguity while allowing efficient hardware and software implementations. Altogether, the scheme represents a compelling candidate for robust, scalable, and quantum-resistant public-key cryptography.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u56fe\u89e3\u5bc6\u548c\u566a\u58f0\u589e\u5f3a\u7684\u9ad8\u5185\u5b58\u5377\u79ef\u7801\u7684\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u65b0\u65b9\u6cd5\uff0c\u5b89\u5168\u88d5\u5ea6\u8d85\u8fc7Classic McEliece\u65b9\u68482^200\u500d\u4ee5\u4e0a", "motivation": "\u9700\u8981\u5f00\u53d1\u80fd\u591f\u62b5\u6297\u91cf\u5b50\u8ba1\u7b97\u653b\u51fb\u7684\u5bc6\u7801\u5b66\u65b9\u6848\uff0c\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u8bbe\u8ba1\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027", "method": "\u4f7f\u7528\u968f\u673a\u5316\u751f\u6210\u77e9\u9635\u9690\u85cf\u4ee3\u6570\u7ed3\u6784\uff0c\u5728\u89e3\u5bc6\u8fc7\u7a0b\u4e2d\u6545\u610f\u6ce8\u5165\u5f3a\u566a\u58f0\u6765\u81ea\u591a\u9879\u5f0f\u9664\u6cd5\uff0c\u901a\u8fc7\u6709\u5411\u56fe\u89e3\u7801\u5668\u9635\u5217\u8fdb\u884c\u5e76\u884c\u89e3\u5bc6", "result": "\u5408\u6cd5\u63a5\u6536\u8005\u4fdd\u6301\u591a\u9879\u5f0f\u65f6\u95f4\u89e3\u7801\uff0c\u800c\u653b\u51fb\u8005\u9762\u4e34\u6307\u6570\u7ea7\u65f6\u95f4\u590d\u6742\u6027\uff0c\u652f\u6301\u4efb\u610f\u660e\u6587\u957f\u5ea6\u548c\u7ebf\u6027\u65f6\u95f4\u89e3\u5bc6", "conclusion": "\u8be5\u65b9\u6848\u662f\u5f3a\u5927\u3001\u53ef\u6269\u5c55\u4e14\u91cf\u5b50\u62b5\u6297\u7684\u516c\u94a5\u5bc6\u7801\u5b66\u7684\u6709\u524d\u666f\u5019\u9009\u65b9\u6848"}}
{"id": "2512.02677", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02677", "abs": "https://arxiv.org/abs/2512.02677", "authors": ["Zhiyuan He"], "title": "Exploring Depth Generalization in Large Language Models for Solving Recursive Logic Tasks", "comment": null, "summary": "Large language models have demonstrated remarkable capabilities across many tasks, yet face significant challenges when dealing with recursive reasoning problems, those requiring the resolution of nested hierarchical structures. While prior research has extensively studied length generalization (a model's ability to handle longer sequences than seen during training), we investigate a distinct and underexplored limitation: depth generalization. Here, depth refers to the number of nested levels in a hierarchical problem, such as the layers of parentheses in a mathematical expression or the nesting of logical clauses in a Boolean formula. Our work reveals that standard transformer architectures struggle with problems involving deeper recursion than encountered during training, even when they perform well on longer but non-nested sequences. This limitation stems from their inability to maintain stack-like behavior, the capacity to track and resolve multiple levels of nested dependencies. Through systematic analysis, we demonstrate how this architectural constraint leads to rapid performance decay as the depth of the recursion increases. To address this challenge, we develop a novel looped locate-and-replace pipeline that decomposes recursive problems into manageable subcomponents. The approach employs two specialized models: a locator that identifies solvable subexpressions and a replacer that evaluates these components while preserving the overall structure. We evaluated this method in three carefully designed domains: Boolean algebra, recursive arithmetic, and propositional logic, each with a controllable depth of recursion. We show that our method effectively alleviates the performance decay when tested on out-of-distribution recursion depth.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u6807\u51c6Transformer\u67b6\u6784\u5728\u5904\u7406\u6df1\u5ea6\u9012\u5f52\u63a8\u7406\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u6d41\u6c34\u7ebf\u65b9\u6cd5\u6765\u6539\u5584\u6df1\u5ea6\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u9700\u8981\u89e3\u51b3\u5d4c\u5957\u5c42\u6b21\u7ed3\u6784\u7684\u9012\u5f52\u63a8\u7406\u95ee\u9898\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u6df1\u5ea6\u6cdb\u5316\u95ee\u9898\uff08\u5904\u7406\u6bd4\u8bad\u7ec3\u65f6\u66f4\u6df1\u7684\u5d4c\u5957\u5c42\u6b21\uff09\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u6d41\u6c34\u7ebf\uff0c\u5305\u542b\u4e24\u4e2a\u4e13\u95e8\u6a21\u578b\uff1a\u5b9a\u4f4d\u5668\u8bc6\u522b\u53ef\u89e3\u51b3\u7684\u5b50\u8868\u8fbe\u5f0f\uff0c\u66ff\u6362\u5668\u8bc4\u4f30\u8fd9\u4e9b\u7ec4\u4ef6\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7ed3\u6784\u3002\u5728\u5e03\u5c14\u4ee3\u6570\u3001\u9012\u5f52\u7b97\u672f\u548c\u547d\u9898\u903b\u8f91\u4e09\u4e2a\u9886\u57df\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u5728\u5206\u5e03\u5916\u9012\u5f52\u6df1\u5ea6\u4e0a\u6d4b\u8bd5\u65f6\u7684\u6027\u80fd\u8870\u51cf\u95ee\u9898\uff0c\u8868\u660e\u80fd\u591f\u6539\u5584\u6a21\u578b\u5bf9\u6df1\u5ea6\u9012\u5f52\u95ee\u9898\u7684\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u6807\u51c6Transformer\u67b6\u6784\u96be\u4ee5\u7ef4\u6301\u7c7b\u4f3c\u6808\u7684\u884c\u4e3a\u6765\u8ddf\u8e2a\u591a\u7ea7\u5d4c\u5957\u4f9d\u8d56\uff0c\u800c\u63d0\u51fa\u7684\u5faa\u73af\u5b9a\u4f4d\u66ff\u6362\u65b9\u6cd5\u4e3a\u89e3\u51b3\u6df1\u5ea6\u6cdb\u5316\u6311\u6218\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2512.02699", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02699", "abs": "https://arxiv.org/abs/2512.02699", "authors": ["Hyeongseop Rha", "Jeong Hun Yeo", "Junil Won", "Se Jin Park", "Yong Man Ro"], "title": "Learning What to Attend First: Modality-Importance-Guided Reasoning for Reliable Multimodal Emotion Understanding", "comment": "16 pages, 8 figures", "summary": "In this paper, we present Modality-Importance-Guided Reasoning (MIGR), a framework designed to improve the reliability of reasoning-based multimodal emotion understanding in multimodal large language models. Although existing methods have advanced emotion understanding, they often suffer from reasoning drift: models gradually rely on their own generated text instead of multimodal evidence, and their explanations are overly shaped by visually initiated reasoning paths. To address these issues, we introduce Modality Importance (MI), a simple yet effective mechanism for identifying the emotion-dominant modality. Using MI, MIGR reorganizes reasoning sequences so that explanations begin from the modality most critical to the target emotion, preventing early reasoning from being misled by less informative cues. Our two-stage framework-comprising modality-aligned supervised fine-tuning and modality-aware reward optimization-encourages models to generate emotionally grounded, causally relevant, and coherence-preserving explanations. Experimental results on the DFEW benchmark show that MIGR substantially improves reasoning reliability, decreasing instances of correct predictions accompanied by emotionally inconsistent explanations from 18.10% to 7.37%. These results confirm the benefit of initiating reasoning from the emotion-dominant modality.", "AI": {"tldr": "MIGR\u6846\u67b6\u901a\u8fc7\u6a21\u6001\u91cd\u8981\u6027\u5f15\u5bfc\u63a8\u7406\uff0c\u6539\u5584\u591a\u6a21\u6001\u60c5\u611f\u7406\u89e3\u7684\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u63a8\u7406\u6f02\u79fb\u95ee\u9898", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u6f02\u79fb\u95ee\u9898\uff1a\u6a21\u578b\u9010\u6e10\u4f9d\u8d56\u81ea\u8eab\u751f\u6210\u7684\u6587\u672c\u800c\u975e\u591a\u6a21\u6001\u8bc1\u636e\uff0c\u4e14\u89e3\u91ca\u8fc7\u5ea6\u53d7\u89c6\u89c9\u63a8\u7406\u8def\u5f84\u5f71\u54cd", "method": "\u5f15\u5165\u6a21\u6001\u91cd\u8981\u6027\u673a\u5236\u8bc6\u522b\u60c5\u611f\u4e3b\u5bfc\u6a21\u6001\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u6846\u67b6\uff08\u6a21\u6001\u5bf9\u9f50\u76d1\u7763\u5fae\u8c03+\u6a21\u6001\u611f\u77e5\u5956\u52b1\u4f18\u5316\uff09\u91cd\u7ec4\u63a8\u7406\u5e8f\u5217", "result": "\u5728DFEW\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c06\u6b63\u786e\u9884\u6d4b\u4f46\u60c5\u611f\u4e0d\u4e00\u81f4\u89e3\u91ca\u7684\u6bd4\u4f8b\u4ece18.10%\u964d\u81f37.37%", "conclusion": "\u4ece\u60c5\u611f\u4e3b\u5bfc\u6a21\u6001\u5f00\u59cb\u63a8\u7406\u80fd\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u60c5\u611f\u7406\u89e3\u7684\u53ef\u4fe1\u5ea6"}}
{"id": "2512.02713", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02713", "abs": "https://arxiv.org/abs/2512.02713", "authors": ["Theodoros Aivalis", "Iraklis A. Klampanos", "Antonis Troumpoukis", "Joemon M. Jose"], "title": "Training Data Attribution for Image Generation using Ontology-Aligned Knowledge Graphs", "comment": null, "summary": "As generative models become powerful, concerns around transparency, accountability, and copyright violations have intensified. Understanding how specific training data contributes to a model's output is critical. We introduce a framework for interpreting generative outputs through the automatic construction of ontologyaligned knowledge graphs (KGs). While automatic KG construction from natural text has advanced, extracting structured and ontology-consistent representations from visual content remains challenging -- due to the richness and multi-object nature of images. Leveraging multimodal large language models (LLMs), our method extracts structured triples from images, aligned with a domain-specific ontology. By comparing the KGs of generated and training images, we can trace potential influences, enabling copyright analysis, dataset transparency, and interpretable AI. We validate our method through experiments on locally trained models via unlearning, and on large-scale models through a style-specific experiment. Our framework supports the development of AI systems that foster human collaboration, creativity and stimulate curiosity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u751f\u6210\u6a21\u578b\u8f93\u51fa\u6eaf\u6e90\u6846\u67b6\uff0c\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u4e09\u5143\u7ec4\uff0c\u901a\u8fc7\u6bd4\u8f83\u751f\u6210\u56fe\u50cf\u548c\u8bad\u7ec3\u56fe\u50cf\u7684\u56fe\u8c31\u6765\u5206\u6790\u7248\u6743\u548c\u900f\u660e\u5ea6\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u751f\u6210\u6a21\u578b\u7684\u5f3a\u5927\uff0c\u5bf9\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u7248\u6743\u4fb5\u6743\u7684\u62c5\u5fe7\u52a0\u5267\u3002\u9700\u8981\u7406\u89e3\u7279\u5b9a\u8bad\u7ec3\u6570\u636e\u5982\u4f55\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u4e0e\u9886\u57df\u672c\u4f53\u5bf9\u9f50\u7684\u7ed3\u6784\u5316\u4e09\u5143\u7ec4\uff0c\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u3002\u901a\u8fc7\u6bd4\u8f83\u751f\u6210\u56fe\u50cf\u548c\u8bad\u7ec3\u56fe\u50cf\u7684\u56fe\u8c31\u6765\u6eaf\u6e90\u3002", "result": "\u901a\u8fc7\u5c40\u90e8\u6a21\u578b\u7684\u53bb\u5b66\u4e60\u5b9e\u9a8c\u548c\u5927\u89c4\u6a21\u6a21\u578b\u7684\u98ce\u683c\u7279\u5b9a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u5f00\u53d1\u4fc3\u8fdb\u4eba\u7c7b\u534f\u4f5c\u3001\u521b\u9020\u529b\u548c\u6fc0\u53d1\u597d\u5947\u5fc3\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2512.02716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02716", "abs": "https://arxiv.org/abs/2512.02716", "authors": ["Tianyi Zhang", "Xiangyuan Xue", "Lingyan Ruan", "Shiya Fu", "Feng Xia", "Simon D'Alfonso", "Vassilis Kostakos", "Hong Jia"], "title": "Menta: A Small Language Model for On-Device Mental Health Prediction", "comment": null, "summary": "Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models (LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small language models (SLMs) offer a lightweight alternative, but their use for social media--based mental health prediction remains largely underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy, and a balanced accuracy--oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement of 15.2\\% across tasks covering depression, stress, and suicidality compared with the best-performing non--fine-tuned SLMs. It also achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately 3.25x smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential for scalable, privacy-preserving mental health monitoring. Code is available at: https://xxue752-nz.github.io/menta-project/", "AI": {"tldr": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u540d\u4e3aMenta\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u8fdb\u884c\u591a\u4efb\u52a1\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8f7b\u91cf\u5316\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4f18\u4e8e\u672a\u5fae\u8c03\u7684SLM\u57fa\u7ebf\uff0c\u5e76\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5ab2\u7f8e\u66f4\u5927\u7684LLM\uff0c\u652f\u6301\u5b9e\u65f6\u8bbe\u5907\u90e8\u7f72\u3002", "motivation": "\u5fc3\u7406\u5065\u5eb7\u95ee\u9898\u5f71\u54cd\u5e7f\u6cdb\uff0c\u4f46\u65e9\u671f\u68c0\u6d4b\u53d7\u9650\uff1b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5fc3\u7406\u5065\u5eb7\u5e94\u7528\u4e2d\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u96be\u4ee5\u5b9e\u9645\u90e8\u7f72\uff1b\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u4f5c\u4e3a\u8f7b\u91cf\u66ff\u4ee3\u65b9\u6848\uff0c\u4f46\u5728\u57fa\u4e8e\u793e\u4ea4\u5a92\u4f53\u7684\u5fc3\u7406\u5065\u5eb7\u9884\u6d4b\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002", "method": "\u63d0\u51faMenta\u6a21\u578b\uff0c\u9996\u4e2a\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u4f18\u5316\u7684\u591a\u4efb\u52a1\u5fc3\u7406\u5065\u5eb7\u9884\u6d4bSLM\uff1b\u91c7\u7528\u57fa\u4e8eLoRA\u7684\u6846\u67b6\u3001\u8de8\u6570\u636e\u96c6\u7b56\u7565\u548c\u5e73\u8861\u7cbe\u5ea6\u5bfc\u5411\u7684\u635f\u5931\u51fd\u6570\uff0c\u8054\u5408\u8bad\u7ec3\u516d\u4e2a\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u4e0e\u4e5d\u4e2a\u5148\u8fdbSLM\u57fa\u7ebf\u76f8\u6bd4\uff0cMenta\u5728\u6291\u90c1\u3001\u538b\u529b\u548c\u81ea\u6740\u503e\u5411\u7b49\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u534715.2%\uff1b\u5728\u6291\u90c1\u548c\u538b\u529b\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0c\u6027\u80fd\u4f18\u4e8e130\u4ebf\u53c2\u6570LLM\uff0c\u800c\u6a21\u578b\u5927\u5c0f\u4ec5\u4e3a\u5176\u7ea61/3\uff1b\u5728iPhone 15 Pro Max\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u90e8\u7f72\uff0c\u4ec5\u9700\u7ea63GB\u5185\u5b58\u3002", "conclusion": "Menta\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u5fc3\u7406\u5065\u5eb7\u76d1\u6d4b\u6f5c\u529b\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\uff1b\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.02720", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02720", "abs": "https://arxiv.org/abs/2512.02720", "authors": ["He Wang", "Wenyilin Xiao", "Songqiao Han", "Hailiang Huang"], "title": "StockMem: An Event-Reflection Memory Framework for Stock Forecasting", "comment": null, "summary": "Stock price prediction is challenging due to market volatility and its sensitivity to real-time events. While large language models (LLMs) offer new avenues for text-based forecasting, their application in finance is hindered by noisy news data and the lack of explicit answers in text. General-purpose memory architectures struggle to identify the key drivers of price movements. To address this, we propose StockMem, an event-reflection dual-layer memory framework. It structures news into events and mines them along two dimensions: horizontal consolidation integrates daily events, while longitudinal tracking captures event evolution to extract incremental information reflecting market expectation discrepancies. This builds a temporal event knowledge base. By analyzing event-price dynamics, the framework further forms a reflection knowledge base of causal experiences. For prediction, it retrieves analogous historical scenarios and reasons with current events, incremental data, and past experiences. Experiments show StockMem outperforms existing memory architectures and provides superior, explainable reasoning by tracing the information chain affecting prices, enhancing decision transparency in financial forecasting.", "AI": {"tldr": "StockMem\uff1a\u4e00\u79cd\u53cc\u5c42\u5185\u5b58\u6846\u67b6\uff0c\u901a\u8fc7\u4e8b\u4ef6\u6574\u5408\u4e0e\u7eb5\u5411\u8ddf\u8e2a\u6784\u5efa\u65f6\u6001\u4e8b\u4ef6\u77e5\u8bc6\u5e93\uff0c\u7ed3\u5408\u56e0\u679c\u7ecf\u9a8c\u8fdb\u884c\u80a1\u4ef7\u9884\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u63a8\u7406\u3002", "motivation": "\u80a1\u4ef7\u9884\u6d4b\u53d7\u5e02\u573a\u6ce2\u52a8\u548c\u5b9e\u65f6\u4e8b\u4ef6\u5f71\u54cd\uff0c\u73b0\u6709LLM\u5728\u91d1\u878d\u5e94\u7528\u4e2d\u53d7\u566a\u58f0\u65b0\u95fb\u6570\u636e\u548c\u7f3a\u4e4f\u660e\u786e\u7b54\u6848\u9650\u5236\uff0c\u901a\u7528\u5185\u5b58\u67b6\u6784\u96be\u4ee5\u8bc6\u522b\u4ef7\u683c\u53d8\u52a8\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002", "method": "\u63d0\u51faStockMem\u4e8b\u4ef6\u53cd\u601d\u53cc\u5c42\u5185\u5b58\u6846\u67b6\uff1a\u5c06\u65b0\u95fb\u7ed3\u6784\u5316\u4e3a\u4e8b\u4ef6\uff0c\u6a2a\u5411\u6574\u5408\u6bcf\u65e5\u4e8b\u4ef6\uff0c\u7eb5\u5411\u8ddf\u8e2a\u4e8b\u4ef6\u6f14\u53d8\u63d0\u53d6\u53cd\u6620\u5e02\u573a\u9884\u671f\u5dee\u5f02\u7684\u589e\u91cf\u4fe1\u606f\uff0c\u6784\u5efa\u65f6\u6001\u4e8b\u4ef6\u77e5\u8bc6\u5e93\u548c\u56e0\u679c\u7ecf\u9a8c\u53cd\u601d\u77e5\u8bc6\u5e93\u3002", "result": "\u5b9e\u9a8c\u8868\u660eStockMem\u4f18\u4e8e\u73b0\u6709\u5185\u5b58\u67b6\u6784\uff0c\u901a\u8fc7\u8ffd\u8e2a\u5f71\u54cd\u4ef7\u683c\u7684\u4fe1\u606f\u94fe\u63d0\u4f9b\u4f18\u8d8a\u7684\u53ef\u89e3\u91ca\u63a8\u7406\uff0c\u589e\u5f3a\u91d1\u878d\u9884\u6d4b\u7684\u51b3\u7b56\u900f\u660e\u5ea6\u3002", "conclusion": "StockMem\u901a\u8fc7\u7ed3\u6784\u5316\u4e8b\u4ef6\u5206\u6790\u548c\u5386\u53f2\u573a\u666f\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u80a1\u4ef7\u9884\u6d4b\u4e2d\u7684\u566a\u58f0\u548c\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u4e3a\u57fa\u4e8e\u6587\u672c\u7684\u91d1\u878d\u9884\u6d4b\u63d0\u4f9b\u65b0\u9014\u5f84\u3002"}}
{"id": "2512.02726", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02726", "abs": "https://arxiv.org/abs/2512.02726", "authors": ["Md Abdul Kadir", "Sai Suresh Macharla Vasu", "Sidharth S. Nair", "Daniel Sonntag"], "title": "AuditCopilot: Leveraging LLMs for Fraud Detection in Double-Entry Bookkeeping", "comment": null, "summary": "Auditors rely on Journal Entry Tests (JETs) to detect anomalies in tax-related ledger records, but rule-based methods generate overwhelming false positives and struggle with subtle irregularities. We investigate whether large language models (LLMs) can serve as anomaly detectors in double-entry bookkeeping. Benchmarking SoTA LLMs such as LLaMA and Gemma on both synthetic and real-world anonymized ledgers, we compare them against JETs and machine learning baselines. Our results show that LLMs consistently outperform traditional rule-based JETs and classical ML baselines, while also providing natural-language explanations that enhance interpretability. These results highlight the potential of \\textbf{AI-augmented auditing}, where human auditors collaborate with foundation models to strengthen financial integrity.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5ba1\u8ba1\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5ba1\u8ba1\u5e08\u4f9d\u8d56\u65e5\u8bb0\u8d26\u6d4b\u8bd5\u68c0\u6d4b\u7a0e\u52a1\u76f8\u5173\u5206\u7c7b\u8d26\u5f02\u5e38\uff0c\u4f46\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u4f1a\u4ea7\u751f\u5927\u91cf\u8bef\u62a5\u4e14\u96be\u4ee5\u68c0\u6d4b\u5fae\u5999\u5f02\u5e38\u3002", "method": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u533f\u540d\u5206\u7c7b\u8d26\u4e0a\u5bf9LLaMA\u548cGemma\u7b49\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u65e5\u8bb0\u8d26\u6d4b\u8bd5\u548c\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u65e5\u8bb0\u8d26\u6d4b\u8bd5\u548c\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u57fa\u7ebf\uff0c\u540c\u65f6\u63d0\u4f9b\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u7ed3\u679c\u7a81\u51fa\u4e86AI\u589e\u5f3a\u5ba1\u8ba1\u7684\u6f5c\u529b\uff0c\u4eba\u7c7b\u5ba1\u8ba1\u5e08\u4e0e\u57fa\u7840\u6a21\u578b\u5408\u4f5c\u53ef\u52a0\u5f3a\u8d22\u52a1\u5b8c\u6574\u6027\u3002"}}
{"id": "2512.02731", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.02731", "abs": "https://arxiv.org/abs/2512.02731", "authors": ["Przemyslaw Chojecki"], "title": "Self-Improving AI Agents through Self-Play", "comment": null, "summary": "We extend the moduli-theoretic framework of psychometric batteries to the domain of dynamical systems. While previous work established the AAI capability score as a static functional on the space of agent representations, this paper formalizes the agent as a flow $\u03bd_r$ parameterized by computational resource $r$, governed by a recursive Generator-Verifier-Updater (GVU) operator. We prove that this operator generates a vector field on the parameter manifold $\u0398$, and we identify the coefficient of self-improvement $\u03ba$ as the Lie derivative of the capability functional along this flow.\n  The central contribution of this work is the derivation of the Variance Inequality, a spectral condition that is sufficient (under mild regularity) for the stability of self-improvement. We show that a sufficient condition for $\u03ba> 0$ is that, up to curvature and step-size effects, the combined noise of generation and verification must be small enough.\n  We then apply this formalism to unify the recent literature on Language Self-Play (LSP), Self-Correction, and Synthetic Data bootstrapping. We demonstrate that architectures such as STaR, SPIN, Reflexion, GANs and AlphaZero are specific topological realizations of the GVU operator that satisfy the Variance Inequality through filtration, adversarial discrimination, or grounding in formal systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u529b\u5b66\u7cfb\u7edf\u7684\u6a21\u6001\u7406\u8bba\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u5efa\u6a21\u4e3a\u7531\u8ba1\u7b97\u8d44\u6e90\u53c2\u6570\u5316\u7684\u6d41\uff0c\u5e76\u63a8\u5bfc\u4e86\u4fdd\u8bc1\u81ea\u6539\u8fdb\u7a33\u5b9a\u6027\u7684\u65b9\u5dee\u4e0d\u7b49\u5f0f\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4ec5\u5c06AAI\u80fd\u529b\u5206\u6570\u5b9a\u4e49\u4e3a\u667a\u80fd\u4f53\u8868\u793a\u7a7a\u95f4\u4e0a\u7684\u9759\u6001\u6cdb\u51fd\uff0c\u9700\u8981\u5c06\u5176\u6269\u5c55\u4e3a\u8003\u8651\u52a8\u529b\u5b66\u6f14\u5316\u8fc7\u7a0b\u7684\u6846\u67b6\u3002", "method": "\u5f15\u5165\u9012\u5f52\u7684\u751f\u6210\u5668-\u9a8c\u8bc1\u5668-\u66f4\u65b0\u5668(GVU)\u7b97\u5b50\uff0c\u8bc1\u660e\u5176\u5728\u53c2\u6570\u6d41\u5f62\u4e0a\u751f\u6210\u5411\u91cf\u573a\uff0c\u5e76\u5c06\u81ea\u6539\u8fdb\u7cfb\u6570\u5b9a\u4e49\u4e3a\u80fd\u529b\u6cdb\u51fd\u6cbf\u8be5\u6d41\u7684\u674e\u5bfc\u6570\u3002", "result": "\u63a8\u5bfc\u51fa\u65b9\u5dee\u4e0d\u7b49\u5f0f\u8fd9\u4e00\u8c31\u6761\u4ef6\uff0c\u8bc1\u660e\u751f\u6210\u548c\u9a8c\u8bc1\u7684\u7ec4\u5408\u566a\u58f0\u8db3\u591f\u5c0f\u65f6\u53ef\u4fdd\u8bc1\u81ea\u6539\u8fdb\u7a33\u5b9a\u3002\u8be5\u6846\u67b6\u7edf\u4e00\u4e86LSP\u3001\u81ea\u6821\u6b63\u548c\u5408\u6210\u6570\u636e\u5f15\u5bfc\u7b49\u591a\u79cd\u65b9\u6cd5\u3002", "conclusion": "GVU\u7b97\u5b50\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u81ea\u6539\u8fdb\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u5f62\u5f0f\u5316\u6846\u67b6\uff0cSTaR\u3001SPIN\u3001Reflexion\u3001GANs\u548cAlphaZero\u7b49\u67b6\u6784\u90fd\u662f\u5176\u7279\u5b9a\u62d3\u6251\u5b9e\u73b0\u3002"}}
{"id": "2512.02735", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02735", "abs": "https://arxiv.org/abs/2512.02735", "authors": ["Anna Rodum Bj\u00f8ru", "Jacob Lysn\u00e6s-Larsen", "Oskar J\u00f8rgensen", "Inga Str\u00fcmke", "Helge Langseth"], "title": "A Framework for Causal Concept-based Model Explanations", "comment": null, "summary": "This work presents a conceptual framework for causal concept-based post-hoc Explainable Artificial Intelligence (XAI), based on the requirements that explanations for non-interpretable models should be understandable as well as faithful to the model being explained. Local and global explanations are generated by calculating the probability of sufficiency of concept interventions. Example explanations are presented, generated with a proof-of-concept model made to explain classifiers trained on the CelebA dataset. Understandability is demonstrated through a clear concept-based vocabulary, subject to an implicit causal interpretation. Fidelity is addressed by highlighting important framework assumptions, stressing that the context of explanation interpretation must align with the context of explanation generation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u6982\u5ff5\u7684\u4e8b\u540e\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd(XAI)\u6846\u67b6\uff0c\u5f3a\u8c03\u89e3\u91ca\u9700\u8981\u540c\u65f6\u5177\u5907\u53ef\u7406\u89e3\u6027\u548c\u5bf9\u6a21\u578b\u7684\u5fe0\u5b9e\u6027\u3002", "motivation": "\u73b0\u6709\u975e\u89e3\u91ca\u6027AI\u6a21\u578b\u7684\u9ed1\u7bb1\u7279\u6027\u4f7f\u5f97\u89e3\u91ca\u96be\u4ee5\u540c\u65f6\u6ee1\u8db3\u53ef\u7406\u89e3\u6027\u548c\u5fe0\u5b9e\u6027\u8981\u6c42\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u6982\u5ff5\u5e72\u9884\u7684\u5145\u5206\u6982\u7387\u6765\u751f\u6210\u5c40\u90e8\u548c\u5168\u5c40\u89e3\u91ca\uff0c\u5e76\u4f7f\u7528CelebA\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u5668\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\u6a21\u578b\u3002", "result": "\u5c55\u793a\u4e86\u793a\u4f8b\u89e3\u91ca\uff0c\u8bc1\u660e\u4e86\u6846\u67b6\u901a\u8fc7\u6e05\u6670\u7684\u6982\u5ff5\u8bcd\u6c47\u8868\u5b9e\u73b0\u53ef\u7406\u89e3\u6027\uff0c\u5e76\u901a\u8fc7\u5f3a\u8c03\u6846\u67b6\u5047\u8bbe\u6765\u786e\u4fdd\u5fe0\u5b9e\u6027\u3002", "conclusion": "\u8be5\u56e0\u679c\u6982\u5ff5XAI\u6846\u67b6\u6210\u529f\u5e73\u8861\u4e86\u89e3\u91ca\u7684\u53ef\u7406\u89e3\u6027\u548c\u5fe0\u5b9e\u6027\uff0c\u4f46\u9700\u8981\u786e\u4fdd\u89e3\u91ca\u751f\u6210\u548c\u89e3\u91ca\u89e3\u8bfb\u7684\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.02814", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02814", "abs": "https://arxiv.org/abs/2512.02814", "authors": ["Yongrui Yu", "Zhongzhen Huang", "Linjie Mu", "Shaoting Zhang", "Xiaofan Zhang"], "title": "Radiologist Copilot: An Agentic Assistant with Orchestrated Tools for Radiology Reporting with Quality Control", "comment": null, "summary": "Radiology reporting is an essential yet time-consuming and error-prone task for radiologists in clinical examinations, especially for volumetric medical images. Rigorous quality control is also critical but tedious, ensuring that the final report meets clinical standards. Existing automated approaches, including radiology report generation methods and medical vision-language models, focus mainly on the report generation phase and neglect the crucial quality control procedure, limiting their capability to provide comprehensive support to radiologists. We propose Radiologist Copilot, an agentic AI assistant equipped with orchestrated tools designed for automated radiology reporting with quality control. Leveraging large language models as the reasoning backbone, the agentic system autonomously selects tools, plans, and executes actions, emulating the behavior of radiologists throughout the holistic radiology reporting process. The orchestrated tools include region localization, think with image paradigm directed region analysis planning, strategic template selection for report generation, quality assessment and feedback-driven adaptive refinement for quality control. Therefore, Radiologist Copilot facilitates accurate, complete, and efficient radiology reporting, assisting radiologists and improving clinical efficiency. Experimental results demonstrate that Radiologist Copilot significantly surpasses other state-of-the-art methods in radiology reporting. The source code will be released upon acceptance.", "AI": {"tldr": "Radiologist Copilot\u662f\u4e00\u4e2a\u5177\u5907\u5de5\u5177\u7f16\u6392\u80fd\u529b\u7684AI\u52a9\u624b\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u62a5\u544a\u751f\u6210\u548c\u8d28\u91cf\u63a7\u5236\u6765\u8f85\u52a9\u653e\u5c04\u79d1\u533b\u751f", "motivation": "\u653e\u5c04\u5b66\u62a5\u544a\u64b0\u5199\u8017\u65f6\u4e14\u6613\u51fa\u9519\uff0c\u73b0\u6709\u81ea\u52a8\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u62a5\u544a\u751f\u6210\u800c\u5ffd\u7565\u4e86\u8d28\u91cf\u63a7\u5236\u8fd9\u4e2a\u5173\u952e\u73af\u8282", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u63a8\u7406\u6838\u5fc3\uff0c\u901a\u8fc7\u533a\u57df\u5b9a\u4f4d\u3001\u5b9a\u5411\u533a\u57df\u5206\u6790\u3001\u6a21\u677f\u9009\u62e9\u548c\u81ea\u9002\u5e94\u4f18\u5316\u7b49\u7f16\u6392\u5de5\u5177\u6a21\u62df\u653e\u5c04\u79d1\u533b\u751f\u7684\u5de5\u4f5c\u6d41\u7a0b", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eRadiologist Copilot\u5728\u653e\u5c04\u5b66\u62a5\u544a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5", "conclusion": "\u8be5\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u51c6\u786e\u3001\u5b8c\u6574\u548c\u9ad8\u6548\u7684\u653e\u5c04\u5b66\u62a5\u544a\uff0c\u63d0\u9ad8\u4e34\u5e8a\u5de5\u4f5c\u6548\u7387"}}
{"id": "2512.02879", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.02879", "abs": "https://arxiv.org/abs/2512.02879", "authors": ["Jef Caers"], "title": "The future of AI in critical mineral exploration", "comment": null, "summary": "The energy transition through increased electrification has put the worlds attention on critical mineral exploration Even with increased investments a decrease in new discoveries has taken place over the last two decades Here I propose a solution to this problem where AI is implemented as the enabler of a rigorous scientific method for mineral exploration that aims to reduce cognitive bias and false positives drive down the cost of exploration I propose a new scientific method that is based on a philosophical approach founded on the principles of Bayesianism and falsification In this approach data acquisition is in the first place seen as a means to falsify human generated hypothesis Decision of what data to acquire next is quantified with verifiable metrics and based on rational decision making A practical protocol is provided that can be used as a template in any exploration campaign However in order to make this protocol practical various form of artificial intelligence are needed I will argue that the most important form are one novel unsupervised learning methods that collaborate with domain experts to better understand data and generate multiple competing geological hypotheses and two humanintheloop AI algorithms that can optimally plan various geological geophysical geochemical and drilling data acquisition where uncertainty reduction of geological hypothesis precedes the uncertainty reduction on grade and tonnage", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eAI\u7684\u77ff\u4ea7\u52d8\u63a2\u79d1\u5b66\u65b9\u6cd5\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4e3b\u4e49\u548c\u8bc1\u4f2a\u539f\u5219\u51cf\u5c11\u8ba4\u77e5\u504f\u5dee\uff0c\u5229\u7528\u65e0\u76d1\u7763\u5b66\u4e60\u548c\u4eba\u5728\u73afAI\u4f18\u5316\u6570\u636e\u91c7\u96c6", "motivation": "\u8fc7\u53bb20\u5e74\u5c3d\u7ba1\u6295\u8d44\u589e\u52a0\u4f46\u65b0\u77ff\u4ea7\u53d1\u73b0\u51cf\u5c11\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u52d8\u63a2\u65b9\u6cd5", "method": "\u57fa\u4e8e\u8d1d\u53f6\u65af\u4e3b\u4e49\u548c\u8bc1\u4f2a\u539f\u5219\u7684\u65b0\u79d1\u5b66\u65b9\u6cd5\uff0cAI\u8f85\u52a9\u751f\u6210\u7ade\u4e89\u6027\u5730\u8d28\u5047\u8bf4\u5e76\u4f18\u5316\u6570\u636e\u91c7\u96c6\u51b3\u7b56", "result": "\u5f00\u53d1\u4e86\u5b9e\u7528\u7684\u52d8\u63a2\u534f\u8bae\u6a21\u677f\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6307\u5bfc\u6570\u636e\u91c7\u96c6\u987a\u5e8f", "conclusion": "AI\u9a71\u52a8\u7684\u79d1\u5b66\u65b9\u6cd5\u6709\u671b\u964d\u4f4e\u52d8\u63a2\u6210\u672c\uff0c\u63d0\u9ad8\u53d1\u73b0\u6548\u7387"}}
