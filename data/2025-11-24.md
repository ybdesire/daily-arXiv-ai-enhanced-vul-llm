<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 6]
- [cs.CE](#cs.CE) [Total: 3]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.SE](#cs.SE) [Total: 10]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models](https://arxiv.org/abs/2511.16716)
*Maurizio Atzori,Eleonora Calò,Loredana Caruccio,Stefano Cirillo,Giuseppe Polese,Giandomenico Solimando*

Main category: cs.CR

TL;DR: 本文介绍了SODA ADVANCE工具，用于改进密码强度评估，并研究了LLMs在密码生成和评估中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有密码评估方法不足，用户倾向于使用易记但脆弱的密码，导致安全风险增加。

Method: 开发SODA ADVANCE工具，集成多源公开数据评估密码强度；测试LLMs在密码生成和评估中的表现，涉及100名真实用户的实验。

Result: 实验显示LLMs能生成强且个性化的密码，并在考虑用户资料时有效评估密码强度。

Conclusion: LLMs在密码安全领域具有潜力，SODA ADVANCE工具有助于提升密码评估的准确性。

Abstract: Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.

</details>


### [2] [Membership Inference Attacks Beyond Overfitting](https://arxiv.org/abs/2511.16792)
*Mona Khalil,Alberto Blanco-Justicia,Najeeb Jebreel,Josep Domingo-Ferrer*

Main category: cs.CR

TL;DR: This paper investigates membership inference attacks (MIAs) beyond overfitting, finding that outliers in training data are vulnerable even in generalized models, and proposes targeted defenses to protect these samples.


<details>
  <summary>Details</summary>
Motivation: To understand root causes of MIA vulnerabilities in non-overfitted ML models and develop effective defenses without sacrificing accuracy like differential privacy often does.

Method: Empirical analysis of training data characteristics vulnerable to MIAs in models that can generalize well, focusing on identifying outlier samples.

Result: Found that vulnerable samples are typically outliers within their classes (noisy or hard-to-classify data points) rather than just overfitted samples.

Conclusion: Targeted defensive strategies can protect vulnerable outlier training samples to enhance ML model privacy without the significant accuracy costs of broader defenses like differential privacy.

Abstract: Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.

</details>


### [3] [TICAL: Trusted and Integrity-protected Compilation of AppLications](https://arxiv.org/abs/2511.17070)
*Robert Krahn,Nikson Kanti Paul,Franz Gregor,Do Le Quoc,Andrey Brito,André Martin,Christof Fetzer*

Main category: cs.CR

TL;DR: Tical是一个实用的可信编译框架，在整个构建流水线中（从源代码到最终可执行文件）提供完整性保护和保密性，解决构建时保护常被忽视的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管现有硬件扩展（如Intel SGX、TDX、AMD SEV等）为不可信环境中的应用程序提供了运行时保密性和完整性保护，但构建时的保护和机密性常被忽视，恶意注入的代码可能在编译时破坏整个系统和应用。

Method: 利用可信执行环境（TEEs）作为运行时保护，并通过文件系统屏蔽和带有版本历史的不可变审计日志增强TEEs，确保编译链只能访问可信文件和可信进程生成的中间输出。

Result: 使用微基准和宏基准进行的评估表明，Tical能以可接受的性能开销保护整个CI/CD流水线的保密性和完整性。

Conclusion: Tical是一个实用的可信编译框架，填补了构建时保护的空缺，并通过增强的TEE机制实现了构建流水线的端到端安全保障。

Abstract: During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system.In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.

</details>


### [4] [Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows](https://arxiv.org/abs/2511.17118)
*Leo Kao*

Main category: cs.CR

TL;DR: This paper proposes constant-size cryptographic evidence structures for verifiable audit trails in regulated AI workflows, providing fixed-size tuples that ensure integrity, efficient storage/verification, and compatibility with hash-chains and Merkle trees.


<details>
  <summary>Details</summary>
Motivation: Need for cryptographic verification of AI workflow events in regulated environments (e.g., clinical trials) where audit integrity and non-repudiation are critical, inspired by industrial experience at Codebat Technologies.

Method: Formalizes regulated AI workflows, defines evidence structure syntax/algorithms, and presents a hash-and-sign construction using collision-resistant hash functions and digital signatures. Integrates with hash-chains, Merkle trees, and trusted execution environments.

Result: Achieves constant-size storage and uniform verification cost per event. Prototype implementation shows small, predictable per-event overhead on commodity hardware.

Conclusion: The constant-size evidence abstraction enables practical, verifiable audit trails for regulated AI systems, with applications in clinical trial management and medical AI governance.

Abstract: This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.

</details>


### [5] [A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control](https://arxiv.org/abs/2511.17464)
*Tanzim Hossain Romel,Kawshik Kumar Paul,Tanberul Islam Ruhan,Maisha Rahman Mim,Abu Sayed Md. Latiful Hoque*

Main category: cs.CR

TL;DR: 提出了基于区块链的患者中心化电子健康记录共享架构，实现存储与授权分离，保证安全性的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统电子健康记录系统患者数据控制权弱、隐私保护不足的问题，同时满足医疗数据的安全合规要求。

Method: 采用链下存储加密FHIR资源，链上记录加密承诺和时限权限；使用公钥包装分发密钥，Solidity智能合约实现。

Result: 权限授予平均gas成本78000（L1），1MB记录端到端访问延迟0.7-1.4秒；Layer-2部署可降低gas消耗10-13倍。

Conclusion: 该架构在保持临床数据安全性的同时有效恢复患者控制权，为HIPAA/GDPR合规提供了可行路径。

Abstract: We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.

</details>


### [6] [Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models](https://arxiv.org/abs/2511.17194)
*Zhiyuan Xu,Stanislav Abaimov,Joseph Gardiner,Sana Belguith*

Main category: cs.CR

TL;DR: 研究发现LLM中间激活层存在安全漏洞，提出了敏感性缩放导向(SSS)攻击方法，能在不影响模型基本能力的情况下控制LLM行为。


<details>
  <summary>Details</summary>
Motivation: 当前LLM安全主要关注数据、提示和拒绝策略，但忽略了前向传播过程中的中间激活层可能成为攻击面。

Method: 基于注意力汇聚和压缩谷理论，识别残差流中的高增益区域，提出SSS攻击方法，结合BOS锚定和敏感性强化技术。

Result: 在多款开源模型和四个行为维度上测试，SSS能有效诱导恶意行为、幻觉、奉承和情感偏见的显著变化。

Conclusion: 激活导向成为LLM白盒和供应链部署中的实际安全威胁，需要新的防御措施。

Abstract: Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [7] [Multivariate Sensitivity Analysis of Electric Machine Efficiency Maps and Profiles Under Design Uncertainty](https://arxiv.org/abs/2511.17099)
*Aylar Partovizadeh,Sebastian Schöps,Dimitrios Loukrezis*

Main category: cs.CE

TL;DR: Proposes multivariate global sensitivity analysis for electric machine design, providing holistic parameter importance assessments over efficiency maps, with model simplification applications.


<details>
  <summary>Details</summary>
Motivation: Common variance-based sensitivity analysis approaches evaluate parameters elementwise, lacking a holistic view of parameter importance across entire efficiency maps/profiles.

Method: Uses multivariate global sensitivity analysis with Monte Carlo sampling and polynomial chaos expansions on permanent magnet synchronous machine models of varying fidelity.

Result: Multivariate analysis provides single sensitivity indices per parameter, enabling effective model simplification by fixing non-influential parameters while maintaining accurate uncertainty estimates.

Conclusion: Multivariate sensitivity analysis is valid for holistic parameter importance assessment and effective model simplification in electric machine design, with reduced models maintaining accuracy comparable to full models.

Abstract: This work proposes the use of multivariate global sensitivity analysis for assessing the impact of uncertain electric machine design parameters on efficiency maps and profiles. Contrary to the common approach of applying variance-based (Sobol') sensitivity analysis elementwise, multivariate sensitivity analysis provides a single sensitivity index per parameter, thus allowing for a holistic estimation of parameter importance over the full efficiency map or profile. Its benefits are demonstrated on permanent magnet synchronous machine models of different fidelity. Computations based on Monte Carlo sampling and polynomial chaos expansions are compared in terms of computational cost. The sensitivity analysis results are subsequently used to simplify the models, by fixing non-influential parameters to their nominal values and allowing random variations only for influential parameters. Uncertainty estimates obtained with the full and reduced models confirm the validity of model simplification guided by multivariate sensitivity analysis.

</details>


### [8] [Towards Generative Design Using Optimal Transport for Shape Exploration and Solution Field Interpolation](https://arxiv.org/abs/2511.17111)
*Sergio Torregrosa,David Munoz,Hector Navarro,Charbel Farhat,Francisco Chinesta*

Main category: cs.CE

TL;DR: 提出基于最优传输的统一生成设计框架，能够处理非匹配网格和大幅几何变化，解决了现有方法的泛化性、计算复杂度和多物理场建模局限性。


<details>
  <summary>Details</summary>
Motivation: 当前生成设计方法面临三大挑战：AI方法需要大数据且泛化性差；拓扑优化计算量大且难以扩展到多物理场问题；几何演化的模型降阶方法不成熟。

Method: 基于最优传输理论构建结构保持框架，结合高斯点渲染提供连续网格无关表示，利用Wasserstein质心实现几何平滑混合。

Result: 测试案例显示该框架能高效插值任意形状演化几何中的标量场，保持物理特征的空间分布，无需相同网格拓扑或维度。

Conclusion: 该框架为未来基础模型驱动的生成设计工作流程奠定了基础，在效率、适应性和物理保真度方面展现出显著优势。

Abstract: Generative Design (GD) combines artificial intelligence (AI), physics-based modeling, and multi-objective optimization to autonomously explore and refine engineering designs. Despite its promise in aerospace, automotive, and other high-performance applications, current GD methods face critical challenges: AI approaches require large datasets and often struggle to generalize; topology optimization is computationally intensive and difficult to extend to multiphysics problems; and model order reduction for evolving geometries remains underdeveloped. To address these challenges, we introduce a unified, structure-preserving framework for GD based on optimal transport (OT), enabling simultaneous interpolation of complex geometries and their associated physical solution fields across evolving design spaces, even with non-matching meshes and substantial shape changes. This capability leverages Gaussian splatting to provide a continuous, mesh-independent representation of the solution and Wasserstein barycenters to enable smooth, mathematically ''mass''-preserving blending of geometries, offering a major advance over surrogate models tied to static meshes. Our framework efficiently interpolates positive scalar fields across arbitrarily shaped, evolving geometries without requiring identical mesh topology or dimensionality. OT also naturally preserves localized physical features -- such as stress concentrations or sharp gradients -- by conserving the spatial distribution of quantities, interpreted as ''mass'' in a mathematical sense, rather than averaging them, avoiding artificial smoothing. Preliminary extensions to signed and vector fields are presented. Representative test cases demonstrate enhanced efficiency, adaptability, and physical fidelity, establishing a foundation for future foundation-model-powered generative design workflows.

</details>


### [9] [Randomness as Reference: Benchmark Metric for Optimization in Engineering](https://arxiv.org/abs/2511.17226)
*Stefan Ivić,Siniša Družeta,Luka Grbčić*

Main category: cs.CE

TL;DR: 本文提出了一个新的包含231个优化问题的基准测试集和性能度量方法，用于更准确地评估优化算法在工程问题上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的优化算法基准测试集与真实工程问题的多样性和复杂性对应有限，需要更贴近实际的评估平台。

Method: 构建了基于工程设计和仿真场景的测试集，引入使用随机采样作为统计参考的新性能度量，对20种优化方法进行了系统评估。

Result: 少数优化方法表现优异，而一些常用元启发式算法在工程类问题上效率严重下降，凸显了传统基准的局限性。

Conclusion: 提出的测试集和度量方法为优化算法的评估提供了透明、可复制且实用的平台，缩小了基准测试与工程应用之间的差距。

Abstract: Benchmarking optimization algorithms is fundamental for the advancement of computational intelligence. However, widely adopted artificial test suites exhibit limited correspondence with the diversity and complexity of real-world engineering optimization tasks. This paper presents a new benchmark suite comprising 231 bounded, continuous, unconstrained optimization problems, the majority derived from engineering design and simulation scenarios, including computational fluid dynamics and finite element analysis models. In conjunction with this suite, a novel performance metric is introduced, which employs random sampling as a statistical reference, providing nonlinear normalization of objective values and enabling unbiased comparison of algorithmic efficiency across heterogeneous problems. Using this framework, 20 deterministic and stochastic optimization methods were systematically evaluated through hundreds of independent runs per problem, ensuring statistical robustness. The results indicate that only a few of the tested optimization methods consistently achieve excellent performance, while several commonly used metaheuristics exhibit severe efficiency loss on engineering-type problems, emphasizing the limitations of conventional benchmarks. Furthermore, the conducted tests are used for analyzing various features of the optimization methods, providing practical guidelines for their application. The proposed test suite and metric together offer a transparent, reproducible, and practically relevant platform for evaluating and comparing optimization methods, thereby narrowing the gap between the available benchmark tests and realistic engineering applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [10] [Stable diffusion models reveal a persisting human and AI gap in visual creativity](https://arxiv.org/abs/2511.16814)
*Silvia Rondini,Claudia Alvarez-Martin,Paula Angermair-Barkai,Olivier Penacchio,M. Paz,Matthew Pelowski,Dan Dediu,Antoni Rodriguez-Fornells,Xim Cerda-Company*

Main category: cs.AI

TL;DR: Study compares visual creativity between humans (artists/non-artists) and AI image generation under different prompting conditions, finding humans superior with a creativity gradient from artists to AI, and different rating patterns between human and AI evaluators.


<details>
  <summary>Details</summary>
Motivation: Visual creativity remains underexplored compared to language creativity, despite research showing LLMs match humans in divergent thinking tasks.

Method: Compared image generation from human participants (Visual Artists and Non-Artists) and AI (with high human input/Human Inspired vs low input/Self Guided prompting), evaluated by human raters (N=255) and GPT4o.

Result: Clear creativity gradient: Visual Artists > Non-Artists > Human Inspired AI > Self Guided AI. Human guidance strongly improved AI creativity. Human and AI raters showed different judgment patterns.

Conclusion: GenAI faces unique challenges in visual creativity domains where perceptual nuance and contextual sensitivity - distinctly human capacities - are crucial, unlike language-centered tasks.

Abstract: While recent research suggests Large Language Models match human creative performance in divergent thinking tasks, visual creativity remains underexplored. This study compared image generation in human participants (Visual Artists and Non Artists) and using an image generation AI model (two prompting conditions with varying human input: high for Human Inspired, low for Self Guided). Human raters (N=255) and GPT4o evaluated the creativity of the resulting images. We found a clear creativity gradient, with Visual Artists being the most creative, followed by Non Artists, then Human Inspired generative AI, and finally Self Guided generative AI. Increased human guidance strongly improved GenAI's creative output, bringing its productions close to those of Non Artists. Notably, human and AI raters also showed vastly different creativity judgment patterns. These results suggest that, in contrast to language centered tasks, GenAI models may face unique challenges in visual domains, where creativity depends on perceptual nuance and contextual sensitivity, distinctly human capacities that may not be readily transferable from language models.

</details>


### [11] [Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs](https://arxiv.org/abs/2511.16837)
*Oliver Kramer*

Main category: cs.AI

TL;DR: 研究人员开发了一种名为Cognitive BASIC的简约提示语言和模型内解释器，将大语言模型的推理结构化为明确的逐步执行轨迹


<details>
  <summary>Details</summary>
Motivation: 受到复古BASIC简单性的启发，旨在为LLM创建一个可解释的认知控制层，实现透明的多步推理

Method: 利用编号行和简单命令作为认知控制层，通过自然语言解释器文件指定命令语义、内存更新和日志行为

Result: 在三个LLM的基准测试中，所有模型都能执行Cognitive BASIC程序，整体表现出强劲但非均匀的性能

Conclusion: Cognitive BASIC成功地将LLM推理结构化，实现了透明的多步推理，但不同模型间存在性能差异

Abstract: Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.

</details>


### [12] [Fantastic Bugs and Where to Find Them in AI Benchmarks](https://arxiv.org/abs/2511.16842)
*Sang Truong,Yuheng Tu,Michael Hardy,Anka Reuel,Zeyu Tang,Jirayu Burapacheep,Jonathan Perera,Chibuike Uwakwe,Ben Domingue,Nick Haber,Sanmi Koyejo*

Main category: cs.AI

TL;DR: 提出了一个利用统计分析自动识别基准测试中无效问题的框架，通过响应模式分析标记潜在问题题目供专家审核，在九个基准测试中达到84%的精确度，并引入LLM-judge初步审核以减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 基准测试对AI发展至关重要，但无效问题会削弱其可靠性。手动检查成千上万个问题不可行，成为可靠评估的关键瓶颈。

Method: 基于AI评估中常用的核心假设（平均分足够概括模型性能），通过统计分析响应模式，当题目的统计值超出预期范围时标记为潜在问题题目。

Result: 在九个广泛使用的基准测试中，该方法指导专家审核识别问题题目的精确度高达84%。LLM-judge初步审核进一步减少了人工工作量。

Conclusion: 该框架为系统化基准测试修订提供了高效且可扩展的解决方案，结合统计分析与专家审核，显著提升了基准测试的可靠性。

Abstract: Benchmarks are pivotal in driving AI progress, and invalid benchmark questions frequently undermine their reliability. Manually identifying and correcting errors among thousands of benchmark questions is not only infeasible but also a critical bottleneck for reliable evaluation. In this work, we introduce a framework for systematic benchmark revision that leverages statistical analysis of response patterns to flag potentially invalid questions for further expert review. Our approach builds on a core assumption commonly used in AI evaluations that the mean score sufficiently summarizes model performance. This implies a unidimensional latent construct underlying the measurement experiment, yielding expected ranges for various statistics for each item. When empirically estimated values for these statistics fall outside the expected range for an item, the item is more likely to be problematic. Across nine widely used benchmarks, our method guides expert review to identify problematic questions with up to 84\% precision. In addition, we introduce an LLM-judge first pass to review questions, further reducing human effort. Together, these components provide an efficient and scalable framework for systematic benchmark revision.

</details>


### [13] [Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving](https://arxiv.org/abs/2511.16916)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: Proposes a Hybrid Differential Reward (HDR) mechanism to address vanishing reward differences in multi-vehicle control, combining temporal and action-based rewards to improve policy learning.


<details>
  <summary>Details</summary>
Motivation: Traditional state-based rewards in multi-agent driving tasks suffer from low signal-to-noise ratios due to temporal quasi-steady states and action proximity, hindering convergence.

Method: HDR integrates Temporal Difference Reward (based on global potential function) and Action Gradient Reward (measuring action utility) within a Multi-Agent POMDP framework.

Result: Experiments with MCTS, QMIX, MAPPO, and MADDPG show HDR significantly improves convergence speed, stability, and policy quality in cooperative driving.

Conclusion: HDR effectively balances traffic efficiency and safety by providing high-SNR guidance, overcoming limitations of traditional reward structures.

Abstract: In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.

</details>


### [14] [Comparing verbal, visual and combined explanations for Bayesian Network inferences](https://arxiv.org/abs/2511.16961)
*Erik P. Nyberg,Steven Mascaro,Ingrid Zukerman,Michael Wybrow,Duc-Minh Vo,Ann Nicholson*

Main category: cs.AI

TL;DR: Study comparing verbal, visual, and combined UI extensions for Bayesian Networks, showing improved user performance over baseline for understanding probabilistic reasoning.


<details>
  <summary>Details</summary>
Motivation: Bayesian Networks are considered transparent but users struggle to understand them; current UIs do not sufficiently clarify the reasoning process.

Method: Designed verbal and visual UI extensions to guide users through inference patterns, conducted a user study comparing these extensions against a baseline UI.

Result: Users performed better with all extension types than baseline for questions about observation impact, enabling paths, and influence of observations; combined modality was best for some tasks.

Conclusion: UI extensions, especially combining verbal and visual modalities, can significantly improve user comprehension of Bayesian Network reasoning.

Abstract: Bayesian Networks (BNs) are an important tool for assisting probabilistic reasoning, but despite being considered transparent models, people have trouble understanding them. Further, current User Interfaces (UIs) still do not clarify the reasoning of BNs. To address this problem, we have designed verbal and visual extensions to the standard BN UI, which can guide users through common inference patterns.
  We conducted a user study to compare our verbal, visual and combined UI extensions, and a baseline UI. Our main findings are: (1) users did better with all three types of extensions than with the baseline UI for questions about the impact of an observation, the paths that enable this impact, and the way in which an observation influences the impact of other observations; and (2) using verbal and visual modalities together is better than using either modality alone for some of these question types.

</details>


### [15] [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://arxiv.org/abs/2511.17006)
*Tengxiao Liu,Zifeng Wang,Jin Miao,I-Hung Hsu,Jun Yan,Jiefeng Chen,Rujun Han,Fangyuan Xu,Yanfei Chen,Ke Jiang,Samira Daruki,Yi Liang,William Yang Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.AI

TL;DR: 论文提出预算感知方法提升工具增强智能体的扩展性能，通过Budget Tracker和BATS框架实现动态规划，统一成本度量分析成本-性能关系。


<details>
  <summary>Details</summary>
Motivation: 当前工具增强智能体在增加工具调用预算时缺乏预算意识，导致性能提升有限，需要系统方法解决预算约束下的有效扩展问题。

Method: 引入轻量级Budget Tracker插件提供持续预算感知，开发BATS框架动态调整规划和验证策略，统一化token和工具调用的成本度量。

Result: 预算感知方法产生更优的扩展曲线，提升成本-性能帕累托前沿，在受控实验中验证了有效性。

Conclusion: 预算感知是实现工具增强智能体透明和原则性扩展的关键，为后续研究提供实证基础。

Abstract: Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only "thinking" in tokens but also "acting" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack "budget awareness" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to "dig deeper" on a promising lead or "pivot" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.

</details>


### [16] [DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing](https://arxiv.org/abs/2511.17038)
*Hao Chen,Renzheng Zhang,Scott S. Howard*

Main category: cs.AI

TL;DR: 论文提出了DAPS++方法，重新解释扩散模型在逆问题求解中的角色，将其作为期望最大化框架的初始化阶段，实现了更高的计算效率和鲁棒的重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于贝叶斯视角的得分扩散方法在实践中存在局限性：先验提供的引导有限，重建主要由测量一致性项驱动，与扩散动力学有效解耦。需要更清晰地解释这一结构。

Method: 将扩散重新解释为期望最大化（EM）框架中的初始化阶段，使扩散阶段和数据驱动细化完全解耦。提出的DAPS++方法允许似然项更直接地指导推理，同时保持数值稳定性。

Result: DAPS++通过减少函数评估次数和测量优化步骤，在多种图像复原任务中实现了高计算效率和鲁棒的重建性能。

Conclusion: DAPS++方法提供了对统一扩散轨迹在实践中保持有效的理论解释，并为逆问题求解提供了更高效稳定的解决方案。

Abstract: From a Bayesian perspective, score-based diffusion solves inverse problems through joint inference, embedding the likelihood with the prior to guide the sampling process. However, this formulation fails to explain its practical behavior: the prior offers limited guidance, while reconstruction is largely driven by the measurement-consistency term, leading to an inference process that is effectively decoupled from the diffusion dynamics. To clarify this structure, we reinterpret the role of diffusion in inverse problem solving as an initialization stage within an expectation--maximization (EM)--style framework, where the diffusion stage and the data-driven refinement are fully decoupled. We introduce \textbf{DAPS++}, which allows the likelihood term to guide inference more directly while maintaining numerical stability and providing insight into why unified diffusion trajectories remain effective in practice. By requiring fewer function evaluations (NFEs) and measurement-optimization steps, \textbf{DAPS++} achieves high computational efficiency and robust reconstruction performance across diverse image restoration tasks.

</details>


### [17] [Patient-level Information Extraction by Consistent Integration of Textual and Tabular Evidence with Bayesian Networks](https://arxiv.org/abs/2511.17056)
*Paloma Rabaey,Adrick Tench,Stefan Heytens,Thomas Demeester*

Main category: cs.AI

TL;DR: A multi-modal approach combining structured EHR data (via Bayesian network) and unstructured clinical notes (via neural classifiers) for patient-level information extraction, enhanced with virtual evidence and consistency nodes for better prediction calibration.


<details>
  <summary>Details</summary>
Motivation: EHRs contain valuable but fragmented information across structured (diagnosis codes, medications) and unstructured (clinical notes) formats, requiring effective fusion methods for reliable clinical decision support systems.

Method: Proposes a probabilistic fusion method using: 1) Expert-informed Bayesian network for tabular EHR features 2) Neural text classifiers for clinical notes 3) Virtual evidence augmented with consistency nodes to handle missing information and resolve contradictions

Result: The method improves prediction calibration compared to using virtual evidence alone, effectively handling data inconsistencies between structured and unstructured sources on the SimSUM benchmark dataset.

Conclusion: The proposed multi-modal fusion approach provides an interpretable framework that leverages both structured and unstructured EHR data while addressing challenges like missing information and contradictory evidence through probabilistic consistency modeling.

Abstract: Electronic health records (EHRs) form an invaluable resource for training clinical decision support systems. To leverage the potential of such systems in high-risk applications, we need large, structured tabular datasets on which we can build transparent feature-based models. While part of the EHR already contains structured information (e.g. diagnosis codes, medications, and lab results), much of the information is contained within unstructured text (e.g. discharge summaries and nursing notes). In this work, we propose a method for multi-modal patient-level information extraction that leverages both the tabular features available in the patient's EHR (using an expert-informed Bayesian network) as well as clinical notes describing the patient's symptoms (using neural text classifiers). We propose the use of virtual evidence augmented with a consistency node to provide an interpretable, probabilistic fusion of the models' predictions. The consistency node improves the calibration of the final predictions compared to virtual evidence alone, allowing the Bayesian network to better adjust the neural classifier's output to handle missing information and resolve contradictions between the tabular and text data. We show the potential of our method on the SimSUM dataset, a simulated benchmark linking tabular EHRs with clinical notes through expert knowledge.

</details>


### [18] [The Belief-Desire-Intention Ontology for modelling mental reality and agency](https://arxiv.org/abs/2511.17162)
*Sara Zuppiroli,Carmelo Fabio Longo,Anna Sofia Lippolis,Rocco Paolillo,Lorenzo Giammei,Miguel Ceriani,Francesco Poggi,Antonio Zinilli,Andrea Giovanni Nuzzolese*

Main category: cs.AI

TL;DR: This paper introduces a formal BDI Ontology as a modular pattern to represent agent cognition, with experiments showing its integration with LLMs via Logic Augmented Generation and the Semas reasoning platform.


<details>
  <summary>Details</summary>
Motivation: To address the limited integration of the BDI model into semantically interoperable knowledge representations, creating a bridge between declarative and procedural intelligence.

Method: Development of a modular BDI Ontology aligned with foundational ontologies, tested through LLM integration via Logic Augmented Generation and implementation in the Semas platform using the T2B2T paradigm.

Result: The ontology enables bidirectional flow between RDF triples and agent mental states, enhancing inferential coherence and consistency in neuro-symbolic systems.

Conclusion: The BDI Ontology serves as both conceptual and operational framework for explainable, semantically interoperable multi-agent systems within the Web of Data.

Abstract: The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.

</details>


### [19] [MIR: Efficient Exploration in Episodic Multi-Agent Reinforcement Learning via Mutual Intrinsic Reward](https://arxiv.org/abs/2511.17165)
*Kesheng Chen,Wenjian Luo,Bang Zhang,Zeping Yin,Zipeng Ye*

Main category: cs.AI

TL;DR: MIR introduces mutual intrinsic rewards for multi-agent reinforcement learning to address sparse episodic rewards by encouraging agents to explore actions that influence teammates, validated through MiniGrid-MA environment.


<details>
  <summary>Details</summary>
Motivation: Episodic rewards pose challenges in MARL due to exponential sparsity of joint action trajectories and inadequate consideration of team-influencing actions in existing methods.

Method: Proposes Mutual Intrinsic Reward (MIR) strategy enhancement where agents are incentivized to explore actions affecting teammates, combined with original strategies for team exploration.

Result: Experimental validation in extended MiniGrid-MA environments shows MIR outperforms state-of-the-art approaches in scenarios with extremely sparse rewards.

Conclusion: MIR effectively addresses sparse reward challenges in MARL by promoting team-oriented exploration, demonstrating superior performance in experimental comparisons.

Abstract: Episodic rewards present a significant challenge in reinforcement learning. While intrinsic reward methods have demonstrated effectiveness in single-agent rein-forcement learning scenarios, their application to multi-agent reinforcement learn-ing (MARL) remains problematic. The primary difficulties stem from two fac-tors: (1) the exponential sparsity of joint action trajectories that lead to rewards as the exploration space expands, and (2) existing methods often fail to account for joint actions that can influence team states. To address these challenges, this paper introduces Mutual Intrinsic Reward (MIR), a simple yet effective enhancement strategy for MARL with extremely sparse rewards like episodic rewards. MIR incentivizes individual agents to explore actions that affect their teammates, and when combined with original strategies, effectively stimulates team exploration and improves algorithm performance. For comprehensive experimental valida-tion, we extend the representative single-agent MiniGrid environment to create MiniGrid-MA, a series of MARL environments with sparse rewards. Our evalu-ation compares the proposed method against state-of-the-art approaches in the MiniGrid-MA setting, with experimental results demonstrating superior perfor-mance.

</details>


### [20] [Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism](https://arxiv.org/abs/2511.17198)
*Kaiyu Li,Jiayu Wang,Zhi Wang,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.AI

TL;DR: EarthAgent框架通过分层任务抽象机制将多智能体系统结构化，专门用于复杂地理空间分析，解决了通用LLM智能体在专业领域中无法处理结构化工作流程的问题。


<details>
  <summary>Details</summary>
Motivation: 通用LLM智能体在需要严格结构化工作流程的专业领域表现不佳，特别是在需要专用工具和多步骤程序的领域如遥感。为解决这一差距，需要一种新的智能体设计框架。

Method: 提出了分层任务抽象机制，将多智能体系统构建为反映领域固有任务依赖关系的逻辑层次结构，确保程序正确性并将复杂问题分解为顺序层级。框架实例化为EarthAgent系统。

Result: 构建了GeoPlan-bench基准测试进行评估，实验表明EarthAgent在工具选择、路径相似性和逻辑完整性方面显著优于现有的单智能体和多智能体系统。

Conclusion: 将智能体架构与领域固有任务结构对齐是构建鲁棒可靠专用自治系统的关键步骤。

Abstract: LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.

</details>


### [21] [That's not natural: The Impact of Off-Policy Training Data on Probe Performance](https://arxiv.org/abs/2511.17408)
*Nathalie Kirch,Samuel Dower,Adrians Skapars,Ekdeep Singh Lubana,Dmitrii Krasheninnikov*

Main category: cs.AI

TL;DR: 本文系统评估了在大型语言模型监控中，使用合成或非策略数据训练探测器的泛化能力，发现数据生成策略和领域偏移显著影响探测器性能。


<details>
  <summary>Details</summary>
Motivation: 自然行为样本稀缺，研究者被迫依赖合成或非策略数据训练探测器，但这类数据对探测器泛化能力的影响尚不明确。

Method: 在八种LLM行为上测试线性和注意力探测器，比较不同响应生成策略（合成、非策略、同领域、不同领域）对探测器性能的影响。

Result: 非策略数据泛化到目标行为测试集的能力可预测其策略内泛化成功率；领域偏移导致的性能下降比策略差异更严重。

Conclusion: 缺乏策略内数据时，使用同领域非策略数据比不同领域策略内数据更可靠；需开发更好处理分布偏移的LLM监控方法。

Abstract: Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.

</details>


### [22] [SRA-CP: Spontaneous Risk-Aware Selective Cooperative Perception](https://arxiv.org/abs/2511.17461)
*Jiaxi Liu,Chengyuan Ma,Hang Zhou,Weizhe Tang,Shixiao Liang,Haoyang Ding,Xiaopeng Li,Bin Ran*

Main category: cs.AI

TL;DR: 本文提出了一种自发的风险感知选择性协同感知框架SRA-CP，通过轻量级盲区检测和按需信息交换，在保持感知精度的同时大幅降低了通信带宽需求。


<details>
  <summary>Details</summary>
Motivation: 现有协同感知方法需要传输大量与驾驶安全无关的数据，且依赖预定义的通信伙伴，无法适应动态交通环境。

Method: 采用分布式协议，车辆持续广播轻量级感知覆盖摘要，只在检测到风险相关盲区时触发有针对性的合作。通过风险识别模块评估遮挡影响，选择性进行信息交换。

Result: 在公开数据集上的测试表明，SRA-CP相比通用CP方法仅产生不到1%的关键安全对象检测精度损失，但通信带宽使用量减少80%。相比无风险感知的选择性CP方法，感知性能提升15%。

Conclusion: SRA-CP框架有效解决了协同感知中的通信效率问题，通过风险感知和选择性合作实现了安全与效率的平衡，适用于动态交通环境。

Abstract: Cooperative perception (CP) offers significant potential to overcome the limitations of single-vehicle sensing by enabling information sharing among connected vehicles (CVs). However, existing generic CP approaches need to transmit large volumes of perception data that are irrelevant to the driving safety, exceeding available communication bandwidth. Moreover, most CP frameworks rely on pre-defined communication partners, making them unsuitable for dynamic traffic environments. This paper proposes a Spontaneous Risk-Aware Selective Cooperative Perception (SRA-CP) framework to address these challenges. SRA-CP introduces a decentralized protocol where connected agents continuously broadcast lightweight perception coverage summaries and initiate targeted cooperation only when risk-relevant blind zones are detected. A perceptual risk identification module enables each CV to locally assess the impact of occlusions on its driving task and determine whether cooperation is necessary. When CP is triggered, the ego vehicle selects appropriate peers based on shared perception coverage and engages in selective information exchange through a fusion module that prioritizes safety-critical content and adapts to bandwidth constraints. We evaluate SRA-CP on a public dataset against several representative baselines. Results show that SRA-CP achieves less than 1% average precision (AP) loss for safety-critical objects compared to generic CP, while using only 20% of the communication bandwidth. Moreover, it improves the perception performance by 15% over existing selective CP methods that do not incorporate risk awareness.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [23] [Multi-Agent Code Verification with Compound Vulnerability Detection](https://arxiv.org/abs/2511.16708)
*Shreshth Rajan*

Main category: cs.SE

TL;DR: 论文介绍了CodeX-Verify多智能体系统，该系统通过四个专用智能体检测不同类型代码缺陷，相比单一智能体可提高检测准确率39.7个百分点，在300个真实补丁上测试达到79.3%准确率且每样本耗时<200ms。


<details>
  <summary>Details</summary>
Motivation: 现有工具仅能捕获65%的代码缺陷且存在35%假阳性，而大语言模型生成的代码存在严重漏洞（SWE-bench中29.6%补丁失效，BaxBench中62%方案含漏洞），亟需更有效的缺陷检测方法。

Method: 构建多智能体系统CodeX-Verify，使用四个专用智能体分别检测不同类型缺陷，通过数学证明不同检测模式的智能体组合能发现更多缺陷（智能体相关性p=0.05-0.25）。

Result: 在99个带标注代码样本上测试显示系统捕获76.1%缺陷，与最佳现有方法持平但运行更快且无需测试执行；多智能体组合比单一智能体准确率提升39.7个百分点（从32.8%至72.4%），最佳双智能体组合达79.3%准确率。

Conclusion: 多智能体方法能显著提升代码缺陷检测效果，同时证明同一代码中存在多个漏洞会产生指数级风险（如SQL注入加凭证泄露风险达300 vs 传统模型预测的20），系统在真实场景下具备实用性（300个补丁测试耗时<200ms/样本）。

Abstract: LLMs generate buggy code: 29.6% of SWE-bench "solved" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.

</details>


### [24] [Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair](https://arxiv.org/abs/2511.16858)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 该论文研究在大型语言模型时代下，程序自动修复中的测试过拟合问题是否依然存在。


<details>
  <summary>Details</summary>
Motivation: 虽然测试过拟合问题在大型语言模型兴起之前已被识别和研究，但需要实验验证这个问题在当前是否仍然显著。

Method: 使用基于仓库级别的SWE-bench任务进行实验研究。

Result: 论文通过实验分析了测试过拟合在当代程序修复中的程度。

Conclusion: 研究表明测试过拟合问题在今天仍然是一个需要关注的重要问题。

Abstract: Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.

</details>


### [25] [MOOT: a Repository of Many Multi-Objective Optimization Tasks](https://arxiv.org/abs/2511.16882)
*Tim Menzies,Tao Chen,Yulong Ye,Kishan Kumar Ganguly,Amirali Rayegan,Srinath Srinivasan,Andre Lustosa*

Main category: cs.SE

TL;DR: MOOT是一个包含120多个软件工程多目标优化任务的仓库，帮助研究者探索软件工程中的权衡决策问题


<details>
  <summary>Details</summary>
Motivation: 软件工程师需要在相互竞争的目标之间做出权衡决策，但缺乏有效的工具来探索这些权衡

Method: 创建MOOT仓库，收集来自近期软件工程研究论文的多目标优化任务，涵盖软件配置、云调优、项目健康等多个领域

Result: 目前已收集120多个任务，在MIT许可下开源，支持多种新颖的研究问题

Conclusion: MOOT仓库为软件工程领域的多目标优化研究提供了宝贵资源，有助于改善软件决策过程

Abstract: Software engineers must make decisions that trade off competing goals (faster vs. cheaper, secure vs. usable, accurate vs. interpretable, etc.). Despite MSR's proven techniques for exploring such goals, researchers still struggle with these trade-offs. Similarly, industrial practitioners deliver sub-optimal products since they lack the tools needed to explore these trade-offs.
  To enable more research in this important area, we introduce MOOT, a repository of multi-objective optimization tasks taken from recent SE research papers. MOOT's tasks cover software configuration, cloud tuning, project health, process modeling, hyperparameter optimization, and more. Located at github.com/timm/moot, MOOT's current 120+ tasks are freely available under an MIT license (and we invite community contributions). As shown here, this data enables dozens of novel research questions.

</details>


### [26] [ReVul-CoT: Towards Effective Software Vulnerability Assessment with Retrieval-Augmented Generation and Chain-of-Thought Prompting](https://arxiv.org/abs/2511.17027)
*Zhijie Chen,Xiang Chen,Ziming Li,Jiacheng Xue,Chaoyang Gao*

Main category: cs.SE

TL;DR: 提出ReVul-CoT框架，结合RAG和CoT提示，解决LLM在软件漏洞评估中缺乏领域知识和浅层推理的问题，在12,070个漏洞数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件漏洞评估中存在两个主要局限：缺乏领域特定知识，以及依赖浅层模式匹配而非深度上下文推理。

Method: ReVul-CoT框架集成检索增强生成和思维链提示。RAG模块从本地知识库动态检索漏洞数据，CoT提示引导LLM逐步推理可利用性、影响范围等因素。

Result: 在12,070个漏洞数据集上，ReVul-CoT在MCC指标上超越最先进基线16.50%-42.26%，在准确率、F1分数和MCC上分别优于最佳基线10.43%、15.86%和16.50%。

Conclusion: 结合RAG与CoT提示能显著提升基于LLM的软件漏洞评估性能，为未来研究指明有前途的方向。

Abstract: Context: Software Vulnerability Assessment (SVA) plays a vital role in evaluating and ranking vulnerabilities in software systems to ensure their security and reliability. Objective: Although Large Language Models (LLMs) have recently shown remarkable potential in SVA, they still face two major limitations. First, most LLMs are trained on general-purpose corpora and thus lack domain-specific knowledge essential for effective SVA. Second, they tend to rely on shallow pattern matching instead of deep contextual reasoning, making it challenging to fully comprehend complex code semantics and their security implications. Method: To alleviate these limitations, we propose a novel framework ReVul-CoT that integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (COT) prompting. In ReVul-CoT, the RAG module dynamically retrieves contextually relevant information from a constructed local knowledge base that consolidates vulnerability data from authoritative sources (such as NVD and CWE), along with corresponding code snippets and descriptive information. Building on DeepSeek-V3.1, CoT prompting guides the LLM to perform step-by-step reasoning over exploitability, impact scope, and related factors Results: We evaluate ReVul-CoT on a dataset of 12,070 vulnerabilities. Experimental results show that ReVul-CoT outperforms state-of-the-art SVA baselines by 16.50%-42.26% in terms of MCC, and outperforms the best baseline by 10.43%, 15.86%, and 16.50% in Accuracy, F1-score, and MCC, respectively. Our ablation studies further validate the contributions of considering dynamic retrieval, knowledge integration, and CoT-based reasoning. Conclusion: Our results demonstrate that combining RAG with CoT prompting significantly enhances LLM-based SVA and points out promising directions for future research.

</details>


### [27] [SlsReuse: LLM-Powered Serverless Function Reuse](https://arxiv.org/abs/2511.17262)
*Jinfeng Wen,Yuehan Sun*

Main category: cs.SE

TL;DR: SlsReuse是基于大语言模型的第一个服务器less函数重用框架，通过构建可重用函数库和使用提示工程学习统一语义表示，实现函数推荐，在ChatGPT-4o上达到91.20%的Recall@10


<details>
  <summary>Details</summary>
Motivation: 服务器less计算虽然减少运营开销，但对新手开发者面临挑战：从头开发函数需要适应异构的平台特定编程风格，过程耗时且易错。现有传统推荐技术因任务描述与异构函数实现间的语义鸿沟而不足。

Method: SlsReuse框架构建可重用函数库作为基础知识库，通过少量提示的有效提示工程学习异构函数的统一语义增强表示，结合意图感知发现、多级剪枝策略和相似性匹配进行函数推荐。

Result: 在110个任务查询的策划数据集上评估，基于ChatGPT-4o的SlsReuse达到91.20%的Recall@10，比最先进基线高出24.53个百分点。

Conclusion: SlsReuse通过LLM有效桥接开发者需求与函数语义间的鸿沟，为服务器less函数重用提供了有效的解决方案，显著提升了函数推荐的准确性。

Abstract: Serverless computing has rapidly emerged as a popular cloud computing paradigm. It enables developers to implement function-level tasks, i.e., serverless functions, without managing infrastructure. While reducing operational overhead, it poses challenges, especially for novice developers. Developing functions from scratch requires adapting to heterogeneous, platform-specific programming styles, making the process time-consuming and error-prone. Function reuse offers a promising solution to address these challenges. However, research on serverless computing lacks a dedicated approach for function recommendation. Existing techniques from traditional contexts remain insufficient due to the semantic gap between task descriptions and heterogeneous function implementations. Advances in large language models (LLMs), pre-trained on large-scale corpora, create opportunities to bridge this gap by aligning developer requirements with function semantics.
  This paper presents SlsReuse, the first LLM-powered framework for serverless function reuse. Specifically, SlsReuse first constructs a reusable function repository serving as a foundational knowledge base. Then, it learns unified semantic-enhanced representations of heterogeneous functions through effective prompt engineering with few-shot prompting, capturing implicit code intent, target platforms, programming languages, and cloud services. Finally, given a natural language task query, SlsReuse performs intent-aware discovery combined with a multi-level pruning strategy and similarity matching. We evaluate SlsReuse on a curated dataset of 110 task queries. Built on ChatGPT-4o, one of the most representative LLMs, SlsReuse achieves Recall@10 of 91.20%, exceeding the state-of-the-art baseline by 24.53 percentage points.

</details>


### [28] [Detecting Performance-Relevant Changes in Configurable Software Systems](https://arxiv.org/abs/2511.17271)
*Sebastian Böhm,Florian Sattler,Norbert Siegmund,Sven Apel*

Main category: cs.SE

TL;DR: ConfFLARE is a method that reduces performance testing costs by identifying performance-relevant code interactions and selecting optimal configuration subsets.


<details>
  <summary>Details</summary>
Motivation: Frequent performance profiling is expensive, especially for configurable systems where testing all configurations is costly.

Method: Identifies data-flow interactions with performance-relevant code and selects configurations based on affected features.

Result: Reduces configurations by 79% (synthetic) and 70% (real-world) while maintaining high regression detection accuracy.

Conclusion: ConfFLARE effectively minimizes performance testing effort while reliably detecting performance regressions.

Abstract: Performance is a volatile property of a software system and frequent performance profiling is required to keep the knowledge about a software system's performance behavior up to date. Repeating all performance measurements after every revision is a cost-intensive task, especially in the presence of configurability, where one has to measure multiple configurations to obtain a comprehensive picture. Configuration sampling is a common approach to control the measurement cost. However, it cannot guarantee completeness and might miss performance regressions, especially if they only affect few configurations. As an alternative to solve the cost reduction problem, we present ConfFLARE: ConfFLARE estimates whether a change potentially impacts performance by identifying data-flow interactions with performance-relevant code and extracts which software features participate in such interactions. Based on these features, we can select a subset of relevant configurations to focus performance profiling efforts on. In a study conducted on both, synthetic and real-world software systems, ConfFLARE correctly detects performance regressions in almost all cases and identifies relevant features in all but two cases, reducing the number of configurations to be tested on average by $79\%$ for synthetic and by $70\%$ for real-world regression scenarios saving hours of performance testing time.

</details>


### [29] [Framework Matters: Energy Efficiency of UI Automation Testing Frameworks](https://arxiv.org/abs/2511.17303)
*Timmie M. R. Lagermann,Kristina Sophia Carter,Su Mei Gwen Ho,Luís Cruz,Kerstin Eder,Maja H. Kirkeby*

Main category: cs.SE

TL;DR: This paper compares energy consumption of four web UI automation testing frameworks (Puppeteer, Selenium, Nightwatch) across different UI actions, finding significant energy variations (up to 6x) between frameworks.


<details>
  <summary>Details</summary>
Motivation: To provide transparency about energy consumption differences between web UI testing frameworks, enabling developers to make energy-aware decisions when selecting frameworks for specific UI actions.

Method: Controlled client-server setup with external power metering, repeating each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times across four frameworks.

Result: Puppeteer was most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium was most efficient for refresh and scroll; Nightwatch was generally least energy efficient.

Conclusion: Significant energy cost variations (up to 6x) exist between frameworks for the same actions, highlighting the importance of energy transparency for informed framework selection in UI testing.

Abstract: We examine per action energy consumption across four web user interface (UI) automation testing frameworks to determine whether consistent tendencies can guide energy-aware test design. Using a controlled client-server setup with external power metering, we repeat each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times. Across each of the actions, energy costs vary by both framework and action. Puppeteer is the most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium is the most efficient for refresh and scroll; Nightwatch is generally the least energy efficient. The energy cost of performing the same action varied by up to a factor of six depending on the framework. This indicates that providing transparency of energy consumption for UI automation testing frameworks allows developers to make informed, energy-aware decisions when testing a specific UI action.

</details>


### [30] [Agentic Program Verification](https://arxiv.org/abs/2511.17330)
*Haoxin Tu,Huan Zhao,Yahui Song,Mehtab Zafar,Ruijie Meng,Abhik Roychoudhury*

Main category: cs.SE

TL;DR: 本文提出了首个用于程序验证的LLM智能体AutoRocq，它通过与Rocq定理证明器的自主协作，实现了无需大量训练样本的迭代式证明生成。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成代码的普及，需要自动化工具来验证这些代码的正确性。现有方法依赖大量训练数据，而本文探索通过即时学习实现程序验证。

Method: AutoRocq通过迭代细化循环与Rocq定理证明器交互，获取上下文反馈，自主构建经证明器验证的推导过程。

Result: 在SV-COMP基准测试和Linux内核模块上的实验表明，该方法在自动化程序验证方面具有良好效果。

Conclusion: 该验证智能体未来可与AI代码生成器集成，形成'生成-验证'循环，推动可信自动编程的发展。

Abstract: Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.
  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.
  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.

</details>


### [31] [Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software](https://arxiv.org/abs/2511.17368)
*Eric L. Melin,Ahmed Musa Awon,Nasir U. Eisty,Neil A. Ernst,Shurui Zhou*

Main category: cs.SE

TL;DR: 这篇论文研究了科学软件中的自认技术债务，发现在科学软件中存在比通用软件高9.25倍的科学债务和4.93倍的SATD，并证明基于transformer的模型在识别SATD方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 科学软件中的自认技术债务对研究结果的准确性和可重现性构成重大威胁，但目前科学软件与SATD之间的关系尚未得到充分探索。

Method: 分析了27个科学和通用软件仓库，在67,066个标注代码注释上微调比较了10个基于transformer的模型。

Result: 科学软件中的SATD显著高于通用软件，最佳模型性能优于现有模型。

Conclusion: 研究揭示了科学软件中SATD的特殊性及其对科学有效性的影响，为开发者管理技术债务提供了重要见解。

Abstract: Developers often leave behind clues in their code, admitting where it falls short, known as Self-Admitted Technical Debt (SATD). In the world of Scientific Software (SSW), where innovation moves fast and collaboration is key, such debt is not just common but deeply impactful. As research relies on accurate and reproducible results, accumulating SATD can threaten the very foundations of scientific discovery. Yet, despite its significance, the relationship between SATD and SSW remains largely unexplored, leaving a crucial gap in understanding how to manage SATD in this critical domain. This study explores SATD in SSW repositories, comparing SATD in scientific versus general-purpose open-source software and evaluating transformer-based models for SATD identification. We analyzed SATD in 27 scientific and general-purpose repositories across multiple domains and languages. We fine-tuned and compared 10 transformer-based models (100M-7B parameters) on 67,066 labeled code comments. SSW contains 9.25x more Scientific Debt and 4.93x more SATD than general-purpose software due to complex computations, domain constraints, and evolving research needs. Furthermore, our best model outperforms existing ones. This study uncovers how SATD in SSW differs from general software, revealing its impact on quality and scientific validity. By recognizing these challenges, developers and researchers can adopt smarter strategies to manage debt and safeguard the integrity of scientific discovery.

</details>


### [32] [CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval](https://arxiv.org/abs/2511.17417)
*Soroush Javdan,Pragash Krishnamoorthy,Olga Baysal*

Main category: cs.SE

TL;DR: 研究提出CREST方法，通过专门化模型处理电信故障报告的不同标准，提升检索效果和可解释性。


<details>
  <summary>Details</summary>
Motivation: 电信行业故障报告数据复杂多样，现有检索系统难以有效处理不同标准的故障信息。

Method: 采用两阶段工作流（初始检索和重排序），为不同TR标准训练专门模型并集成输出。

Result: 在爱立信内部TR数据上验证，CREST在关键评估指标上显著优于单一模型方法。

Conclusion: 针对不同标准使用专门化模型能优化检索系统性能，提高故障解决效率。

Abstract: The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \textbf{CREST} (\textbf{C}riteria-specific \textbf{R}etrieval via \textbf{E}nsemble of \textbf{S}pecialized \textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.

</details>
